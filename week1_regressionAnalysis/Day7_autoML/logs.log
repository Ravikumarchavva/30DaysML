2024-05-24 12:31:27,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:31:27,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:31:27,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:31:27,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:36:15,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:36:15,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:36:15,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:36:15,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:53:48,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:53:48,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:53:48,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 12:53:48,936:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:26:33,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:26:33,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:26:33,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:26:33,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:27:22,901:INFO:PyCaret RegressionExperiment
2024-05-24 14:27:22,902:INFO:Logging name: reg-default-name
2024-05-24 14:27:22,902:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 14:27:22,902:INFO:version 3.3.2
2024-05-24 14:27:22,902:INFO:Initializing setup()
2024-05-24 14:27:22,902:INFO:self.USI: 1a67
2024-05-24 14:27:22,902:INFO:self._variable_keys: {'gpu_param', 'y', 'pipeline', 'seed', '_ml_usecase', 'logging_param', 'data', 'exp_name_log', 'n_jobs_param', 'X_train', 'y_test', 'fold_shuffle_param', 'X_test', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'memory', 'html_param', 'fold_groups_param', 'X', 'transform_target_param', '_available_plots', 'log_plots_param', 'USI', 'exp_id', 'idx', 'y_train'}
2024-05-24 14:27:22,902:INFO:Checking environment
2024-05-24 14:27:22,902:INFO:python_version: 3.10.14
2024-05-24 14:27:22,902:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 14:27:22,902:INFO:machine: AMD64
2024-05-24 14:27:22,902:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 14:27:22,903:INFO:Memory: svmem(total=16541802496, available=5088817152, percent=69.2, used=11452985344, free=5088817152)
2024-05-24 14:27:22,903:INFO:Physical Core: 6
2024-05-24 14:27:22,903:INFO:Logical Core: 12
2024-05-24 14:27:22,903:INFO:Checking libraries
2024-05-24 14:27:22,903:INFO:System:
2024-05-24 14:27:22,903:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 14:27:22,903:INFO:executable: C:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 14:27:22,903:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 14:27:22,903:INFO:PyCaret required dependencies:
2024-05-24 14:27:23,213:INFO:                 pip: 24.0
2024-05-24 14:27:23,213:INFO:          setuptools: 69.5.1
2024-05-24 14:27:23,213:INFO:             pycaret: 3.3.2
2024-05-24 14:27:23,213:INFO:             IPython: 8.20.0
2024-05-24 14:27:23,213:INFO:          ipywidgets: 8.1.2
2024-05-24 14:27:23,213:INFO:                tqdm: 4.66.4
2024-05-24 14:27:23,213:INFO:               numpy: 1.26.4
2024-05-24 14:27:23,213:INFO:              pandas: 2.1.4
2024-05-24 14:27:23,213:INFO:              jinja2: 3.1.3
2024-05-24 14:27:23,213:INFO:               scipy: 1.11.4
2024-05-24 14:27:23,213:INFO:              joblib: 1.3.2
2024-05-24 14:27:23,213:INFO:             sklearn: 1.4.2
2024-05-24 14:27:23,213:INFO:                pyod: 1.1.3
2024-05-24 14:27:23,213:INFO:            imblearn: 0.12.2
2024-05-24 14:27:23,213:INFO:   category_encoders: 2.6.3
2024-05-24 14:27:23,213:INFO:            lightgbm: 4.3.0
2024-05-24 14:27:23,213:INFO:               numba: 0.59.1
2024-05-24 14:27:23,214:INFO:            requests: 2.32.2
2024-05-24 14:27:23,214:INFO:          matplotlib: 3.7.5
2024-05-24 14:27:23,214:INFO:          scikitplot: 0.3.7
2024-05-24 14:27:23,214:INFO:         yellowbrick: 1.5
2024-05-24 14:27:23,214:INFO:              plotly: 5.22.0
2024-05-24 14:27:23,214:INFO:    plotly-resampler: Not installed
2024-05-24 14:27:23,214:INFO:             kaleido: 0.2.1
2024-05-24 14:27:23,214:INFO:           schemdraw: 0.15
2024-05-24 14:27:23,214:INFO:         statsmodels: 0.14.2
2024-05-24 14:27:23,214:INFO:              sktime: 0.26.0
2024-05-24 14:27:23,214:INFO:               tbats: 1.1.3
2024-05-24 14:27:23,214:INFO:            pmdarima: 2.0.4
2024-05-24 14:27:23,214:INFO:              psutil: 5.9.0
2024-05-24 14:27:23,214:INFO:          markupsafe: 2.1.3
2024-05-24 14:27:23,214:INFO:             pickle5: Not installed
2024-05-24 14:27:23,214:INFO:         cloudpickle: 3.0.0
2024-05-24 14:27:23,214:INFO:         deprecation: 2.1.0
2024-05-24 14:27:23,214:INFO:              xxhash: 3.4.1
2024-05-24 14:27:23,214:INFO:           wurlitzer: Not installed
2024-05-24 14:27:23,214:INFO:PyCaret optional dependencies:
2024-05-24 14:27:23,234:INFO:                shap: Not installed
2024-05-24 14:27:23,235:INFO:           interpret: Not installed
2024-05-24 14:27:23,235:INFO:                umap: Not installed
2024-05-24 14:27:23,235:INFO:     ydata_profiling: Not installed
2024-05-24 14:27:23,235:INFO:  explainerdashboard: Not installed
2024-05-24 14:27:23,235:INFO:             autoviz: Not installed
2024-05-24 14:27:23,235:INFO:           fairlearn: Not installed
2024-05-24 14:27:23,235:INFO:          deepchecks: Not installed
2024-05-24 14:27:23,235:INFO:             xgboost: Not installed
2024-05-24 14:27:23,235:INFO:            catboost: Not installed
2024-05-24 14:27:23,235:INFO:              kmodes: Not installed
2024-05-24 14:27:23,235:INFO:             mlxtend: Not installed
2024-05-24 14:27:23,235:INFO:       statsforecast: Not installed
2024-05-24 14:27:23,235:INFO:        tune_sklearn: Not installed
2024-05-24 14:27:23,235:INFO:                 ray: Not installed
2024-05-24 14:27:23,235:INFO:            hyperopt: Not installed
2024-05-24 14:27:23,235:INFO:              optuna: Not installed
2024-05-24 14:27:23,235:INFO:               skopt: Not installed
2024-05-24 14:27:23,235:INFO:              mlflow: Not installed
2024-05-24 14:27:23,235:INFO:              gradio: Not installed
2024-05-24 14:27:23,235:INFO:             fastapi: Not installed
2024-05-24 14:27:23,235:INFO:             uvicorn: Not installed
2024-05-24 14:27:23,235:INFO:              m2cgen: Not installed
2024-05-24 14:27:23,235:INFO:           evidently: Not installed
2024-05-24 14:27:23,236:INFO:               fugue: Not installed
2024-05-24 14:27:23,236:INFO:           streamlit: Not installed
2024-05-24 14:27:23,236:INFO:             prophet: Not installed
2024-05-24 14:27:23,236:INFO:None
2024-05-24 14:27:23,236:INFO:Set up data.
2024-05-24 14:27:23,247:INFO:Set up folding strategy.
2024-05-24 14:27:23,247:INFO:Set up train/test split.
2024-05-24 14:27:23,436:INFO:Set up index.
2024-05-24 14:27:23,436:INFO:Assigning column types.
2024-05-24 14:27:23,442:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 14:27:23,442:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,454:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,595:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,600:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,738:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 14:27:23,746:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,818:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,868:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,872:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:23,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:23,964:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 14:27:23,972:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,103:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,174:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,227:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 14:27:24,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,539:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 14:27:24,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:27:24,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,833:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 14:27:24,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:24,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:25,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:25,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:25,139:INFO:Preparing preprocessing pipeline...
2024-05-24 14:27:25,139:INFO:Set up simple imputation.
2024-05-24 14:27:25,146:INFO:Set up encoding of ordinal features.
2024-05-24 14:27:25,152:INFO:Set up encoding of categorical features.
2024-05-24 14:27:25,387:INFO:Finished creating preprocessing pipeline.
2024-05-24 14:27:25,478:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['car_ID', 'symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('cat...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 14:27:25,478:INFO:Creating final display dataframe.
2024-05-24 14:27:25,993:INFO:Setup _display_container:                     Description             Value
0                    Session id              2057
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 26)
4        Transformed data shape         (205, 48)
5   Transformed train set shape         (143, 48)
6    Transformed test set shape          (62, 48)
7              Numeric features                15
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              1a67
2024-05-24 14:27:26,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:26,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:26,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:26,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:27:26,275:INFO:setup() successfully completed in 3.39s...............
2024-05-24 14:27:36,006:INFO:Initializing compare_models()
2024-05-24 14:27:36,007:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:27:36,007:INFO:Checking exceptions
2024-05-24 14:27:36,010:INFO:Preparing display monitor
2024-05-24 14:27:36,037:INFO:Initializing Linear Regression
2024-05-24 14:27:36,037:INFO:Total runtime is 1.8024444580078124e-05 minutes
2024-05-24 14:27:36,042:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:36,042:INFO:Initializing create_model()
2024-05-24 14:27:36,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:36,043:INFO:Checking exceptions
2024-05-24 14:27:36,043:INFO:Importing libraries
2024-05-24 14:27:36,043:INFO:Copying training dataset
2024-05-24 14:27:36,048:INFO:Defining folds
2024-05-24 14:27:36,049:INFO:Declaring metric variables
2024-05-24 14:27:36,052:INFO:Importing untrained model
2024-05-24 14:27:36,056:INFO:Linear Regression Imported successfully
2024-05-24 14:27:36,063:INFO:Starting cross validation
2024-05-24 14:27:36,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:39,955:INFO:Calculating mean and std
2024-05-24 14:27:39,957:INFO:Creating metrics dataframe
2024-05-24 14:27:39,960:INFO:Uploading results into container
2024-05-24 14:27:39,961:INFO:Uploading model into container now
2024-05-24 14:27:39,962:INFO:_master_model_container: 1
2024-05-24 14:27:39,962:INFO:_display_container: 2
2024-05-24 14:27:39,963:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:27:39,963:INFO:create_model() successfully completed......................................
2024-05-24 14:27:40,091:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:40,091:INFO:Creating metrics dataframe
2024-05-24 14:27:40,099:INFO:Initializing Lasso Regression
2024-05-24 14:27:40,100:INFO:Total runtime is 0.06773680845896403 minutes
2024-05-24 14:27:40,103:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:40,105:INFO:Initializing create_model()
2024-05-24 14:27:40,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:40,105:INFO:Checking exceptions
2024-05-24 14:27:40,105:INFO:Importing libraries
2024-05-24 14:27:40,106:INFO:Copying training dataset
2024-05-24 14:27:40,112:INFO:Defining folds
2024-05-24 14:27:40,112:INFO:Declaring metric variables
2024-05-24 14:27:40,115:INFO:Importing untrained model
2024-05-24 14:27:40,119:INFO:Lasso Regression Imported successfully
2024-05-24 14:27:40,126:INFO:Starting cross validation
2024-05-24 14:27:40,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:40,349:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:27:40,351:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 9.060e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:27:40,365:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e+06, tolerance: 5.930e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:27:42,272:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.231e+06, tolerance: 8.660e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:27:42,290:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.447e+06, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:27:42,360:INFO:Calculating mean and std
2024-05-24 14:27:42,363:INFO:Creating metrics dataframe
2024-05-24 14:27:42,366:INFO:Uploading results into container
2024-05-24 14:27:42,367:INFO:Uploading model into container now
2024-05-24 14:27:42,367:INFO:_master_model_container: 2
2024-05-24 14:27:42,367:INFO:_display_container: 2
2024-05-24 14:27:42,368:INFO:Lasso(random_state=2057)
2024-05-24 14:27:42,368:INFO:create_model() successfully completed......................................
2024-05-24 14:27:42,519:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:42,520:INFO:Creating metrics dataframe
2024-05-24 14:27:42,526:INFO:Initializing Ridge Regression
2024-05-24 14:27:42,526:INFO:Total runtime is 0.10817131996154786 minutes
2024-05-24 14:27:42,531:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:42,531:INFO:Initializing create_model()
2024-05-24 14:27:42,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:42,532:INFO:Checking exceptions
2024-05-24 14:27:42,532:INFO:Importing libraries
2024-05-24 14:27:42,532:INFO:Copying training dataset
2024-05-24 14:27:42,540:INFO:Defining folds
2024-05-24 14:27:42,541:INFO:Declaring metric variables
2024-05-24 14:27:42,545:INFO:Importing untrained model
2024-05-24 14:27:42,549:INFO:Ridge Regression Imported successfully
2024-05-24 14:27:42,565:INFO:Starting cross validation
2024-05-24 14:27:42,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:42,921:INFO:Calculating mean and std
2024-05-24 14:27:42,922:INFO:Creating metrics dataframe
2024-05-24 14:27:42,925:INFO:Uploading results into container
2024-05-24 14:27:42,926:INFO:Uploading model into container now
2024-05-24 14:27:42,926:INFO:_master_model_container: 3
2024-05-24 14:27:42,926:INFO:_display_container: 2
2024-05-24 14:27:42,927:INFO:Ridge(random_state=2057)
2024-05-24 14:27:42,927:INFO:create_model() successfully completed......................................
2024-05-24 14:27:43,074:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:43,074:INFO:Creating metrics dataframe
2024-05-24 14:27:43,083:INFO:Initializing Elastic Net
2024-05-24 14:27:43,083:INFO:Total runtime is 0.1174615502357483 minutes
2024-05-24 14:27:43,087:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:43,088:INFO:Initializing create_model()
2024-05-24 14:27:43,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:43,088:INFO:Checking exceptions
2024-05-24 14:27:43,088:INFO:Importing libraries
2024-05-24 14:27:43,089:INFO:Copying training dataset
2024-05-24 14:27:43,097:INFO:Defining folds
2024-05-24 14:27:43,097:INFO:Declaring metric variables
2024-05-24 14:27:43,101:INFO:Importing untrained model
2024-05-24 14:27:43,107:INFO:Elastic Net Imported successfully
2024-05-24 14:27:43,115:INFO:Starting cross validation
2024-05-24 14:27:43,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:43,496:INFO:Calculating mean and std
2024-05-24 14:27:43,497:INFO:Creating metrics dataframe
2024-05-24 14:27:43,499:INFO:Uploading results into container
2024-05-24 14:27:43,500:INFO:Uploading model into container now
2024-05-24 14:27:43,500:INFO:_master_model_container: 4
2024-05-24 14:27:43,501:INFO:_display_container: 2
2024-05-24 14:27:43,501:INFO:ElasticNet(random_state=2057)
2024-05-24 14:27:43,501:INFO:create_model() successfully completed......................................
2024-05-24 14:27:43,632:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:43,633:INFO:Creating metrics dataframe
2024-05-24 14:27:43,642:INFO:Initializing Least Angle Regression
2024-05-24 14:27:43,642:INFO:Total runtime is 0.12677587270736695 minutes
2024-05-24 14:27:43,646:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:43,646:INFO:Initializing create_model()
2024-05-24 14:27:43,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:43,647:INFO:Checking exceptions
2024-05-24 14:27:43,647:INFO:Importing libraries
2024-05-24 14:27:43,647:INFO:Copying training dataset
2024-05-24 14:27:43,652:INFO:Defining folds
2024-05-24 14:27:43,653:INFO:Declaring metric variables
2024-05-24 14:27:43,657:INFO:Importing untrained model
2024-05-24 14:27:43,661:INFO:Least Angle Regression Imported successfully
2024-05-24 14:27:43,668:INFO:Starting cross validation
2024-05-24 14:27:43,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:43,850:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.665e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,850:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.598e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,851:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.469e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,851:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.713e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,852:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.713e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,852:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.713e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,853:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.544e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,853:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.954e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,853:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.668e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,854:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.668e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,854:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=3.834e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,855:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=3.834e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,858:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.237e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,858:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=8.568e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,859:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.538e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,860:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.650e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,860:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.270e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,861:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.270e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,861:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.201e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,861:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.187e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,861:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.043e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,862:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.101e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,862:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.520e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,862:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.527e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,862:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.142e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,863:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.318e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,863:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.318e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,866:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.838e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,867:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.628e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,867:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.291e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,867:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.851e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,867:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.742e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,868:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.985e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,868:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.094e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,868:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.548e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,868:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.099e+04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,868:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.109e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,886:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.380e+06, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,888:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.204e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,888:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.178e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,889:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.175e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,890:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.692e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,890:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.100e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,890:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.319e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,891:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.984e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,891:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.287e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,892:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.190e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,895:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=9.376e+05, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,905:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.345e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,906:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.069e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,906:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.551e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,906:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.290e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,907:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=5.138e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,907:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=5.038e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,907:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.686e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,907:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.515e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,912:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.030e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,913:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.097e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,915:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.063e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,915:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.995e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,915:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.295e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:43,980:INFO:Calculating mean and std
2024-05-24 14:27:43,981:INFO:Creating metrics dataframe
2024-05-24 14:27:43,983:INFO:Uploading results into container
2024-05-24 14:27:43,983:INFO:Uploading model into container now
2024-05-24 14:27:43,984:INFO:_master_model_container: 5
2024-05-24 14:27:43,984:INFO:_display_container: 2
2024-05-24 14:27:43,984:INFO:Lars(random_state=2057)
2024-05-24 14:27:43,985:INFO:create_model() successfully completed......................................
2024-05-24 14:27:44,104:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:44,104:INFO:Creating metrics dataframe
2024-05-24 14:27:44,113:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:27:44,113:INFO:Total runtime is 0.13462959130605062 minutes
2024-05-24 14:27:44,118:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:44,118:INFO:Initializing create_model()
2024-05-24 14:27:44,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:44,119:INFO:Checking exceptions
2024-05-24 14:27:44,119:INFO:Importing libraries
2024-05-24 14:27:44,119:INFO:Copying training dataset
2024-05-24 14:27:44,127:INFO:Defining folds
2024-05-24 14:27:44,127:INFO:Declaring metric variables
2024-05-24 14:27:44,133:INFO:Importing untrained model
2024-05-24 14:27:44,136:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:27:44,144:INFO:Starting cross validation
2024-05-24 14:27:44,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:44,327:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.001e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,330:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.956e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,330:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.956e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,330:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.956e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,335:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.780e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,336:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.325e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,371:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.975e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,374:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=2.691e+00, previous alpha=2.015e+00, with an active set of 37 regressors.
  warnings.warn(

2024-05-24 14:27:44,398:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.814e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,399:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.814e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,399:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.351e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,400:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.407e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,401:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.147e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:27:44,478:INFO:Calculating mean and std
2024-05-24 14:27:44,479:INFO:Creating metrics dataframe
2024-05-24 14:27:44,481:INFO:Uploading results into container
2024-05-24 14:27:44,482:INFO:Uploading model into container now
2024-05-24 14:27:44,482:INFO:_master_model_container: 6
2024-05-24 14:27:44,482:INFO:_display_container: 2
2024-05-24 14:27:44,484:INFO:LassoLars(random_state=2057)
2024-05-24 14:27:44,484:INFO:create_model() successfully completed......................................
2024-05-24 14:27:44,617:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:44,617:INFO:Creating metrics dataframe
2024-05-24 14:27:44,627:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:27:44,627:INFO:Total runtime is 0.14319018522898355 minutes
2024-05-24 14:27:44,631:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:44,631:INFO:Initializing create_model()
2024-05-24 14:27:44,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:44,631:INFO:Checking exceptions
2024-05-24 14:27:44,632:INFO:Importing libraries
2024-05-24 14:27:44,632:INFO:Copying training dataset
2024-05-24 14:27:44,640:INFO:Defining folds
2024-05-24 14:27:44,640:INFO:Declaring metric variables
2024-05-24 14:27:44,645:INFO:Importing untrained model
2024-05-24 14:27:44,649:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:27:44,659:INFO:Starting cross validation
2024-05-24 14:27:44,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:45,027:INFO:Calculating mean and std
2024-05-24 14:27:45,029:INFO:Creating metrics dataframe
2024-05-24 14:27:45,030:INFO:Uploading results into container
2024-05-24 14:27:45,031:INFO:Uploading model into container now
2024-05-24 14:27:45,032:INFO:_master_model_container: 7
2024-05-24 14:27:45,032:INFO:_display_container: 2
2024-05-24 14:27:45,032:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:27:45,032:INFO:create_model() successfully completed......................................
2024-05-24 14:27:45,169:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:45,169:INFO:Creating metrics dataframe
2024-05-24 14:27:45,180:INFO:Initializing Bayesian Ridge
2024-05-24 14:27:45,180:INFO:Total runtime is 0.15239948829015096 minutes
2024-05-24 14:27:45,183:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:45,184:INFO:Initializing create_model()
2024-05-24 14:27:45,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:45,184:INFO:Checking exceptions
2024-05-24 14:27:45,184:INFO:Importing libraries
2024-05-24 14:27:45,184:INFO:Copying training dataset
2024-05-24 14:27:45,191:INFO:Defining folds
2024-05-24 14:27:45,191:INFO:Declaring metric variables
2024-05-24 14:27:45,196:INFO:Importing untrained model
2024-05-24 14:27:45,200:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:27:45,208:INFO:Starting cross validation
2024-05-24 14:27:45,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:45,539:INFO:Calculating mean and std
2024-05-24 14:27:45,540:INFO:Creating metrics dataframe
2024-05-24 14:27:45,543:INFO:Uploading results into container
2024-05-24 14:27:45,543:INFO:Uploading model into container now
2024-05-24 14:27:45,544:INFO:_master_model_container: 8
2024-05-24 14:27:45,544:INFO:_display_container: 2
2024-05-24 14:27:45,544:INFO:BayesianRidge()
2024-05-24 14:27:45,544:INFO:create_model() successfully completed......................................
2024-05-24 14:27:45,677:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:45,677:INFO:Creating metrics dataframe
2024-05-24 14:27:45,690:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:27:45,690:INFO:Total runtime is 0.16090389092763266 minutes
2024-05-24 14:27:45,695:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:45,696:INFO:Initializing create_model()
2024-05-24 14:27:45,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:45,696:INFO:Checking exceptions
2024-05-24 14:27:45,697:INFO:Importing libraries
2024-05-24 14:27:45,697:INFO:Copying training dataset
2024-05-24 14:27:45,705:INFO:Defining folds
2024-05-24 14:27:45,705:INFO:Declaring metric variables
2024-05-24 14:27:45,710:INFO:Importing untrained model
2024-05-24 14:27:45,714:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:27:45,722:INFO:Starting cross validation
2024-05-24 14:27:45,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:46,054:INFO:Calculating mean and std
2024-05-24 14:27:46,055:INFO:Creating metrics dataframe
2024-05-24 14:27:46,058:INFO:Uploading results into container
2024-05-24 14:27:46,058:INFO:Uploading model into container now
2024-05-24 14:27:46,059:INFO:_master_model_container: 9
2024-05-24 14:27:46,059:INFO:_display_container: 2
2024-05-24 14:27:46,059:INFO:PassiveAggressiveRegressor(random_state=2057)
2024-05-24 14:27:46,059:INFO:create_model() successfully completed......................................
2024-05-24 14:27:46,187:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:46,187:INFO:Creating metrics dataframe
2024-05-24 14:27:46,197:INFO:Initializing Huber Regressor
2024-05-24 14:27:46,197:INFO:Total runtime is 0.1693501075108846 minutes
2024-05-24 14:27:46,201:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:46,201:INFO:Initializing create_model()
2024-05-24 14:27:46,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:46,202:INFO:Checking exceptions
2024-05-24 14:27:46,202:INFO:Importing libraries
2024-05-24 14:27:46,202:INFO:Copying training dataset
2024-05-24 14:27:46,209:INFO:Defining folds
2024-05-24 14:27:46,209:INFO:Declaring metric variables
2024-05-24 14:27:46,214:INFO:Importing untrained model
2024-05-24 14:27:46,218:INFO:Huber Regressor Imported successfully
2024-05-24 14:27:46,226:INFO:Starting cross validation
2024-05-24 14:27:46,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:46,477:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,485:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,495:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,495:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,509:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,512:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,546:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,550:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,555:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,566:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:46,629:INFO:Calculating mean and std
2024-05-24 14:27:46,630:INFO:Creating metrics dataframe
2024-05-24 14:27:46,632:INFO:Uploading results into container
2024-05-24 14:27:46,633:INFO:Uploading model into container now
2024-05-24 14:27:46,634:INFO:_master_model_container: 10
2024-05-24 14:27:46,634:INFO:_display_container: 2
2024-05-24 14:27:46,634:INFO:HuberRegressor()
2024-05-24 14:27:46,634:INFO:create_model() successfully completed......................................
2024-05-24 14:27:46,762:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:46,762:INFO:Creating metrics dataframe
2024-05-24 14:27:46,773:INFO:Initializing K Neighbors Regressor
2024-05-24 14:27:46,773:INFO:Total runtime is 0.1789540727933248 minutes
2024-05-24 14:27:46,779:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:46,779:INFO:Initializing create_model()
2024-05-24 14:27:46,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:46,780:INFO:Checking exceptions
2024-05-24 14:27:46,780:INFO:Importing libraries
2024-05-24 14:27:46,780:INFO:Copying training dataset
2024-05-24 14:27:46,787:INFO:Defining folds
2024-05-24 14:27:46,787:INFO:Declaring metric variables
2024-05-24 14:27:46,792:INFO:Importing untrained model
2024-05-24 14:27:46,797:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:27:46,806:INFO:Starting cross validation
2024-05-24 14:27:46,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:47,270:INFO:Calculating mean and std
2024-05-24 14:27:47,271:INFO:Creating metrics dataframe
2024-05-24 14:27:47,274:INFO:Uploading results into container
2024-05-24 14:27:47,274:INFO:Uploading model into container now
2024-05-24 14:27:47,275:INFO:_master_model_container: 11
2024-05-24 14:27:47,275:INFO:_display_container: 2
2024-05-24 14:27:47,276:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:27:47,276:INFO:create_model() successfully completed......................................
2024-05-24 14:27:47,410:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:47,410:INFO:Creating metrics dataframe
2024-05-24 14:27:47,420:INFO:Initializing Decision Tree Regressor
2024-05-24 14:27:47,420:INFO:Total runtime is 0.18974424203236898 minutes
2024-05-24 14:27:47,424:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:47,424:INFO:Initializing create_model()
2024-05-24 14:27:47,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:47,425:INFO:Checking exceptions
2024-05-24 14:27:47,425:INFO:Importing libraries
2024-05-24 14:27:47,425:INFO:Copying training dataset
2024-05-24 14:27:47,432:INFO:Defining folds
2024-05-24 14:27:47,432:INFO:Declaring metric variables
2024-05-24 14:27:47,437:INFO:Importing untrained model
2024-05-24 14:27:47,441:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:27:47,450:INFO:Starting cross validation
2024-05-24 14:27:47,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:47,784:INFO:Calculating mean and std
2024-05-24 14:27:47,786:INFO:Creating metrics dataframe
2024-05-24 14:27:47,789:INFO:Uploading results into container
2024-05-24 14:27:47,789:INFO:Uploading model into container now
2024-05-24 14:27:47,790:INFO:_master_model_container: 12
2024-05-24 14:27:47,790:INFO:_display_container: 2
2024-05-24 14:27:47,791:INFO:DecisionTreeRegressor(random_state=2057)
2024-05-24 14:27:47,791:INFO:create_model() successfully completed......................................
2024-05-24 14:27:47,909:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:47,909:INFO:Creating metrics dataframe
2024-05-24 14:27:47,920:INFO:Initializing Random Forest Regressor
2024-05-24 14:27:47,921:INFO:Total runtime is 0.19809536933898925 minutes
2024-05-24 14:27:47,925:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:47,925:INFO:Initializing create_model()
2024-05-24 14:27:47,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:47,925:INFO:Checking exceptions
2024-05-24 14:27:47,926:INFO:Importing libraries
2024-05-24 14:27:47,926:INFO:Copying training dataset
2024-05-24 14:27:47,932:INFO:Defining folds
2024-05-24 14:27:47,932:INFO:Declaring metric variables
2024-05-24 14:27:47,937:INFO:Importing untrained model
2024-05-24 14:27:47,941:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:27:47,949:INFO:Starting cross validation
2024-05-24 14:27:47,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:48,681:INFO:Calculating mean and std
2024-05-24 14:27:48,682:INFO:Creating metrics dataframe
2024-05-24 14:27:48,684:INFO:Uploading results into container
2024-05-24 14:27:48,684:INFO:Uploading model into container now
2024-05-24 14:27:48,684:INFO:_master_model_container: 13
2024-05-24 14:27:48,686:INFO:_display_container: 2
2024-05-24 14:27:48,686:INFO:RandomForestRegressor(n_jobs=-1, random_state=2057)
2024-05-24 14:27:48,686:INFO:create_model() successfully completed......................................
2024-05-24 14:27:48,815:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:48,815:INFO:Creating metrics dataframe
2024-05-24 14:27:48,824:INFO:Initializing Extra Trees Regressor
2024-05-24 14:27:48,824:INFO:Total runtime is 0.2131429115931193 minutes
2024-05-24 14:27:48,828:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:48,829:INFO:Initializing create_model()
2024-05-24 14:27:48,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:48,829:INFO:Checking exceptions
2024-05-24 14:27:48,829:INFO:Importing libraries
2024-05-24 14:27:48,829:INFO:Copying training dataset
2024-05-24 14:27:48,836:INFO:Defining folds
2024-05-24 14:27:48,837:INFO:Declaring metric variables
2024-05-24 14:27:48,842:INFO:Importing untrained model
2024-05-24 14:27:48,847:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:27:48,853:INFO:Starting cross validation
2024-05-24 14:27:48,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:49,463:INFO:Calculating mean and std
2024-05-24 14:27:49,464:INFO:Creating metrics dataframe
2024-05-24 14:27:49,466:INFO:Uploading results into container
2024-05-24 14:27:49,467:INFO:Uploading model into container now
2024-05-24 14:27:49,467:INFO:_master_model_container: 14
2024-05-24 14:27:49,468:INFO:_display_container: 2
2024-05-24 14:27:49,468:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2057)
2024-05-24 14:27:49,468:INFO:create_model() successfully completed......................................
2024-05-24 14:27:49,604:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:49,604:INFO:Creating metrics dataframe
2024-05-24 14:27:49,617:INFO:Initializing AdaBoost Regressor
2024-05-24 14:27:49,618:INFO:Total runtime is 0.22636537949244182 minutes
2024-05-24 14:27:49,621:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:49,623:INFO:Initializing create_model()
2024-05-24 14:27:49,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:49,623:INFO:Checking exceptions
2024-05-24 14:27:49,623:INFO:Importing libraries
2024-05-24 14:27:49,623:INFO:Copying training dataset
2024-05-24 14:27:49,632:INFO:Defining folds
2024-05-24 14:27:49,632:INFO:Declaring metric variables
2024-05-24 14:27:49,638:INFO:Importing untrained model
2024-05-24 14:27:49,643:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:27:49,651:INFO:Starting cross validation
2024-05-24 14:27:49,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:50,118:INFO:Calculating mean and std
2024-05-24 14:27:50,119:INFO:Creating metrics dataframe
2024-05-24 14:27:50,122:INFO:Uploading results into container
2024-05-24 14:27:50,123:INFO:Uploading model into container now
2024-05-24 14:27:50,123:INFO:_master_model_container: 15
2024-05-24 14:27:50,124:INFO:_display_container: 2
2024-05-24 14:27:50,124:INFO:AdaBoostRegressor(random_state=2057)
2024-05-24 14:27:50,124:INFO:create_model() successfully completed......................................
2024-05-24 14:27:50,263:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:50,263:INFO:Creating metrics dataframe
2024-05-24 14:27:50,277:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:27:50,277:INFO:Total runtime is 0.23734758694966634 minutes
2024-05-24 14:27:50,282:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:50,282:INFO:Initializing create_model()
2024-05-24 14:27:50,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:50,283:INFO:Checking exceptions
2024-05-24 14:27:50,283:INFO:Importing libraries
2024-05-24 14:27:50,283:INFO:Copying training dataset
2024-05-24 14:27:50,291:INFO:Defining folds
2024-05-24 14:27:50,291:INFO:Declaring metric variables
2024-05-24 14:27:50,296:INFO:Importing untrained model
2024-05-24 14:27:50,301:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:27:50,309:INFO:Starting cross validation
2024-05-24 14:27:50,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:50,851:INFO:Calculating mean and std
2024-05-24 14:27:50,852:INFO:Creating metrics dataframe
2024-05-24 14:27:50,855:INFO:Uploading results into container
2024-05-24 14:27:50,855:INFO:Uploading model into container now
2024-05-24 14:27:50,856:INFO:_master_model_container: 16
2024-05-24 14:27:50,856:INFO:_display_container: 2
2024-05-24 14:27:50,857:INFO:GradientBoostingRegressor(random_state=2057)
2024-05-24 14:27:50,857:INFO:create_model() successfully completed......................................
2024-05-24 14:27:51,002:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:51,002:INFO:Creating metrics dataframe
2024-05-24 14:27:51,016:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:27:51,016:INFO:Total runtime is 0.24967916011810304 minutes
2024-05-24 14:27:51,022:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:51,022:INFO:Initializing create_model()
2024-05-24 14:27:51,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:51,023:INFO:Checking exceptions
2024-05-24 14:27:51,023:INFO:Importing libraries
2024-05-24 14:27:51,023:INFO:Copying training dataset
2024-05-24 14:27:51,033:INFO:Defining folds
2024-05-24 14:27:51,033:INFO:Declaring metric variables
2024-05-24 14:27:51,037:INFO:Importing untrained model
2024-05-24 14:27:51,042:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:27:51,050:INFO:Starting cross validation
2024-05-24 14:27:51,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:52,069:INFO:Calculating mean and std
2024-05-24 14:27:52,071:INFO:Creating metrics dataframe
2024-05-24 14:27:52,074:INFO:Uploading results into container
2024-05-24 14:27:52,075:INFO:Uploading model into container now
2024-05-24 14:27:52,076:INFO:_master_model_container: 17
2024-05-24 14:27:52,076:INFO:_display_container: 2
2024-05-24 14:27:52,077:INFO:LGBMRegressor(n_jobs=-1, random_state=2057)
2024-05-24 14:27:52,077:INFO:create_model() successfully completed......................................
2024-05-24 14:27:52,203:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:52,203:INFO:Creating metrics dataframe
2024-05-24 14:27:52,213:INFO:Initializing Dummy Regressor
2024-05-24 14:27:52,213:INFO:Total runtime is 0.26961321830749513 minutes
2024-05-24 14:27:52,218:INFO:SubProcess create_model() called ==================================
2024-05-24 14:27:52,219:INFO:Initializing create_model()
2024-05-24 14:27:52,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9CFF0B9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:52,219:INFO:Checking exceptions
2024-05-24 14:27:52,219:INFO:Importing libraries
2024-05-24 14:27:52,219:INFO:Copying training dataset
2024-05-24 14:27:52,225:INFO:Defining folds
2024-05-24 14:27:52,225:INFO:Declaring metric variables
2024-05-24 14:27:52,230:INFO:Importing untrained model
2024-05-24 14:27:52,234:INFO:Dummy Regressor Imported successfully
2024-05-24 14:27:52,242:INFO:Starting cross validation
2024-05-24 14:27:52,246:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:27:52,631:INFO:Calculating mean and std
2024-05-24 14:27:52,632:INFO:Creating metrics dataframe
2024-05-24 14:27:52,635:INFO:Uploading results into container
2024-05-24 14:27:52,636:INFO:Uploading model into container now
2024-05-24 14:27:52,636:INFO:_master_model_container: 18
2024-05-24 14:27:52,637:INFO:_display_container: 2
2024-05-24 14:27:52,637:INFO:DummyRegressor()
2024-05-24 14:27:52,637:INFO:create_model() successfully completed......................................
2024-05-24 14:27:52,774:INFO:SubProcess create_model() end ==================================
2024-05-24 14:27:52,775:INFO:Creating metrics dataframe
2024-05-24 14:27:52,790:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:27:52,800:INFO:Initializing create_model()
2024-05-24 14:27:52,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:27:52,800:INFO:Checking exceptions
2024-05-24 14:27:52,802:INFO:Importing libraries
2024-05-24 14:27:52,802:INFO:Copying training dataset
2024-05-24 14:27:52,811:INFO:Defining folds
2024-05-24 14:27:52,811:INFO:Declaring metric variables
2024-05-24 14:27:52,812:INFO:Importing untrained model
2024-05-24 14:27:52,812:INFO:Declaring custom model
2024-05-24 14:27:52,812:INFO:Huber Regressor Imported successfully
2024-05-24 14:27:52,816:INFO:Cross validation set to False
2024-05-24 14:27:52,816:INFO:Fitting Model
2024-05-24 14:27:52,954:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:27:52,954:INFO:HuberRegressor()
2024-05-24 14:27:52,954:INFO:create_model() successfully completed......................................
2024-05-24 14:27:53,117:INFO:_master_model_container: 18
2024-05-24 14:27:53,117:INFO:_display_container: 2
2024-05-24 14:27:53,117:INFO:HuberRegressor()
2024-05-24 14:27:53,119:INFO:compare_models() successfully completed......................................
2024-05-24 14:29:42,601:INFO:Initializing compare_models()
2024-05-24 14:29:42,601:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:29:42,602:INFO:Checking exceptions
2024-05-24 14:29:42,605:INFO:Preparing display monitor
2024-05-24 14:29:42,634:INFO:Initializing Linear Regression
2024-05-24 14:29:42,634:INFO:Total runtime is 0.0 minutes
2024-05-24 14:29:42,637:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:42,638:INFO:Initializing create_model()
2024-05-24 14:29:42,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:42,638:INFO:Checking exceptions
2024-05-24 14:29:42,639:INFO:Importing libraries
2024-05-24 14:29:42,639:INFO:Copying training dataset
2024-05-24 14:29:42,644:INFO:Defining folds
2024-05-24 14:29:42,644:INFO:Declaring metric variables
2024-05-24 14:29:42,648:INFO:Importing untrained model
2024-05-24 14:29:42,652:INFO:Linear Regression Imported successfully
2024-05-24 14:29:42,659:INFO:Starting cross validation
2024-05-24 14:29:42,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:42,977:INFO:Calculating mean and std
2024-05-24 14:29:42,977:INFO:Creating metrics dataframe
2024-05-24 14:29:42,979:INFO:Uploading results into container
2024-05-24 14:29:42,979:INFO:Uploading model into container now
2024-05-24 14:29:42,980:INFO:_master_model_container: 19
2024-05-24 14:29:42,980:INFO:_display_container: 3
2024-05-24 14:29:42,980:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:29:42,980:INFO:create_model() successfully completed......................................
2024-05-24 14:29:43,114:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:43,115:INFO:Creating metrics dataframe
2024-05-24 14:29:43,124:INFO:Initializing Lasso Regression
2024-05-24 14:29:43,124:INFO:Total runtime is 0.008174586296081542 minutes
2024-05-24 14:29:43,129:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:43,129:INFO:Initializing create_model()
2024-05-24 14:29:43,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:43,130:INFO:Checking exceptions
2024-05-24 14:29:43,130:INFO:Importing libraries
2024-05-24 14:29:43,130:INFO:Copying training dataset
2024-05-24 14:29:43,139:INFO:Defining folds
2024-05-24 14:29:43,140:INFO:Declaring metric variables
2024-05-24 14:29:43,145:INFO:Importing untrained model
2024-05-24 14:29:43,151:INFO:Lasso Regression Imported successfully
2024-05-24 14:29:43,161:INFO:Starting cross validation
2024-05-24 14:29:43,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:43,366:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.231e+06, tolerance: 8.660e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:29:43,369:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.447e+06, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:29:43,376:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e+06, tolerance: 5.930e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:29:43,391:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+07, tolerance: 9.060e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:29:43,407:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:29:43,480:INFO:Calculating mean and std
2024-05-24 14:29:43,481:INFO:Creating metrics dataframe
2024-05-24 14:29:43,483:INFO:Uploading results into container
2024-05-24 14:29:43,484:INFO:Uploading model into container now
2024-05-24 14:29:43,484:INFO:_master_model_container: 20
2024-05-24 14:29:43,484:INFO:_display_container: 3
2024-05-24 14:29:43,484:INFO:Lasso(random_state=2057)
2024-05-24 14:29:43,484:INFO:create_model() successfully completed......................................
2024-05-24 14:29:43,606:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:43,607:INFO:Creating metrics dataframe
2024-05-24 14:29:43,614:INFO:Initializing Ridge Regression
2024-05-24 14:29:43,614:INFO:Total runtime is 0.016345834732055663 minutes
2024-05-24 14:29:43,618:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:43,620:INFO:Initializing create_model()
2024-05-24 14:29:43,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:43,620:INFO:Checking exceptions
2024-05-24 14:29:43,620:INFO:Importing libraries
2024-05-24 14:29:43,621:INFO:Copying training dataset
2024-05-24 14:29:43,628:INFO:Defining folds
2024-05-24 14:29:43,628:INFO:Declaring metric variables
2024-05-24 14:29:43,633:INFO:Importing untrained model
2024-05-24 14:29:43,637:INFO:Ridge Regression Imported successfully
2024-05-24 14:29:43,646:INFO:Starting cross validation
2024-05-24 14:29:43,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:43,964:INFO:Calculating mean and std
2024-05-24 14:29:43,965:INFO:Creating metrics dataframe
2024-05-24 14:29:43,968:INFO:Uploading results into container
2024-05-24 14:29:43,968:INFO:Uploading model into container now
2024-05-24 14:29:43,969:INFO:_master_model_container: 21
2024-05-24 14:29:43,969:INFO:_display_container: 3
2024-05-24 14:29:43,969:INFO:Ridge(random_state=2057)
2024-05-24 14:29:43,969:INFO:create_model() successfully completed......................................
2024-05-24 14:29:44,078:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:44,078:INFO:Creating metrics dataframe
2024-05-24 14:29:44,084:INFO:Initializing Elastic Net
2024-05-24 14:29:44,084:INFO:Total runtime is 0.024173410733540852 minutes
2024-05-24 14:29:44,087:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:44,087:INFO:Initializing create_model()
2024-05-24 14:29:44,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:44,088:INFO:Checking exceptions
2024-05-24 14:29:44,088:INFO:Importing libraries
2024-05-24 14:29:44,088:INFO:Copying training dataset
2024-05-24 14:29:44,093:INFO:Defining folds
2024-05-24 14:29:44,093:INFO:Declaring metric variables
2024-05-24 14:29:44,098:INFO:Importing untrained model
2024-05-24 14:29:44,102:INFO:Elastic Net Imported successfully
2024-05-24 14:29:44,107:INFO:Starting cross validation
2024-05-24 14:29:44,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:44,386:INFO:Calculating mean and std
2024-05-24 14:29:44,387:INFO:Creating metrics dataframe
2024-05-24 14:29:44,389:INFO:Uploading results into container
2024-05-24 14:29:44,390:INFO:Uploading model into container now
2024-05-24 14:29:44,390:INFO:_master_model_container: 22
2024-05-24 14:29:44,390:INFO:_display_container: 3
2024-05-24 14:29:44,391:INFO:ElasticNet(random_state=2057)
2024-05-24 14:29:44,391:INFO:create_model() successfully completed......................................
2024-05-24 14:29:44,504:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:44,505:INFO:Creating metrics dataframe
2024-05-24 14:29:44,511:INFO:Initializing Least Angle Regression
2024-05-24 14:29:44,511:INFO:Total runtime is 0.031294008096059166 minutes
2024-05-24 14:29:44,515:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:44,515:INFO:Initializing create_model()
2024-05-24 14:29:44,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:44,516:INFO:Checking exceptions
2024-05-24 14:29:44,516:INFO:Importing libraries
2024-05-24 14:29:44,516:INFO:Copying training dataset
2024-05-24 14:29:44,522:INFO:Defining folds
2024-05-24 14:29:44,522:INFO:Declaring metric variables
2024-05-24 14:29:44,527:INFO:Importing untrained model
2024-05-24 14:29:44,531:INFO:Least Angle Regression Imported successfully
2024-05-24 14:29:44,539:INFO:Starting cross validation
2024-05-24 14:29:44,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:44,723:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.665e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,723:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.598e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,724:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.469e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,724:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.713e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,724:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.713e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,724:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=7.713e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,724:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.544e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,726:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.954e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,726:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.668e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,726:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.668e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,726:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=3.834e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,727:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=3.834e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,732:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.237e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,733:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=8.568e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,734:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.838e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,734:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.538e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,734:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.628e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,734:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=2.650e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,735:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.291e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,735:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=8.851e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,735:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.270e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,735:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.270e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,735:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.742e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.985e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.201e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.094e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.187e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.548e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=6.043e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.109e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,736:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.101e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,737:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.520e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,737:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.527e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,737:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.142e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,737:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.318e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,738:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.318e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,751:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.692e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,752:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.319e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,753:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.984e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,757:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=9.376e+05, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,757:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=2.099e+04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,759:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.204e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,759:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.178e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,760:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.175e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,760:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.100e-02, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,762:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.287e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,762:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.190e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,771:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.380e+06, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,785:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.345e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,785:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.069e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,786:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.551e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,786:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.290e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,788:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=5.138e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,788:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=5.038e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,788:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.686e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,788:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.515e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,789:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.030e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,790:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.097e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,792:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.063e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,793:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.995e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,793:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.295e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:44,854:INFO:Calculating mean and std
2024-05-24 14:29:44,855:INFO:Creating metrics dataframe
2024-05-24 14:29:44,858:INFO:Uploading results into container
2024-05-24 14:29:44,858:INFO:Uploading model into container now
2024-05-24 14:29:44,860:INFO:_master_model_container: 23
2024-05-24 14:29:44,860:INFO:_display_container: 3
2024-05-24 14:29:44,860:INFO:Lars(random_state=2057)
2024-05-24 14:29:44,860:INFO:create_model() successfully completed......................................
2024-05-24 14:29:44,982:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:44,982:INFO:Creating metrics dataframe
2024-05-24 14:29:44,991:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:29:44,991:INFO:Total runtime is 0.039287503560384116 minutes
2024-05-24 14:29:44,996:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:44,996:INFO:Initializing create_model()
2024-05-24 14:29:44,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:44,997:INFO:Checking exceptions
2024-05-24 14:29:44,997:INFO:Importing libraries
2024-05-24 14:29:44,997:INFO:Copying training dataset
2024-05-24 14:29:45,006:INFO:Defining folds
2024-05-24 14:29:45,006:INFO:Declaring metric variables
2024-05-24 14:29:45,011:INFO:Importing untrained model
2024-05-24 14:29:45,016:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:29:45,021:INFO:Starting cross validation
2024-05-24 14:29:45,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:45,223:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.001e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,224:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.956e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,224:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.956e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,225:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.956e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,225:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.780e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,225:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.325e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,261:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.975e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,262:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=2.691e+00, previous alpha=2.015e+00, with an active set of 37 regressors.
  warnings.warn(

2024-05-24 14:29:45,271:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.814e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,271:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.814e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,271:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.351e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,273:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.407e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,273:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.147e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:29:45,326:INFO:Calculating mean and std
2024-05-24 14:29:45,327:INFO:Creating metrics dataframe
2024-05-24 14:29:45,329:INFO:Uploading results into container
2024-05-24 14:29:45,330:INFO:Uploading model into container now
2024-05-24 14:29:45,330:INFO:_master_model_container: 24
2024-05-24 14:29:45,330:INFO:_display_container: 3
2024-05-24 14:29:45,331:INFO:LassoLars(random_state=2057)
2024-05-24 14:29:45,331:INFO:create_model() successfully completed......................................
2024-05-24 14:29:45,454:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:45,454:INFO:Creating metrics dataframe
2024-05-24 14:29:45,464:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:29:45,464:INFO:Total runtime is 0.047167901198069254 minutes
2024-05-24 14:29:45,468:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:45,469:INFO:Initializing create_model()
2024-05-24 14:29:45,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:45,469:INFO:Checking exceptions
2024-05-24 14:29:45,469:INFO:Importing libraries
2024-05-24 14:29:45,469:INFO:Copying training dataset
2024-05-24 14:29:45,479:INFO:Defining folds
2024-05-24 14:29:45,479:INFO:Declaring metric variables
2024-05-24 14:29:45,484:INFO:Importing untrained model
2024-05-24 14:29:45,488:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:29:45,494:INFO:Starting cross validation
2024-05-24 14:29:45,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:45,796:INFO:Calculating mean and std
2024-05-24 14:29:45,797:INFO:Creating metrics dataframe
2024-05-24 14:29:45,800:INFO:Uploading results into container
2024-05-24 14:29:45,800:INFO:Uploading model into container now
2024-05-24 14:29:45,801:INFO:_master_model_container: 25
2024-05-24 14:29:45,801:INFO:_display_container: 3
2024-05-24 14:29:45,801:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:29:45,801:INFO:create_model() successfully completed......................................
2024-05-24 14:29:45,920:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:45,920:INFO:Creating metrics dataframe
2024-05-24 14:29:45,929:INFO:Initializing Bayesian Ridge
2024-05-24 14:29:45,929:INFO:Total runtime is 0.05492860476175944 minutes
2024-05-24 14:29:45,934:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:45,934:INFO:Initializing create_model()
2024-05-24 14:29:45,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:45,934:INFO:Checking exceptions
2024-05-24 14:29:45,934:INFO:Importing libraries
2024-05-24 14:29:45,935:INFO:Copying training dataset
2024-05-24 14:29:45,941:INFO:Defining folds
2024-05-24 14:29:45,941:INFO:Declaring metric variables
2024-05-24 14:29:45,946:INFO:Importing untrained model
2024-05-24 14:29:45,953:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:29:45,959:INFO:Starting cross validation
2024-05-24 14:29:45,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:46,279:INFO:Calculating mean and std
2024-05-24 14:29:46,283:INFO:Creating metrics dataframe
2024-05-24 14:29:46,285:INFO:Uploading results into container
2024-05-24 14:29:46,286:INFO:Uploading model into container now
2024-05-24 14:29:46,286:INFO:_master_model_container: 26
2024-05-24 14:29:46,286:INFO:_display_container: 3
2024-05-24 14:29:46,287:INFO:BayesianRidge()
2024-05-24 14:29:46,287:INFO:create_model() successfully completed......................................
2024-05-24 14:29:46,393:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:46,393:INFO:Creating metrics dataframe
2024-05-24 14:29:46,402:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:29:46,403:INFO:Total runtime is 0.06280561288197835 minutes
2024-05-24 14:29:46,406:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:46,406:INFO:Initializing create_model()
2024-05-24 14:29:46,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:46,407:INFO:Checking exceptions
2024-05-24 14:29:46,407:INFO:Importing libraries
2024-05-24 14:29:46,407:INFO:Copying training dataset
2024-05-24 14:29:46,414:INFO:Defining folds
2024-05-24 14:29:46,414:INFO:Declaring metric variables
2024-05-24 14:29:46,418:INFO:Importing untrained model
2024-05-24 14:29:46,423:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:29:46,430:INFO:Starting cross validation
2024-05-24 14:29:46,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:46,730:INFO:Calculating mean and std
2024-05-24 14:29:46,732:INFO:Creating metrics dataframe
2024-05-24 14:29:46,734:INFO:Uploading results into container
2024-05-24 14:29:46,735:INFO:Uploading model into container now
2024-05-24 14:29:46,735:INFO:_master_model_container: 27
2024-05-24 14:29:46,735:INFO:_display_container: 3
2024-05-24 14:29:46,737:INFO:PassiveAggressiveRegressor(random_state=2057)
2024-05-24 14:29:46,737:INFO:create_model() successfully completed......................................
2024-05-24 14:29:46,868:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:46,868:INFO:Creating metrics dataframe
2024-05-24 14:29:46,877:INFO:Initializing Huber Regressor
2024-05-24 14:29:46,877:INFO:Total runtime is 0.07072443167368571 minutes
2024-05-24 14:29:46,881:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:46,882:INFO:Initializing create_model()
2024-05-24 14:29:46,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:46,882:INFO:Checking exceptions
2024-05-24 14:29:46,882:INFO:Importing libraries
2024-05-24 14:29:46,882:INFO:Copying training dataset
2024-05-24 14:29:46,890:INFO:Defining folds
2024-05-24 14:29:46,890:INFO:Declaring metric variables
2024-05-24 14:29:46,894:INFO:Importing untrained model
2024-05-24 14:29:46,899:INFO:Huber Regressor Imported successfully
2024-05-24 14:29:46,906:INFO:Starting cross validation
2024-05-24 14:29:46,910:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:47,121:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,129:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,141:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,155:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,161:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,170:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,174:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,177:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,186:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,188:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:47,263:INFO:Calculating mean and std
2024-05-24 14:29:47,264:INFO:Creating metrics dataframe
2024-05-24 14:29:47,266:INFO:Uploading results into container
2024-05-24 14:29:47,267:INFO:Uploading model into container now
2024-05-24 14:29:47,267:INFO:_master_model_container: 28
2024-05-24 14:29:47,268:INFO:_display_container: 3
2024-05-24 14:29:47,268:INFO:HuberRegressor()
2024-05-24 14:29:47,268:INFO:create_model() successfully completed......................................
2024-05-24 14:29:47,392:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:47,393:INFO:Creating metrics dataframe
2024-05-24 14:29:47,402:INFO:Initializing K Neighbors Regressor
2024-05-24 14:29:47,402:INFO:Total runtime is 0.07946902910868327 minutes
2024-05-24 14:29:47,407:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:47,407:INFO:Initializing create_model()
2024-05-24 14:29:47,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:47,408:INFO:Checking exceptions
2024-05-24 14:29:47,408:INFO:Importing libraries
2024-05-24 14:29:47,408:INFO:Copying training dataset
2024-05-24 14:29:47,415:INFO:Defining folds
2024-05-24 14:29:47,415:INFO:Declaring metric variables
2024-05-24 14:29:47,420:INFO:Importing untrained model
2024-05-24 14:29:47,424:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:29:47,431:INFO:Starting cross validation
2024-05-24 14:29:47,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:47,806:INFO:Calculating mean and std
2024-05-24 14:29:47,808:INFO:Creating metrics dataframe
2024-05-24 14:29:47,810:INFO:Uploading results into container
2024-05-24 14:29:47,811:INFO:Uploading model into container now
2024-05-24 14:29:47,811:INFO:_master_model_container: 29
2024-05-24 14:29:47,811:INFO:_display_container: 3
2024-05-24 14:29:47,812:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:29:47,812:INFO:create_model() successfully completed......................................
2024-05-24 14:29:47,939:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:47,939:INFO:Creating metrics dataframe
2024-05-24 14:29:47,950:INFO:Initializing Decision Tree Regressor
2024-05-24 14:29:47,950:INFO:Total runtime is 0.08859893480936686 minutes
2024-05-24 14:29:47,954:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:47,955:INFO:Initializing create_model()
2024-05-24 14:29:47,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:47,955:INFO:Checking exceptions
2024-05-24 14:29:47,955:INFO:Importing libraries
2024-05-24 14:29:47,955:INFO:Copying training dataset
2024-05-24 14:29:47,962:INFO:Defining folds
2024-05-24 14:29:47,962:INFO:Declaring metric variables
2024-05-24 14:29:47,966:INFO:Importing untrained model
2024-05-24 14:29:47,970:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:29:47,977:INFO:Starting cross validation
2024-05-24 14:29:47,980:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:48,275:INFO:Calculating mean and std
2024-05-24 14:29:48,277:INFO:Creating metrics dataframe
2024-05-24 14:29:48,280:INFO:Uploading results into container
2024-05-24 14:29:48,281:INFO:Uploading model into container now
2024-05-24 14:29:48,281:INFO:_master_model_container: 30
2024-05-24 14:29:48,281:INFO:_display_container: 3
2024-05-24 14:29:48,281:INFO:DecisionTreeRegressor(random_state=2057)
2024-05-24 14:29:48,282:INFO:create_model() successfully completed......................................
2024-05-24 14:29:48,408:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:48,409:INFO:Creating metrics dataframe
2024-05-24 14:29:48,419:INFO:Initializing Random Forest Regressor
2024-05-24 14:29:48,419:INFO:Total runtime is 0.09642919699350992 minutes
2024-05-24 14:29:48,423:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:48,425:INFO:Initializing create_model()
2024-05-24 14:29:48,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:48,425:INFO:Checking exceptions
2024-05-24 14:29:48,425:INFO:Importing libraries
2024-05-24 14:29:48,425:INFO:Copying training dataset
2024-05-24 14:29:48,438:INFO:Defining folds
2024-05-24 14:29:48,438:INFO:Declaring metric variables
2024-05-24 14:29:48,442:INFO:Importing untrained model
2024-05-24 14:29:48,447:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:29:48,456:INFO:Starting cross validation
2024-05-24 14:29:48,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:49,118:INFO:Calculating mean and std
2024-05-24 14:29:49,119:INFO:Creating metrics dataframe
2024-05-24 14:29:49,121:INFO:Uploading results into container
2024-05-24 14:29:49,123:INFO:Uploading model into container now
2024-05-24 14:29:49,124:INFO:_master_model_container: 31
2024-05-24 14:29:49,124:INFO:_display_container: 3
2024-05-24 14:29:49,124:INFO:RandomForestRegressor(n_jobs=-1, random_state=2057)
2024-05-24 14:29:49,124:INFO:create_model() successfully completed......................................
2024-05-24 14:29:49,266:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:49,266:INFO:Creating metrics dataframe
2024-05-24 14:29:49,281:INFO:Initializing Extra Trees Regressor
2024-05-24 14:29:49,281:INFO:Total runtime is 0.1107842485109965 minutes
2024-05-24 14:29:49,286:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:49,286:INFO:Initializing create_model()
2024-05-24 14:29:49,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:49,287:INFO:Checking exceptions
2024-05-24 14:29:49,287:INFO:Importing libraries
2024-05-24 14:29:49,287:INFO:Copying training dataset
2024-05-24 14:29:49,295:INFO:Defining folds
2024-05-24 14:29:49,295:INFO:Declaring metric variables
2024-05-24 14:29:49,301:INFO:Importing untrained model
2024-05-24 14:29:49,305:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:29:49,311:INFO:Starting cross validation
2024-05-24 14:29:49,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:49,892:INFO:Calculating mean and std
2024-05-24 14:29:49,893:INFO:Creating metrics dataframe
2024-05-24 14:29:49,895:INFO:Uploading results into container
2024-05-24 14:29:49,896:INFO:Uploading model into container now
2024-05-24 14:29:49,896:INFO:_master_model_container: 32
2024-05-24 14:29:49,896:INFO:_display_container: 3
2024-05-24 14:29:49,897:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2057)
2024-05-24 14:29:49,897:INFO:create_model() successfully completed......................................
2024-05-24 14:29:50,015:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:50,016:INFO:Creating metrics dataframe
2024-05-24 14:29:50,025:INFO:Initializing AdaBoost Regressor
2024-05-24 14:29:50,025:INFO:Total runtime is 0.12319326400756836 minutes
2024-05-24 14:29:50,028:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:50,028:INFO:Initializing create_model()
2024-05-24 14:29:50,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:50,028:INFO:Checking exceptions
2024-05-24 14:29:50,028:INFO:Importing libraries
2024-05-24 14:29:50,029:INFO:Copying training dataset
2024-05-24 14:29:50,034:INFO:Defining folds
2024-05-24 14:29:50,034:INFO:Declaring metric variables
2024-05-24 14:29:50,038:INFO:Importing untrained model
2024-05-24 14:29:50,042:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:29:50,047:INFO:Starting cross validation
2024-05-24 14:29:50,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:50,458:INFO:Calculating mean and std
2024-05-24 14:29:50,459:INFO:Creating metrics dataframe
2024-05-24 14:29:50,461:INFO:Uploading results into container
2024-05-24 14:29:50,462:INFO:Uploading model into container now
2024-05-24 14:29:50,462:INFO:_master_model_container: 33
2024-05-24 14:29:50,462:INFO:_display_container: 3
2024-05-24 14:29:50,462:INFO:AdaBoostRegressor(random_state=2057)
2024-05-24 14:29:50,462:INFO:create_model() successfully completed......................................
2024-05-24 14:29:50,589:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:50,590:INFO:Creating metrics dataframe
2024-05-24 14:29:50,604:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:29:50,604:INFO:Total runtime is 0.13284813563028972 minutes
2024-05-24 14:29:50,609:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:50,609:INFO:Initializing create_model()
2024-05-24 14:29:50,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:50,609:INFO:Checking exceptions
2024-05-24 14:29:50,609:INFO:Importing libraries
2024-05-24 14:29:50,609:INFO:Copying training dataset
2024-05-24 14:29:50,623:INFO:Defining folds
2024-05-24 14:29:50,623:INFO:Declaring metric variables
2024-05-24 14:29:50,627:INFO:Importing untrained model
2024-05-24 14:29:50,632:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:29:50,641:INFO:Starting cross validation
2024-05-24 14:29:50,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:51,094:INFO:Calculating mean and std
2024-05-24 14:29:51,096:INFO:Creating metrics dataframe
2024-05-24 14:29:51,099:INFO:Uploading results into container
2024-05-24 14:29:51,099:INFO:Uploading model into container now
2024-05-24 14:29:51,100:INFO:_master_model_container: 34
2024-05-24 14:29:51,100:INFO:_display_container: 3
2024-05-24 14:29:51,101:INFO:GradientBoostingRegressor(random_state=2057)
2024-05-24 14:29:51,101:INFO:create_model() successfully completed......................................
2024-05-24 14:29:51,248:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:51,248:INFO:Creating metrics dataframe
2024-05-24 14:29:51,263:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:29:51,263:INFO:Total runtime is 0.14381592671076457 minutes
2024-05-24 14:29:51,266:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:51,267:INFO:Initializing create_model()
2024-05-24 14:29:51,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:51,267:INFO:Checking exceptions
2024-05-24 14:29:51,267:INFO:Importing libraries
2024-05-24 14:29:51,267:INFO:Copying training dataset
2024-05-24 14:29:51,276:INFO:Defining folds
2024-05-24 14:29:51,276:INFO:Declaring metric variables
2024-05-24 14:29:51,280:INFO:Importing untrained model
2024-05-24 14:29:51,286:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:29:51,293:INFO:Starting cross validation
2024-05-24 14:29:51,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:51,912:INFO:Calculating mean and std
2024-05-24 14:29:51,913:INFO:Creating metrics dataframe
2024-05-24 14:29:51,916:INFO:Uploading results into container
2024-05-24 14:29:51,917:INFO:Uploading model into container now
2024-05-24 14:29:51,918:INFO:_master_model_container: 35
2024-05-24 14:29:51,918:INFO:_display_container: 3
2024-05-24 14:29:51,918:INFO:LGBMRegressor(n_jobs=-1, random_state=2057)
2024-05-24 14:29:51,918:INFO:create_model() successfully completed......................................
2024-05-24 14:29:52,059:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:52,059:INFO:Creating metrics dataframe
2024-05-24 14:29:52,070:INFO:Initializing Dummy Regressor
2024-05-24 14:29:52,070:INFO:Total runtime is 0.157273264726003 minutes
2024-05-24 14:29:52,073:INFO:SubProcess create_model() called ==================================
2024-05-24 14:29:52,073:INFO:Initializing create_model()
2024-05-24 14:29:52,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D071BC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:52,074:INFO:Checking exceptions
2024-05-24 14:29:52,074:INFO:Importing libraries
2024-05-24 14:29:52,074:INFO:Copying training dataset
2024-05-24 14:29:52,080:INFO:Defining folds
2024-05-24 14:29:52,080:INFO:Declaring metric variables
2024-05-24 14:29:52,085:INFO:Importing untrained model
2024-05-24 14:29:52,088:INFO:Dummy Regressor Imported successfully
2024-05-24 14:29:52,095:INFO:Starting cross validation
2024-05-24 14:29:52,097:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:29:52,380:INFO:Calculating mean and std
2024-05-24 14:29:52,382:INFO:Creating metrics dataframe
2024-05-24 14:29:52,384:INFO:Uploading results into container
2024-05-24 14:29:52,385:INFO:Uploading model into container now
2024-05-24 14:29:52,386:INFO:_master_model_container: 36
2024-05-24 14:29:52,386:INFO:_display_container: 3
2024-05-24 14:29:52,386:INFO:DummyRegressor()
2024-05-24 14:29:52,386:INFO:create_model() successfully completed......................................
2024-05-24 14:29:52,516:INFO:SubProcess create_model() end ==================================
2024-05-24 14:29:52,516:INFO:Creating metrics dataframe
2024-05-24 14:29:52,528:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:29:52,538:INFO:Initializing create_model()
2024-05-24 14:29:52,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9CFF0BA30>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:29:52,538:INFO:Checking exceptions
2024-05-24 14:29:52,541:INFO:Importing libraries
2024-05-24 14:29:52,541:INFO:Copying training dataset
2024-05-24 14:29:52,554:INFO:Defining folds
2024-05-24 14:29:52,554:INFO:Declaring metric variables
2024-05-24 14:29:52,554:INFO:Importing untrained model
2024-05-24 14:29:52,554:INFO:Declaring custom model
2024-05-24 14:29:52,555:INFO:Huber Regressor Imported successfully
2024-05-24 14:29:52,557:INFO:Cross validation set to False
2024-05-24 14:29:52,557:INFO:Fitting Model
2024-05-24 14:29:52,694:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:29:52,695:INFO:HuberRegressor()
2024-05-24 14:29:52,695:INFO:create_model() successfully completed......................................
2024-05-24 14:29:52,849:INFO:_master_model_container: 36
2024-05-24 14:29:52,849:INFO:_display_container: 3
2024-05-24 14:29:52,849:INFO:HuberRegressor()
2024-05-24 14:29:52,849:INFO:compare_models() successfully completed......................................
2024-05-24 14:30:14,853:INFO:PyCaret RegressionExperiment
2024-05-24 14:30:14,853:INFO:Logging name: reg-default-name
2024-05-24 14:30:14,853:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 14:30:14,853:INFO:version 3.3.2
2024-05-24 14:30:14,853:INFO:Initializing setup()
2024-05-24 14:30:14,853:INFO:self.USI: 2728
2024-05-24 14:30:14,853:INFO:self._variable_keys: {'gpu_param', 'y', 'pipeline', 'seed', '_ml_usecase', 'logging_param', 'data', 'exp_name_log', 'n_jobs_param', 'X_train', 'y_test', 'fold_shuffle_param', 'X_test', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'memory', 'html_param', 'fold_groups_param', 'X', 'transform_target_param', '_available_plots', 'log_plots_param', 'USI', 'exp_id', 'idx', 'y_train'}
2024-05-24 14:30:14,853:INFO:Checking environment
2024-05-24 14:30:14,853:INFO:python_version: 3.10.14
2024-05-24 14:30:14,853:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 14:30:14,853:INFO:machine: AMD64
2024-05-24 14:30:14,853:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 14:30:14,854:INFO:Memory: svmem(total=16541802496, available=3345960960, percent=79.8, used=13195841536, free=3345960960)
2024-05-24 14:30:14,854:INFO:Physical Core: 6
2024-05-24 14:30:14,854:INFO:Logical Core: 12
2024-05-24 14:30:14,854:INFO:Checking libraries
2024-05-24 14:30:14,854:INFO:System:
2024-05-24 14:30:14,855:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 14:30:14,855:INFO:executable: C:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 14:30:14,856:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 14:30:14,857:INFO:PyCaret required dependencies:
2024-05-24 14:30:14,859:INFO:                 pip: 24.0
2024-05-24 14:30:14,859:INFO:          setuptools: 69.5.1
2024-05-24 14:30:14,859:INFO:             pycaret: 3.3.2
2024-05-24 14:30:14,859:INFO:             IPython: 8.20.0
2024-05-24 14:30:14,859:INFO:          ipywidgets: 8.1.2
2024-05-24 14:30:14,859:INFO:                tqdm: 4.66.4
2024-05-24 14:30:14,859:INFO:               numpy: 1.26.4
2024-05-24 14:30:14,859:INFO:              pandas: 2.1.4
2024-05-24 14:30:14,859:INFO:              jinja2: 3.1.3
2024-05-24 14:30:14,859:INFO:               scipy: 1.11.4
2024-05-24 14:30:14,859:INFO:              joblib: 1.3.2
2024-05-24 14:30:14,859:INFO:             sklearn: 1.4.2
2024-05-24 14:30:14,859:INFO:                pyod: 1.1.3
2024-05-24 14:30:14,859:INFO:            imblearn: 0.12.2
2024-05-24 14:30:14,859:INFO:   category_encoders: 2.6.3
2024-05-24 14:30:14,859:INFO:            lightgbm: 4.3.0
2024-05-24 14:30:14,859:INFO:               numba: 0.59.1
2024-05-24 14:30:14,859:INFO:            requests: 2.32.2
2024-05-24 14:30:14,859:INFO:          matplotlib: 3.7.5
2024-05-24 14:30:14,859:INFO:          scikitplot: 0.3.7
2024-05-24 14:30:14,859:INFO:         yellowbrick: 1.5
2024-05-24 14:30:14,859:INFO:              plotly: 5.22.0
2024-05-24 14:30:14,859:INFO:    plotly-resampler: Not installed
2024-05-24 14:30:14,859:INFO:             kaleido: 0.2.1
2024-05-24 14:30:14,860:INFO:           schemdraw: 0.15
2024-05-24 14:30:14,860:INFO:         statsmodels: 0.14.2
2024-05-24 14:30:14,860:INFO:              sktime: 0.26.0
2024-05-24 14:30:14,860:INFO:               tbats: 1.1.3
2024-05-24 14:30:14,860:INFO:            pmdarima: 2.0.4
2024-05-24 14:30:14,860:INFO:              psutil: 5.9.0
2024-05-24 14:30:14,860:INFO:          markupsafe: 2.1.3
2024-05-24 14:30:14,860:INFO:             pickle5: Not installed
2024-05-24 14:30:14,860:INFO:         cloudpickle: 3.0.0
2024-05-24 14:30:14,860:INFO:         deprecation: 2.1.0
2024-05-24 14:30:14,860:INFO:              xxhash: 3.4.1
2024-05-24 14:30:14,860:INFO:           wurlitzer: Not installed
2024-05-24 14:30:14,860:INFO:PyCaret optional dependencies:
2024-05-24 14:30:14,860:INFO:                shap: Not installed
2024-05-24 14:30:14,860:INFO:           interpret: Not installed
2024-05-24 14:30:14,860:INFO:                umap: Not installed
2024-05-24 14:30:14,860:INFO:     ydata_profiling: Not installed
2024-05-24 14:30:14,860:INFO:  explainerdashboard: Not installed
2024-05-24 14:30:14,860:INFO:             autoviz: Not installed
2024-05-24 14:30:14,860:INFO:           fairlearn: Not installed
2024-05-24 14:30:14,860:INFO:          deepchecks: Not installed
2024-05-24 14:30:14,860:INFO:             xgboost: Not installed
2024-05-24 14:30:14,860:INFO:            catboost: Not installed
2024-05-24 14:30:14,860:INFO:              kmodes: Not installed
2024-05-24 14:30:14,860:INFO:             mlxtend: Not installed
2024-05-24 14:30:14,860:INFO:       statsforecast: Not installed
2024-05-24 14:30:14,860:INFO:        tune_sklearn: Not installed
2024-05-24 14:30:14,860:INFO:                 ray: Not installed
2024-05-24 14:30:14,860:INFO:            hyperopt: Not installed
2024-05-24 14:30:14,860:INFO:              optuna: Not installed
2024-05-24 14:30:14,860:INFO:               skopt: Not installed
2024-05-24 14:30:14,860:INFO:              mlflow: Not installed
2024-05-24 14:30:14,860:INFO:              gradio: Not installed
2024-05-24 14:30:14,860:INFO:             fastapi: Not installed
2024-05-24 14:30:14,862:INFO:             uvicorn: Not installed
2024-05-24 14:30:14,862:INFO:              m2cgen: Not installed
2024-05-24 14:30:14,862:INFO:           evidently: Not installed
2024-05-24 14:30:14,862:INFO:               fugue: Not installed
2024-05-24 14:30:14,862:INFO:           streamlit: Not installed
2024-05-24 14:30:14,862:INFO:             prophet: Not installed
2024-05-24 14:30:14,862:INFO:None
2024-05-24 14:30:14,862:INFO:Set up data.
2024-05-24 14:30:14,873:INFO:Set up folding strategy.
2024-05-24 14:30:14,873:INFO:Set up train/test split.
2024-05-24 14:30:14,880:INFO:Set up index.
2024-05-24 14:30:14,880:INFO:Assigning column types.
2024-05-24 14:30:14,884:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 14:30:14,884:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:30:14,889:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:30:14,896:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:30:14,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,041:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,046:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,169:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 14:30:15,173:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,178:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,309:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,440:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 14:30:15,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,588:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,710:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 14:30:15,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:15,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:15,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:16,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:30:16,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,009:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 14:30:16,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:16,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:30:16,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,265:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 14:30:16,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:16,494:INFO:Preparing preprocessing pipeline...
2024-05-24 14:30:16,494:INFO:Set up simple imputation.
2024-05-24 14:30:16,499:INFO:Set up encoding of ordinal features.
2024-05-24 14:30:16,506:INFO:Set up encoding of categorical features.
2024-05-24 14:30:16,699:INFO:Finished creating preprocessing pipeline.
2024-05-24 14:30:16,776:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['car_ID', 'symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('cat...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 14:30:16,776:INFO:Creating final display dataframe.
2024-05-24 14:30:17,288:INFO:Setup _display_container:                     Description             Value
0                    Session id              1042
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 26)
4        Transformed data shape         (205, 48)
5   Transformed train set shape         (143, 48)
6    Transformed test set shape          (62, 48)
7              Numeric features                15
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              2728
2024-05-24 14:30:17,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:17,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:17,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:17,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:30:17,561:INFO:setup() successfully completed in 2.71s...............
2024-05-24 14:30:20,857:INFO:Initializing compare_models()
2024-05-24 14:30:20,857:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:30:20,857:INFO:Checking exceptions
2024-05-24 14:30:20,861:INFO:Preparing display monitor
2024-05-24 14:30:20,889:INFO:Initializing Linear Regression
2024-05-24 14:30:20,889:INFO:Total runtime is 0.0 minutes
2024-05-24 14:30:20,894:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:20,894:INFO:Initializing create_model()
2024-05-24 14:30:20,895:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=lr, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:20,895:INFO:Checking exceptions
2024-05-24 14:30:20,895:INFO:Importing libraries
2024-05-24 14:30:20,895:INFO:Copying training dataset
2024-05-24 14:30:20,904:INFO:Defining folds
2024-05-24 14:30:20,904:INFO:Declaring metric variables
2024-05-24 14:30:20,908:INFO:Importing untrained model
2024-05-24 14:30:20,912:INFO:Linear Regression Imported successfully
2024-05-24 14:30:20,920:INFO:Starting cross validation
2024-05-24 14:30:20,924:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:21,141:INFO:Calculating mean and std
2024-05-24 14:30:21,141:INFO:Creating metrics dataframe
2024-05-24 14:30:21,143:INFO:Uploading results into container
2024-05-24 14:30:21,143:INFO:Uploading model into container now
2024-05-24 14:30:21,144:INFO:_master_model_container: 1
2024-05-24 14:30:21,144:INFO:_display_container: 2
2024-05-24 14:30:21,144:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:30:21,144:INFO:create_model() successfully completed......................................
2024-05-24 14:30:21,268:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:21,269:INFO:Creating metrics dataframe
2024-05-24 14:30:21,276:INFO:Initializing Lasso Regression
2024-05-24 14:30:21,276:INFO:Total runtime is 0.006453335285186768 minutes
2024-05-24 14:30:21,280:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:21,280:INFO:Initializing create_model()
2024-05-24 14:30:21,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=lasso, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:21,280:INFO:Checking exceptions
2024-05-24 14:30:21,280:INFO:Importing libraries
2024-05-24 14:30:21,281:INFO:Copying training dataset
2024-05-24 14:30:21,286:INFO:Defining folds
2024-05-24 14:30:21,286:INFO:Declaring metric variables
2024-05-24 14:30:21,290:INFO:Importing untrained model
2024-05-24 14:30:21,293:INFO:Lasso Regression Imported successfully
2024-05-24 14:30:21,302:INFO:Starting cross validation
2024-05-24 14:30:21,304:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:21,474:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+07, tolerance: 8.516e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:30:21,534:INFO:Calculating mean and std
2024-05-24 14:30:21,535:INFO:Creating metrics dataframe
2024-05-24 14:30:21,537:INFO:Uploading results into container
2024-05-24 14:30:21,537:INFO:Uploading model into container now
2024-05-24 14:30:21,537:INFO:_master_model_container: 2
2024-05-24 14:30:21,537:INFO:_display_container: 2
2024-05-24 14:30:21,538:INFO:Lasso(random_state=1042)
2024-05-24 14:30:21,538:INFO:create_model() successfully completed......................................
2024-05-24 14:30:21,655:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:21,655:INFO:Creating metrics dataframe
2024-05-24 14:30:21,663:INFO:Initializing Ridge Regression
2024-05-24 14:30:21,663:INFO:Total runtime is 0.012897562980651856 minutes
2024-05-24 14:30:21,669:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:21,669:INFO:Initializing create_model()
2024-05-24 14:30:21,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=ridge, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:21,670:INFO:Checking exceptions
2024-05-24 14:30:21,670:INFO:Importing libraries
2024-05-24 14:30:21,670:INFO:Copying training dataset
2024-05-24 14:30:21,678:INFO:Defining folds
2024-05-24 14:30:21,678:INFO:Declaring metric variables
2024-05-24 14:30:21,683:INFO:Importing untrained model
2024-05-24 14:30:21,689:INFO:Ridge Regression Imported successfully
2024-05-24 14:30:21,695:INFO:Starting cross validation
2024-05-24 14:30:21,698:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:21,908:INFO:Calculating mean and std
2024-05-24 14:30:21,909:INFO:Creating metrics dataframe
2024-05-24 14:30:21,912:INFO:Uploading results into container
2024-05-24 14:30:21,912:INFO:Uploading model into container now
2024-05-24 14:30:21,913:INFO:_master_model_container: 3
2024-05-24 14:30:21,913:INFO:_display_container: 2
2024-05-24 14:30:21,914:INFO:Ridge(random_state=1042)
2024-05-24 14:30:21,914:INFO:create_model() successfully completed......................................
2024-05-24 14:30:22,036:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:22,036:INFO:Creating metrics dataframe
2024-05-24 14:30:22,042:INFO:Initializing Elastic Net
2024-05-24 14:30:22,042:INFO:Total runtime is 0.019215039412180585 minutes
2024-05-24 14:30:22,045:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:22,045:INFO:Initializing create_model()
2024-05-24 14:30:22,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=en, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:22,046:INFO:Checking exceptions
2024-05-24 14:30:22,046:INFO:Importing libraries
2024-05-24 14:30:22,046:INFO:Copying training dataset
2024-05-24 14:30:22,051:INFO:Defining folds
2024-05-24 14:30:22,051:INFO:Declaring metric variables
2024-05-24 14:30:22,055:INFO:Importing untrained model
2024-05-24 14:30:22,058:INFO:Elastic Net Imported successfully
2024-05-24 14:30:22,064:INFO:Starting cross validation
2024-05-24 14:30:22,067:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:22,268:INFO:Calculating mean and std
2024-05-24 14:30:22,269:INFO:Creating metrics dataframe
2024-05-24 14:30:22,271:INFO:Uploading results into container
2024-05-24 14:30:22,271:INFO:Uploading model into container now
2024-05-24 14:30:22,272:INFO:_master_model_container: 4
2024-05-24 14:30:22,272:INFO:_display_container: 2
2024-05-24 14:30:22,272:INFO:ElasticNet(random_state=1042)
2024-05-24 14:30:22,272:INFO:create_model() successfully completed......................................
2024-05-24 14:30:22,391:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:22,391:INFO:Creating metrics dataframe
2024-05-24 14:30:22,397:INFO:Initializing Least Angle Regression
2024-05-24 14:30:22,397:INFO:Total runtime is 0.025143039226531983 minutes
2024-05-24 14:30:22,401:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:22,402:INFO:Initializing create_model()
2024-05-24 14:30:22,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=lar, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:22,402:INFO:Checking exceptions
2024-05-24 14:30:22,402:INFO:Importing libraries
2024-05-24 14:30:22,402:INFO:Copying training dataset
2024-05-24 14:30:22,408:INFO:Defining folds
2024-05-24 14:30:22,408:INFO:Declaring metric variables
2024-05-24 14:30:22,411:INFO:Importing untrained model
2024-05-24 14:30:22,416:INFO:Least Angle Regression Imported successfully
2024-05-24 14:30:22,425:INFO:Starting cross validation
2024-05-24 14:30:22,429:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:22,543:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.096e+01, with an active set of 25 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,544:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.823e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,545:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.386e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,546:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.016e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,547:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.348e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,547:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.081e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,547:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.080e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,550:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.394e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,552:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.847e+03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,552:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=6.770e+03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,575:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.931e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,626:INFO:Calculating mean and std
2024-05-24 14:30:22,628:INFO:Creating metrics dataframe
2024-05-24 14:30:22,630:INFO:Uploading results into container
2024-05-24 14:30:22,630:INFO:Uploading model into container now
2024-05-24 14:30:22,631:INFO:_master_model_container: 5
2024-05-24 14:30:22,631:INFO:_display_container: 2
2024-05-24 14:30:22,631:INFO:Lars(random_state=1042)
2024-05-24 14:30:22,631:INFO:create_model() successfully completed......................................
2024-05-24 14:30:22,752:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:22,753:INFO:Creating metrics dataframe
2024-05-24 14:30:22,761:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:30:22,761:INFO:Total runtime is 0.031205852826436363 minutes
2024-05-24 14:30:22,765:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:22,765:INFO:Initializing create_model()
2024-05-24 14:30:22,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=llar, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:22,766:INFO:Checking exceptions
2024-05-24 14:30:22,766:INFO:Importing libraries
2024-05-24 14:30:22,766:INFO:Copying training dataset
2024-05-24 14:30:22,773:INFO:Defining folds
2024-05-24 14:30:22,773:INFO:Declaring metric variables
2024-05-24 14:30:22,776:INFO:Importing untrained model
2024-05-24 14:30:22,780:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:30:22,789:INFO:Starting cross validation
2024-05-24 14:30:22,792:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:22,911:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.322e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,911:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.929e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,912:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.661e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,912:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.661e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,918:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=4.329e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,920:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.252e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,936:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.516e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,936:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.516e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,938:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.258e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,938:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.232e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,938:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.717e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:30:22,939:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=2.239e+00, previous alpha=1.605e+00, with an active set of 38 regressors.
  warnings.warn(

2024-05-24 14:30:23,000:INFO:Calculating mean and std
2024-05-24 14:30:23,001:INFO:Creating metrics dataframe
2024-05-24 14:30:23,004:INFO:Uploading results into container
2024-05-24 14:30:23,004:INFO:Uploading model into container now
2024-05-24 14:30:23,005:INFO:_master_model_container: 6
2024-05-24 14:30:23,005:INFO:_display_container: 2
2024-05-24 14:30:23,006:INFO:LassoLars(random_state=1042)
2024-05-24 14:30:23,006:INFO:create_model() successfully completed......................................
2024-05-24 14:30:23,138:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:23,138:INFO:Creating metrics dataframe
2024-05-24 14:30:23,146:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:30:23,146:INFO:Total runtime is 0.037624017397562666 minutes
2024-05-24 14:30:23,150:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:23,150:INFO:Initializing create_model()
2024-05-24 14:30:23,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=omp, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:23,151:INFO:Checking exceptions
2024-05-24 14:30:23,151:INFO:Importing libraries
2024-05-24 14:30:23,151:INFO:Copying training dataset
2024-05-24 14:30:23,160:INFO:Defining folds
2024-05-24 14:30:23,160:INFO:Declaring metric variables
2024-05-24 14:30:23,164:INFO:Importing untrained model
2024-05-24 14:30:23,169:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:30:23,177:INFO:Starting cross validation
2024-05-24 14:30:23,180:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:23,391:INFO:Calculating mean and std
2024-05-24 14:30:23,392:INFO:Creating metrics dataframe
2024-05-24 14:30:23,395:INFO:Uploading results into container
2024-05-24 14:30:23,395:INFO:Uploading model into container now
2024-05-24 14:30:23,397:INFO:_master_model_container: 7
2024-05-24 14:30:23,397:INFO:_display_container: 2
2024-05-24 14:30:23,397:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:30:23,397:INFO:create_model() successfully completed......................................
2024-05-24 14:30:23,523:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:23,523:INFO:Creating metrics dataframe
2024-05-24 14:30:23,533:INFO:Initializing Bayesian Ridge
2024-05-24 14:30:23,533:INFO:Total runtime is 0.044062236944834396 minutes
2024-05-24 14:30:23,536:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:23,537:INFO:Initializing create_model()
2024-05-24 14:30:23,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=br, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:23,537:INFO:Checking exceptions
2024-05-24 14:30:23,537:INFO:Importing libraries
2024-05-24 14:30:23,537:INFO:Copying training dataset
2024-05-24 14:30:23,546:INFO:Defining folds
2024-05-24 14:30:23,546:INFO:Declaring metric variables
2024-05-24 14:30:23,551:INFO:Importing untrained model
2024-05-24 14:30:23,554:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:30:23,563:INFO:Starting cross validation
2024-05-24 14:30:23,567:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:23,797:INFO:Calculating mean and std
2024-05-24 14:30:23,799:INFO:Creating metrics dataframe
2024-05-24 14:30:23,801:INFO:Uploading results into container
2024-05-24 14:30:23,802:INFO:Uploading model into container now
2024-05-24 14:30:23,802:INFO:_master_model_container: 8
2024-05-24 14:30:23,802:INFO:_display_container: 2
2024-05-24 14:30:23,803:INFO:BayesianRidge()
2024-05-24 14:30:23,803:INFO:create_model() successfully completed......................................
2024-05-24 14:30:23,920:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:23,920:INFO:Creating metrics dataframe
2024-05-24 14:30:23,927:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:30:23,928:INFO:Total runtime is 0.05066123008728028 minutes
2024-05-24 14:30:23,931:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:23,931:INFO:Initializing create_model()
2024-05-24 14:30:23,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=par, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:23,931:INFO:Checking exceptions
2024-05-24 14:30:23,933:INFO:Importing libraries
2024-05-24 14:30:23,933:INFO:Copying training dataset
2024-05-24 14:30:23,940:INFO:Defining folds
2024-05-24 14:30:23,940:INFO:Declaring metric variables
2024-05-24 14:30:23,945:INFO:Importing untrained model
2024-05-24 14:30:23,949:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:30:23,956:INFO:Starting cross validation
2024-05-24 14:30:23,959:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:24,110:INFO:Calculating mean and std
2024-05-24 14:30:24,112:INFO:Creating metrics dataframe
2024-05-24 14:30:24,115:INFO:Uploading results into container
2024-05-24 14:30:24,115:INFO:Uploading model into container now
2024-05-24 14:30:24,116:INFO:_master_model_container: 9
2024-05-24 14:30:24,116:INFO:_display_container: 2
2024-05-24 14:30:24,116:INFO:PassiveAggressiveRegressor(random_state=1042)
2024-05-24 14:30:24,116:INFO:create_model() successfully completed......................................
2024-05-24 14:30:24,238:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:24,238:INFO:Creating metrics dataframe
2024-05-24 14:30:24,249:INFO:Initializing Huber Regressor
2024-05-24 14:30:24,249:INFO:Total runtime is 0.05599836111068726 minutes
2024-05-24 14:30:24,253:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:24,253:INFO:Initializing create_model()
2024-05-24 14:30:24,253:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=huber, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:24,253:INFO:Checking exceptions
2024-05-24 14:30:24,253:INFO:Importing libraries
2024-05-24 14:30:24,254:INFO:Copying training dataset
2024-05-24 14:30:24,259:INFO:Defining folds
2024-05-24 14:30:24,259:INFO:Declaring metric variables
2024-05-24 14:30:24,264:INFO:Importing untrained model
2024-05-24 14:30:24,269:INFO:Huber Regressor Imported successfully
2024-05-24 14:30:24,276:INFO:Starting cross validation
2024-05-24 14:30:24,280:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:24,407:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:30:24,410:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:30:24,436:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:30:24,487:INFO:Calculating mean and std
2024-05-24 14:30:24,488:INFO:Creating metrics dataframe
2024-05-24 14:30:24,490:INFO:Uploading results into container
2024-05-24 14:30:24,491:INFO:Uploading model into container now
2024-05-24 14:30:24,491:INFO:_master_model_container: 10
2024-05-24 14:30:24,491:INFO:_display_container: 2
2024-05-24 14:30:24,492:INFO:HuberRegressor()
2024-05-24 14:30:24,492:INFO:create_model() successfully completed......................................
2024-05-24 14:30:24,607:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:24,608:INFO:Creating metrics dataframe
2024-05-24 14:30:24,618:INFO:Initializing K Neighbors Regressor
2024-05-24 14:30:24,618:INFO:Total runtime is 0.06215970118840536 minutes
2024-05-24 14:30:24,622:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:24,622:INFO:Initializing create_model()
2024-05-24 14:30:24,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=knn, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:24,623:INFO:Checking exceptions
2024-05-24 14:30:24,623:INFO:Importing libraries
2024-05-24 14:30:24,623:INFO:Copying training dataset
2024-05-24 14:30:24,628:INFO:Defining folds
2024-05-24 14:30:24,628:INFO:Declaring metric variables
2024-05-24 14:30:24,634:INFO:Importing untrained model
2024-05-24 14:30:24,640:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:30:24,647:INFO:Starting cross validation
2024-05-24 14:30:24,650:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:24,848:INFO:Calculating mean and std
2024-05-24 14:30:24,849:INFO:Creating metrics dataframe
2024-05-24 14:30:24,851:INFO:Uploading results into container
2024-05-24 14:30:24,852:INFO:Uploading model into container now
2024-05-24 14:30:24,852:INFO:_master_model_container: 11
2024-05-24 14:30:24,853:INFO:_display_container: 2
2024-05-24 14:30:24,853:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:30:24,853:INFO:create_model() successfully completed......................................
2024-05-24 14:30:24,970:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:24,970:INFO:Creating metrics dataframe
2024-05-24 14:30:24,980:INFO:Initializing Decision Tree Regressor
2024-05-24 14:30:24,980:INFO:Total runtime is 0.06818603277206421 minutes
2024-05-24 14:30:24,983:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:24,984:INFO:Initializing create_model()
2024-05-24 14:30:24,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=dt, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:24,984:INFO:Checking exceptions
2024-05-24 14:30:24,984:INFO:Importing libraries
2024-05-24 14:30:24,984:INFO:Copying training dataset
2024-05-24 14:30:24,992:INFO:Defining folds
2024-05-24 14:30:24,992:INFO:Declaring metric variables
2024-05-24 14:30:24,996:INFO:Importing untrained model
2024-05-24 14:30:25,000:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:30:25,012:INFO:Starting cross validation
2024-05-24 14:30:25,016:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:25,243:INFO:Calculating mean and std
2024-05-24 14:30:25,244:INFO:Creating metrics dataframe
2024-05-24 14:30:25,246:INFO:Uploading results into container
2024-05-24 14:30:25,246:INFO:Uploading model into container now
2024-05-24 14:30:25,246:INFO:_master_model_container: 12
2024-05-24 14:30:25,247:INFO:_display_container: 2
2024-05-24 14:30:25,247:INFO:DecisionTreeRegressor(random_state=1042)
2024-05-24 14:30:25,247:INFO:create_model() successfully completed......................................
2024-05-24 14:30:25,381:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:25,381:INFO:Creating metrics dataframe
2024-05-24 14:30:25,392:INFO:Initializing Random Forest Regressor
2024-05-24 14:30:25,392:INFO:Total runtime is 0.07505263090133667 minutes
2024-05-24 14:30:25,396:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:25,396:INFO:Initializing create_model()
2024-05-24 14:30:25,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=rf, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:25,396:INFO:Checking exceptions
2024-05-24 14:30:25,396:INFO:Importing libraries
2024-05-24 14:30:25,397:INFO:Copying training dataset
2024-05-24 14:30:25,405:INFO:Defining folds
2024-05-24 14:30:25,405:INFO:Declaring metric variables
2024-05-24 14:30:25,410:INFO:Importing untrained model
2024-05-24 14:30:25,415:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:30:25,424:INFO:Starting cross validation
2024-05-24 14:30:25,428:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:25,822:INFO:Calculating mean and std
2024-05-24 14:30:25,823:INFO:Creating metrics dataframe
2024-05-24 14:30:25,826:INFO:Uploading results into container
2024-05-24 14:30:25,827:INFO:Uploading model into container now
2024-05-24 14:30:25,827:INFO:_master_model_container: 13
2024-05-24 14:30:25,827:INFO:_display_container: 2
2024-05-24 14:30:25,827:INFO:RandomForestRegressor(n_jobs=-1, random_state=1042)
2024-05-24 14:30:25,828:INFO:create_model() successfully completed......................................
2024-05-24 14:30:25,955:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:25,955:INFO:Creating metrics dataframe
2024-05-24 14:30:25,966:INFO:Initializing Extra Trees Regressor
2024-05-24 14:30:25,966:INFO:Total runtime is 0.08461398681004842 minutes
2024-05-24 14:30:25,969:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:25,969:INFO:Initializing create_model()
2024-05-24 14:30:25,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=et, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:25,970:INFO:Checking exceptions
2024-05-24 14:30:25,970:INFO:Importing libraries
2024-05-24 14:30:25,970:INFO:Copying training dataset
2024-05-24 14:30:25,979:INFO:Defining folds
2024-05-24 14:30:25,980:INFO:Declaring metric variables
2024-05-24 14:30:25,984:INFO:Importing untrained model
2024-05-24 14:30:25,990:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:30:25,998:INFO:Starting cross validation
2024-05-24 14:30:26,001:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:26,287:INFO:Calculating mean and std
2024-05-24 14:30:26,288:INFO:Creating metrics dataframe
2024-05-24 14:30:26,290:INFO:Uploading results into container
2024-05-24 14:30:26,290:INFO:Uploading model into container now
2024-05-24 14:30:26,291:INFO:_master_model_container: 14
2024-05-24 14:30:26,291:INFO:_display_container: 2
2024-05-24 14:30:26,291:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1042)
2024-05-24 14:30:26,291:INFO:create_model() successfully completed......................................
2024-05-24 14:30:26,398:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:26,398:INFO:Creating metrics dataframe
2024-05-24 14:30:26,410:INFO:Initializing AdaBoost Regressor
2024-05-24 14:30:26,410:INFO:Total runtime is 0.09202375411987304 minutes
2024-05-24 14:30:26,413:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:26,414:INFO:Initializing create_model()
2024-05-24 14:30:26,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=ada, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:26,414:INFO:Checking exceptions
2024-05-24 14:30:26,414:INFO:Importing libraries
2024-05-24 14:30:26,414:INFO:Copying training dataset
2024-05-24 14:30:26,423:INFO:Defining folds
2024-05-24 14:30:26,423:INFO:Declaring metric variables
2024-05-24 14:30:26,427:INFO:Importing untrained model
2024-05-24 14:30:26,432:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:30:26,440:INFO:Starting cross validation
2024-05-24 14:30:26,444:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:26,714:INFO:Calculating mean and std
2024-05-24 14:30:26,715:INFO:Creating metrics dataframe
2024-05-24 14:30:26,718:INFO:Uploading results into container
2024-05-24 14:30:26,719:INFO:Uploading model into container now
2024-05-24 14:30:26,719:INFO:_master_model_container: 15
2024-05-24 14:30:26,719:INFO:_display_container: 2
2024-05-24 14:30:26,720:INFO:AdaBoostRegressor(random_state=1042)
2024-05-24 14:30:26,720:INFO:create_model() successfully completed......................................
2024-05-24 14:30:26,837:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:26,838:INFO:Creating metrics dataframe
2024-05-24 14:30:26,848:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:30:26,848:INFO:Total runtime is 0.09931997855504353 minutes
2024-05-24 14:30:26,851:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:26,852:INFO:Initializing create_model()
2024-05-24 14:30:26,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=gbr, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:26,852:INFO:Checking exceptions
2024-05-24 14:30:26,852:INFO:Importing libraries
2024-05-24 14:30:26,852:INFO:Copying training dataset
2024-05-24 14:30:26,860:INFO:Defining folds
2024-05-24 14:30:26,860:INFO:Declaring metric variables
2024-05-24 14:30:26,864:INFO:Importing untrained model
2024-05-24 14:30:26,868:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:30:26,877:INFO:Starting cross validation
2024-05-24 14:30:26,880:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:27,167:INFO:Calculating mean and std
2024-05-24 14:30:27,168:INFO:Creating metrics dataframe
2024-05-24 14:30:27,171:INFO:Uploading results into container
2024-05-24 14:30:27,171:INFO:Uploading model into container now
2024-05-24 14:30:27,172:INFO:_master_model_container: 16
2024-05-24 14:30:27,172:INFO:_display_container: 2
2024-05-24 14:30:27,172:INFO:GradientBoostingRegressor(random_state=1042)
2024-05-24 14:30:27,173:INFO:create_model() successfully completed......................................
2024-05-24 14:30:27,295:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:27,296:INFO:Creating metrics dataframe
2024-05-24 14:30:27,308:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:30:27,308:INFO:Total runtime is 0.10697914361953734 minutes
2024-05-24 14:30:27,312:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:27,313:INFO:Initializing create_model()
2024-05-24 14:30:27,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=lightgbm, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:27,313:INFO:Checking exceptions
2024-05-24 14:30:27,313:INFO:Importing libraries
2024-05-24 14:30:27,313:INFO:Copying training dataset
2024-05-24 14:30:27,324:INFO:Defining folds
2024-05-24 14:30:27,324:INFO:Declaring metric variables
2024-05-24 14:30:27,329:INFO:Importing untrained model
2024-05-24 14:30:27,333:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:30:27,342:INFO:Starting cross validation
2024-05-24 14:30:27,346:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:27,651:INFO:Calculating mean and std
2024-05-24 14:30:27,652:INFO:Creating metrics dataframe
2024-05-24 14:30:27,655:INFO:Uploading results into container
2024-05-24 14:30:27,656:INFO:Uploading model into container now
2024-05-24 14:30:27,657:INFO:_master_model_container: 17
2024-05-24 14:30:27,657:INFO:_display_container: 2
2024-05-24 14:30:27,657:INFO:LGBMRegressor(n_jobs=-1, random_state=1042)
2024-05-24 14:30:27,658:INFO:create_model() successfully completed......................................
2024-05-24 14:30:27,801:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:27,801:INFO:Creating metrics dataframe
2024-05-24 14:30:27,815:INFO:Initializing Dummy Regressor
2024-05-24 14:30:27,815:INFO:Total runtime is 0.11543185710906981 minutes
2024-05-24 14:30:27,819:INFO:SubProcess create_model() called ==================================
2024-05-24 14:30:27,820:INFO:Initializing create_model()
2024-05-24 14:30:27,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=dummy, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9B312C460>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:27,820:INFO:Checking exceptions
2024-05-24 14:30:27,820:INFO:Importing libraries
2024-05-24 14:30:27,820:INFO:Copying training dataset
2024-05-24 14:30:27,827:INFO:Defining folds
2024-05-24 14:30:27,828:INFO:Declaring metric variables
2024-05-24 14:30:27,833:INFO:Importing untrained model
2024-05-24 14:30:27,839:INFO:Dummy Regressor Imported successfully
2024-05-24 14:30:27,848:INFO:Starting cross validation
2024-05-24 14:30:27,852:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:30:28,039:INFO:Calculating mean and std
2024-05-24 14:30:28,040:INFO:Creating metrics dataframe
2024-05-24 14:30:28,041:INFO:Uploading results into container
2024-05-24 14:30:28,042:INFO:Uploading model into container now
2024-05-24 14:30:28,042:INFO:_master_model_container: 18
2024-05-24 14:30:28,042:INFO:_display_container: 2
2024-05-24 14:30:28,043:INFO:DummyRegressor()
2024-05-24 14:30:28,043:INFO:create_model() successfully completed......................................
2024-05-24 14:30:28,146:INFO:SubProcess create_model() end ==================================
2024-05-24 14:30:28,146:INFO:Creating metrics dataframe
2024-05-24 14:30:28,157:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:30:28,165:INFO:Initializing create_model()
2024-05-24 14:30:28,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D071BEB0>, estimator=HuberRegressor(), fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:30:28,165:INFO:Checking exceptions
2024-05-24 14:30:28,166:INFO:Importing libraries
2024-05-24 14:30:28,166:INFO:Copying training dataset
2024-05-24 14:30:28,174:INFO:Defining folds
2024-05-24 14:30:28,175:INFO:Declaring metric variables
2024-05-24 14:30:28,175:INFO:Importing untrained model
2024-05-24 14:30:28,175:INFO:Declaring custom model
2024-05-24 14:30:28,175:INFO:Huber Regressor Imported successfully
2024-05-24 14:30:28,178:INFO:Cross validation set to False
2024-05-24 14:30:28,178:INFO:Fitting Model
2024-05-24 14:30:28,286:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:30:28,287:INFO:HuberRegressor()
2024-05-24 14:30:28,287:INFO:create_model() successfully completed......................................
2024-05-24 14:30:28,454:INFO:_master_model_container: 18
2024-05-24 14:30:28,456:INFO:_display_container: 2
2024-05-24 14:30:28,456:INFO:HuberRegressor()
2024-05-24 14:30:28,456:INFO:compare_models() successfully completed......................................
2024-05-24 14:40:26,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:40:26,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:40:26,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:40:26,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 14:40:26,664:INFO:PyCaret RegressionExperiment
2024-05-24 14:40:26,665:INFO:Logging name: reg-default-name
2024-05-24 14:40:26,665:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 14:40:26,665:INFO:version 3.3.2
2024-05-24 14:40:26,665:INFO:Initializing setup()
2024-05-24 14:40:26,665:INFO:self.USI: d710
2024-05-24 14:40:26,665:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 14:40:26,665:INFO:Checking environment
2024-05-24 14:40:26,665:INFO:python_version: 3.10.14
2024-05-24 14:40:26,665:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 14:40:26,665:INFO:machine: AMD64
2024-05-24 14:40:26,666:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 14:40:26,666:INFO:Memory: svmem(total=16541802496, available=1768886272, percent=89.3, used=14772916224, free=1768886272)
2024-05-24 14:40:26,666:INFO:Physical Core: 6
2024-05-24 14:40:26,666:INFO:Logical Core: 12
2024-05-24 14:40:26,666:INFO:Checking libraries
2024-05-24 14:40:26,666:INFO:System:
2024-05-24 14:40:26,666:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 14:40:26,666:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 14:40:26,666:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 14:40:26,666:INFO:PyCaret required dependencies:
2024-05-24 14:40:26,701:INFO:                 pip: 24.0
2024-05-24 14:40:26,701:INFO:          setuptools: 69.5.1
2024-05-24 14:40:26,701:INFO:             pycaret: 3.3.2
2024-05-24 14:40:26,701:INFO:             IPython: 8.20.0
2024-05-24 14:40:26,701:INFO:          ipywidgets: 8.1.2
2024-05-24 14:40:26,701:INFO:                tqdm: 4.66.4
2024-05-24 14:40:26,701:INFO:               numpy: 1.26.4
2024-05-24 14:40:26,701:INFO:              pandas: 2.1.4
2024-05-24 14:40:26,701:INFO:              jinja2: 3.1.3
2024-05-24 14:40:26,702:INFO:               scipy: 1.11.4
2024-05-24 14:40:26,702:INFO:              joblib: 1.3.2
2024-05-24 14:40:26,702:INFO:             sklearn: 1.4.2
2024-05-24 14:40:26,702:INFO:                pyod: 1.1.3
2024-05-24 14:40:26,702:INFO:            imblearn: 0.12.2
2024-05-24 14:40:26,702:INFO:   category_encoders: 2.6.3
2024-05-24 14:40:26,702:INFO:            lightgbm: 4.3.0
2024-05-24 14:40:26,702:INFO:               numba: 0.59.1
2024-05-24 14:40:26,702:INFO:            requests: 2.32.2
2024-05-24 14:40:26,702:INFO:          matplotlib: 3.7.5
2024-05-24 14:40:26,702:INFO:          scikitplot: 0.3.7
2024-05-24 14:40:26,702:INFO:         yellowbrick: 1.5
2024-05-24 14:40:26,702:INFO:              plotly: 5.22.0
2024-05-24 14:40:26,702:INFO:    plotly-resampler: Not installed
2024-05-24 14:40:26,702:INFO:             kaleido: 0.2.1
2024-05-24 14:40:26,702:INFO:           schemdraw: 0.15
2024-05-24 14:40:26,702:INFO:         statsmodels: 0.14.2
2024-05-24 14:40:26,702:INFO:              sktime: 0.26.0
2024-05-24 14:40:26,702:INFO:               tbats: 1.1.3
2024-05-24 14:40:26,702:INFO:            pmdarima: 2.0.4
2024-05-24 14:40:26,702:INFO:              psutil: 5.9.0
2024-05-24 14:40:26,702:INFO:          markupsafe: 2.1.3
2024-05-24 14:40:26,702:INFO:             pickle5: Not installed
2024-05-24 14:40:26,702:INFO:         cloudpickle: 3.0.0
2024-05-24 14:40:26,702:INFO:         deprecation: 2.1.0
2024-05-24 14:40:26,702:INFO:              xxhash: 3.4.1
2024-05-24 14:40:26,702:INFO:           wurlitzer: Not installed
2024-05-24 14:40:26,702:INFO:PyCaret optional dependencies:
2024-05-24 14:40:26,717:INFO:                shap: Not installed
2024-05-24 14:40:26,717:INFO:           interpret: Not installed
2024-05-24 14:40:26,718:INFO:                umap: Not installed
2024-05-24 14:40:26,718:INFO:     ydata_profiling: Not installed
2024-05-24 14:40:26,718:INFO:  explainerdashboard: Not installed
2024-05-24 14:40:26,718:INFO:             autoviz: Not installed
2024-05-24 14:40:26,718:INFO:           fairlearn: Not installed
2024-05-24 14:40:26,718:INFO:          deepchecks: Not installed
2024-05-24 14:40:26,718:INFO:             xgboost: Not installed
2024-05-24 14:40:26,718:INFO:            catboost: Not installed
2024-05-24 14:40:26,718:INFO:              kmodes: Not installed
2024-05-24 14:40:26,718:INFO:             mlxtend: Not installed
2024-05-24 14:40:26,718:INFO:       statsforecast: Not installed
2024-05-24 14:40:26,718:INFO:        tune_sklearn: Not installed
2024-05-24 14:40:26,718:INFO:                 ray: Not installed
2024-05-24 14:40:26,718:INFO:            hyperopt: Not installed
2024-05-24 14:40:26,719:INFO:              optuna: Not installed
2024-05-24 14:40:26,719:INFO:               skopt: Not installed
2024-05-24 14:40:26,719:INFO:              mlflow: Not installed
2024-05-24 14:40:26,719:INFO:              gradio: Not installed
2024-05-24 14:40:26,719:INFO:             fastapi: Not installed
2024-05-24 14:40:26,719:INFO:             uvicorn: Not installed
2024-05-24 14:40:26,719:INFO:              m2cgen: Not installed
2024-05-24 14:40:26,719:INFO:           evidently: Not installed
2024-05-24 14:40:26,719:INFO:               fugue: Not installed
2024-05-24 14:40:26,719:INFO:           streamlit: Not installed
2024-05-24 14:40:26,719:INFO:             prophet: Not installed
2024-05-24 14:40:26,719:INFO:None
2024-05-24 14:40:26,719:INFO:Set up data.
2024-05-24 14:40:26,740:INFO:Set up folding strategy.
2024-05-24 14:40:26,741:INFO:Set up train/test split.
2024-05-24 14:40:26,756:INFO:Set up index.
2024-05-24 14:40:26,756:INFO:Assigning column types.
2024-05-24 14:40:26,766:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 14:40:26,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:40:26,777:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:40:26,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:40:26,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,039:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,048:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,169:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,355:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 14:40:27,362:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,369:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,605:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:27,821:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 14:40:27,837:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:40:27,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,063:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,081:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,352:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 14:40:28,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,667:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:40:28,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:28,769:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 14:40:28,924:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:29,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:40:29,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,224:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 14:40:29,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:29,649:INFO:Preparing preprocessing pipeline...
2024-05-24 14:40:29,649:INFO:Set up simple imputation.
2024-05-24 14:40:29,656:INFO:Set up encoding of ordinal features.
2024-05-24 14:40:29,671:INFO:Set up encoding of categorical features.
2024-05-24 14:40:30,041:INFO:Finished creating preprocessing pipeline.
2024-05-24 14:40:30,121:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['car_ID', 'symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('cat...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 14:40:30,121:INFO:Creating final display dataframe.
2024-05-24 14:40:31,087:INFO:Setup _display_container:                     Description             Value
0                    Session id              3557
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 26)
4        Transformed data shape         (205, 49)
5   Transformed train set shape         (143, 49)
6    Transformed test set shape          (62, 49)
7              Numeric features                15
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d710
2024-05-24 14:40:31,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:31,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:31,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:31,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:40:31,552:INFO:setup() successfully completed in 4.89s...............
2024-05-24 14:40:31,584:INFO:Initializing compare_models()
2024-05-24 14:40:31,584:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:40:31,584:INFO:Checking exceptions
2024-05-24 14:40:31,590:INFO:Preparing display monitor
2024-05-24 14:40:31,650:INFO:Initializing Linear Regression
2024-05-24 14:40:31,650:INFO:Total runtime is 8.805592854817708e-06 minutes
2024-05-24 14:40:31,656:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:31,657:INFO:Initializing create_model()
2024-05-24 14:40:31,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=lr, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:31,657:INFO:Checking exceptions
2024-05-24 14:40:31,657:INFO:Importing libraries
2024-05-24 14:40:31,658:INFO:Copying training dataset
2024-05-24 14:40:31,668:INFO:Defining folds
2024-05-24 14:40:31,668:INFO:Declaring metric variables
2024-05-24 14:40:31,673:INFO:Importing untrained model
2024-05-24 14:40:31,680:INFO:Linear Regression Imported successfully
2024-05-24 14:40:31,694:INFO:Starting cross validation
2024-05-24 14:40:31,708:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:37,106:INFO:Calculating mean and std
2024-05-24 14:40:37,110:INFO:Creating metrics dataframe
2024-05-24 14:40:37,114:INFO:Uploading results into container
2024-05-24 14:40:37,115:INFO:Uploading model into container now
2024-05-24 14:40:37,116:INFO:_master_model_container: 1
2024-05-24 14:40:37,117:INFO:_display_container: 2
2024-05-24 14:40:37,118:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:40:37,118:INFO:create_model() successfully completed......................................
2024-05-24 14:40:37,249:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:37,250:INFO:Creating metrics dataframe
2024-05-24 14:40:37,260:INFO:Initializing Lasso Regression
2024-05-24 14:40:37,261:INFO:Total runtime is 0.09351770083109538 minutes
2024-05-24 14:40:37,271:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:37,272:INFO:Initializing create_model()
2024-05-24 14:40:37,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=lasso, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:37,272:INFO:Checking exceptions
2024-05-24 14:40:37,272:INFO:Importing libraries
2024-05-24 14:40:37,273:INFO:Copying training dataset
2024-05-24 14:40:37,285:INFO:Defining folds
2024-05-24 14:40:37,289:INFO:Declaring metric variables
2024-05-24 14:40:37,295:INFO:Importing untrained model
2024-05-24 14:40:37,303:INFO:Lasso Regression Imported successfully
2024-05-24 14:40:37,320:INFO:Starting cross validation
2024-05-24 14:40:37,323:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:41,285:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.052e+07, tolerance: 5.882e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:40:41,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.547e+06, tolerance: 5.143e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:40:41,432:INFO:Calculating mean and std
2024-05-24 14:40:41,434:INFO:Creating metrics dataframe
2024-05-24 14:40:41,439:INFO:Uploading results into container
2024-05-24 14:40:41,442:INFO:Uploading model into container now
2024-05-24 14:40:41,443:INFO:_master_model_container: 2
2024-05-24 14:40:41,443:INFO:_display_container: 2
2024-05-24 14:40:41,443:INFO:Lasso(random_state=3557)
2024-05-24 14:40:41,443:INFO:create_model() successfully completed......................................
2024-05-24 14:40:41,579:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:41,579:INFO:Creating metrics dataframe
2024-05-24 14:40:41,595:INFO:Initializing Ridge Regression
2024-05-24 14:40:41,595:INFO:Total runtime is 0.16574986378351847 minutes
2024-05-24 14:40:41,602:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:41,603:INFO:Initializing create_model()
2024-05-24 14:40:41,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=ridge, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:41,604:INFO:Checking exceptions
2024-05-24 14:40:41,604:INFO:Importing libraries
2024-05-24 14:40:41,605:INFO:Copying training dataset
2024-05-24 14:40:41,623:INFO:Defining folds
2024-05-24 14:40:41,624:INFO:Declaring metric variables
2024-05-24 14:40:41,635:INFO:Importing untrained model
2024-05-24 14:40:41,649:INFO:Ridge Regression Imported successfully
2024-05-24 14:40:41,666:INFO:Starting cross validation
2024-05-24 14:40:41,673:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:46,247:INFO:Calculating mean and std
2024-05-24 14:40:46,249:INFO:Creating metrics dataframe
2024-05-24 14:40:46,253:INFO:Uploading results into container
2024-05-24 14:40:46,254:INFO:Uploading model into container now
2024-05-24 14:40:46,254:INFO:_master_model_container: 3
2024-05-24 14:40:46,255:INFO:_display_container: 2
2024-05-24 14:40:46,255:INFO:Ridge(random_state=3557)
2024-05-24 14:40:46,255:INFO:create_model() successfully completed......................................
2024-05-24 14:40:46,372:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:46,372:INFO:Creating metrics dataframe
2024-05-24 14:40:46,393:INFO:Initializing Elastic Net
2024-05-24 14:40:46,393:INFO:Total runtime is 0.24572657346725463 minutes
2024-05-24 14:40:46,401:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:46,401:INFO:Initializing create_model()
2024-05-24 14:40:46,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=en, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:46,402:INFO:Checking exceptions
2024-05-24 14:40:46,402:INFO:Importing libraries
2024-05-24 14:40:46,403:INFO:Copying training dataset
2024-05-24 14:40:46,412:INFO:Defining folds
2024-05-24 14:40:46,412:INFO:Declaring metric variables
2024-05-24 14:40:46,420:INFO:Importing untrained model
2024-05-24 14:40:46,435:INFO:Elastic Net Imported successfully
2024-05-24 14:40:46,466:INFO:Starting cross validation
2024-05-24 14:40:46,474:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:51,420:INFO:Calculating mean and std
2024-05-24 14:40:51,422:INFO:Creating metrics dataframe
2024-05-24 14:40:51,425:INFO:Uploading results into container
2024-05-24 14:40:51,426:INFO:Uploading model into container now
2024-05-24 14:40:51,427:INFO:_master_model_container: 4
2024-05-24 14:40:51,427:INFO:_display_container: 2
2024-05-24 14:40:51,428:INFO:ElasticNet(random_state=3557)
2024-05-24 14:40:51,428:INFO:create_model() successfully completed......................................
2024-05-24 14:40:51,564:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:51,564:INFO:Creating metrics dataframe
2024-05-24 14:40:51,578:INFO:Initializing Least Angle Regression
2024-05-24 14:40:51,579:INFO:Total runtime is 0.33214815457661945 minutes
2024-05-24 14:40:51,603:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:51,605:INFO:Initializing create_model()
2024-05-24 14:40:51,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=lar, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:51,605:INFO:Checking exceptions
2024-05-24 14:40:51,605:INFO:Importing libraries
2024-05-24 14:40:51,605:INFO:Copying training dataset
2024-05-24 14:40:51,622:INFO:Defining folds
2024-05-24 14:40:51,658:INFO:Declaring metric variables
2024-05-24 14:40:51,667:INFO:Importing untrained model
2024-05-24 14:40:51,674:INFO:Least Angle Regression Imported successfully
2024-05-24 14:40:51,693:INFO:Starting cross validation
2024-05-24 14:40:51,708:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:51,928:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.627e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,928:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.953e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.365e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.041e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.853e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,933:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.619e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,933:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.162e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,933:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.508e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,939:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.882e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,939:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.875e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,940:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.059e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,940:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.827e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,940:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.127e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,941:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.118e+00, with an active set of 45 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:51,941:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.120e-01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:40:52,055:INFO:Calculating mean and std
2024-05-24 14:40:52,076:INFO:Creating metrics dataframe
2024-05-24 14:40:52,096:INFO:Uploading results into container
2024-05-24 14:40:52,097:INFO:Uploading model into container now
2024-05-24 14:40:52,101:INFO:_master_model_container: 5
2024-05-24 14:40:52,101:INFO:_display_container: 2
2024-05-24 14:40:52,102:INFO:Lars(random_state=3557)
2024-05-24 14:40:52,102:INFO:create_model() successfully completed......................................
2024-05-24 14:40:52,224:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:52,224:INFO:Creating metrics dataframe
2024-05-24 14:40:52,263:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:40:52,263:INFO:Total runtime is 0.3435607035954793 minutes
2024-05-24 14:40:52,272:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:52,273:INFO:Initializing create_model()
2024-05-24 14:40:52,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=llar, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:52,273:INFO:Checking exceptions
2024-05-24 14:40:52,274:INFO:Importing libraries
2024-05-24 14:40:52,274:INFO:Copying training dataset
2024-05-24 14:40:52,292:INFO:Defining folds
2024-05-24 14:40:52,293:INFO:Declaring metric variables
2024-05-24 14:40:52,309:INFO:Importing untrained model
2024-05-24 14:40:52,335:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:40:52,348:INFO:Starting cross validation
2024-05-24 14:40:52,352:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:52,670:INFO:Calculating mean and std
2024-05-24 14:40:52,672:INFO:Creating metrics dataframe
2024-05-24 14:40:52,678:INFO:Uploading results into container
2024-05-24 14:40:52,679:INFO:Uploading model into container now
2024-05-24 14:40:52,680:INFO:_master_model_container: 6
2024-05-24 14:40:52,680:INFO:_display_container: 2
2024-05-24 14:40:52,681:INFO:LassoLars(random_state=3557)
2024-05-24 14:40:52,682:INFO:create_model() successfully completed......................................
2024-05-24 14:40:52,825:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:52,825:INFO:Creating metrics dataframe
2024-05-24 14:40:52,852:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:40:52,856:INFO:Total runtime is 0.3534367084503173 minutes
2024-05-24 14:40:52,869:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:52,869:INFO:Initializing create_model()
2024-05-24 14:40:52,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=omp, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:52,870:INFO:Checking exceptions
2024-05-24 14:40:52,870:INFO:Importing libraries
2024-05-24 14:40:52,870:INFO:Copying training dataset
2024-05-24 14:40:52,884:INFO:Defining folds
2024-05-24 14:40:52,885:INFO:Declaring metric variables
2024-05-24 14:40:52,906:INFO:Importing untrained model
2024-05-24 14:40:52,917:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:40:52,926:INFO:Starting cross validation
2024-05-24 14:40:52,930:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:53,261:INFO:Calculating mean and std
2024-05-24 14:40:53,263:INFO:Creating metrics dataframe
2024-05-24 14:40:53,269:INFO:Uploading results into container
2024-05-24 14:40:53,274:INFO:Uploading model into container now
2024-05-24 14:40:53,275:INFO:_master_model_container: 7
2024-05-24 14:40:53,276:INFO:_display_container: 2
2024-05-24 14:40:53,276:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:40:53,276:INFO:create_model() successfully completed......................................
2024-05-24 14:40:53,429:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:53,429:INFO:Creating metrics dataframe
2024-05-24 14:40:53,452:INFO:Initializing Bayesian Ridge
2024-05-24 14:40:53,452:INFO:Total runtime is 0.3633746743202209 minutes
2024-05-24 14:40:53,459:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:53,459:INFO:Initializing create_model()
2024-05-24 14:40:53,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=br, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:53,460:INFO:Checking exceptions
2024-05-24 14:40:53,460:INFO:Importing libraries
2024-05-24 14:40:53,460:INFO:Copying training dataset
2024-05-24 14:40:53,477:INFO:Defining folds
2024-05-24 14:40:53,479:INFO:Declaring metric variables
2024-05-24 14:40:53,511:INFO:Importing untrained model
2024-05-24 14:40:53,522:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:40:53,548:INFO:Starting cross validation
2024-05-24 14:40:53,554:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:53,953:INFO:Calculating mean and std
2024-05-24 14:40:53,957:INFO:Creating metrics dataframe
2024-05-24 14:40:53,964:INFO:Uploading results into container
2024-05-24 14:40:53,969:INFO:Uploading model into container now
2024-05-24 14:40:53,970:INFO:_master_model_container: 8
2024-05-24 14:40:53,970:INFO:_display_container: 2
2024-05-24 14:40:53,971:INFO:BayesianRidge()
2024-05-24 14:40:53,971:INFO:create_model() successfully completed......................................
2024-05-24 14:40:54,113:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:54,113:INFO:Creating metrics dataframe
2024-05-24 14:40:54,137:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:40:54,138:INFO:Total runtime is 0.37481132745742796 minutes
2024-05-24 14:40:54,146:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:54,147:INFO:Initializing create_model()
2024-05-24 14:40:54,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=par, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:54,147:INFO:Checking exceptions
2024-05-24 14:40:54,148:INFO:Importing libraries
2024-05-24 14:40:54,148:INFO:Copying training dataset
2024-05-24 14:40:54,161:INFO:Defining folds
2024-05-24 14:40:54,162:INFO:Declaring metric variables
2024-05-24 14:40:54,176:INFO:Importing untrained model
2024-05-24 14:40:54,182:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:40:54,192:INFO:Starting cross validation
2024-05-24 14:40:54,196:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:54,479:INFO:Calculating mean and std
2024-05-24 14:40:54,492:INFO:Creating metrics dataframe
2024-05-24 14:40:54,496:INFO:Uploading results into container
2024-05-24 14:40:54,497:INFO:Uploading model into container now
2024-05-24 14:40:54,498:INFO:_master_model_container: 9
2024-05-24 14:40:54,498:INFO:_display_container: 2
2024-05-24 14:40:54,499:INFO:PassiveAggressiveRegressor(random_state=3557)
2024-05-24 14:40:54,499:INFO:create_model() successfully completed......................................
2024-05-24 14:40:54,641:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:54,641:INFO:Creating metrics dataframe
2024-05-24 14:40:54,656:INFO:Initializing Huber Regressor
2024-05-24 14:40:54,671:INFO:Total runtime is 0.38368875980377193 minutes
2024-05-24 14:40:54,679:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:54,679:INFO:Initializing create_model()
2024-05-24 14:40:54,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=huber, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:54,684:INFO:Checking exceptions
2024-05-24 14:40:54,685:INFO:Importing libraries
2024-05-24 14:40:54,685:INFO:Copying training dataset
2024-05-24 14:40:54,700:INFO:Defining folds
2024-05-24 14:40:54,704:INFO:Declaring metric variables
2024-05-24 14:40:54,717:INFO:Importing untrained model
2024-05-24 14:40:54,730:INFO:Huber Regressor Imported successfully
2024-05-24 14:40:54,742:INFO:Starting cross validation
2024-05-24 14:40:54,745:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:54,977:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:40:55,003:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:40:55,100:INFO:Calculating mean and std
2024-05-24 14:40:55,103:INFO:Creating metrics dataframe
2024-05-24 14:40:55,108:INFO:Uploading results into container
2024-05-24 14:40:55,109:INFO:Uploading model into container now
2024-05-24 14:40:55,110:INFO:_master_model_container: 10
2024-05-24 14:40:55,110:INFO:_display_container: 2
2024-05-24 14:40:55,112:INFO:HuberRegressor()
2024-05-24 14:40:55,112:INFO:create_model() successfully completed......................................
2024-05-24 14:40:55,270:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:55,270:INFO:Creating metrics dataframe
2024-05-24 14:40:55,289:INFO:Initializing K Neighbors Regressor
2024-05-24 14:40:55,289:INFO:Total runtime is 0.39399504264195756 minutes
2024-05-24 14:40:55,304:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:55,305:INFO:Initializing create_model()
2024-05-24 14:40:55,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=knn, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:55,305:INFO:Checking exceptions
2024-05-24 14:40:55,306:INFO:Importing libraries
2024-05-24 14:40:55,306:INFO:Copying training dataset
2024-05-24 14:40:55,321:INFO:Defining folds
2024-05-24 14:40:55,321:INFO:Declaring metric variables
2024-05-24 14:40:55,328:INFO:Importing untrained model
2024-05-24 14:40:55,333:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:40:55,342:INFO:Starting cross validation
2024-05-24 14:40:55,347:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:55,991:INFO:Calculating mean and std
2024-05-24 14:40:55,992:INFO:Creating metrics dataframe
2024-05-24 14:40:55,995:INFO:Uploading results into container
2024-05-24 14:40:55,996:INFO:Uploading model into container now
2024-05-24 14:40:55,996:INFO:_master_model_container: 11
2024-05-24 14:40:55,996:INFO:_display_container: 2
2024-05-24 14:40:55,997:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:40:55,997:INFO:create_model() successfully completed......................................
2024-05-24 14:40:56,107:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:56,107:INFO:Creating metrics dataframe
2024-05-24 14:40:56,123:INFO:Initializing Decision Tree Regressor
2024-05-24 14:40:56,123:INFO:Total runtime is 0.4078971107800801 minutes
2024-05-24 14:40:56,128:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:56,128:INFO:Initializing create_model()
2024-05-24 14:40:56,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=dt, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:56,129:INFO:Checking exceptions
2024-05-24 14:40:56,129:INFO:Importing libraries
2024-05-24 14:40:56,129:INFO:Copying training dataset
2024-05-24 14:40:56,141:INFO:Defining folds
2024-05-24 14:40:56,152:INFO:Declaring metric variables
2024-05-24 14:40:56,160:INFO:Importing untrained model
2024-05-24 14:40:56,165:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:40:56,184:INFO:Starting cross validation
2024-05-24 14:40:56,194:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:56,559:INFO:Calculating mean and std
2024-05-24 14:40:56,561:INFO:Creating metrics dataframe
2024-05-24 14:40:56,563:INFO:Uploading results into container
2024-05-24 14:40:56,564:INFO:Uploading model into container now
2024-05-24 14:40:56,565:INFO:_master_model_container: 12
2024-05-24 14:40:56,565:INFO:_display_container: 2
2024-05-24 14:40:56,565:INFO:DecisionTreeRegressor(random_state=3557)
2024-05-24 14:40:56,565:INFO:create_model() successfully completed......................................
2024-05-24 14:40:56,677:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:56,677:INFO:Creating metrics dataframe
2024-05-24 14:40:56,694:INFO:Initializing Random Forest Regressor
2024-05-24 14:40:56,696:INFO:Total runtime is 0.41744377215703327 minutes
2024-05-24 14:40:56,714:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:56,715:INFO:Initializing create_model()
2024-05-24 14:40:56,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=rf, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:56,717:INFO:Checking exceptions
2024-05-24 14:40:56,717:INFO:Importing libraries
2024-05-24 14:40:56,717:INFO:Copying training dataset
2024-05-24 14:40:56,733:INFO:Defining folds
2024-05-24 14:40:56,733:INFO:Declaring metric variables
2024-05-24 14:40:56,759:INFO:Importing untrained model
2024-05-24 14:40:56,770:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:40:56,785:INFO:Starting cross validation
2024-05-24 14:40:56,858:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:57,508:INFO:Calculating mean and std
2024-05-24 14:40:57,510:INFO:Creating metrics dataframe
2024-05-24 14:40:57,519:INFO:Uploading results into container
2024-05-24 14:40:57,521:INFO:Uploading model into container now
2024-05-24 14:40:57,522:INFO:_master_model_container: 13
2024-05-24 14:40:57,522:INFO:_display_container: 2
2024-05-24 14:40:57,523:INFO:RandomForestRegressor(n_jobs=-1, random_state=3557)
2024-05-24 14:40:57,523:INFO:create_model() successfully completed......................................
2024-05-24 14:40:57,657:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:57,657:INFO:Creating metrics dataframe
2024-05-24 14:40:57,678:INFO:Initializing Extra Trees Regressor
2024-05-24 14:40:57,678:INFO:Total runtime is 0.43380117416381836 minutes
2024-05-24 14:40:57,685:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:57,686:INFO:Initializing create_model()
2024-05-24 14:40:57,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=et, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:57,686:INFO:Checking exceptions
2024-05-24 14:40:57,686:INFO:Importing libraries
2024-05-24 14:40:57,687:INFO:Copying training dataset
2024-05-24 14:40:57,704:INFO:Defining folds
2024-05-24 14:40:57,775:INFO:Declaring metric variables
2024-05-24 14:40:57,783:INFO:Importing untrained model
2024-05-24 14:40:57,792:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:40:57,809:INFO:Starting cross validation
2024-05-24 14:40:57,813:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:58,500:INFO:Calculating mean and std
2024-05-24 14:40:58,502:INFO:Creating metrics dataframe
2024-05-24 14:40:58,505:INFO:Uploading results into container
2024-05-24 14:40:58,505:INFO:Uploading model into container now
2024-05-24 14:40:58,506:INFO:_master_model_container: 14
2024-05-24 14:40:58,506:INFO:_display_container: 2
2024-05-24 14:40:58,507:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3557)
2024-05-24 14:40:58,507:INFO:create_model() successfully completed......................................
2024-05-24 14:40:58,615:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:58,616:INFO:Creating metrics dataframe
2024-05-24 14:40:58,629:INFO:Initializing AdaBoost Regressor
2024-05-24 14:40:58,629:INFO:Total runtime is 0.4496522108713786 minutes
2024-05-24 14:40:58,636:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:58,639:INFO:Initializing create_model()
2024-05-24 14:40:58,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=ada, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:58,640:INFO:Checking exceptions
2024-05-24 14:40:58,640:INFO:Importing libraries
2024-05-24 14:40:58,640:INFO:Copying training dataset
2024-05-24 14:40:58,655:INFO:Defining folds
2024-05-24 14:40:58,656:INFO:Declaring metric variables
2024-05-24 14:40:58,664:INFO:Importing untrained model
2024-05-24 14:40:58,673:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:40:58,700:INFO:Starting cross validation
2024-05-24 14:40:58,710:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:59,169:INFO:Calculating mean and std
2024-05-24 14:40:59,171:INFO:Creating metrics dataframe
2024-05-24 14:40:59,174:INFO:Uploading results into container
2024-05-24 14:40:59,175:INFO:Uploading model into container now
2024-05-24 14:40:59,176:INFO:_master_model_container: 15
2024-05-24 14:40:59,176:INFO:_display_container: 2
2024-05-24 14:40:59,177:INFO:AdaBoostRegressor(random_state=3557)
2024-05-24 14:40:59,177:INFO:create_model() successfully completed......................................
2024-05-24 14:40:59,295:INFO:SubProcess create_model() end ==================================
2024-05-24 14:40:59,295:INFO:Creating metrics dataframe
2024-05-24 14:40:59,341:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:40:59,341:INFO:Total runtime is 0.4615164836247762 minutes
2024-05-24 14:40:59,348:INFO:SubProcess create_model() called ==================================
2024-05-24 14:40:59,349:INFO:Initializing create_model()
2024-05-24 14:40:59,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=gbr, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:40:59,350:INFO:Checking exceptions
2024-05-24 14:40:59,350:INFO:Importing libraries
2024-05-24 14:40:59,350:INFO:Copying training dataset
2024-05-24 14:40:59,364:INFO:Defining folds
2024-05-24 14:40:59,364:INFO:Declaring metric variables
2024-05-24 14:40:59,371:INFO:Importing untrained model
2024-05-24 14:40:59,377:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:40:59,431:INFO:Starting cross validation
2024-05-24 14:40:59,441:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:40:59,960:INFO:Calculating mean and std
2024-05-24 14:40:59,962:INFO:Creating metrics dataframe
2024-05-24 14:40:59,967:INFO:Uploading results into container
2024-05-24 14:40:59,970:INFO:Uploading model into container now
2024-05-24 14:40:59,972:INFO:_master_model_container: 16
2024-05-24 14:40:59,972:INFO:_display_container: 2
2024-05-24 14:40:59,973:INFO:GradientBoostingRegressor(random_state=3557)
2024-05-24 14:40:59,973:INFO:create_model() successfully completed......................................
2024-05-24 14:41:00,110:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:00,110:INFO:Creating metrics dataframe
2024-05-24 14:41:00,141:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:41:00,142:INFO:Total runtime is 0.474872092405955 minutes
2024-05-24 14:41:00,152:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:00,153:INFO:Initializing create_model()
2024-05-24 14:41:00,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=lightgbm, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:00,156:INFO:Checking exceptions
2024-05-24 14:41:00,156:INFO:Importing libraries
2024-05-24 14:41:00,156:INFO:Copying training dataset
2024-05-24 14:41:00,200:INFO:Defining folds
2024-05-24 14:41:00,202:INFO:Declaring metric variables
2024-05-24 14:41:00,212:INFO:Importing untrained model
2024-05-24 14:41:00,223:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:41:00,237:INFO:Starting cross validation
2024-05-24 14:41:00,244:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:01,909:INFO:Calculating mean and std
2024-05-24 14:41:01,912:INFO:Creating metrics dataframe
2024-05-24 14:41:01,916:INFO:Uploading results into container
2024-05-24 14:41:01,918:INFO:Uploading model into container now
2024-05-24 14:41:01,919:INFO:_master_model_container: 17
2024-05-24 14:41:01,919:INFO:_display_container: 2
2024-05-24 14:41:01,919:INFO:LGBMRegressor(n_jobs=-1, random_state=3557)
2024-05-24 14:41:01,920:INFO:create_model() successfully completed......................................
2024-05-24 14:41:02,038:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:02,039:INFO:Creating metrics dataframe
2024-05-24 14:41:02,060:INFO:Initializing Dummy Regressor
2024-05-24 14:41:02,061:INFO:Total runtime is 0.5068536003430685 minutes
2024-05-24 14:41:02,075:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:02,076:INFO:Initializing create_model()
2024-05-24 14:41:02,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=dummy, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BA39CB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:02,077:INFO:Checking exceptions
2024-05-24 14:41:02,077:INFO:Importing libraries
2024-05-24 14:41:02,077:INFO:Copying training dataset
2024-05-24 14:41:02,095:INFO:Defining folds
2024-05-24 14:41:02,095:INFO:Declaring metric variables
2024-05-24 14:41:02,107:INFO:Importing untrained model
2024-05-24 14:41:02,116:INFO:Dummy Regressor Imported successfully
2024-05-24 14:41:02,146:INFO:Starting cross validation
2024-05-24 14:41:02,152:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:02,553:INFO:Calculating mean and std
2024-05-24 14:41:02,556:INFO:Creating metrics dataframe
2024-05-24 14:41:02,559:INFO:Uploading results into container
2024-05-24 14:41:02,560:INFO:Uploading model into container now
2024-05-24 14:41:02,561:INFO:_master_model_container: 18
2024-05-24 14:41:02,562:INFO:_display_container: 2
2024-05-24 14:41:02,562:INFO:DummyRegressor()
2024-05-24 14:41:02,562:INFO:create_model() successfully completed......................................
2024-05-24 14:41:02,695:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:02,695:INFO:Creating metrics dataframe
2024-05-24 14:41:02,742:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:41:02,771:INFO:Initializing create_model()
2024-05-24 14:41:02,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAB251E0>, estimator=LGBMRegressor(n_jobs=-1, random_state=3557), fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:02,772:INFO:Checking exceptions
2024-05-24 14:41:02,774:INFO:Importing libraries
2024-05-24 14:41:02,774:INFO:Copying training dataset
2024-05-24 14:41:02,785:INFO:Defining folds
2024-05-24 14:41:02,785:INFO:Declaring metric variables
2024-05-24 14:41:02,786:INFO:Importing untrained model
2024-05-24 14:41:02,786:INFO:Declaring custom model
2024-05-24 14:41:02,787:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:41:02,791:INFO:Cross validation set to False
2024-05-24 14:41:02,791:INFO:Fitting Model
2024-05-24 14:41:03,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058031 seconds.
2024-05-24 14:41:03,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-24 14:41:03,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-24 14:41:03,289:INFO:[LightGBM] [Info] Total Bins 463
2024-05-24 14:41:03,290:INFO:[LightGBM] [Info] Number of data points in the train set: 143, number of used features: 26
2024-05-24 14:41:03,290:INFO:[LightGBM] [Info] Start training from score 13336.088587
2024-05-24 14:41:03,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 14:41:03,386:INFO:LGBMRegressor(n_jobs=-1, random_state=3557)
2024-05-24 14:41:03,386:INFO:create_model() successfully completed......................................
2024-05-24 14:41:03,689:INFO:_master_model_container: 18
2024-05-24 14:41:03,690:INFO:_display_container: 2
2024-05-24 14:41:03,690:INFO:LGBMRegressor(n_jobs=-1, random_state=3557)
2024-05-24 14:41:03,691:INFO:compare_models() successfully completed......................................
2024-05-24 14:41:29,598:INFO:PyCaret RegressionExperiment
2024-05-24 14:41:29,598:INFO:Logging name: reg-default-name
2024-05-24 14:41:29,598:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 14:41:29,598:INFO:version 3.3.2
2024-05-24 14:41:29,598:INFO:Initializing setup()
2024-05-24 14:41:29,598:INFO:self.USI: 62fc
2024-05-24 14:41:29,598:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 14:41:29,598:INFO:Checking environment
2024-05-24 14:41:29,598:INFO:python_version: 3.10.14
2024-05-24 14:41:29,598:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 14:41:29,598:INFO:machine: AMD64
2024-05-24 14:41:29,598:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 14:41:29,598:INFO:Memory: svmem(total=16541802496, available=705159168, percent=95.7, used=15836643328, free=705159168)
2024-05-24 14:41:29,598:INFO:Physical Core: 6
2024-05-24 14:41:29,598:INFO:Logical Core: 12
2024-05-24 14:41:29,598:INFO:Checking libraries
2024-05-24 14:41:29,599:INFO:System:
2024-05-24 14:41:29,599:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 14:41:29,599:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 14:41:29,599:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 14:41:29,599:INFO:PyCaret required dependencies:
2024-05-24 14:41:29,599:INFO:                 pip: 24.0
2024-05-24 14:41:29,599:INFO:          setuptools: 69.5.1
2024-05-24 14:41:29,599:INFO:             pycaret: 3.3.2
2024-05-24 14:41:29,599:INFO:             IPython: 8.20.0
2024-05-24 14:41:29,599:INFO:          ipywidgets: 8.1.2
2024-05-24 14:41:29,599:INFO:                tqdm: 4.66.4
2024-05-24 14:41:29,599:INFO:               numpy: 1.26.4
2024-05-24 14:41:29,599:INFO:              pandas: 2.1.4
2024-05-24 14:41:29,599:INFO:              jinja2: 3.1.3
2024-05-24 14:41:29,599:INFO:               scipy: 1.11.4
2024-05-24 14:41:29,599:INFO:              joblib: 1.3.2
2024-05-24 14:41:29,599:INFO:             sklearn: 1.4.2
2024-05-24 14:41:29,599:INFO:                pyod: 1.1.3
2024-05-24 14:41:29,599:INFO:            imblearn: 0.12.2
2024-05-24 14:41:29,599:INFO:   category_encoders: 2.6.3
2024-05-24 14:41:29,599:INFO:            lightgbm: 4.3.0
2024-05-24 14:41:29,599:INFO:               numba: 0.59.1
2024-05-24 14:41:29,600:INFO:            requests: 2.32.2
2024-05-24 14:41:29,600:INFO:          matplotlib: 3.7.5
2024-05-24 14:41:29,600:INFO:          scikitplot: 0.3.7
2024-05-24 14:41:29,600:INFO:         yellowbrick: 1.5
2024-05-24 14:41:29,600:INFO:              plotly: 5.22.0
2024-05-24 14:41:29,600:INFO:    plotly-resampler: Not installed
2024-05-24 14:41:29,600:INFO:             kaleido: 0.2.1
2024-05-24 14:41:29,600:INFO:           schemdraw: 0.15
2024-05-24 14:41:29,600:INFO:         statsmodels: 0.14.2
2024-05-24 14:41:29,600:INFO:              sktime: 0.26.0
2024-05-24 14:41:29,600:INFO:               tbats: 1.1.3
2024-05-24 14:41:29,600:INFO:            pmdarima: 2.0.4
2024-05-24 14:41:29,600:INFO:              psutil: 5.9.0
2024-05-24 14:41:29,600:INFO:          markupsafe: 2.1.3
2024-05-24 14:41:29,600:INFO:             pickle5: Not installed
2024-05-24 14:41:29,600:INFO:         cloudpickle: 3.0.0
2024-05-24 14:41:29,600:INFO:         deprecation: 2.1.0
2024-05-24 14:41:29,600:INFO:              xxhash: 3.4.1
2024-05-24 14:41:29,600:INFO:           wurlitzer: Not installed
2024-05-24 14:41:29,600:INFO:PyCaret optional dependencies:
2024-05-24 14:41:29,600:INFO:                shap: Not installed
2024-05-24 14:41:29,600:INFO:           interpret: Not installed
2024-05-24 14:41:29,600:INFO:                umap: Not installed
2024-05-24 14:41:29,600:INFO:     ydata_profiling: Not installed
2024-05-24 14:41:29,600:INFO:  explainerdashboard: Not installed
2024-05-24 14:41:29,600:INFO:             autoviz: Not installed
2024-05-24 14:41:29,601:INFO:           fairlearn: Not installed
2024-05-24 14:41:29,601:INFO:          deepchecks: Not installed
2024-05-24 14:41:29,601:INFO:             xgboost: Not installed
2024-05-24 14:41:29,601:INFO:            catboost: Not installed
2024-05-24 14:41:29,601:INFO:              kmodes: Not installed
2024-05-24 14:41:29,601:INFO:             mlxtend: Not installed
2024-05-24 14:41:29,601:INFO:       statsforecast: Not installed
2024-05-24 14:41:29,601:INFO:        tune_sklearn: Not installed
2024-05-24 14:41:29,601:INFO:                 ray: Not installed
2024-05-24 14:41:29,601:INFO:            hyperopt: Not installed
2024-05-24 14:41:29,601:INFO:              optuna: Not installed
2024-05-24 14:41:29,601:INFO:               skopt: Not installed
2024-05-24 14:41:29,601:INFO:              mlflow: Not installed
2024-05-24 14:41:29,601:INFO:              gradio: Not installed
2024-05-24 14:41:29,601:INFO:             fastapi: Not installed
2024-05-24 14:41:29,601:INFO:             uvicorn: Not installed
2024-05-24 14:41:29,601:INFO:              m2cgen: Not installed
2024-05-24 14:41:29,601:INFO:           evidently: Not installed
2024-05-24 14:41:29,601:INFO:               fugue: Not installed
2024-05-24 14:41:29,601:INFO:           streamlit: Not installed
2024-05-24 14:41:29,601:INFO:             prophet: Not installed
2024-05-24 14:41:29,601:INFO:None
2024-05-24 14:41:29,601:INFO:Set up data.
2024-05-24 14:41:29,610:INFO:Set up folding strategy.
2024-05-24 14:41:29,610:INFO:Set up train/test split.
2024-05-24 14:41:29,615:INFO:Set up index.
2024-05-24 14:41:29,615:INFO:Assigning column types.
2024-05-24 14:41:29,620:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 14:41:29,620:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,624:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:29,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:29,722:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,726:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,730:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:29,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:29,823:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 14:41:29,827:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:29,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:29,928:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,932:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:29,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,025:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 14:41:30,033:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,085:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,134:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,229:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 14:41:30,298:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,514:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 14:41:30,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:30,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,736:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 14:41:30,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:30,940:INFO:Preparing preprocessing pipeline...
2024-05-24 14:41:30,940:INFO:Set up simple imputation.
2024-05-24 14:41:30,945:INFO:Set up encoding of ordinal features.
2024-05-24 14:41:30,949:INFO:Set up encoding of categorical features.
2024-05-24 14:41:31,102:INFO:Finished creating preprocessing pipeline.
2024-05-24 14:41:31,157:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['car_ID', 'symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('cat...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 14:41:31,157:INFO:Creating final display dataframe.
2024-05-24 14:41:31,842:INFO:Setup _display_container:                     Description             Value
0                    Session id              5011
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 26)
4        Transformed data shape         (205, 50)
5   Transformed train set shape         (143, 50)
6    Transformed test set shape          (62, 50)
7              Numeric features                15
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              62fc
2024-05-24 14:41:31,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:31,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:32,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:32,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:32,068:INFO:setup() successfully completed in 2.47s...............
2024-05-24 14:41:32,085:INFO:Initializing compare_models()
2024-05-24 14:41:32,085:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:41:32,085:INFO:Checking exceptions
2024-05-24 14:41:32,088:INFO:Preparing display monitor
2024-05-24 14:41:32,112:INFO:Initializing Linear Regression
2024-05-24 14:41:32,112:INFO:Total runtime is 0.0 minutes
2024-05-24 14:41:32,116:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:32,116:INFO:Initializing create_model()
2024-05-24 14:41:32,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:32,116:INFO:Checking exceptions
2024-05-24 14:41:32,116:INFO:Importing libraries
2024-05-24 14:41:32,116:INFO:Copying training dataset
2024-05-24 14:41:32,124:INFO:Defining folds
2024-05-24 14:41:32,125:INFO:Declaring metric variables
2024-05-24 14:41:32,128:INFO:Importing untrained model
2024-05-24 14:41:32,133:INFO:Linear Regression Imported successfully
2024-05-24 14:41:32,142:INFO:Starting cross validation
2024-05-24 14:41:32,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:32,477:INFO:Calculating mean and std
2024-05-24 14:41:32,478:INFO:Creating metrics dataframe
2024-05-24 14:41:32,480:INFO:Uploading results into container
2024-05-24 14:41:32,480:INFO:Uploading model into container now
2024-05-24 14:41:32,480:INFO:_master_model_container: 1
2024-05-24 14:41:32,480:INFO:_display_container: 2
2024-05-24 14:41:32,481:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:41:32,481:INFO:create_model() successfully completed......................................
2024-05-24 14:41:32,562:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:32,562:INFO:Creating metrics dataframe
2024-05-24 14:41:32,568:INFO:Initializing Lasso Regression
2024-05-24 14:41:32,568:INFO:Total runtime is 0.0075865904490153 minutes
2024-05-24 14:41:32,571:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:32,572:INFO:Initializing create_model()
2024-05-24 14:41:32,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:32,572:INFO:Checking exceptions
2024-05-24 14:41:32,572:INFO:Importing libraries
2024-05-24 14:41:32,572:INFO:Copying training dataset
2024-05-24 14:41:32,577:INFO:Defining folds
2024-05-24 14:41:32,577:INFO:Declaring metric variables
2024-05-24 14:41:32,580:INFO:Importing untrained model
2024-05-24 14:41:32,583:INFO:Lasso Regression Imported successfully
2024-05-24 14:41:32,593:INFO:Starting cross validation
2024-05-24 14:41:32,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:32,784:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.298e+07, tolerance: 9.407e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,792:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.609e+07, tolerance: 9.858e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,801:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.590e+07, tolerance: 9.790e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,812:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.568e+07, tolerance: 9.432e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,817:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.097e+07, tolerance: 9.392e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,823:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.565e+07, tolerance: 8.627e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,833:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.251e+07, tolerance: 9.973e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,844:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.699e+07, tolerance: 8.589e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:32,917:INFO:Calculating mean and std
2024-05-24 14:41:32,918:INFO:Creating metrics dataframe
2024-05-24 14:41:32,920:INFO:Uploading results into container
2024-05-24 14:41:32,920:INFO:Uploading model into container now
2024-05-24 14:41:32,921:INFO:_master_model_container: 2
2024-05-24 14:41:32,921:INFO:_display_container: 2
2024-05-24 14:41:32,921:INFO:Lasso(random_state=5011)
2024-05-24 14:41:32,921:INFO:create_model() successfully completed......................................
2024-05-24 14:41:33,007:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:33,008:INFO:Creating metrics dataframe
2024-05-24 14:41:33,017:INFO:Initializing Ridge Regression
2024-05-24 14:41:33,017:INFO:Total runtime is 0.015067235628763834 minutes
2024-05-24 14:41:33,023:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:33,023:INFO:Initializing create_model()
2024-05-24 14:41:33,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:33,023:INFO:Checking exceptions
2024-05-24 14:41:33,023:INFO:Importing libraries
2024-05-24 14:41:33,023:INFO:Copying training dataset
2024-05-24 14:41:33,029:INFO:Defining folds
2024-05-24 14:41:33,029:INFO:Declaring metric variables
2024-05-24 14:41:33,032:INFO:Importing untrained model
2024-05-24 14:41:33,036:INFO:Ridge Regression Imported successfully
2024-05-24 14:41:33,045:INFO:Starting cross validation
2024-05-24 14:41:33,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:33,416:INFO:Calculating mean and std
2024-05-24 14:41:33,418:INFO:Creating metrics dataframe
2024-05-24 14:41:33,420:INFO:Uploading results into container
2024-05-24 14:41:33,421:INFO:Uploading model into container now
2024-05-24 14:41:33,421:INFO:_master_model_container: 3
2024-05-24 14:41:33,422:INFO:_display_container: 2
2024-05-24 14:41:33,422:INFO:Ridge(random_state=5011)
2024-05-24 14:41:33,422:INFO:create_model() successfully completed......................................
2024-05-24 14:41:33,532:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:33,532:INFO:Creating metrics dataframe
2024-05-24 14:41:33,542:INFO:Initializing Elastic Net
2024-05-24 14:41:33,542:INFO:Total runtime is 0.023826690514882405 minutes
2024-05-24 14:41:33,548:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:33,549:INFO:Initializing create_model()
2024-05-24 14:41:33,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:33,549:INFO:Checking exceptions
2024-05-24 14:41:33,549:INFO:Importing libraries
2024-05-24 14:41:33,549:INFO:Copying training dataset
2024-05-24 14:41:33,559:INFO:Defining folds
2024-05-24 14:41:33,560:INFO:Declaring metric variables
2024-05-24 14:41:33,566:INFO:Importing untrained model
2024-05-24 14:41:33,575:INFO:Elastic Net Imported successfully
2024-05-24 14:41:33,586:INFO:Starting cross validation
2024-05-24 14:41:33,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:33,959:INFO:Calculating mean and std
2024-05-24 14:41:33,961:INFO:Creating metrics dataframe
2024-05-24 14:41:33,962:INFO:Uploading results into container
2024-05-24 14:41:33,963:INFO:Uploading model into container now
2024-05-24 14:41:33,963:INFO:_master_model_container: 4
2024-05-24 14:41:33,963:INFO:_display_container: 2
2024-05-24 14:41:33,964:INFO:ElasticNet(random_state=5011)
2024-05-24 14:41:33,964:INFO:create_model() successfully completed......................................
2024-05-24 14:41:34,051:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:34,052:INFO:Creating metrics dataframe
2024-05-24 14:41:34,059:INFO:Initializing Least Angle Regression
2024-05-24 14:41:34,059:INFO:Total runtime is 0.03244980573654175 minutes
2024-05-24 14:41:34,062:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:34,063:INFO:Initializing create_model()
2024-05-24 14:41:34,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:34,063:INFO:Checking exceptions
2024-05-24 14:41:34,063:INFO:Importing libraries
2024-05-24 14:41:34,063:INFO:Copying training dataset
2024-05-24 14:41:34,070:INFO:Defining folds
2024-05-24 14:41:34,070:INFO:Declaring metric variables
2024-05-24 14:41:34,073:INFO:Importing untrained model
2024-05-24 14:41:34,077:INFO:Least Angle Regression Imported successfully
2024-05-24 14:41:34,084:INFO:Starting cross validation
2024-05-24 14:41:34,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:34,266:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.509e+01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,267:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.401e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,272:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.413e+03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,273:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.053e+03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,273:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.415e+03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=9.581e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.704e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.729e+01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.266e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.022e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.276e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.630e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,277:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.062e+01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,277:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.046e+01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,279:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.589e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.158e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.818e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,281:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=7.543e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,281:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=5.517e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,281:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.947e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,281:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.692e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,281:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.470e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,299:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.420e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,299:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.420e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,300:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.278e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,300:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.004e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,302:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.614e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,303:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.614e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,303:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.975e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.731e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 3.161e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.052e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.723e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.269e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,305:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=9.632e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,305:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=9.342e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,305:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.472e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,305:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=4.685e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,306:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.684e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,306:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.482e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,306:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.569e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,306:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.994e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,307:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.708e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,307:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.977e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,308:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.756e+00, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,308:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.068e+00, with an active set of 46 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,309:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.703e+00, with an active set of 47 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,309:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.522e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,309:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.346e+00, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,309:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.859e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.367e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,311:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.235e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,311:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.051e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,311:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.037e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,313:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=9.699e+04, with an active set of 47 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,322:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.244e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=4.970e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=4.603e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=4.534e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,325:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.610e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,327:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=6.065e+02, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,327:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.265e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,327:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.477e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,328:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.337e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,328:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.223e+02, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,328:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.848e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,328:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.037e+02, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,328:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.668e+01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,329:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.851e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,329:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.176e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,329:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.037e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,330:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.447e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,330:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.419e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,330:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.153e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.730e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.473e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.000e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.195e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=6.040e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,332:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.952e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,332:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=9.491e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.637e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,334:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=3.745e+02, with an active set of 46 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,334:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.104e+02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,334:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=9.406e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,340:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.118e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,340:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.100e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,342:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=9.412e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,343:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.438e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,343:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.034e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,348:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.305e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,348:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.600e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,413:INFO:Calculating mean and std
2024-05-24 14:41:34,414:INFO:Creating metrics dataframe
2024-05-24 14:41:34,415:INFO:Uploading results into container
2024-05-24 14:41:34,416:INFO:Uploading model into container now
2024-05-24 14:41:34,416:INFO:_master_model_container: 5
2024-05-24 14:41:34,416:INFO:_display_container: 2
2024-05-24 14:41:34,417:INFO:Lars(random_state=5011)
2024-05-24 14:41:34,417:INFO:create_model() successfully completed......................................
2024-05-24 14:41:34,504:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:34,504:INFO:Creating metrics dataframe
2024-05-24 14:41:34,511:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:41:34,511:INFO:Total runtime is 0.03998139301935832 minutes
2024-05-24 14:41:34,515:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:34,515:INFO:Initializing create_model()
2024-05-24 14:41:34,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:34,515:INFO:Checking exceptions
2024-05-24 14:41:34,516:INFO:Importing libraries
2024-05-24 14:41:34,516:INFO:Copying training dataset
2024-05-24 14:41:34,523:INFO:Defining folds
2024-05-24 14:41:34,523:INFO:Declaring metric variables
2024-05-24 14:41:34,527:INFO:Importing untrained model
2024-05-24 14:41:34,530:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:41:34,540:INFO:Starting cross validation
2024-05-24 14:41:34,543:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:34,725:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.413e+01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,726:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.400e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,726:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.177e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,727:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.334e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,727:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.220e+01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,728:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=7.951e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,728:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=1.197e+01, previous alpha=1.157e+01, with an active set of 31 regressors.
  warnings.warn(

2024-05-24 14:41:34,728:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.698e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,729:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 48 iterations, alpha=5.589e+00, previous alpha=3.302e+00, with an active set of 35 regressors.
  warnings.warn(

2024-05-24 14:41:34,731:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=4.152e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,731:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=3.939e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,732:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.605e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,733:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.778e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 51 iterations, alpha=4.127e+00, previous alpha=4.105e+00, with an active set of 40 regressors.
  warnings.warn(

2024-05-24 14:41:34,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.624e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,752:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.760e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,753:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=3.635e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,753:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=3.542e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,754:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.629e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,754:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 60 iterations, alpha=3.471e+00, previous alpha=2.629e+00, with an active set of 37 regressors.
  warnings.warn(

2024-05-24 14:41:34,757:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.162e+01, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,757:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.438e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,758:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.438e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,758:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=8.419e+00, previous alpha=7.985e+00, with an active set of 32 regressors.
  warnings.warn(

2024-05-24 14:41:34,765:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.765e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,765:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.012e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,767:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 54 iterations, alpha=2.483e+00, previous alpha=1.801e+00, with an active set of 41 regressors.
  warnings.warn(

2024-05-24 14:41:34,771:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.424e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,773:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.264e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,773:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.097e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:34,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 52 iterations, alpha=2.997e+00, previous alpha=2.060e+00, with an active set of 37 regressors.
  warnings.warn(

2024-05-24 14:41:34,837:INFO:Calculating mean and std
2024-05-24 14:41:34,838:INFO:Creating metrics dataframe
2024-05-24 14:41:34,840:INFO:Uploading results into container
2024-05-24 14:41:34,840:INFO:Uploading model into container now
2024-05-24 14:41:34,841:INFO:_master_model_container: 6
2024-05-24 14:41:34,841:INFO:_display_container: 2
2024-05-24 14:41:34,841:INFO:LassoLars(random_state=5011)
2024-05-24 14:41:34,841:INFO:create_model() successfully completed......................................
2024-05-24 14:41:34,924:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:34,924:INFO:Creating metrics dataframe
2024-05-24 14:41:34,931:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:41:34,931:INFO:Total runtime is 0.04697348674138387 minutes
2024-05-24 14:41:34,935:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:34,936:INFO:Initializing create_model()
2024-05-24 14:41:34,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:34,936:INFO:Checking exceptions
2024-05-24 14:41:34,936:INFO:Importing libraries
2024-05-24 14:41:34,936:INFO:Copying training dataset
2024-05-24 14:41:34,943:INFO:Defining folds
2024-05-24 14:41:34,943:INFO:Declaring metric variables
2024-05-24 14:41:34,946:INFO:Importing untrained model
2024-05-24 14:41:34,951:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:41:34,959:INFO:Starting cross validation
2024-05-24 14:41:34,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:35,290:INFO:Calculating mean and std
2024-05-24 14:41:35,291:INFO:Creating metrics dataframe
2024-05-24 14:41:35,293:INFO:Uploading results into container
2024-05-24 14:41:35,294:INFO:Uploading model into container now
2024-05-24 14:41:35,295:INFO:_master_model_container: 7
2024-05-24 14:41:35,295:INFO:_display_container: 2
2024-05-24 14:41:35,295:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:41:35,295:INFO:create_model() successfully completed......................................
2024-05-24 14:41:35,380:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:35,381:INFO:Creating metrics dataframe
2024-05-24 14:41:35,388:INFO:Initializing Bayesian Ridge
2024-05-24 14:41:35,388:INFO:Total runtime is 0.05459725856781006 minutes
2024-05-24 14:41:35,391:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:35,391:INFO:Initializing create_model()
2024-05-24 14:41:35,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:35,392:INFO:Checking exceptions
2024-05-24 14:41:35,392:INFO:Importing libraries
2024-05-24 14:41:35,392:INFO:Copying training dataset
2024-05-24 14:41:35,397:INFO:Defining folds
2024-05-24 14:41:35,397:INFO:Declaring metric variables
2024-05-24 14:41:35,402:INFO:Importing untrained model
2024-05-24 14:41:35,408:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:41:35,415:INFO:Starting cross validation
2024-05-24 14:41:35,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:35,758:INFO:Calculating mean and std
2024-05-24 14:41:35,759:INFO:Creating metrics dataframe
2024-05-24 14:41:35,761:INFO:Uploading results into container
2024-05-24 14:41:35,761:INFO:Uploading model into container now
2024-05-24 14:41:35,761:INFO:_master_model_container: 8
2024-05-24 14:41:35,761:INFO:_display_container: 2
2024-05-24 14:41:35,763:INFO:BayesianRidge()
2024-05-24 14:41:35,763:INFO:create_model() successfully completed......................................
2024-05-24 14:41:35,851:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:35,851:INFO:Creating metrics dataframe
2024-05-24 14:41:35,859:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:41:35,859:INFO:Total runtime is 0.06243418057759603 minutes
2024-05-24 14:41:35,862:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:35,862:INFO:Initializing create_model()
2024-05-24 14:41:35,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:35,863:INFO:Checking exceptions
2024-05-24 14:41:35,863:INFO:Importing libraries
2024-05-24 14:41:35,863:INFO:Copying training dataset
2024-05-24 14:41:35,869:INFO:Defining folds
2024-05-24 14:41:35,870:INFO:Declaring metric variables
2024-05-24 14:41:35,873:INFO:Importing untrained model
2024-05-24 14:41:35,879:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:41:35,887:INFO:Starting cross validation
2024-05-24 14:41:35,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:36,242:INFO:Calculating mean and std
2024-05-24 14:41:36,243:INFO:Creating metrics dataframe
2024-05-24 14:41:36,244:INFO:Uploading results into container
2024-05-24 14:41:36,245:INFO:Uploading model into container now
2024-05-24 14:41:36,245:INFO:_master_model_container: 9
2024-05-24 14:41:36,245:INFO:_display_container: 2
2024-05-24 14:41:36,246:INFO:PassiveAggressiveRegressor(random_state=5011)
2024-05-24 14:41:36,246:INFO:create_model() successfully completed......................................
2024-05-24 14:41:36,340:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:36,340:INFO:Creating metrics dataframe
2024-05-24 14:41:36,348:INFO:Initializing Huber Regressor
2024-05-24 14:41:36,349:INFO:Total runtime is 0.07061618169148763 minutes
2024-05-24 14:41:36,353:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:36,353:INFO:Initializing create_model()
2024-05-24 14:41:36,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:36,354:INFO:Checking exceptions
2024-05-24 14:41:36,354:INFO:Importing libraries
2024-05-24 14:41:36,354:INFO:Copying training dataset
2024-05-24 14:41:36,360:INFO:Defining folds
2024-05-24 14:41:36,360:INFO:Declaring metric variables
2024-05-24 14:41:36,364:INFO:Importing untrained model
2024-05-24 14:41:36,368:INFO:Huber Regressor Imported successfully
2024-05-24 14:41:36,378:INFO:Starting cross validation
2024-05-24 14:41:36,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:36,615:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,625:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,634:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,644:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,645:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,649:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,660:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,668:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,686:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:36,741:INFO:Calculating mean and std
2024-05-24 14:41:36,742:INFO:Creating metrics dataframe
2024-05-24 14:41:36,744:INFO:Uploading results into container
2024-05-24 14:41:36,745:INFO:Uploading model into container now
2024-05-24 14:41:36,745:INFO:_master_model_container: 10
2024-05-24 14:41:36,745:INFO:_display_container: 2
2024-05-24 14:41:36,746:INFO:HuberRegressor()
2024-05-24 14:41:36,746:INFO:create_model() successfully completed......................................
2024-05-24 14:41:36,823:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:36,824:INFO:Creating metrics dataframe
2024-05-24 14:41:36,833:INFO:Initializing K Neighbors Regressor
2024-05-24 14:41:36,833:INFO:Total runtime is 0.07867842117945353 minutes
2024-05-24 14:41:36,839:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:36,839:INFO:Initializing create_model()
2024-05-24 14:41:36,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:36,840:INFO:Checking exceptions
2024-05-24 14:41:36,840:INFO:Importing libraries
2024-05-24 14:41:36,840:INFO:Copying training dataset
2024-05-24 14:41:36,848:INFO:Defining folds
2024-05-24 14:41:36,848:INFO:Declaring metric variables
2024-05-24 14:41:36,853:INFO:Importing untrained model
2024-05-24 14:41:36,858:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:41:36,868:INFO:Starting cross validation
2024-05-24 14:41:36,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:37,335:INFO:Calculating mean and std
2024-05-24 14:41:37,337:INFO:Creating metrics dataframe
2024-05-24 14:41:37,340:INFO:Uploading results into container
2024-05-24 14:41:37,341:INFO:Uploading model into container now
2024-05-24 14:41:37,342:INFO:_master_model_container: 11
2024-05-24 14:41:37,342:INFO:_display_container: 2
2024-05-24 14:41:37,342:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:41:37,342:INFO:create_model() successfully completed......................................
2024-05-24 14:41:37,431:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:37,431:INFO:Creating metrics dataframe
2024-05-24 14:41:37,440:INFO:Initializing Decision Tree Regressor
2024-05-24 14:41:37,440:INFO:Total runtime is 0.08879645665486655 minutes
2024-05-24 14:41:37,444:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:37,444:INFO:Initializing create_model()
2024-05-24 14:41:37,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:37,444:INFO:Checking exceptions
2024-05-24 14:41:37,444:INFO:Importing libraries
2024-05-24 14:41:37,444:INFO:Copying training dataset
2024-05-24 14:41:37,451:INFO:Defining folds
2024-05-24 14:41:37,451:INFO:Declaring metric variables
2024-05-24 14:41:37,455:INFO:Importing untrained model
2024-05-24 14:41:37,459:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:41:37,465:INFO:Starting cross validation
2024-05-24 14:41:37,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:37,783:INFO:Calculating mean and std
2024-05-24 14:41:37,784:INFO:Creating metrics dataframe
2024-05-24 14:41:37,787:INFO:Uploading results into container
2024-05-24 14:41:37,788:INFO:Uploading model into container now
2024-05-24 14:41:37,788:INFO:_master_model_container: 12
2024-05-24 14:41:37,788:INFO:_display_container: 2
2024-05-24 14:41:37,789:INFO:DecisionTreeRegressor(random_state=5011)
2024-05-24 14:41:37,789:INFO:create_model() successfully completed......................................
2024-05-24 14:41:37,873:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:37,873:INFO:Creating metrics dataframe
2024-05-24 14:41:37,885:INFO:Initializing Random Forest Regressor
2024-05-24 14:41:37,885:INFO:Total runtime is 0.09621092081069947 minutes
2024-05-24 14:41:37,890:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:37,890:INFO:Initializing create_model()
2024-05-24 14:41:37,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:37,891:INFO:Checking exceptions
2024-05-24 14:41:37,891:INFO:Importing libraries
2024-05-24 14:41:37,891:INFO:Copying training dataset
2024-05-24 14:41:37,900:INFO:Defining folds
2024-05-24 14:41:37,900:INFO:Declaring metric variables
2024-05-24 14:41:37,905:INFO:Importing untrained model
2024-05-24 14:41:37,911:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:41:37,920:INFO:Starting cross validation
2024-05-24 14:41:37,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:38,609:INFO:Calculating mean and std
2024-05-24 14:41:38,611:INFO:Creating metrics dataframe
2024-05-24 14:41:38,613:INFO:Uploading results into container
2024-05-24 14:41:38,614:INFO:Uploading model into container now
2024-05-24 14:41:38,614:INFO:_master_model_container: 13
2024-05-24 14:41:38,615:INFO:_display_container: 2
2024-05-24 14:41:38,615:INFO:RandomForestRegressor(n_jobs=-1, random_state=5011)
2024-05-24 14:41:38,615:INFO:create_model() successfully completed......................................
2024-05-24 14:41:38,728:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:38,729:INFO:Creating metrics dataframe
2024-05-24 14:41:38,741:INFO:Initializing Extra Trees Regressor
2024-05-24 14:41:38,741:INFO:Total runtime is 0.11047819455464682 minutes
2024-05-24 14:41:38,745:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:38,746:INFO:Initializing create_model()
2024-05-24 14:41:38,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:38,746:INFO:Checking exceptions
2024-05-24 14:41:38,746:INFO:Importing libraries
2024-05-24 14:41:38,746:INFO:Copying training dataset
2024-05-24 14:41:38,756:INFO:Defining folds
2024-05-24 14:41:38,757:INFO:Declaring metric variables
2024-05-24 14:41:38,761:INFO:Importing untrained model
2024-05-24 14:41:38,765:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:41:38,775:INFO:Starting cross validation
2024-05-24 14:41:38,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:39,467:INFO:Calculating mean and std
2024-05-24 14:41:39,468:INFO:Creating metrics dataframe
2024-05-24 14:41:39,472:INFO:Uploading results into container
2024-05-24 14:41:39,473:INFO:Uploading model into container now
2024-05-24 14:41:39,473:INFO:_master_model_container: 14
2024-05-24 14:41:39,473:INFO:_display_container: 2
2024-05-24 14:41:39,474:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5011)
2024-05-24 14:41:39,474:INFO:create_model() successfully completed......................................
2024-05-24 14:41:39,573:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:39,574:INFO:Creating metrics dataframe
2024-05-24 14:41:39,584:INFO:Initializing AdaBoost Regressor
2024-05-24 14:41:39,584:INFO:Total runtime is 0.12452578544616699 minutes
2024-05-24 14:41:39,588:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:39,589:INFO:Initializing create_model()
2024-05-24 14:41:39,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:39,589:INFO:Checking exceptions
2024-05-24 14:41:39,589:INFO:Importing libraries
2024-05-24 14:41:39,589:INFO:Copying training dataset
2024-05-24 14:41:39,597:INFO:Defining folds
2024-05-24 14:41:39,597:INFO:Declaring metric variables
2024-05-24 14:41:39,601:INFO:Importing untrained model
2024-05-24 14:41:39,605:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:41:39,613:INFO:Starting cross validation
2024-05-24 14:41:39,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:40,160:INFO:Calculating mean and std
2024-05-24 14:41:40,161:INFO:Creating metrics dataframe
2024-05-24 14:41:40,163:INFO:Uploading results into container
2024-05-24 14:41:40,164:INFO:Uploading model into container now
2024-05-24 14:41:40,165:INFO:_master_model_container: 15
2024-05-24 14:41:40,165:INFO:_display_container: 2
2024-05-24 14:41:40,165:INFO:AdaBoostRegressor(random_state=5011)
2024-05-24 14:41:40,165:INFO:create_model() successfully completed......................................
2024-05-24 14:41:40,265:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:40,265:INFO:Creating metrics dataframe
2024-05-24 14:41:40,279:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:41:40,279:INFO:Total runtime is 0.1361086328824361 minutes
2024-05-24 14:41:40,283:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:40,283:INFO:Initializing create_model()
2024-05-24 14:41:40,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:40,284:INFO:Checking exceptions
2024-05-24 14:41:40,284:INFO:Importing libraries
2024-05-24 14:41:40,284:INFO:Copying training dataset
2024-05-24 14:41:40,291:INFO:Defining folds
2024-05-24 14:41:40,291:INFO:Declaring metric variables
2024-05-24 14:41:40,295:INFO:Importing untrained model
2024-05-24 14:41:40,301:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:41:40,311:INFO:Starting cross validation
2024-05-24 14:41:40,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:40,815:INFO:Calculating mean and std
2024-05-24 14:41:40,816:INFO:Creating metrics dataframe
2024-05-24 14:41:40,819:INFO:Uploading results into container
2024-05-24 14:41:40,819:INFO:Uploading model into container now
2024-05-24 14:41:40,820:INFO:_master_model_container: 16
2024-05-24 14:41:40,820:INFO:_display_container: 2
2024-05-24 14:41:40,821:INFO:GradientBoostingRegressor(random_state=5011)
2024-05-24 14:41:40,822:INFO:create_model() successfully completed......................................
2024-05-24 14:41:40,934:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:40,935:INFO:Creating metrics dataframe
2024-05-24 14:41:40,956:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:41:40,956:INFO:Total runtime is 0.1473855892817179 minutes
2024-05-24 14:41:40,962:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:40,963:INFO:Initializing create_model()
2024-05-24 14:41:40,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:40,963:INFO:Checking exceptions
2024-05-24 14:41:40,963:INFO:Importing libraries
2024-05-24 14:41:40,963:INFO:Copying training dataset
2024-05-24 14:41:40,971:INFO:Defining folds
2024-05-24 14:41:40,971:INFO:Declaring metric variables
2024-05-24 14:41:40,977:INFO:Importing untrained model
2024-05-24 14:41:40,981:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:41:40,990:INFO:Starting cross validation
2024-05-24 14:41:40,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:42,052:INFO:Calculating mean and std
2024-05-24 14:41:42,054:INFO:Creating metrics dataframe
2024-05-24 14:41:42,058:INFO:Uploading results into container
2024-05-24 14:41:42,058:INFO:Uploading model into container now
2024-05-24 14:41:42,059:INFO:_master_model_container: 17
2024-05-24 14:41:42,059:INFO:_display_container: 2
2024-05-24 14:41:42,059:INFO:LGBMRegressor(n_jobs=-1, random_state=5011)
2024-05-24 14:41:42,060:INFO:create_model() successfully completed......................................
2024-05-24 14:41:42,168:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:42,168:INFO:Creating metrics dataframe
2024-05-24 14:41:42,178:INFO:Initializing Dummy Regressor
2024-05-24 14:41:42,178:INFO:Total runtime is 0.16775860389073688 minutes
2024-05-24 14:41:42,182:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:42,183:INFO:Initializing create_model()
2024-05-24 14:41:42,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC20130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:42,183:INFO:Checking exceptions
2024-05-24 14:41:42,183:INFO:Importing libraries
2024-05-24 14:41:42,183:INFO:Copying training dataset
2024-05-24 14:41:42,191:INFO:Defining folds
2024-05-24 14:41:42,191:INFO:Declaring metric variables
2024-05-24 14:41:42,195:INFO:Importing untrained model
2024-05-24 14:41:42,200:INFO:Dummy Regressor Imported successfully
2024-05-24 14:41:42,209:INFO:Starting cross validation
2024-05-24 14:41:42,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:42,550:INFO:Calculating mean and std
2024-05-24 14:41:42,551:INFO:Creating metrics dataframe
2024-05-24 14:41:42,555:INFO:Uploading results into container
2024-05-24 14:41:42,555:INFO:Uploading model into container now
2024-05-24 14:41:42,555:INFO:_master_model_container: 18
2024-05-24 14:41:42,556:INFO:_display_container: 2
2024-05-24 14:41:42,556:INFO:DummyRegressor()
2024-05-24 14:41:42,556:INFO:create_model() successfully completed......................................
2024-05-24 14:41:42,647:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:42,647:INFO:Creating metrics dataframe
2024-05-24 14:41:42,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:41:42,671:INFO:Initializing create_model()
2024-05-24 14:41:42,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BABDF5E0>, estimator=AdaBoostRegressor(random_state=5011), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:42,671:INFO:Checking exceptions
2024-05-24 14:41:42,673:INFO:Importing libraries
2024-05-24 14:41:42,673:INFO:Copying training dataset
2024-05-24 14:41:42,681:INFO:Defining folds
2024-05-24 14:41:42,681:INFO:Declaring metric variables
2024-05-24 14:41:42,681:INFO:Importing untrained model
2024-05-24 14:41:42,681:INFO:Declaring custom model
2024-05-24 14:41:42,682:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:41:42,685:INFO:Cross validation set to False
2024-05-24 14:41:42,685:INFO:Fitting Model
2024-05-24 14:41:42,896:INFO:AdaBoostRegressor(random_state=5011)
2024-05-24 14:41:42,896:INFO:create_model() successfully completed......................................
2024-05-24 14:41:43,019:INFO:_master_model_container: 18
2024-05-24 14:41:43,019:INFO:_display_container: 2
2024-05-24 14:41:43,019:INFO:AdaBoostRegressor(random_state=5011)
2024-05-24 14:41:43,019:INFO:compare_models() successfully completed......................................
2024-05-24 14:41:50,295:INFO:PyCaret RegressionExperiment
2024-05-24 14:41:50,295:INFO:Logging name: reg-default-name
2024-05-24 14:41:50,295:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 14:41:50,295:INFO:version 3.3.2
2024-05-24 14:41:50,295:INFO:Initializing setup()
2024-05-24 14:41:50,296:INFO:self.USI: b85a
2024-05-24 14:41:50,296:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 14:41:50,296:INFO:Checking environment
2024-05-24 14:41:50,296:INFO:python_version: 3.10.14
2024-05-24 14:41:50,296:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 14:41:50,296:INFO:machine: AMD64
2024-05-24 14:41:50,296:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 14:41:50,296:INFO:Memory: svmem(total=16541802496, available=646676480, percent=96.1, used=15895126016, free=646676480)
2024-05-24 14:41:50,296:INFO:Physical Core: 6
2024-05-24 14:41:50,296:INFO:Logical Core: 12
2024-05-24 14:41:50,296:INFO:Checking libraries
2024-05-24 14:41:50,296:INFO:System:
2024-05-24 14:41:50,296:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 14:41:50,296:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 14:41:50,296:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 14:41:50,296:INFO:PyCaret required dependencies:
2024-05-24 14:41:50,296:INFO:                 pip: 24.0
2024-05-24 14:41:50,296:INFO:          setuptools: 69.5.1
2024-05-24 14:41:50,296:INFO:             pycaret: 3.3.2
2024-05-24 14:41:50,296:INFO:             IPython: 8.20.0
2024-05-24 14:41:50,296:INFO:          ipywidgets: 8.1.2
2024-05-24 14:41:50,296:INFO:                tqdm: 4.66.4
2024-05-24 14:41:50,298:INFO:               numpy: 1.26.4
2024-05-24 14:41:50,298:INFO:              pandas: 2.1.4
2024-05-24 14:41:50,298:INFO:              jinja2: 3.1.3
2024-05-24 14:41:50,298:INFO:               scipy: 1.11.4
2024-05-24 14:41:50,298:INFO:              joblib: 1.3.2
2024-05-24 14:41:50,298:INFO:             sklearn: 1.4.2
2024-05-24 14:41:50,298:INFO:                pyod: 1.1.3
2024-05-24 14:41:50,298:INFO:            imblearn: 0.12.2
2024-05-24 14:41:50,298:INFO:   category_encoders: 2.6.3
2024-05-24 14:41:50,298:INFO:            lightgbm: 4.3.0
2024-05-24 14:41:50,298:INFO:               numba: 0.59.1
2024-05-24 14:41:50,298:INFO:            requests: 2.32.2
2024-05-24 14:41:50,298:INFO:          matplotlib: 3.7.5
2024-05-24 14:41:50,298:INFO:          scikitplot: 0.3.7
2024-05-24 14:41:50,298:INFO:         yellowbrick: 1.5
2024-05-24 14:41:50,298:INFO:              plotly: 5.22.0
2024-05-24 14:41:50,298:INFO:    plotly-resampler: Not installed
2024-05-24 14:41:50,298:INFO:             kaleido: 0.2.1
2024-05-24 14:41:50,298:INFO:           schemdraw: 0.15
2024-05-24 14:41:50,298:INFO:         statsmodels: 0.14.2
2024-05-24 14:41:50,298:INFO:              sktime: 0.26.0
2024-05-24 14:41:50,298:INFO:               tbats: 1.1.3
2024-05-24 14:41:50,298:INFO:            pmdarima: 2.0.4
2024-05-24 14:41:50,298:INFO:              psutil: 5.9.0
2024-05-24 14:41:50,298:INFO:          markupsafe: 2.1.3
2024-05-24 14:41:50,298:INFO:             pickle5: Not installed
2024-05-24 14:41:50,298:INFO:         cloudpickle: 3.0.0
2024-05-24 14:41:50,299:INFO:         deprecation: 2.1.0
2024-05-24 14:41:50,299:INFO:              xxhash: 3.4.1
2024-05-24 14:41:50,299:INFO:           wurlitzer: Not installed
2024-05-24 14:41:50,299:INFO:PyCaret optional dependencies:
2024-05-24 14:41:50,299:INFO:                shap: Not installed
2024-05-24 14:41:50,299:INFO:           interpret: Not installed
2024-05-24 14:41:50,299:INFO:                umap: Not installed
2024-05-24 14:41:50,299:INFO:     ydata_profiling: Not installed
2024-05-24 14:41:50,299:INFO:  explainerdashboard: Not installed
2024-05-24 14:41:50,299:INFO:             autoviz: Not installed
2024-05-24 14:41:50,299:INFO:           fairlearn: Not installed
2024-05-24 14:41:50,299:INFO:          deepchecks: Not installed
2024-05-24 14:41:50,299:INFO:             xgboost: Not installed
2024-05-24 14:41:50,299:INFO:            catboost: Not installed
2024-05-24 14:41:50,299:INFO:              kmodes: Not installed
2024-05-24 14:41:50,299:INFO:             mlxtend: Not installed
2024-05-24 14:41:50,299:INFO:       statsforecast: Not installed
2024-05-24 14:41:50,299:INFO:        tune_sklearn: Not installed
2024-05-24 14:41:50,299:INFO:                 ray: Not installed
2024-05-24 14:41:50,299:INFO:            hyperopt: Not installed
2024-05-24 14:41:50,299:INFO:              optuna: Not installed
2024-05-24 14:41:50,299:INFO:               skopt: Not installed
2024-05-24 14:41:50,299:INFO:              mlflow: Not installed
2024-05-24 14:41:50,299:INFO:              gradio: Not installed
2024-05-24 14:41:50,299:INFO:             fastapi: Not installed
2024-05-24 14:41:50,299:INFO:             uvicorn: Not installed
2024-05-24 14:41:50,300:INFO:              m2cgen: Not installed
2024-05-24 14:41:50,300:INFO:           evidently: Not installed
2024-05-24 14:41:50,300:INFO:               fugue: Not installed
2024-05-24 14:41:50,300:INFO:           streamlit: Not installed
2024-05-24 14:41:50,300:INFO:             prophet: Not installed
2024-05-24 14:41:50,300:INFO:None
2024-05-24 14:41:50,300:INFO:Set up data.
2024-05-24 14:41:50,309:INFO:Set up folding strategy.
2024-05-24 14:41:50,309:INFO:Set up train/test split.
2024-05-24 14:41:50,316:INFO:Set up index.
2024-05-24 14:41:50,317:INFO:Assigning column types.
2024-05-24 14:41:50,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 14:41:50,323:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,328:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,333:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,492:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,497:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,503:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,645:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 14:41:50,649:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,752:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,756:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,848:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 14:41:50,856:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,908:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:50,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:50,957:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,053:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 14:41:51,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,216:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,258:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 14:41:51,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:41:51,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,537:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 14:41:51,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:51,799:INFO:Preparing preprocessing pipeline...
2024-05-24 14:41:51,799:INFO:Set up simple imputation.
2024-05-24 14:41:51,803:INFO:Set up encoding of ordinal features.
2024-05-24 14:41:51,810:INFO:Set up encoding of categorical features.
2024-05-24 14:41:51,963:INFO:Finished creating preprocessing pipeline.
2024-05-24 14:41:52,031:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['car_ID', 'symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('cat...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 14:41:52,031:INFO:Creating final display dataframe.
2024-05-24 14:41:52,688:INFO:Setup _display_container:                     Description             Value
0                    Session id              1258
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 26)
4        Transformed data shape         (205, 48)
5   Transformed train set shape         (143, 48)
6    Transformed test set shape          (62, 48)
7              Numeric features                15
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              b85a
2024-05-24 14:41:52,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:52,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:52,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:52,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:41:52,978:INFO:setup() successfully completed in 2.69s...............
2024-05-24 14:41:53,006:INFO:Initializing compare_models()
2024-05-24 14:41:53,006:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:41:53,006:INFO:Checking exceptions
2024-05-24 14:41:53,010:INFO:Preparing display monitor
2024-05-24 14:41:53,035:INFO:Initializing Linear Regression
2024-05-24 14:41:53,035:INFO:Total runtime is 0.0 minutes
2024-05-24 14:41:53,042:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:53,042:INFO:Initializing create_model()
2024-05-24 14:41:53,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=lr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:53,043:INFO:Checking exceptions
2024-05-24 14:41:53,043:INFO:Importing libraries
2024-05-24 14:41:53,043:INFO:Copying training dataset
2024-05-24 14:41:53,053:INFO:Defining folds
2024-05-24 14:41:53,053:INFO:Declaring metric variables
2024-05-24 14:41:53,058:INFO:Importing untrained model
2024-05-24 14:41:53,062:INFO:Linear Regression Imported successfully
2024-05-24 14:41:53,071:INFO:Starting cross validation
2024-05-24 14:41:53,075:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:53,351:INFO:Calculating mean and std
2024-05-24 14:41:53,352:INFO:Creating metrics dataframe
2024-05-24 14:41:53,355:INFO:Uploading results into container
2024-05-24 14:41:53,356:INFO:Uploading model into container now
2024-05-24 14:41:53,357:INFO:_master_model_container: 1
2024-05-24 14:41:53,357:INFO:_display_container: 2
2024-05-24 14:41:53,358:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:41:53,358:INFO:create_model() successfully completed......................................
2024-05-24 14:41:53,463:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:53,463:INFO:Creating metrics dataframe
2024-05-24 14:41:53,471:INFO:Initializing Lasso Regression
2024-05-24 14:41:53,471:INFO:Total runtime is 0.007259786128997803 minutes
2024-05-24 14:41:53,474:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:53,474:INFO:Initializing create_model()
2024-05-24 14:41:53,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=lasso, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:53,474:INFO:Checking exceptions
2024-05-24 14:41:53,474:INFO:Importing libraries
2024-05-24 14:41:53,474:INFO:Copying training dataset
2024-05-24 14:41:53,480:INFO:Defining folds
2024-05-24 14:41:53,481:INFO:Declaring metric variables
2024-05-24 14:41:53,484:INFO:Importing untrained model
2024-05-24 14:41:53,487:INFO:Lasso Regression Imported successfully
2024-05-24 14:41:53,497:INFO:Starting cross validation
2024-05-24 14:41:53,499:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:53,716:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e+07, tolerance: 7.008e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:53,723:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e+07, tolerance: 6.107e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:53,737:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.180e+07, tolerance: 6.485e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:41:53,817:INFO:Calculating mean and std
2024-05-24 14:41:53,817:INFO:Creating metrics dataframe
2024-05-24 14:41:53,819:INFO:Uploading results into container
2024-05-24 14:41:53,819:INFO:Uploading model into container now
2024-05-24 14:41:53,820:INFO:_master_model_container: 2
2024-05-24 14:41:53,820:INFO:_display_container: 2
2024-05-24 14:41:53,820:INFO:Lasso(random_state=1258)
2024-05-24 14:41:53,820:INFO:create_model() successfully completed......................................
2024-05-24 14:41:53,921:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:53,921:INFO:Creating metrics dataframe
2024-05-24 14:41:53,932:INFO:Initializing Ridge Regression
2024-05-24 14:41:53,932:INFO:Total runtime is 0.014951447645823162 minutes
2024-05-24 14:41:53,936:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:53,937:INFO:Initializing create_model()
2024-05-24 14:41:53,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=ridge, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:53,937:INFO:Checking exceptions
2024-05-24 14:41:53,938:INFO:Importing libraries
2024-05-24 14:41:53,938:INFO:Copying training dataset
2024-05-24 14:41:53,947:INFO:Defining folds
2024-05-24 14:41:53,948:INFO:Declaring metric variables
2024-05-24 14:41:53,951:INFO:Importing untrained model
2024-05-24 14:41:53,956:INFO:Ridge Regression Imported successfully
2024-05-24 14:41:53,964:INFO:Starting cross validation
2024-05-24 14:41:53,968:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:54,222:INFO:Calculating mean and std
2024-05-24 14:41:54,223:INFO:Creating metrics dataframe
2024-05-24 14:41:54,225:INFO:Uploading results into container
2024-05-24 14:41:54,226:INFO:Uploading model into container now
2024-05-24 14:41:54,226:INFO:_master_model_container: 3
2024-05-24 14:41:54,226:INFO:_display_container: 2
2024-05-24 14:41:54,226:INFO:Ridge(random_state=1258)
2024-05-24 14:41:54,226:INFO:create_model() successfully completed......................................
2024-05-24 14:41:54,323:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:54,323:INFO:Creating metrics dataframe
2024-05-24 14:41:54,333:INFO:Initializing Elastic Net
2024-05-24 14:41:54,333:INFO:Total runtime is 0.021633621056874594 minutes
2024-05-24 14:41:54,339:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:54,340:INFO:Initializing create_model()
2024-05-24 14:41:54,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=en, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:54,341:INFO:Checking exceptions
2024-05-24 14:41:54,341:INFO:Importing libraries
2024-05-24 14:41:54,341:INFO:Copying training dataset
2024-05-24 14:41:54,351:INFO:Defining folds
2024-05-24 14:41:54,351:INFO:Declaring metric variables
2024-05-24 14:41:54,356:INFO:Importing untrained model
2024-05-24 14:41:54,363:INFO:Elastic Net Imported successfully
2024-05-24 14:41:54,374:INFO:Starting cross validation
2024-05-24 14:41:54,380:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:54,677:INFO:Calculating mean and std
2024-05-24 14:41:54,678:INFO:Creating metrics dataframe
2024-05-24 14:41:54,681:INFO:Uploading results into container
2024-05-24 14:41:54,681:INFO:Uploading model into container now
2024-05-24 14:41:54,682:INFO:_master_model_container: 4
2024-05-24 14:41:54,682:INFO:_display_container: 2
2024-05-24 14:41:54,682:INFO:ElasticNet(random_state=1258)
2024-05-24 14:41:54,682:INFO:create_model() successfully completed......................................
2024-05-24 14:41:54,777:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:54,777:INFO:Creating metrics dataframe
2024-05-24 14:41:54,784:INFO:Initializing Least Angle Regression
2024-05-24 14:41:54,784:INFO:Total runtime is 0.029147009054819744 minutes
2024-05-24 14:41:54,788:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:54,788:INFO:Initializing create_model()
2024-05-24 14:41:54,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=lar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:54,788:INFO:Checking exceptions
2024-05-24 14:41:54,789:INFO:Importing libraries
2024-05-24 14:41:54,789:INFO:Copying training dataset
2024-05-24 14:41:54,794:INFO:Defining folds
2024-05-24 14:41:54,794:INFO:Declaring metric variables
2024-05-24 14:41:54,799:INFO:Importing untrained model
2024-05-24 14:41:54,802:INFO:Least Angle Regression Imported successfully
2024-05-24 14:41:54,809:INFO:Starting cross validation
2024-05-24 14:41:54,812:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:54,954:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.892e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,955:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.458e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,956:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.149e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,956:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.350e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,956:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=3.011e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.260e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=3.407e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.686e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.356e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=5.837e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.480e+00, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,958:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.319e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,958:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.981e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,961:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.268e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,963:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=9.303e+01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,964:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.346e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,965:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.233e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,965:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.233e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=6.975e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.787e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,969:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.258e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,970:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.210e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:54,970:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=3.616e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,067:INFO:Calculating mean and std
2024-05-24 14:41:55,068:INFO:Creating metrics dataframe
2024-05-24 14:41:55,070:INFO:Uploading results into container
2024-05-24 14:41:55,070:INFO:Uploading model into container now
2024-05-24 14:41:55,071:INFO:_master_model_container: 5
2024-05-24 14:41:55,071:INFO:_display_container: 2
2024-05-24 14:41:55,071:INFO:Lars(random_state=1258)
2024-05-24 14:41:55,071:INFO:create_model() successfully completed......................................
2024-05-24 14:41:55,161:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:55,161:INFO:Creating metrics dataframe
2024-05-24 14:41:55,171:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:41:55,172:INFO:Total runtime is 0.03562207221984864 minutes
2024-05-24 14:41:55,177:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:55,178:INFO:Initializing create_model()
2024-05-24 14:41:55,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=llar, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:55,178:INFO:Checking exceptions
2024-05-24 14:41:55,178:INFO:Importing libraries
2024-05-24 14:41:55,178:INFO:Copying training dataset
2024-05-24 14:41:55,188:INFO:Defining folds
2024-05-24 14:41:55,189:INFO:Declaring metric variables
2024-05-24 14:41:55,194:INFO:Importing untrained model
2024-05-24 14:41:55,199:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:41:55,208:INFO:Starting cross validation
2024-05-24 14:41:55,212:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:55,382:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=2.821e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,383:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.780e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,383:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.390e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,384:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.370e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,384:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.369e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,390:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.404e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,390:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.318e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,390:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.243e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,391:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.038e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,391:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=2.014e+00, previous alpha=1.622e+00, with an active set of 38 regressors.
  warnings.warn(

2024-05-24 14:41:55,402:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.741e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:41:55,467:INFO:Calculating mean and std
2024-05-24 14:41:55,468:INFO:Creating metrics dataframe
2024-05-24 14:41:55,470:INFO:Uploading results into container
2024-05-24 14:41:55,471:INFO:Uploading model into container now
2024-05-24 14:41:55,471:INFO:_master_model_container: 6
2024-05-24 14:41:55,471:INFO:_display_container: 2
2024-05-24 14:41:55,472:INFO:LassoLars(random_state=1258)
2024-05-24 14:41:55,472:INFO:create_model() successfully completed......................................
2024-05-24 14:41:55,554:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:55,554:INFO:Creating metrics dataframe
2024-05-24 14:41:55,565:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:41:55,565:INFO:Total runtime is 0.04216216405232748 minutes
2024-05-24 14:41:55,568:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:55,569:INFO:Initializing create_model()
2024-05-24 14:41:55,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=omp, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:55,569:INFO:Checking exceptions
2024-05-24 14:41:55,569:INFO:Importing libraries
2024-05-24 14:41:55,569:INFO:Copying training dataset
2024-05-24 14:41:55,576:INFO:Defining folds
2024-05-24 14:41:55,577:INFO:Declaring metric variables
2024-05-24 14:41:55,581:INFO:Importing untrained model
2024-05-24 14:41:55,585:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:41:55,594:INFO:Starting cross validation
2024-05-24 14:41:55,598:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:55,811:INFO:Calculating mean and std
2024-05-24 14:41:55,812:INFO:Creating metrics dataframe
2024-05-24 14:41:55,814:INFO:Uploading results into container
2024-05-24 14:41:55,814:INFO:Uploading model into container now
2024-05-24 14:41:55,814:INFO:_master_model_container: 7
2024-05-24 14:41:55,815:INFO:_display_container: 2
2024-05-24 14:41:55,815:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:41:55,815:INFO:create_model() successfully completed......................................
2024-05-24 14:41:55,903:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:55,903:INFO:Creating metrics dataframe
2024-05-24 14:41:55,910:INFO:Initializing Bayesian Ridge
2024-05-24 14:41:55,910:INFO:Total runtime is 0.04791827201843262 minutes
2024-05-24 14:41:55,914:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:55,914:INFO:Initializing create_model()
2024-05-24 14:41:55,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=br, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:55,914:INFO:Checking exceptions
2024-05-24 14:41:55,915:INFO:Importing libraries
2024-05-24 14:41:55,915:INFO:Copying training dataset
2024-05-24 14:41:55,920:INFO:Defining folds
2024-05-24 14:41:55,920:INFO:Declaring metric variables
2024-05-24 14:41:55,924:INFO:Importing untrained model
2024-05-24 14:41:55,928:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:41:55,947:INFO:Starting cross validation
2024-05-24 14:41:55,951:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:56,232:INFO:Calculating mean and std
2024-05-24 14:41:56,233:INFO:Creating metrics dataframe
2024-05-24 14:41:56,235:INFO:Uploading results into container
2024-05-24 14:41:56,236:INFO:Uploading model into container now
2024-05-24 14:41:56,236:INFO:_master_model_container: 8
2024-05-24 14:41:56,236:INFO:_display_container: 2
2024-05-24 14:41:56,237:INFO:BayesianRidge()
2024-05-24 14:41:56,237:INFO:create_model() successfully completed......................................
2024-05-24 14:41:56,321:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:56,322:INFO:Creating metrics dataframe
2024-05-24 14:41:56,331:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:41:56,332:INFO:Total runtime is 0.05495225588480632 minutes
2024-05-24 14:41:56,336:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:56,336:INFO:Initializing create_model()
2024-05-24 14:41:56,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=par, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:56,336:INFO:Checking exceptions
2024-05-24 14:41:56,336:INFO:Importing libraries
2024-05-24 14:41:56,336:INFO:Copying training dataset
2024-05-24 14:41:56,344:INFO:Defining folds
2024-05-24 14:41:56,344:INFO:Declaring metric variables
2024-05-24 14:41:56,349:INFO:Importing untrained model
2024-05-24 14:41:56,353:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:41:56,363:INFO:Starting cross validation
2024-05-24 14:41:56,366:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:56,622:INFO:Calculating mean and std
2024-05-24 14:41:56,623:INFO:Creating metrics dataframe
2024-05-24 14:41:56,626:INFO:Uploading results into container
2024-05-24 14:41:56,626:INFO:Uploading model into container now
2024-05-24 14:41:56,627:INFO:_master_model_container: 9
2024-05-24 14:41:56,627:INFO:_display_container: 2
2024-05-24 14:41:56,627:INFO:PassiveAggressiveRegressor(random_state=1258)
2024-05-24 14:41:56,627:INFO:create_model() successfully completed......................................
2024-05-24 14:41:56,722:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:56,722:INFO:Creating metrics dataframe
2024-05-24 14:41:56,732:INFO:Initializing Huber Regressor
2024-05-24 14:41:56,732:INFO:Total runtime is 0.061620549360911055 minutes
2024-05-24 14:41:56,736:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:56,736:INFO:Initializing create_model()
2024-05-24 14:41:56,737:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=huber, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:56,737:INFO:Checking exceptions
2024-05-24 14:41:56,737:INFO:Importing libraries
2024-05-24 14:41:56,737:INFO:Copying training dataset
2024-05-24 14:41:56,743:INFO:Defining folds
2024-05-24 14:41:56,743:INFO:Declaring metric variables
2024-05-24 14:41:56,747:INFO:Importing untrained model
2024-05-24 14:41:56,751:INFO:Huber Regressor Imported successfully
2024-05-24 14:41:56,760:INFO:Starting cross validation
2024-05-24 14:41:56,762:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:56,973:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:56,977:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:56,980:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:56,983:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:57,003:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:41:57,059:INFO:Calculating mean and std
2024-05-24 14:41:57,060:INFO:Creating metrics dataframe
2024-05-24 14:41:57,062:INFO:Uploading results into container
2024-05-24 14:41:57,063:INFO:Uploading model into container now
2024-05-24 14:41:57,063:INFO:_master_model_container: 10
2024-05-24 14:41:57,063:INFO:_display_container: 2
2024-05-24 14:41:57,064:INFO:HuberRegressor()
2024-05-24 14:41:57,064:INFO:create_model() successfully completed......................................
2024-05-24 14:41:57,148:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:57,148:INFO:Creating metrics dataframe
2024-05-24 14:41:57,157:INFO:Initializing K Neighbors Regressor
2024-05-24 14:41:57,157:INFO:Total runtime is 0.06870398918787639 minutes
2024-05-24 14:41:57,162:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:57,163:INFO:Initializing create_model()
2024-05-24 14:41:57,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=knn, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:57,163:INFO:Checking exceptions
2024-05-24 14:41:57,163:INFO:Importing libraries
2024-05-24 14:41:57,163:INFO:Copying training dataset
2024-05-24 14:41:57,170:INFO:Defining folds
2024-05-24 14:41:57,170:INFO:Declaring metric variables
2024-05-24 14:41:57,175:INFO:Importing untrained model
2024-05-24 14:41:57,179:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:41:57,186:INFO:Starting cross validation
2024-05-24 14:41:57,190:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:57,496:INFO:Calculating mean and std
2024-05-24 14:41:57,497:INFO:Creating metrics dataframe
2024-05-24 14:41:57,500:INFO:Uploading results into container
2024-05-24 14:41:57,501:INFO:Uploading model into container now
2024-05-24 14:41:57,501:INFO:_master_model_container: 11
2024-05-24 14:41:57,501:INFO:_display_container: 2
2024-05-24 14:41:57,501:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:41:57,501:INFO:create_model() successfully completed......................................
2024-05-24 14:41:57,590:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:57,590:INFO:Creating metrics dataframe
2024-05-24 14:41:57,601:INFO:Initializing Decision Tree Regressor
2024-05-24 14:41:57,601:INFO:Total runtime is 0.07610299984614055 minutes
2024-05-24 14:41:57,606:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:57,606:INFO:Initializing create_model()
2024-05-24 14:41:57,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=dt, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:57,607:INFO:Checking exceptions
2024-05-24 14:41:57,607:INFO:Importing libraries
2024-05-24 14:41:57,607:INFO:Copying training dataset
2024-05-24 14:41:57,613:INFO:Defining folds
2024-05-24 14:41:57,613:INFO:Declaring metric variables
2024-05-24 14:41:57,617:INFO:Importing untrained model
2024-05-24 14:41:57,622:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:41:57,631:INFO:Starting cross validation
2024-05-24 14:41:57,634:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:57,900:INFO:Calculating mean and std
2024-05-24 14:41:57,902:INFO:Creating metrics dataframe
2024-05-24 14:41:57,904:INFO:Uploading results into container
2024-05-24 14:41:57,904:INFO:Uploading model into container now
2024-05-24 14:41:57,905:INFO:_master_model_container: 12
2024-05-24 14:41:57,905:INFO:_display_container: 2
2024-05-24 14:41:57,905:INFO:DecisionTreeRegressor(random_state=1258)
2024-05-24 14:41:57,906:INFO:create_model() successfully completed......................................
2024-05-24 14:41:57,997:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:57,998:INFO:Creating metrics dataframe
2024-05-24 14:41:58,011:INFO:Initializing Random Forest Regressor
2024-05-24 14:41:58,011:INFO:Total runtime is 0.08293444315592449 minutes
2024-05-24 14:41:58,015:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:58,015:INFO:Initializing create_model()
2024-05-24 14:41:58,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=rf, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:58,017:INFO:Checking exceptions
2024-05-24 14:41:58,017:INFO:Importing libraries
2024-05-24 14:41:58,017:INFO:Copying training dataset
2024-05-24 14:41:58,026:INFO:Defining folds
2024-05-24 14:41:58,026:INFO:Declaring metric variables
2024-05-24 14:41:58,030:INFO:Importing untrained model
2024-05-24 14:41:58,035:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:41:58,046:INFO:Starting cross validation
2024-05-24 14:41:58,049:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:58,515:INFO:Calculating mean and std
2024-05-24 14:41:58,516:INFO:Creating metrics dataframe
2024-05-24 14:41:58,519:INFO:Uploading results into container
2024-05-24 14:41:58,520:INFO:Uploading model into container now
2024-05-24 14:41:58,520:INFO:_master_model_container: 13
2024-05-24 14:41:58,520:INFO:_display_container: 2
2024-05-24 14:41:58,521:INFO:RandomForestRegressor(n_jobs=-1, random_state=1258)
2024-05-24 14:41:58,521:INFO:create_model() successfully completed......................................
2024-05-24 14:41:58,597:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:58,597:INFO:Creating metrics dataframe
2024-05-24 14:41:58,605:INFO:Initializing Extra Trees Regressor
2024-05-24 14:41:58,606:INFO:Total runtime is 0.09285300572713218 minutes
2024-05-24 14:41:58,609:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:58,609:INFO:Initializing create_model()
2024-05-24 14:41:58,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=et, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:58,609:INFO:Checking exceptions
2024-05-24 14:41:58,610:INFO:Importing libraries
2024-05-24 14:41:58,610:INFO:Copying training dataset
2024-05-24 14:41:58,615:INFO:Defining folds
2024-05-24 14:41:58,615:INFO:Declaring metric variables
2024-05-24 14:41:58,617:INFO:Importing untrained model
2024-05-24 14:41:58,621:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:41:58,629:INFO:Starting cross validation
2024-05-24 14:41:58,633:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:59,035:INFO:Calculating mean and std
2024-05-24 14:41:59,036:INFO:Creating metrics dataframe
2024-05-24 14:41:59,038:INFO:Uploading results into container
2024-05-24 14:41:59,039:INFO:Uploading model into container now
2024-05-24 14:41:59,039:INFO:_master_model_container: 14
2024-05-24 14:41:59,039:INFO:_display_container: 2
2024-05-24 14:41:59,040:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1258)
2024-05-24 14:41:59,040:INFO:create_model() successfully completed......................................
2024-05-24 14:41:59,120:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:59,120:INFO:Creating metrics dataframe
2024-05-24 14:41:59,130:INFO:Initializing AdaBoost Regressor
2024-05-24 14:41:59,130:INFO:Total runtime is 0.1015760660171509 minutes
2024-05-24 14:41:59,133:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:59,134:INFO:Initializing create_model()
2024-05-24 14:41:59,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=ada, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:59,134:INFO:Checking exceptions
2024-05-24 14:41:59,134:INFO:Importing libraries
2024-05-24 14:41:59,134:INFO:Copying training dataset
2024-05-24 14:41:59,138:INFO:Defining folds
2024-05-24 14:41:59,138:INFO:Declaring metric variables
2024-05-24 14:41:59,142:INFO:Importing untrained model
2024-05-24 14:41:59,144:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:41:59,152:INFO:Starting cross validation
2024-05-24 14:41:59,156:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:59,534:INFO:Calculating mean and std
2024-05-24 14:41:59,534:INFO:Creating metrics dataframe
2024-05-24 14:41:59,537:INFO:Uploading results into container
2024-05-24 14:41:59,538:INFO:Uploading model into container now
2024-05-24 14:41:59,538:INFO:_master_model_container: 15
2024-05-24 14:41:59,538:INFO:_display_container: 2
2024-05-24 14:41:59,539:INFO:AdaBoostRegressor(random_state=1258)
2024-05-24 14:41:59,539:INFO:create_model() successfully completed......................................
2024-05-24 14:41:59,620:INFO:SubProcess create_model() end ==================================
2024-05-24 14:41:59,621:INFO:Creating metrics dataframe
2024-05-24 14:41:59,631:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:41:59,631:INFO:Total runtime is 0.10992661317189537 minutes
2024-05-24 14:41:59,634:INFO:SubProcess create_model() called ==================================
2024-05-24 14:41:59,634:INFO:Initializing create_model()
2024-05-24 14:41:59,635:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=gbr, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:41:59,635:INFO:Checking exceptions
2024-05-24 14:41:59,635:INFO:Importing libraries
2024-05-24 14:41:59,635:INFO:Copying training dataset
2024-05-24 14:41:59,640:INFO:Defining folds
2024-05-24 14:41:59,640:INFO:Declaring metric variables
2024-05-24 14:41:59,643:INFO:Importing untrained model
2024-05-24 14:41:59,646:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:41:59,654:INFO:Starting cross validation
2024-05-24 14:41:59,658:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:41:59,953:INFO:Calculating mean and std
2024-05-24 14:41:59,954:INFO:Creating metrics dataframe
2024-05-24 14:41:59,958:INFO:Uploading results into container
2024-05-24 14:41:59,958:INFO:Uploading model into container now
2024-05-24 14:41:59,959:INFO:_master_model_container: 16
2024-05-24 14:41:59,959:INFO:_display_container: 2
2024-05-24 14:41:59,960:INFO:GradientBoostingRegressor(random_state=1258)
2024-05-24 14:41:59,960:INFO:create_model() successfully completed......................................
2024-05-24 14:42:00,066:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:00,066:INFO:Creating metrics dataframe
2024-05-24 14:42:00,081:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:42:00,081:INFO:Total runtime is 0.11743168036142987 minutes
2024-05-24 14:42:00,086:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:00,086:INFO:Initializing create_model()
2024-05-24 14:42:00,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=lightgbm, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:00,087:INFO:Checking exceptions
2024-05-24 14:42:00,087:INFO:Importing libraries
2024-05-24 14:42:00,087:INFO:Copying training dataset
2024-05-24 14:42:00,095:INFO:Defining folds
2024-05-24 14:42:00,096:INFO:Declaring metric variables
2024-05-24 14:42:00,099:INFO:Importing untrained model
2024-05-24 14:42:00,102:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:42:00,115:INFO:Starting cross validation
2024-05-24 14:42:00,120:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:00,609:INFO:Calculating mean and std
2024-05-24 14:42:00,610:INFO:Creating metrics dataframe
2024-05-24 14:42:00,613:INFO:Uploading results into container
2024-05-24 14:42:00,614:INFO:Uploading model into container now
2024-05-24 14:42:00,614:INFO:_master_model_container: 17
2024-05-24 14:42:00,614:INFO:_display_container: 2
2024-05-24 14:42:00,615:INFO:LGBMRegressor(n_jobs=-1, random_state=1258)
2024-05-24 14:42:00,615:INFO:create_model() successfully completed......................................
2024-05-24 14:42:00,714:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:00,714:INFO:Creating metrics dataframe
2024-05-24 14:42:00,726:INFO:Initializing Dummy Regressor
2024-05-24 14:42:00,726:INFO:Total runtime is 0.12817924022674562 minutes
2024-05-24 14:42:00,730:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:00,731:INFO:Initializing create_model()
2024-05-24 14:42:00,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=dummy, fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221874B4370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:00,731:INFO:Checking exceptions
2024-05-24 14:42:00,731:INFO:Importing libraries
2024-05-24 14:42:00,731:INFO:Copying training dataset
2024-05-24 14:42:00,737:INFO:Defining folds
2024-05-24 14:42:00,737:INFO:Declaring metric variables
2024-05-24 14:42:00,742:INFO:Importing untrained model
2024-05-24 14:42:00,746:INFO:Dummy Regressor Imported successfully
2024-05-24 14:42:00,755:INFO:Starting cross validation
2024-05-24 14:42:00,759:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:00,989:INFO:Calculating mean and std
2024-05-24 14:42:00,990:INFO:Creating metrics dataframe
2024-05-24 14:42:00,993:INFO:Uploading results into container
2024-05-24 14:42:00,993:INFO:Uploading model into container now
2024-05-24 14:42:00,994:INFO:_master_model_container: 18
2024-05-24 14:42:00,994:INFO:_display_container: 2
2024-05-24 14:42:00,994:INFO:DummyRegressor()
2024-05-24 14:42:00,994:INFO:create_model() successfully completed......................................
2024-05-24 14:42:01,079:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:01,079:INFO:Creating metrics dataframe
2024-05-24 14:42:01,091:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:42:01,101:INFO:Initializing create_model()
2024-05-24 14:42:01,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC205E0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:01,101:INFO:Checking exceptions
2024-05-24 14:42:01,103:INFO:Importing libraries
2024-05-24 14:42:01,103:INFO:Copying training dataset
2024-05-24 14:42:01,109:INFO:Defining folds
2024-05-24 14:42:01,109:INFO:Declaring metric variables
2024-05-24 14:42:01,109:INFO:Importing untrained model
2024-05-24 14:42:01,110:INFO:Declaring custom model
2024-05-24 14:42:01,110:INFO:Linear Regression Imported successfully
2024-05-24 14:42:01,112:INFO:Cross validation set to False
2024-05-24 14:42:01,112:INFO:Fitting Model
2024-05-24 14:42:01,201:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:42:01,201:INFO:create_model() successfully completed......................................
2024-05-24 14:42:01,311:INFO:_master_model_container: 18
2024-05-24 14:42:01,311:INFO:_display_container: 2
2024-05-24 14:42:01,313:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:42:01,313:INFO:compare_models() successfully completed......................................
2024-05-24 14:42:19,269:INFO:PyCaret RegressionExperiment
2024-05-24 14:42:19,269:INFO:Logging name: reg-default-name
2024-05-24 14:42:19,269:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 14:42:19,269:INFO:version 3.3.2
2024-05-24 14:42:19,269:INFO:Initializing setup()
2024-05-24 14:42:19,269:INFO:self.USI: 4c8b
2024-05-24 14:42:19,269:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 14:42:19,269:INFO:Checking environment
2024-05-24 14:42:19,269:INFO:python_version: 3.10.14
2024-05-24 14:42:19,269:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 14:42:19,269:INFO:machine: AMD64
2024-05-24 14:42:19,269:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 14:42:19,269:INFO:Memory: svmem(total=16541802496, available=683036672, percent=95.9, used=15858765824, free=683036672)
2024-05-24 14:42:19,269:INFO:Physical Core: 6
2024-05-24 14:42:19,269:INFO:Logical Core: 12
2024-05-24 14:42:19,270:INFO:Checking libraries
2024-05-24 14:42:19,270:INFO:System:
2024-05-24 14:42:19,270:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 14:42:19,270:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 14:42:19,270:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 14:42:19,270:INFO:PyCaret required dependencies:
2024-05-24 14:42:19,270:INFO:                 pip: 24.0
2024-05-24 14:42:19,270:INFO:          setuptools: 69.5.1
2024-05-24 14:42:19,270:INFO:             pycaret: 3.3.2
2024-05-24 14:42:19,270:INFO:             IPython: 8.20.0
2024-05-24 14:42:19,270:INFO:          ipywidgets: 8.1.2
2024-05-24 14:42:19,270:INFO:                tqdm: 4.66.4
2024-05-24 14:42:19,270:INFO:               numpy: 1.26.4
2024-05-24 14:42:19,270:INFO:              pandas: 2.1.4
2024-05-24 14:42:19,270:INFO:              jinja2: 3.1.3
2024-05-24 14:42:19,270:INFO:               scipy: 1.11.4
2024-05-24 14:42:19,270:INFO:              joblib: 1.3.2
2024-05-24 14:42:19,270:INFO:             sklearn: 1.4.2
2024-05-24 14:42:19,270:INFO:                pyod: 1.1.3
2024-05-24 14:42:19,270:INFO:            imblearn: 0.12.2
2024-05-24 14:42:19,270:INFO:   category_encoders: 2.6.3
2024-05-24 14:42:19,270:INFO:            lightgbm: 4.3.0
2024-05-24 14:42:19,270:INFO:               numba: 0.59.1
2024-05-24 14:42:19,270:INFO:            requests: 2.32.2
2024-05-24 14:42:19,270:INFO:          matplotlib: 3.7.5
2024-05-24 14:42:19,270:INFO:          scikitplot: 0.3.7
2024-05-24 14:42:19,270:INFO:         yellowbrick: 1.5
2024-05-24 14:42:19,271:INFO:              plotly: 5.22.0
2024-05-24 14:42:19,271:INFO:    plotly-resampler: Not installed
2024-05-24 14:42:19,271:INFO:             kaleido: 0.2.1
2024-05-24 14:42:19,271:INFO:           schemdraw: 0.15
2024-05-24 14:42:19,271:INFO:         statsmodels: 0.14.2
2024-05-24 14:42:19,271:INFO:              sktime: 0.26.0
2024-05-24 14:42:19,271:INFO:               tbats: 1.1.3
2024-05-24 14:42:19,271:INFO:            pmdarima: 2.0.4
2024-05-24 14:42:19,271:INFO:              psutil: 5.9.0
2024-05-24 14:42:19,271:INFO:          markupsafe: 2.1.3
2024-05-24 14:42:19,271:INFO:             pickle5: Not installed
2024-05-24 14:42:19,271:INFO:         cloudpickle: 3.0.0
2024-05-24 14:42:19,271:INFO:         deprecation: 2.1.0
2024-05-24 14:42:19,271:INFO:              xxhash: 3.4.1
2024-05-24 14:42:19,271:INFO:           wurlitzer: Not installed
2024-05-24 14:42:19,271:INFO:PyCaret optional dependencies:
2024-05-24 14:42:19,271:INFO:                shap: Not installed
2024-05-24 14:42:19,271:INFO:           interpret: Not installed
2024-05-24 14:42:19,271:INFO:                umap: Not installed
2024-05-24 14:42:19,271:INFO:     ydata_profiling: Not installed
2024-05-24 14:42:19,271:INFO:  explainerdashboard: Not installed
2024-05-24 14:42:19,271:INFO:             autoviz: Not installed
2024-05-24 14:42:19,271:INFO:           fairlearn: Not installed
2024-05-24 14:42:19,271:INFO:          deepchecks: Not installed
2024-05-24 14:42:19,271:INFO:             xgboost: Not installed
2024-05-24 14:42:19,271:INFO:            catboost: Not installed
2024-05-24 14:42:19,271:INFO:              kmodes: Not installed
2024-05-24 14:42:19,271:INFO:             mlxtend: Not installed
2024-05-24 14:42:19,271:INFO:       statsforecast: Not installed
2024-05-24 14:42:19,271:INFO:        tune_sklearn: Not installed
2024-05-24 14:42:19,271:INFO:                 ray: Not installed
2024-05-24 14:42:19,271:INFO:            hyperopt: Not installed
2024-05-24 14:42:19,271:INFO:              optuna: Not installed
2024-05-24 14:42:19,271:INFO:               skopt: Not installed
2024-05-24 14:42:19,271:INFO:              mlflow: Not installed
2024-05-24 14:42:19,271:INFO:              gradio: Not installed
2024-05-24 14:42:19,271:INFO:             fastapi: Not installed
2024-05-24 14:42:19,273:INFO:             uvicorn: Not installed
2024-05-24 14:42:19,273:INFO:              m2cgen: Not installed
2024-05-24 14:42:19,273:INFO:           evidently: Not installed
2024-05-24 14:42:19,273:INFO:               fugue: Not installed
2024-05-24 14:42:19,273:INFO:           streamlit: Not installed
2024-05-24 14:42:19,273:INFO:             prophet: Not installed
2024-05-24 14:42:19,273:INFO:None
2024-05-24 14:42:19,273:INFO:Set up data.
2024-05-24 14:42:19,280:INFO:Set up folding strategy.
2024-05-24 14:42:19,280:INFO:Set up train/test split.
2024-05-24 14:42:19,287:INFO:Set up index.
2024-05-24 14:42:19,287:INFO:Assigning column types.
2024-05-24 14:42:19,290:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 14:42:19,291:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,297:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,392:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,400:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,489:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,490:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 14:42:19,495:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,499:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,550:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,620:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,629:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,634:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,686:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,726:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 14:42:19,735:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,875:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:19,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:19,968:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 14:42:20,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:20,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:20,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,126:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:20,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 14:42:20,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,167:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 14:42:20,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:20,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,374:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 14:42:20,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,428:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 14:42:20,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:20,644:INFO:Preparing preprocessing pipeline...
2024-05-24 14:42:20,644:INFO:Set up simple imputation.
2024-05-24 14:42:20,648:INFO:Set up encoding of ordinal features.
2024-05-24 14:42:20,653:INFO:Set up encoding of categorical features.
2024-05-24 14:42:20,838:INFO:Finished creating preprocessing pipeline.
2024-05-24 14:42:20,897:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['car_ID', 'symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('cat...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 14:42:20,897:INFO:Creating final display dataframe.
2024-05-24 14:42:21,529:INFO:Setup _display_container:                     Description             Value
0                    Session id              5002
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 26)
4        Transformed data shape         (205, 49)
5   Transformed train set shape         (143, 49)
6    Transformed test set shape          (62, 49)
7              Numeric features                15
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              4c8b
2024-05-24 14:42:21,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:21,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:21,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:21,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 14:42:21,771:INFO:setup() successfully completed in 2.51s...............
2024-05-24 14:42:21,800:INFO:Initializing compare_models()
2024-05-24 14:42:21,800:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 14:42:21,801:INFO:Checking exceptions
2024-05-24 14:42:21,803:INFO:Preparing display monitor
2024-05-24 14:42:21,829:INFO:Initializing Linear Regression
2024-05-24 14:42:21,829:INFO:Total runtime is 0.0 minutes
2024-05-24 14:42:21,833:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:21,833:INFO:Initializing create_model()
2024-05-24 14:42:21,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:21,833:INFO:Checking exceptions
2024-05-24 14:42:21,833:INFO:Importing libraries
2024-05-24 14:42:21,834:INFO:Copying training dataset
2024-05-24 14:42:21,844:INFO:Defining folds
2024-05-24 14:42:21,844:INFO:Declaring metric variables
2024-05-24 14:42:21,848:INFO:Importing untrained model
2024-05-24 14:42:21,852:INFO:Linear Regression Imported successfully
2024-05-24 14:42:21,862:INFO:Starting cross validation
2024-05-24 14:42:21,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:22,226:INFO:Calculating mean and std
2024-05-24 14:42:22,227:INFO:Creating metrics dataframe
2024-05-24 14:42:22,229:INFO:Uploading results into container
2024-05-24 14:42:22,229:INFO:Uploading model into container now
2024-05-24 14:42:22,230:INFO:_master_model_container: 1
2024-05-24 14:42:22,230:INFO:_display_container: 2
2024-05-24 14:42:22,230:INFO:LinearRegression(n_jobs=-1)
2024-05-24 14:42:22,230:INFO:create_model() successfully completed......................................
2024-05-24 14:42:22,342:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:22,343:INFO:Creating metrics dataframe
2024-05-24 14:42:22,351:INFO:Initializing Lasso Regression
2024-05-24 14:42:22,351:INFO:Total runtime is 0.008687607447306315 minutes
2024-05-24 14:42:22,355:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:22,356:INFO:Initializing create_model()
2024-05-24 14:42:22,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:22,356:INFO:Checking exceptions
2024-05-24 14:42:22,356:INFO:Importing libraries
2024-05-24 14:42:22,356:INFO:Copying training dataset
2024-05-24 14:42:22,364:INFO:Defining folds
2024-05-24 14:42:22,364:INFO:Declaring metric variables
2024-05-24 14:42:22,367:INFO:Importing untrained model
2024-05-24 14:42:22,371:INFO:Lasso Regression Imported successfully
2024-05-24 14:42:22,380:INFO:Starting cross validation
2024-05-24 14:42:22,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:22,603:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+07, tolerance: 9.138e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,649:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.816e+07, tolerance: 8.195e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,658:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.303e+07, tolerance: 8.552e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,660:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.089e+07, tolerance: 9.104e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,664:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.579e+07, tolerance: 7.880e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,669:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+07, tolerance: 8.125e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,699:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.473e+07, tolerance: 9.044e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 14:42:22,787:INFO:Calculating mean and std
2024-05-24 14:42:22,788:INFO:Creating metrics dataframe
2024-05-24 14:42:22,791:INFO:Uploading results into container
2024-05-24 14:42:22,792:INFO:Uploading model into container now
2024-05-24 14:42:22,793:INFO:_master_model_container: 2
2024-05-24 14:42:22,793:INFO:_display_container: 2
2024-05-24 14:42:22,793:INFO:Lasso(random_state=5002)
2024-05-24 14:42:22,793:INFO:create_model() successfully completed......................................
2024-05-24 14:42:22,892:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:22,892:INFO:Creating metrics dataframe
2024-05-24 14:42:22,901:INFO:Initializing Ridge Regression
2024-05-24 14:42:22,901:INFO:Total runtime is 0.017859156926472983 minutes
2024-05-24 14:42:22,905:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:22,905:INFO:Initializing create_model()
2024-05-24 14:42:22,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:22,905:INFO:Checking exceptions
2024-05-24 14:42:22,906:INFO:Importing libraries
2024-05-24 14:42:22,906:INFO:Copying training dataset
2024-05-24 14:42:22,913:INFO:Defining folds
2024-05-24 14:42:22,913:INFO:Declaring metric variables
2024-05-24 14:42:22,918:INFO:Importing untrained model
2024-05-24 14:42:22,921:INFO:Ridge Regression Imported successfully
2024-05-24 14:42:22,929:INFO:Starting cross validation
2024-05-24 14:42:22,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:23,286:INFO:Calculating mean and std
2024-05-24 14:42:23,287:INFO:Creating metrics dataframe
2024-05-24 14:42:23,291:INFO:Uploading results into container
2024-05-24 14:42:23,292:INFO:Uploading model into container now
2024-05-24 14:42:23,292:INFO:_master_model_container: 3
2024-05-24 14:42:23,292:INFO:_display_container: 2
2024-05-24 14:42:23,293:INFO:Ridge(random_state=5002)
2024-05-24 14:42:23,293:INFO:create_model() successfully completed......................................
2024-05-24 14:42:23,395:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:23,396:INFO:Creating metrics dataframe
2024-05-24 14:42:23,404:INFO:Initializing Elastic Net
2024-05-24 14:42:23,404:INFO:Total runtime is 0.026252063115437825 minutes
2024-05-24 14:42:23,410:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:23,410:INFO:Initializing create_model()
2024-05-24 14:42:23,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:23,411:INFO:Checking exceptions
2024-05-24 14:42:23,411:INFO:Importing libraries
2024-05-24 14:42:23,411:INFO:Copying training dataset
2024-05-24 14:42:23,419:INFO:Defining folds
2024-05-24 14:42:23,419:INFO:Declaring metric variables
2024-05-24 14:42:23,424:INFO:Importing untrained model
2024-05-24 14:42:23,429:INFO:Elastic Net Imported successfully
2024-05-24 14:42:23,439:INFO:Starting cross validation
2024-05-24 14:42:23,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:23,753:INFO:Calculating mean and std
2024-05-24 14:42:23,850:INFO:Creating metrics dataframe
2024-05-24 14:42:23,853:INFO:Uploading results into container
2024-05-24 14:42:23,854:INFO:Uploading model into container now
2024-05-24 14:42:23,854:INFO:_master_model_container: 4
2024-05-24 14:42:23,854:INFO:_display_container: 2
2024-05-24 14:42:23,854:INFO:ElasticNet(random_state=5002)
2024-05-24 14:42:23,855:INFO:create_model() successfully completed......................................
2024-05-24 14:42:23,937:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:23,937:INFO:Creating metrics dataframe
2024-05-24 14:42:23,945:INFO:Initializing Least Angle Regression
2024-05-24 14:42:23,945:INFO:Total runtime is 0.035263140996297196 minutes
2024-05-24 14:42:23,948:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:23,948:INFO:Initializing create_model()
2024-05-24 14:42:23,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:23,948:INFO:Checking exceptions
2024-05-24 14:42:23,949:INFO:Importing libraries
2024-05-24 14:42:23,949:INFO:Copying training dataset
2024-05-24 14:42:23,954:INFO:Defining folds
2024-05-24 14:42:23,954:INFO:Declaring metric variables
2024-05-24 14:42:23,958:INFO:Importing untrained model
2024-05-24 14:42:23,962:INFO:Least Angle Regression Imported successfully
2024-05-24 14:42:23,968:INFO:Starting cross validation
2024-05-24 14:42:23,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:24,141:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=7.811e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,144:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=5.236e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.030e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.837e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=3.227e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.106e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.489e+01, with an active set of 30 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.071e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.023e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.007e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.305e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.593e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.040e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.668e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.495e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.391e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=9.994e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.714e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,149:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.100e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=8.633e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.301e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.891e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.769e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.180e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.804e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,152:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.466e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,152:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=8.233e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,152:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.961e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,155:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=1.994e+01, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.139e+01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,159:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.469e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,160:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.206e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,160:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.771e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.075e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.982e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.193e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.686e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.266e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.526e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,163:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.579e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,163:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=8.898e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,163:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.863e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.775e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=4.433e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.966e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,169:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=7.108e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.146e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.610e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=2.410e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.426e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.426e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,174:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.156e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,176:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=6.755e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,176:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=5.883e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,176:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.307e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,177:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=3.303e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,177:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.604e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,179:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.433e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,184:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.739e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,197:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=7.090e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,198:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.144e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,207:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.343e+03, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,208:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.723e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.671e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,208:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=6.515e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,209:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.115e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,209:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.099e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.537e+02, with an active set of 43 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.671e+02, with an active set of 43 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.360e+02, with an active set of 43 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=7.038e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,212:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.469e+02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,212:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.437e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,216:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=8.478e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,218:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=5.455e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,219:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.390e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,219:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.306e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,222:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.814e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,224:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.510e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,224:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=5.698e+01, with an active set of 46 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,228:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.065e+01, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,233:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=5.848e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,313:INFO:Calculating mean and std
2024-05-24 14:42:24,315:INFO:Creating metrics dataframe
2024-05-24 14:42:24,317:INFO:Uploading results into container
2024-05-24 14:42:24,318:INFO:Uploading model into container now
2024-05-24 14:42:24,319:INFO:_master_model_container: 5
2024-05-24 14:42:24,319:INFO:_display_container: 2
2024-05-24 14:42:24,319:INFO:Lars(random_state=5002)
2024-05-24 14:42:24,320:INFO:create_model() successfully completed......................................
2024-05-24 14:42:24,415:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:24,415:INFO:Creating metrics dataframe
2024-05-24 14:42:24,425:INFO:Initializing Lasso Least Angle Regression
2024-05-24 14:42:24,425:INFO:Total runtime is 0.04326988855997721 minutes
2024-05-24 14:42:24,428:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:24,429:INFO:Initializing create_model()
2024-05-24 14:42:24,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:24,429:INFO:Checking exceptions
2024-05-24 14:42:24,429:INFO:Importing libraries
2024-05-24 14:42:24,430:INFO:Copying training dataset
2024-05-24 14:42:24,437:INFO:Defining folds
2024-05-24 14:42:24,437:INFO:Declaring metric variables
2024-05-24 14:42:24,441:INFO:Importing untrained model
2024-05-24 14:42:24,447:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 14:42:24,455:INFO:Starting cross validation
2024-05-24 14:42:24,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:24,645:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.649e+01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,650:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=7.516e+00, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,651:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.742e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,651:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.742e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,651:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.742e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,651:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.633e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,652:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 51 iterations, alpha=1.591e+00, previous alpha=1.119e+00, with an active set of 38 regressors.
  warnings.warn(

2024-05-24 14:42:24,652:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.044e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,653:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 47 iterations, alpha=3.037e+00, previous alpha=2.891e+00, with an active set of 34 regressors.
  warnings.warn(

2024-05-24 14:42:24,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.364e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.251e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.251e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.228e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,664:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.734e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,665:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.734e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,665:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.634e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,665:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=4.081e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,665:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.850e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,666:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=4.993e+00, previous alpha=2.007e+00, with an active set of 37 regressors.
  warnings.warn(

2024-05-24 14:42:24,671:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.556e+01, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,672:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.386e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,672:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=1.361e+01, previous alpha=1.360e+01, with an active set of 29 regressors.
  warnings.warn(

2024-05-24 14:42:24,682:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.874e+01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,683:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.874e+01, with an active set of 24 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,684:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=1.562e+01, previous alpha=1.079e+01, with an active set of 27 regressors.
  warnings.warn(

2024-05-24 14:42:24,696:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.499e+01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.457e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.457e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.730e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.730e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.988e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.700e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 58 iterations, alpha=4.045e+00, previous alpha=1.965e+00, with an active set of 39 regressors.
  warnings.warn(

2024-05-24 14:42:24,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.515e+01, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,705:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.515e+01, with an active set of 26 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 14:42:24,706:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 42 iterations, alpha=1.430e+01, previous alpha=1.414e+01, with an active set of 23 regressors.
  warnings.warn(

2024-05-24 14:42:24,783:INFO:Calculating mean and std
2024-05-24 14:42:24,784:INFO:Creating metrics dataframe
2024-05-24 14:42:24,786:INFO:Uploading results into container
2024-05-24 14:42:24,787:INFO:Uploading model into container now
2024-05-24 14:42:24,787:INFO:_master_model_container: 6
2024-05-24 14:42:24,787:INFO:_display_container: 2
2024-05-24 14:42:24,788:INFO:LassoLars(random_state=5002)
2024-05-24 14:42:24,788:INFO:create_model() successfully completed......................................
2024-05-24 14:42:24,874:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:24,875:INFO:Creating metrics dataframe
2024-05-24 14:42:24,884:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 14:42:24,884:INFO:Total runtime is 0.05091837644577026 minutes
2024-05-24 14:42:24,889:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:24,890:INFO:Initializing create_model()
2024-05-24 14:42:24,890:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:24,890:INFO:Checking exceptions
2024-05-24 14:42:24,890:INFO:Importing libraries
2024-05-24 14:42:24,890:INFO:Copying training dataset
2024-05-24 14:42:24,896:INFO:Defining folds
2024-05-24 14:42:24,896:INFO:Declaring metric variables
2024-05-24 14:42:24,901:INFO:Importing untrained model
2024-05-24 14:42:24,904:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 14:42:24,913:INFO:Starting cross validation
2024-05-24 14:42:24,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:25,286:INFO:Calculating mean and std
2024-05-24 14:42:25,288:INFO:Creating metrics dataframe
2024-05-24 14:42:25,291:INFO:Uploading results into container
2024-05-24 14:42:25,292:INFO:Uploading model into container now
2024-05-24 14:42:25,293:INFO:_master_model_container: 7
2024-05-24 14:42:25,293:INFO:_display_container: 2
2024-05-24 14:42:25,293:INFO:OrthogonalMatchingPursuit()
2024-05-24 14:42:25,293:INFO:create_model() successfully completed......................................
2024-05-24 14:42:25,402:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:25,403:INFO:Creating metrics dataframe
2024-05-24 14:42:25,415:INFO:Initializing Bayesian Ridge
2024-05-24 14:42:25,415:INFO:Total runtime is 0.05975858370463053 minutes
2024-05-24 14:42:25,423:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:25,425:INFO:Initializing create_model()
2024-05-24 14:42:25,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:25,425:INFO:Checking exceptions
2024-05-24 14:42:25,425:INFO:Importing libraries
2024-05-24 14:42:25,425:INFO:Copying training dataset
2024-05-24 14:42:25,434:INFO:Defining folds
2024-05-24 14:42:25,435:INFO:Declaring metric variables
2024-05-24 14:42:25,440:INFO:Importing untrained model
2024-05-24 14:42:25,446:INFO:Bayesian Ridge Imported successfully
2024-05-24 14:42:25,456:INFO:Starting cross validation
2024-05-24 14:42:25,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:25,774:INFO:Calculating mean and std
2024-05-24 14:42:25,775:INFO:Creating metrics dataframe
2024-05-24 14:42:25,777:INFO:Uploading results into container
2024-05-24 14:42:25,778:INFO:Uploading model into container now
2024-05-24 14:42:25,778:INFO:_master_model_container: 8
2024-05-24 14:42:25,778:INFO:_display_container: 2
2024-05-24 14:42:25,779:INFO:BayesianRidge()
2024-05-24 14:42:25,779:INFO:create_model() successfully completed......................................
2024-05-24 14:42:25,865:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:25,865:INFO:Creating metrics dataframe
2024-05-24 14:42:25,875:INFO:Initializing Passive Aggressive Regressor
2024-05-24 14:42:25,875:INFO:Total runtime is 0.06742162704467773 minutes
2024-05-24 14:42:25,878:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:25,879:INFO:Initializing create_model()
2024-05-24 14:42:25,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:25,879:INFO:Checking exceptions
2024-05-24 14:42:25,879:INFO:Importing libraries
2024-05-24 14:42:25,879:INFO:Copying training dataset
2024-05-24 14:42:25,888:INFO:Defining folds
2024-05-24 14:42:25,888:INFO:Declaring metric variables
2024-05-24 14:42:25,894:INFO:Importing untrained model
2024-05-24 14:42:25,899:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 14:42:25,914:INFO:Starting cross validation
2024-05-24 14:42:25,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:26,294:INFO:Calculating mean and std
2024-05-24 14:42:26,297:INFO:Creating metrics dataframe
2024-05-24 14:42:26,300:INFO:Uploading results into container
2024-05-24 14:42:26,301:INFO:Uploading model into container now
2024-05-24 14:42:26,302:INFO:_master_model_container: 9
2024-05-24 14:42:26,302:INFO:_display_container: 2
2024-05-24 14:42:26,302:INFO:PassiveAggressiveRegressor(random_state=5002)
2024-05-24 14:42:26,303:INFO:create_model() successfully completed......................................
2024-05-24 14:42:26,408:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:26,409:INFO:Creating metrics dataframe
2024-05-24 14:42:26,416:INFO:Initializing Huber Regressor
2024-05-24 14:42:26,416:INFO:Total runtime is 0.076443612575531 minutes
2024-05-24 14:42:26,419:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:26,420:INFO:Initializing create_model()
2024-05-24 14:42:26,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:26,420:INFO:Checking exceptions
2024-05-24 14:42:26,420:INFO:Importing libraries
2024-05-24 14:42:26,420:INFO:Copying training dataset
2024-05-24 14:42:26,427:INFO:Defining folds
2024-05-24 14:42:26,427:INFO:Declaring metric variables
2024-05-24 14:42:26,431:INFO:Importing untrained model
2024-05-24 14:42:26,435:INFO:Huber Regressor Imported successfully
2024-05-24 14:42:26,443:INFO:Starting cross validation
2024-05-24 14:42:26,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:26,712:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,716:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,719:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,724:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,740:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,753:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,756:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,766:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,776:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,795:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:26,861:INFO:Calculating mean and std
2024-05-24 14:42:26,862:INFO:Creating metrics dataframe
2024-05-24 14:42:26,864:INFO:Uploading results into container
2024-05-24 14:42:26,865:INFO:Uploading model into container now
2024-05-24 14:42:26,865:INFO:_master_model_container: 10
2024-05-24 14:42:26,866:INFO:_display_container: 2
2024-05-24 14:42:26,866:INFO:HuberRegressor()
2024-05-24 14:42:26,866:INFO:create_model() successfully completed......................................
2024-05-24 14:42:26,954:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:26,954:INFO:Creating metrics dataframe
2024-05-24 14:42:26,967:INFO:Initializing K Neighbors Regressor
2024-05-24 14:42:26,967:INFO:Total runtime is 0.08563384612401326 minutes
2024-05-24 14:42:26,971:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:26,972:INFO:Initializing create_model()
2024-05-24 14:42:26,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:26,972:INFO:Checking exceptions
2024-05-24 14:42:26,972:INFO:Importing libraries
2024-05-24 14:42:26,972:INFO:Copying training dataset
2024-05-24 14:42:26,982:INFO:Defining folds
2024-05-24 14:42:26,982:INFO:Declaring metric variables
2024-05-24 14:42:26,986:INFO:Importing untrained model
2024-05-24 14:42:26,994:INFO:K Neighbors Regressor Imported successfully
2024-05-24 14:42:27,003:INFO:Starting cross validation
2024-05-24 14:42:27,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:27,348:INFO:Calculating mean and std
2024-05-24 14:42:27,349:INFO:Creating metrics dataframe
2024-05-24 14:42:27,352:INFO:Uploading results into container
2024-05-24 14:42:27,352:INFO:Uploading model into container now
2024-05-24 14:42:27,353:INFO:_master_model_container: 11
2024-05-24 14:42:27,353:INFO:_display_container: 2
2024-05-24 14:42:27,353:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 14:42:27,353:INFO:create_model() successfully completed......................................
2024-05-24 14:42:27,439:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:27,440:INFO:Creating metrics dataframe
2024-05-24 14:42:27,449:INFO:Initializing Decision Tree Regressor
2024-05-24 14:42:27,449:INFO:Total runtime is 0.09366704622904459 minutes
2024-05-24 14:42:27,452:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:27,452:INFO:Initializing create_model()
2024-05-24 14:42:27,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:27,453:INFO:Checking exceptions
2024-05-24 14:42:27,453:INFO:Importing libraries
2024-05-24 14:42:27,453:INFO:Copying training dataset
2024-05-24 14:42:27,459:INFO:Defining folds
2024-05-24 14:42:27,459:INFO:Declaring metric variables
2024-05-24 14:42:27,465:INFO:Importing untrained model
2024-05-24 14:42:27,469:INFO:Decision Tree Regressor Imported successfully
2024-05-24 14:42:27,478:INFO:Starting cross validation
2024-05-24 14:42:27,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:27,830:INFO:Calculating mean and std
2024-05-24 14:42:27,832:INFO:Creating metrics dataframe
2024-05-24 14:42:27,834:INFO:Uploading results into container
2024-05-24 14:42:27,835:INFO:Uploading model into container now
2024-05-24 14:42:27,835:INFO:_master_model_container: 12
2024-05-24 14:42:27,835:INFO:_display_container: 2
2024-05-24 14:42:27,836:INFO:DecisionTreeRegressor(random_state=5002)
2024-05-24 14:42:27,836:INFO:create_model() successfully completed......................................
2024-05-24 14:42:27,932:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:27,932:INFO:Creating metrics dataframe
2024-05-24 14:42:27,943:INFO:Initializing Random Forest Regressor
2024-05-24 14:42:27,943:INFO:Total runtime is 0.10188728173573812 minutes
2024-05-24 14:42:27,946:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:27,947:INFO:Initializing create_model()
2024-05-24 14:42:27,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:27,947:INFO:Checking exceptions
2024-05-24 14:42:27,947:INFO:Importing libraries
2024-05-24 14:42:27,947:INFO:Copying training dataset
2024-05-24 14:42:27,954:INFO:Defining folds
2024-05-24 14:42:27,954:INFO:Declaring metric variables
2024-05-24 14:42:27,959:INFO:Importing untrained model
2024-05-24 14:42:27,963:INFO:Random Forest Regressor Imported successfully
2024-05-24 14:42:27,971:INFO:Starting cross validation
2024-05-24 14:42:27,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:28,725:INFO:Calculating mean and std
2024-05-24 14:42:28,727:INFO:Creating metrics dataframe
2024-05-24 14:42:28,729:INFO:Uploading results into container
2024-05-24 14:42:28,729:INFO:Uploading model into container now
2024-05-24 14:42:28,730:INFO:_master_model_container: 13
2024-05-24 14:42:28,730:INFO:_display_container: 2
2024-05-24 14:42:28,730:INFO:RandomForestRegressor(n_jobs=-1, random_state=5002)
2024-05-24 14:42:28,730:INFO:create_model() successfully completed......................................
2024-05-24 14:42:28,831:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:28,832:INFO:Creating metrics dataframe
2024-05-24 14:42:28,843:INFO:Initializing Extra Trees Regressor
2024-05-24 14:42:28,843:INFO:Total runtime is 0.11689608494440715 minutes
2024-05-24 14:42:28,847:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:28,847:INFO:Initializing create_model()
2024-05-24 14:42:28,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:28,847:INFO:Checking exceptions
2024-05-24 14:42:28,848:INFO:Importing libraries
2024-05-24 14:42:28,848:INFO:Copying training dataset
2024-05-24 14:42:28,856:INFO:Defining folds
2024-05-24 14:42:28,857:INFO:Declaring metric variables
2024-05-24 14:42:28,861:INFO:Importing untrained model
2024-05-24 14:42:28,867:INFO:Extra Trees Regressor Imported successfully
2024-05-24 14:42:28,875:INFO:Starting cross validation
2024-05-24 14:42:28,878:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:29,586:INFO:Calculating mean and std
2024-05-24 14:42:29,587:INFO:Creating metrics dataframe
2024-05-24 14:42:29,590:INFO:Uploading results into container
2024-05-24 14:42:29,591:INFO:Uploading model into container now
2024-05-24 14:42:29,591:INFO:_master_model_container: 14
2024-05-24 14:42:29,591:INFO:_display_container: 2
2024-05-24 14:42:29,592:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5002)
2024-05-24 14:42:29,592:INFO:create_model() successfully completed......................................
2024-05-24 14:42:29,673:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:29,673:INFO:Creating metrics dataframe
2024-05-24 14:42:29,682:INFO:Initializing AdaBoost Regressor
2024-05-24 14:42:29,682:INFO:Total runtime is 0.13088542620340984 minutes
2024-05-24 14:42:29,685:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:29,685:INFO:Initializing create_model()
2024-05-24 14:42:29,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:29,687:INFO:Checking exceptions
2024-05-24 14:42:29,687:INFO:Importing libraries
2024-05-24 14:42:29,687:INFO:Copying training dataset
2024-05-24 14:42:29,692:INFO:Defining folds
2024-05-24 14:42:29,692:INFO:Declaring metric variables
2024-05-24 14:42:29,696:INFO:Importing untrained model
2024-05-24 14:42:29,701:INFO:AdaBoost Regressor Imported successfully
2024-05-24 14:42:29,709:INFO:Starting cross validation
2024-05-24 14:42:29,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:30,166:INFO:Calculating mean and std
2024-05-24 14:42:30,167:INFO:Creating metrics dataframe
2024-05-24 14:42:30,170:INFO:Uploading results into container
2024-05-24 14:42:30,171:INFO:Uploading model into container now
2024-05-24 14:42:30,171:INFO:_master_model_container: 15
2024-05-24 14:42:30,171:INFO:_display_container: 2
2024-05-24 14:42:30,172:INFO:AdaBoostRegressor(random_state=5002)
2024-05-24 14:42:30,172:INFO:create_model() successfully completed......................................
2024-05-24 14:42:30,259:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:30,259:INFO:Creating metrics dataframe
2024-05-24 14:42:30,274:INFO:Initializing Gradient Boosting Regressor
2024-05-24 14:42:30,274:INFO:Total runtime is 0.1407538692156474 minutes
2024-05-24 14:42:30,280:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:30,281:INFO:Initializing create_model()
2024-05-24 14:42:30,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:30,281:INFO:Checking exceptions
2024-05-24 14:42:30,281:INFO:Importing libraries
2024-05-24 14:42:30,281:INFO:Copying training dataset
2024-05-24 14:42:30,287:INFO:Defining folds
2024-05-24 14:42:30,287:INFO:Declaring metric variables
2024-05-24 14:42:30,292:INFO:Importing untrained model
2024-05-24 14:42:30,297:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 14:42:30,308:INFO:Starting cross validation
2024-05-24 14:42:30,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:30,826:INFO:Calculating mean and std
2024-05-24 14:42:30,828:INFO:Creating metrics dataframe
2024-05-24 14:42:30,830:INFO:Uploading results into container
2024-05-24 14:42:30,831:INFO:Uploading model into container now
2024-05-24 14:42:30,832:INFO:_master_model_container: 16
2024-05-24 14:42:30,832:INFO:_display_container: 2
2024-05-24 14:42:30,832:INFO:GradientBoostingRegressor(random_state=5002)
2024-05-24 14:42:30,832:INFO:create_model() successfully completed......................................
2024-05-24 14:42:30,940:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:30,940:INFO:Creating metrics dataframe
2024-05-24 14:42:30,955:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 14:42:30,955:INFO:Total runtime is 0.15209436813990276 minutes
2024-05-24 14:42:30,962:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:30,962:INFO:Initializing create_model()
2024-05-24 14:42:30,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:30,962:INFO:Checking exceptions
2024-05-24 14:42:30,962:INFO:Importing libraries
2024-05-24 14:42:30,962:INFO:Copying training dataset
2024-05-24 14:42:30,970:INFO:Defining folds
2024-05-24 14:42:30,971:INFO:Declaring metric variables
2024-05-24 14:42:30,976:INFO:Importing untrained model
2024-05-24 14:42:30,981:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 14:42:30,990:INFO:Starting cross validation
2024-05-24 14:42:30,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:31,820:INFO:Calculating mean and std
2024-05-24 14:42:31,822:INFO:Creating metrics dataframe
2024-05-24 14:42:31,826:INFO:Uploading results into container
2024-05-24 14:42:31,827:INFO:Uploading model into container now
2024-05-24 14:42:31,828:INFO:_master_model_container: 17
2024-05-24 14:42:31,828:INFO:_display_container: 2
2024-05-24 14:42:31,828:INFO:LGBMRegressor(n_jobs=-1, random_state=5002)
2024-05-24 14:42:31,829:INFO:create_model() successfully completed......................................
2024-05-24 14:42:31,938:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:31,938:INFO:Creating metrics dataframe
2024-05-24 14:42:31,953:INFO:Initializing Dummy Regressor
2024-05-24 14:42:31,953:INFO:Total runtime is 0.16872772773106895 minutes
2024-05-24 14:42:31,957:INFO:SubProcess create_model() called ==================================
2024-05-24 14:42:31,959:INFO:Initializing create_model()
2024-05-24 14:42:31,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218749CC40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:31,959:INFO:Checking exceptions
2024-05-24 14:42:31,959:INFO:Importing libraries
2024-05-24 14:42:31,960:INFO:Copying training dataset
2024-05-24 14:42:31,966:INFO:Defining folds
2024-05-24 14:42:31,966:INFO:Declaring metric variables
2024-05-24 14:42:31,971:INFO:Importing untrained model
2024-05-24 14:42:31,975:INFO:Dummy Regressor Imported successfully
2024-05-24 14:42:31,984:INFO:Starting cross validation
2024-05-24 14:42:31,986:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 14:42:32,337:INFO:Calculating mean and std
2024-05-24 14:42:32,339:INFO:Creating metrics dataframe
2024-05-24 14:42:32,340:INFO:Uploading results into container
2024-05-24 14:42:32,341:INFO:Uploading model into container now
2024-05-24 14:42:32,341:INFO:_master_model_container: 18
2024-05-24 14:42:32,342:INFO:_display_container: 2
2024-05-24 14:42:32,342:INFO:DummyRegressor()
2024-05-24 14:42:32,342:INFO:create_model() successfully completed......................................
2024-05-24 14:42:32,431:INFO:SubProcess create_model() end ==================================
2024-05-24 14:42:32,431:INFO:Creating metrics dataframe
2024-05-24 14:42:32,447:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 14:42:32,458:INFO:Initializing create_model()
2024-05-24 14:42:32,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 14:42:32,458:INFO:Checking exceptions
2024-05-24 14:42:32,461:INFO:Importing libraries
2024-05-24 14:42:32,462:INFO:Copying training dataset
2024-05-24 14:42:32,469:INFO:Defining folds
2024-05-24 14:42:32,470:INFO:Declaring metric variables
2024-05-24 14:42:32,470:INFO:Importing untrained model
2024-05-24 14:42:32,470:INFO:Declaring custom model
2024-05-24 14:42:32,471:INFO:Huber Regressor Imported successfully
2024-05-24 14:42:32,474:INFO:Cross validation set to False
2024-05-24 14:42:32,474:INFO:Fitting Model
2024-05-24 14:42:32,642:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 14:42:32,642:INFO:HuberRegressor()
2024-05-24 14:42:32,642:INFO:create_model() successfully completed......................................
2024-05-24 14:42:32,762:INFO:_master_model_container: 18
2024-05-24 14:42:32,763:INFO:_display_container: 2
2024-05-24 14:42:32,763:INFO:HuberRegressor()
2024-05-24 14:42:32,763:INFO:compare_models() successfully completed......................................
2024-05-24 15:41:03,665:INFO:Initializing evaluate_model()
2024-05-24 15:41:03,665:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 15:41:03,685:INFO:Initializing plot_model()
2024-05-24 15:41:03,685:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, system=True)
2024-05-24 15:41:03,685:INFO:Checking exceptions
2024-05-24 15:41:03,690:INFO:Preloading libraries
2024-05-24 15:41:03,691:INFO:Copying training dataset
2024-05-24 15:41:03,691:INFO:Plot type: pipeline
2024-05-24 15:41:04,069:INFO:Visual Rendered Successfully
2024-05-24 15:41:04,173:INFO:plot_model() successfully completed......................................
2024-05-24 15:41:06,889:INFO:Initializing plot_model()
2024-05-24 15:41:06,889:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BB44D630>, system=True)
2024-05-24 15:41:06,889:INFO:Checking exceptions
2024-05-24 15:41:06,892:INFO:Preloading libraries
2024-05-24 15:41:06,892:INFO:Copying training dataset
2024-05-24 15:41:06,893:INFO:Plot type: feature_all
2024-05-24 15:41:07,499:INFO:Visual Rendered Successfully
2024-05-24 15:41:07,590:INFO:plot_model() successfully completed......................................
2024-05-24 15:42:00,731:INFO:PyCaret RegressionExperiment
2024-05-24 15:42:00,731:INFO:Logging name: reg-default-name
2024-05-24 15:42:00,731:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:42:00,731:INFO:version 3.3.2
2024-05-24 15:42:00,731:INFO:Initializing setup()
2024-05-24 15:42:00,731:INFO:self.USI: d16a
2024-05-24 15:42:00,732:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:42:00,732:INFO:Checking environment
2024-05-24 15:42:00,732:INFO:python_version: 3.10.14
2024-05-24 15:42:00,732:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:42:00,732:INFO:machine: AMD64
2024-05-24 15:42:00,732:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:42:00,732:INFO:Memory: svmem(total=16541802496, available=3544858624, percent=78.6, used=12996943872, free=3544858624)
2024-05-24 15:42:00,732:INFO:Physical Core: 6
2024-05-24 15:42:00,732:INFO:Logical Core: 12
2024-05-24 15:42:00,732:INFO:Checking libraries
2024-05-24 15:42:00,732:INFO:System:
2024-05-24 15:42:00,733:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:42:00,733:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:42:00,733:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:42:00,733:INFO:PyCaret required dependencies:
2024-05-24 15:42:00,733:INFO:                 pip: 24.0
2024-05-24 15:42:00,733:INFO:          setuptools: 69.5.1
2024-05-24 15:42:00,733:INFO:             pycaret: 3.3.2
2024-05-24 15:42:00,733:INFO:             IPython: 8.20.0
2024-05-24 15:42:00,733:INFO:          ipywidgets: 8.1.2
2024-05-24 15:42:00,733:INFO:                tqdm: 4.66.4
2024-05-24 15:42:00,733:INFO:               numpy: 1.26.4
2024-05-24 15:42:00,733:INFO:              pandas: 2.1.4
2024-05-24 15:42:00,733:INFO:              jinja2: 3.1.3
2024-05-24 15:42:00,733:INFO:               scipy: 1.11.4
2024-05-24 15:42:00,733:INFO:              joblib: 1.3.2
2024-05-24 15:42:00,734:INFO:             sklearn: 1.4.2
2024-05-24 15:42:00,734:INFO:                pyod: 1.1.3
2024-05-24 15:42:00,734:INFO:            imblearn: 0.12.2
2024-05-24 15:42:00,734:INFO:   category_encoders: 2.6.3
2024-05-24 15:42:00,734:INFO:            lightgbm: 4.3.0
2024-05-24 15:42:00,734:INFO:               numba: 0.59.1
2024-05-24 15:42:00,734:INFO:            requests: 2.32.2
2024-05-24 15:42:00,734:INFO:          matplotlib: 3.7.5
2024-05-24 15:42:00,734:INFO:          scikitplot: 0.3.7
2024-05-24 15:42:00,734:INFO:         yellowbrick: 1.5
2024-05-24 15:42:00,734:INFO:              plotly: 5.22.0
2024-05-24 15:42:00,734:INFO:    plotly-resampler: Not installed
2024-05-24 15:42:00,734:INFO:             kaleido: 0.2.1
2024-05-24 15:42:00,734:INFO:           schemdraw: 0.15
2024-05-24 15:42:00,734:INFO:         statsmodels: 0.14.2
2024-05-24 15:42:00,734:INFO:              sktime: 0.26.0
2024-05-24 15:42:00,734:INFO:               tbats: 1.1.3
2024-05-24 15:42:00,734:INFO:            pmdarima: 2.0.4
2024-05-24 15:42:00,734:INFO:              psutil: 5.9.0
2024-05-24 15:42:00,734:INFO:          markupsafe: 2.1.3
2024-05-24 15:42:00,734:INFO:             pickle5: Not installed
2024-05-24 15:42:00,735:INFO:         cloudpickle: 3.0.0
2024-05-24 15:42:00,735:INFO:         deprecation: 2.1.0
2024-05-24 15:42:00,735:INFO:              xxhash: 3.4.1
2024-05-24 15:42:00,735:INFO:           wurlitzer: Not installed
2024-05-24 15:42:00,735:INFO:PyCaret optional dependencies:
2024-05-24 15:42:00,735:INFO:                shap: Not installed
2024-05-24 15:42:00,735:INFO:           interpret: Not installed
2024-05-24 15:42:00,735:INFO:                umap: Not installed
2024-05-24 15:42:00,735:INFO:     ydata_profiling: Not installed
2024-05-24 15:42:00,735:INFO:  explainerdashboard: Not installed
2024-05-24 15:42:00,735:INFO:             autoviz: Not installed
2024-05-24 15:42:00,735:INFO:           fairlearn: Not installed
2024-05-24 15:42:00,735:INFO:          deepchecks: Not installed
2024-05-24 15:42:00,735:INFO:             xgboost: Not installed
2024-05-24 15:42:00,735:INFO:            catboost: Not installed
2024-05-24 15:42:00,735:INFO:              kmodes: Not installed
2024-05-24 15:42:00,735:INFO:             mlxtend: Not installed
2024-05-24 15:42:00,735:INFO:       statsforecast: Not installed
2024-05-24 15:42:00,736:INFO:        tune_sklearn: Not installed
2024-05-24 15:42:00,736:INFO:                 ray: Not installed
2024-05-24 15:42:00,736:INFO:            hyperopt: Not installed
2024-05-24 15:42:00,736:INFO:              optuna: Not installed
2024-05-24 15:42:00,736:INFO:               skopt: Not installed
2024-05-24 15:42:00,736:INFO:              mlflow: Not installed
2024-05-24 15:42:00,736:INFO:              gradio: Not installed
2024-05-24 15:42:00,736:INFO:             fastapi: Not installed
2024-05-24 15:42:00,736:INFO:             uvicorn: Not installed
2024-05-24 15:42:00,736:INFO:              m2cgen: Not installed
2024-05-24 15:42:00,736:INFO:           evidently: Not installed
2024-05-24 15:42:00,736:INFO:               fugue: Not installed
2024-05-24 15:42:00,736:INFO:           streamlit: Not installed
2024-05-24 15:42:00,736:INFO:             prophet: Not installed
2024-05-24 15:42:00,736:INFO:None
2024-05-24 15:42:00,736:INFO:Set up data.
2024-05-24 15:42:00,749:INFO:Set up folding strategy.
2024-05-24 15:42:00,749:INFO:Set up train/test split.
2024-05-24 15:42:00,758:INFO:Set up index.
2024-05-24 15:42:00,759:INFO:Assigning column types.
2024-05-24 15:42:00,765:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:42:00,766:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,771:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:00,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:00,887:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,893:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,897:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:42:00,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,008:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,009:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:42:01,013:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,018:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,131:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,135:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,244:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:42:01,253:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,315:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,434:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,483:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:42:01,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,727:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:42:01,819:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:42:01,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:01,994:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:42:02,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:02,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:02,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:02,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:02,223:INFO:Preparing preprocessing pipeline...
2024-05-24 15:42:02,223:INFO:Set up simple imputation.
2024-05-24 15:42:02,228:INFO:Set up encoding of ordinal features.
2024-05-24 15:42:02,233:INFO:Set up encoding of categorical features.
2024-05-24 15:42:02,409:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:42:02,470:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                 TransformerWrapper(include=['carbody', 'drivewheel',
                                             'enginetype', 'cylindernumber',
                                             'fuelsystem'],
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan')))])
2024-05-24 15:42:02,471:INFO:Creating final display dataframe.
2024-05-24 15:42:02,986:INFO:Setup _display_container:                     Description             Value
0                    Session id              7578
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape         (205, 49)
5   Transformed train set shape         (143, 49)
6    Transformed test set shape          (62, 49)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d16a
2024-05-24 15:42:03,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:03,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:03,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:03,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:42:03,240:INFO:setup() successfully completed in 2.52s...............
2024-05-24 15:42:03,266:INFO:Initializing compare_models()
2024-05-24 15:42:03,266:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:42:03,267:INFO:Checking exceptions
2024-05-24 15:42:03,271:INFO:Preparing display monitor
2024-05-24 15:42:03,300:INFO:Initializing Linear Regression
2024-05-24 15:42:03,300:INFO:Total runtime is 0.0 minutes
2024-05-24 15:42:03,304:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:03,305:INFO:Initializing create_model()
2024-05-24 15:42:03,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:03,305:INFO:Checking exceptions
2024-05-24 15:42:03,305:INFO:Importing libraries
2024-05-24 15:42:03,305:INFO:Copying training dataset
2024-05-24 15:42:03,311:INFO:Defining folds
2024-05-24 15:42:03,313:INFO:Declaring metric variables
2024-05-24 15:42:03,316:INFO:Importing untrained model
2024-05-24 15:42:03,320:INFO:Linear Regression Imported successfully
2024-05-24 15:42:03,328:INFO:Starting cross validation
2024-05-24 15:42:03,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:09,009:INFO:Calculating mean and std
2024-05-24 15:42:09,012:INFO:Creating metrics dataframe
2024-05-24 15:42:09,016:INFO:Uploading results into container
2024-05-24 15:42:09,018:INFO:Uploading model into container now
2024-05-24 15:42:09,018:INFO:_master_model_container: 1
2024-05-24 15:42:09,019:INFO:_display_container: 2
2024-05-24 15:42:09,019:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:42:09,019:INFO:create_model() successfully completed......................................
2024-05-24 15:42:09,244:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:09,244:INFO:Creating metrics dataframe
2024-05-24 15:42:09,252:INFO:Initializing Lasso Regression
2024-05-24 15:42:09,252:INFO:Total runtime is 0.09919910033543905 minutes
2024-05-24 15:42:09,256:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:09,257:INFO:Initializing create_model()
2024-05-24 15:42:09,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:09,257:INFO:Checking exceptions
2024-05-24 15:42:09,257:INFO:Importing libraries
2024-05-24 15:42:09,257:INFO:Copying training dataset
2024-05-24 15:42:09,264:INFO:Defining folds
2024-05-24 15:42:09,265:INFO:Declaring metric variables
2024-05-24 15:42:09,269:INFO:Importing untrained model
2024-05-24 15:42:09,275:INFO:Lasso Regression Imported successfully
2024-05-24 15:42:09,284:INFO:Starting cross validation
2024-05-24 15:42:09,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:09,572:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e+07, tolerance: 7.807e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:09,578:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.803e+07, tolerance: 7.193e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:09,579:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.936e+07, tolerance: 8.613e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:09,592:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.878e+07, tolerance: 7.743e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:09,598:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.922e+07, tolerance: 8.390e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:09,612:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.693e+07, tolerance: 8.687e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:09,649:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+07, tolerance: 8.658e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:11,899:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.206e+07, tolerance: 8.394e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:11,939:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.371e+07, tolerance: 7.556e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:42:11,990:INFO:Calculating mean and std
2024-05-24 15:42:11,992:INFO:Creating metrics dataframe
2024-05-24 15:42:11,995:INFO:Uploading results into container
2024-05-24 15:42:11,996:INFO:Uploading model into container now
2024-05-24 15:42:11,996:INFO:_master_model_container: 2
2024-05-24 15:42:11,997:INFO:_display_container: 2
2024-05-24 15:42:11,997:INFO:Lasso(random_state=7578)
2024-05-24 15:42:11,997:INFO:create_model() successfully completed......................................
2024-05-24 15:42:12,182:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:12,182:INFO:Creating metrics dataframe
2024-05-24 15:42:12,188:INFO:Initializing Ridge Regression
2024-05-24 15:42:12,188:INFO:Total runtime is 0.148147185643514 minutes
2024-05-24 15:42:12,193:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:12,194:INFO:Initializing create_model()
2024-05-24 15:42:12,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:12,194:INFO:Checking exceptions
2024-05-24 15:42:12,194:INFO:Importing libraries
2024-05-24 15:42:12,194:INFO:Copying training dataset
2024-05-24 15:42:12,201:INFO:Defining folds
2024-05-24 15:42:12,201:INFO:Declaring metric variables
2024-05-24 15:42:12,205:INFO:Importing untrained model
2024-05-24 15:42:12,210:INFO:Ridge Regression Imported successfully
2024-05-24 15:42:12,221:INFO:Starting cross validation
2024-05-24 15:42:12,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:12,600:INFO:Calculating mean and std
2024-05-24 15:42:12,602:INFO:Creating metrics dataframe
2024-05-24 15:42:12,604:INFO:Uploading results into container
2024-05-24 15:42:12,604:INFO:Uploading model into container now
2024-05-24 15:42:12,605:INFO:_master_model_container: 3
2024-05-24 15:42:12,605:INFO:_display_container: 2
2024-05-24 15:42:12,606:INFO:Ridge(random_state=7578)
2024-05-24 15:42:12,606:INFO:create_model() successfully completed......................................
2024-05-24 15:42:12,769:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:12,769:INFO:Creating metrics dataframe
2024-05-24 15:42:12,778:INFO:Initializing Elastic Net
2024-05-24 15:42:12,778:INFO:Total runtime is 0.15797295967737834 minutes
2024-05-24 15:42:12,783:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:12,783:INFO:Initializing create_model()
2024-05-24 15:42:12,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:12,783:INFO:Checking exceptions
2024-05-24 15:42:12,784:INFO:Importing libraries
2024-05-24 15:42:12,784:INFO:Copying training dataset
2024-05-24 15:42:12,791:INFO:Defining folds
2024-05-24 15:42:12,791:INFO:Declaring metric variables
2024-05-24 15:42:12,797:INFO:Importing untrained model
2024-05-24 15:42:12,803:INFO:Elastic Net Imported successfully
2024-05-24 15:42:12,816:INFO:Starting cross validation
2024-05-24 15:42:12,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:13,180:INFO:Calculating mean and std
2024-05-24 15:42:13,181:INFO:Creating metrics dataframe
2024-05-24 15:42:13,184:INFO:Uploading results into container
2024-05-24 15:42:13,184:INFO:Uploading model into container now
2024-05-24 15:42:13,185:INFO:_master_model_container: 4
2024-05-24 15:42:13,185:INFO:_display_container: 2
2024-05-24 15:42:13,185:INFO:ElasticNet(random_state=7578)
2024-05-24 15:42:13,185:INFO:create_model() successfully completed......................................
2024-05-24 15:42:13,360:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:13,360:INFO:Creating metrics dataframe
2024-05-24 15:42:13,369:INFO:Initializing Least Angle Regression
2024-05-24 15:42:13,369:INFO:Total runtime is 0.16781962315241497 minutes
2024-05-24 15:42:13,374:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:13,374:INFO:Initializing create_model()
2024-05-24 15:42:13,375:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:13,375:INFO:Checking exceptions
2024-05-24 15:42:13,375:INFO:Importing libraries
2024-05-24 15:42:13,375:INFO:Copying training dataset
2024-05-24 15:42:13,383:INFO:Defining folds
2024-05-24 15:42:13,383:INFO:Declaring metric variables
2024-05-24 15:42:13,388:INFO:Importing untrained model
2024-05-24 15:42:13,395:INFO:Least Angle Regression Imported successfully
2024-05-24 15:42:13,408:INFO:Starting cross validation
2024-05-24 15:42:13,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:13,654:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.173e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,655:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=9.221e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,655:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=6.516e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,656:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.965e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,656:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=4.739e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,657:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.268e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,657:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.217e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,658:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.927e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,658:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.437e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,658:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.559e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,659:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.249e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,659:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.595e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,659:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.572e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,659:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.381e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,660:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=7.175e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,667:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.081e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,668:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.058e+01, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,670:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=9.513e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,671:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.384e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,672:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.709e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,673:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.418e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,674:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=3.904e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,675:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=3.051e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,675:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.869e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,675:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.857e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,676:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.638e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,676:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.726e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,676:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.213e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,676:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.824e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.814e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,677:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.077e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,677:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.173e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,677:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.756e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,694:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.096e+01, with an active set of 29 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,694:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.435e+01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,695:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.555e+01, with an active set of 31 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,696:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.537e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,698:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.008e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,698:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.378e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,699:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.440e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,699:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.440e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,699:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.499e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,699:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.540e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,699:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.499e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.540e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.171e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.291e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.875e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.059e+01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.453e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.349e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.146e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.517e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,701:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=6.739e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.970e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=5.099e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,703:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.175e+01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=5.079e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.338e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.594e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.315e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,707:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.592e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,708:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.082e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,714:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.704e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,716:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=6.020e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,717:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.194e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,718:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=4.165e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,719:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.606e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,719:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.807e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,719:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=4.667e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,728:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.517e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,729:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=2.116e+01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,730:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.433e+04, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,737:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.705e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 9.884e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,745:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.590e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,745:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.347e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.347e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.888e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=4.504e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,748:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.171e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,748:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.938e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,749:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.514e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,749:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.514e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,749:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.050e+00, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,750:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.559e+00, with an active set of 44 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,750:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.732e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,751:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=9.265e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,751:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=8.038e-01, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:13,835:INFO:Calculating mean and std
2024-05-24 15:42:13,838:INFO:Creating metrics dataframe
2024-05-24 15:42:13,840:INFO:Uploading results into container
2024-05-24 15:42:13,841:INFO:Uploading model into container now
2024-05-24 15:42:13,841:INFO:_master_model_container: 5
2024-05-24 15:42:13,841:INFO:_display_container: 2
2024-05-24 15:42:13,842:INFO:Lars(random_state=7578)
2024-05-24 15:42:13,842:INFO:create_model() successfully completed......................................
2024-05-24 15:42:14,009:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:14,009:INFO:Creating metrics dataframe
2024-05-24 15:42:14,019:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:42:14,019:INFO:Total runtime is 0.17865163882573448 minutes
2024-05-24 15:42:14,024:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:14,024:INFO:Initializing create_model()
2024-05-24 15:42:14,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:14,024:INFO:Checking exceptions
2024-05-24 15:42:14,025:INFO:Importing libraries
2024-05-24 15:42:14,025:INFO:Copying training dataset
2024-05-24 15:42:14,032:INFO:Defining folds
2024-05-24 15:42:14,032:INFO:Declaring metric variables
2024-05-24 15:42:14,037:INFO:Importing untrained model
2024-05-24 15:42:14,041:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:42:14,052:INFO:Starting cross validation
2024-05-24 15:42:14,056:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:14,251:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.514e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 52 iterations, alpha=4.428e+00, previous alpha=2.919e+00, with an active set of 37 regressors.
  warnings.warn(

2024-05-24 15:42:14,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.220e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,273:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.860e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.348e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.211e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,277:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=3.494e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,278:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.330e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,279:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.172e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,279:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.600e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,279:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.600e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.307e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.665e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.665e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.665e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,290:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.855e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,291:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.753e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,292:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 45 iterations, alpha=5.394e+00, previous alpha=3.977e+00, with an active set of 34 regressors.
  warnings.warn(

2024-05-24 15:42:14,294:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 54 iterations, alpha=1.222e+00, previous alpha=1.018e+00, with an active set of 39 regressors.
  warnings.warn(

2024-05-24 15:42:14,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.782e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,311:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=1.811e+02, previous alpha=2.699e+00, with an active set of 39 regressors.
  warnings.warn(

2024-05-24 15:42:14,311:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.655e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,313:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.533e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,314:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.349e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,315:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.327e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,322:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.891e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,326:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.017e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:42:14,392:INFO:Calculating mean and std
2024-05-24 15:42:14,394:INFO:Creating metrics dataframe
2024-05-24 15:42:14,396:INFO:Uploading results into container
2024-05-24 15:42:14,396:INFO:Uploading model into container now
2024-05-24 15:42:14,396:INFO:_master_model_container: 6
2024-05-24 15:42:14,397:INFO:_display_container: 2
2024-05-24 15:42:14,397:INFO:LassoLars(random_state=7578)
2024-05-24 15:42:14,397:INFO:create_model() successfully completed......................................
2024-05-24 15:42:14,545:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:14,545:INFO:Creating metrics dataframe
2024-05-24 15:42:14,556:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:42:14,556:INFO:Total runtime is 0.1876011649767558 minutes
2024-05-24 15:42:14,560:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:14,561:INFO:Initializing create_model()
2024-05-24 15:42:14,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:14,561:INFO:Checking exceptions
2024-05-24 15:42:14,561:INFO:Importing libraries
2024-05-24 15:42:14,561:INFO:Copying training dataset
2024-05-24 15:42:14,569:INFO:Defining folds
2024-05-24 15:42:14,569:INFO:Declaring metric variables
2024-05-24 15:42:14,574:INFO:Importing untrained model
2024-05-24 15:42:14,579:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:42:14,585:INFO:Starting cross validation
2024-05-24 15:42:14,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:14,892:INFO:Calculating mean and std
2024-05-24 15:42:14,893:INFO:Creating metrics dataframe
2024-05-24 15:42:14,897:INFO:Uploading results into container
2024-05-24 15:42:14,897:INFO:Uploading model into container now
2024-05-24 15:42:14,897:INFO:_master_model_container: 7
2024-05-24 15:42:14,897:INFO:_display_container: 2
2024-05-24 15:42:14,898:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:42:14,898:INFO:create_model() successfully completed......................................
2024-05-24 15:42:15,050:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:15,050:INFO:Creating metrics dataframe
2024-05-24 15:42:15,058:INFO:Initializing Bayesian Ridge
2024-05-24 15:42:15,059:INFO:Total runtime is 0.19598671595255537 minutes
2024-05-24 15:42:15,062:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:15,063:INFO:Initializing create_model()
2024-05-24 15:42:15,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:15,063:INFO:Checking exceptions
2024-05-24 15:42:15,063:INFO:Importing libraries
2024-05-24 15:42:15,063:INFO:Copying training dataset
2024-05-24 15:42:15,069:INFO:Defining folds
2024-05-24 15:42:15,070:INFO:Declaring metric variables
2024-05-24 15:42:15,073:INFO:Importing untrained model
2024-05-24 15:42:15,079:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:42:15,090:INFO:Starting cross validation
2024-05-24 15:42:15,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:15,467:INFO:Calculating mean and std
2024-05-24 15:42:15,469:INFO:Creating metrics dataframe
2024-05-24 15:42:15,472:INFO:Uploading results into container
2024-05-24 15:42:15,472:INFO:Uploading model into container now
2024-05-24 15:42:15,473:INFO:_master_model_container: 8
2024-05-24 15:42:15,473:INFO:_display_container: 2
2024-05-24 15:42:15,473:INFO:BayesianRidge()
2024-05-24 15:42:15,474:INFO:create_model() successfully completed......................................
2024-05-24 15:42:15,649:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:15,649:INFO:Creating metrics dataframe
2024-05-24 15:42:15,658:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:42:15,658:INFO:Total runtime is 0.2059730370839437 minutes
2024-05-24 15:42:15,662:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:15,664:INFO:Initializing create_model()
2024-05-24 15:42:15,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:15,664:INFO:Checking exceptions
2024-05-24 15:42:15,665:INFO:Importing libraries
2024-05-24 15:42:15,665:INFO:Copying training dataset
2024-05-24 15:42:15,671:INFO:Defining folds
2024-05-24 15:42:15,671:INFO:Declaring metric variables
2024-05-24 15:42:15,675:INFO:Importing untrained model
2024-05-24 15:42:15,680:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:42:15,690:INFO:Starting cross validation
2024-05-24 15:42:15,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:16,014:INFO:Calculating mean and std
2024-05-24 15:42:16,016:INFO:Creating metrics dataframe
2024-05-24 15:42:16,018:INFO:Uploading results into container
2024-05-24 15:42:16,019:INFO:Uploading model into container now
2024-05-24 15:42:16,019:INFO:_master_model_container: 9
2024-05-24 15:42:16,019:INFO:_display_container: 2
2024-05-24 15:42:16,020:INFO:PassiveAggressiveRegressor(random_state=7578)
2024-05-24 15:42:16,020:INFO:create_model() successfully completed......................................
2024-05-24 15:42:16,190:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:16,190:INFO:Creating metrics dataframe
2024-05-24 15:42:16,203:INFO:Initializing Huber Regressor
2024-05-24 15:42:16,203:INFO:Total runtime is 0.21505157550175988 minutes
2024-05-24 15:42:16,208:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:16,209:INFO:Initializing create_model()
2024-05-24 15:42:16,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:16,209:INFO:Checking exceptions
2024-05-24 15:42:16,209:INFO:Importing libraries
2024-05-24 15:42:16,209:INFO:Copying training dataset
2024-05-24 15:42:16,215:INFO:Defining folds
2024-05-24 15:42:16,215:INFO:Declaring metric variables
2024-05-24 15:42:16,218:INFO:Importing untrained model
2024-05-24 15:42:16,223:INFO:Huber Regressor Imported successfully
2024-05-24 15:42:16,230:INFO:Starting cross validation
2024-05-24 15:42:16,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:16,455:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,492:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,506:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,517:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,527:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,537:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,541:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,542:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,553:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,566:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:42:16,625:INFO:Calculating mean and std
2024-05-24 15:42:16,626:INFO:Creating metrics dataframe
2024-05-24 15:42:16,629:INFO:Uploading results into container
2024-05-24 15:42:16,629:INFO:Uploading model into container now
2024-05-24 15:42:16,630:INFO:_master_model_container: 10
2024-05-24 15:42:16,630:INFO:_display_container: 2
2024-05-24 15:42:16,630:INFO:HuberRegressor()
2024-05-24 15:42:16,631:INFO:create_model() successfully completed......................................
2024-05-24 15:42:16,786:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:16,786:INFO:Creating metrics dataframe
2024-05-24 15:42:16,797:INFO:Initializing K Neighbors Regressor
2024-05-24 15:42:16,797:INFO:Total runtime is 0.22495688199996952 minutes
2024-05-24 15:42:16,802:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:16,802:INFO:Initializing create_model()
2024-05-24 15:42:16,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:16,802:INFO:Checking exceptions
2024-05-24 15:42:16,802:INFO:Importing libraries
2024-05-24 15:42:16,803:INFO:Copying training dataset
2024-05-24 15:42:16,811:INFO:Defining folds
2024-05-24 15:42:16,811:INFO:Declaring metric variables
2024-05-24 15:42:16,815:INFO:Importing untrained model
2024-05-24 15:42:16,821:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:42:16,831:INFO:Starting cross validation
2024-05-24 15:42:16,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:17,314:INFO:Calculating mean and std
2024-05-24 15:42:17,315:INFO:Creating metrics dataframe
2024-05-24 15:42:17,317:INFO:Uploading results into container
2024-05-24 15:42:17,317:INFO:Uploading model into container now
2024-05-24 15:42:17,318:INFO:_master_model_container: 11
2024-05-24 15:42:17,318:INFO:_display_container: 2
2024-05-24 15:42:17,318:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:42:17,318:INFO:create_model() successfully completed......................................
2024-05-24 15:42:17,469:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:17,469:INFO:Creating metrics dataframe
2024-05-24 15:42:17,481:INFO:Initializing Decision Tree Regressor
2024-05-24 15:42:17,481:INFO:Total runtime is 0.23636224269866948 minutes
2024-05-24 15:42:17,486:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:17,486:INFO:Initializing create_model()
2024-05-24 15:42:17,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:17,486:INFO:Checking exceptions
2024-05-24 15:42:17,487:INFO:Importing libraries
2024-05-24 15:42:17,487:INFO:Copying training dataset
2024-05-24 15:42:17,494:INFO:Defining folds
2024-05-24 15:42:17,494:INFO:Declaring metric variables
2024-05-24 15:42:17,499:INFO:Importing untrained model
2024-05-24 15:42:17,505:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:42:17,515:INFO:Starting cross validation
2024-05-24 15:42:17,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:17,891:INFO:Calculating mean and std
2024-05-24 15:42:17,892:INFO:Creating metrics dataframe
2024-05-24 15:42:17,894:INFO:Uploading results into container
2024-05-24 15:42:17,895:INFO:Uploading model into container now
2024-05-24 15:42:17,896:INFO:_master_model_container: 12
2024-05-24 15:42:17,896:INFO:_display_container: 2
2024-05-24 15:42:17,897:INFO:DecisionTreeRegressor(random_state=7578)
2024-05-24 15:42:17,897:INFO:create_model() successfully completed......................................
2024-05-24 15:42:18,070:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:18,071:INFO:Creating metrics dataframe
2024-05-24 15:42:18,084:INFO:Initializing Random Forest Regressor
2024-05-24 15:42:18,084:INFO:Total runtime is 0.2464040835698446 minutes
2024-05-24 15:42:18,088:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:18,089:INFO:Initializing create_model()
2024-05-24 15:42:18,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:18,089:INFO:Checking exceptions
2024-05-24 15:42:18,089:INFO:Importing libraries
2024-05-24 15:42:18,089:INFO:Copying training dataset
2024-05-24 15:42:18,098:INFO:Defining folds
2024-05-24 15:42:18,098:INFO:Declaring metric variables
2024-05-24 15:42:18,103:INFO:Importing untrained model
2024-05-24 15:42:18,108:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:42:18,119:INFO:Starting cross validation
2024-05-24 15:42:18,126:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:18,903:INFO:Calculating mean and std
2024-05-24 15:42:18,905:INFO:Creating metrics dataframe
2024-05-24 15:42:18,907:INFO:Uploading results into container
2024-05-24 15:42:18,908:INFO:Uploading model into container now
2024-05-24 15:42:18,908:INFO:_master_model_container: 13
2024-05-24 15:42:18,908:INFO:_display_container: 2
2024-05-24 15:42:18,909:INFO:RandomForestRegressor(n_jobs=-1, random_state=7578)
2024-05-24 15:42:18,909:INFO:create_model() successfully completed......................................
2024-05-24 15:42:19,079:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:19,079:INFO:Creating metrics dataframe
2024-05-24 15:42:19,093:INFO:Initializing Extra Trees Regressor
2024-05-24 15:42:19,093:INFO:Total runtime is 0.2632189273834229 minutes
2024-05-24 15:42:19,098:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:19,099:INFO:Initializing create_model()
2024-05-24 15:42:19,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:19,099:INFO:Checking exceptions
2024-05-24 15:42:19,099:INFO:Importing libraries
2024-05-24 15:42:19,099:INFO:Copying training dataset
2024-05-24 15:42:19,106:INFO:Defining folds
2024-05-24 15:42:19,106:INFO:Declaring metric variables
2024-05-24 15:42:19,111:INFO:Importing untrained model
2024-05-24 15:42:19,118:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:42:19,126:INFO:Starting cross validation
2024-05-24 15:42:19,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:19,735:INFO:Calculating mean and std
2024-05-24 15:42:19,737:INFO:Creating metrics dataframe
2024-05-24 15:42:19,740:INFO:Uploading results into container
2024-05-24 15:42:19,741:INFO:Uploading model into container now
2024-05-24 15:42:19,741:INFO:_master_model_container: 14
2024-05-24 15:42:19,741:INFO:_display_container: 2
2024-05-24 15:42:19,742:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7578)
2024-05-24 15:42:19,742:INFO:create_model() successfully completed......................................
2024-05-24 15:42:19,902:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:19,903:INFO:Creating metrics dataframe
2024-05-24 15:42:19,915:INFO:Initializing AdaBoost Regressor
2024-05-24 15:42:19,915:INFO:Total runtime is 0.27691766023635866 minutes
2024-05-24 15:42:19,918:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:19,919:INFO:Initializing create_model()
2024-05-24 15:42:19,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:19,919:INFO:Checking exceptions
2024-05-24 15:42:19,919:INFO:Importing libraries
2024-05-24 15:42:19,919:INFO:Copying training dataset
2024-05-24 15:42:19,928:INFO:Defining folds
2024-05-24 15:42:19,929:INFO:Declaring metric variables
2024-05-24 15:42:19,932:INFO:Importing untrained model
2024-05-24 15:42:19,937:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:42:19,947:INFO:Starting cross validation
2024-05-24 15:42:19,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:20,438:INFO:Calculating mean and std
2024-05-24 15:42:20,439:INFO:Creating metrics dataframe
2024-05-24 15:42:20,442:INFO:Uploading results into container
2024-05-24 15:42:20,442:INFO:Uploading model into container now
2024-05-24 15:42:20,443:INFO:_master_model_container: 15
2024-05-24 15:42:20,443:INFO:_display_container: 2
2024-05-24 15:42:20,443:INFO:AdaBoostRegressor(random_state=7578)
2024-05-24 15:42:20,443:INFO:create_model() successfully completed......................................
2024-05-24 15:42:20,621:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:20,621:INFO:Creating metrics dataframe
2024-05-24 15:42:20,632:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:42:20,632:INFO:Total runtime is 0.28887752691904706 minutes
2024-05-24 15:42:20,636:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:20,637:INFO:Initializing create_model()
2024-05-24 15:42:20,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:20,637:INFO:Checking exceptions
2024-05-24 15:42:20,637:INFO:Importing libraries
2024-05-24 15:42:20,637:INFO:Copying training dataset
2024-05-24 15:42:20,644:INFO:Defining folds
2024-05-24 15:42:20,644:INFO:Declaring metric variables
2024-05-24 15:42:20,649:INFO:Importing untrained model
2024-05-24 15:42:20,653:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:42:20,661:INFO:Starting cross validation
2024-05-24 15:42:20,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:21,107:INFO:Calculating mean and std
2024-05-24 15:42:21,108:INFO:Creating metrics dataframe
2024-05-24 15:42:21,112:INFO:Uploading results into container
2024-05-24 15:42:21,112:INFO:Uploading model into container now
2024-05-24 15:42:21,112:INFO:_master_model_container: 16
2024-05-24 15:42:21,112:INFO:_display_container: 2
2024-05-24 15:42:21,113:INFO:GradientBoostingRegressor(random_state=7578)
2024-05-24 15:42:21,113:INFO:create_model() successfully completed......................................
2024-05-24 15:42:21,276:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:21,276:INFO:Creating metrics dataframe
2024-05-24 15:42:21,289:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:42:21,289:INFO:Total runtime is 0.2998233993848165 minutes
2024-05-24 15:42:21,294:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:21,294:INFO:Initializing create_model()
2024-05-24 15:42:21,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:21,294:INFO:Checking exceptions
2024-05-24 15:42:21,294:INFO:Importing libraries
2024-05-24 15:42:21,294:INFO:Copying training dataset
2024-05-24 15:42:21,301:INFO:Defining folds
2024-05-24 15:42:21,301:INFO:Declaring metric variables
2024-05-24 15:42:21,306:INFO:Importing untrained model
2024-05-24 15:42:21,311:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:42:21,318:INFO:Starting cross validation
2024-05-24 15:42:21,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:21,939:INFO:Calculating mean and std
2024-05-24 15:42:21,941:INFO:Creating metrics dataframe
2024-05-24 15:42:21,944:INFO:Uploading results into container
2024-05-24 15:42:21,945:INFO:Uploading model into container now
2024-05-24 15:42:21,946:INFO:_master_model_container: 17
2024-05-24 15:42:21,946:INFO:_display_container: 2
2024-05-24 15:42:21,947:INFO:LGBMRegressor(n_jobs=-1, random_state=7578)
2024-05-24 15:42:21,947:INFO:create_model() successfully completed......................................
2024-05-24 15:42:22,123:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:22,123:INFO:Creating metrics dataframe
2024-05-24 15:42:22,135:INFO:Initializing Dummy Regressor
2024-05-24 15:42:22,135:INFO:Total runtime is 0.31391590038935346 minutes
2024-05-24 15:42:22,138:INFO:SubProcess create_model() called ==================================
2024-05-24 15:42:22,138:INFO:Initializing create_model()
2024-05-24 15:42:22,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C704BA30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:22,139:INFO:Checking exceptions
2024-05-24 15:42:22,139:INFO:Importing libraries
2024-05-24 15:42:22,139:INFO:Copying training dataset
2024-05-24 15:42:22,145:INFO:Defining folds
2024-05-24 15:42:22,145:INFO:Declaring metric variables
2024-05-24 15:42:22,149:INFO:Importing untrained model
2024-05-24 15:42:22,155:INFO:Dummy Regressor Imported successfully
2024-05-24 15:42:22,164:INFO:Starting cross validation
2024-05-24 15:42:22,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:42:22,474:INFO:Calculating mean and std
2024-05-24 15:42:22,475:INFO:Creating metrics dataframe
2024-05-24 15:42:22,477:INFO:Uploading results into container
2024-05-24 15:42:22,478:INFO:Uploading model into container now
2024-05-24 15:42:22,479:INFO:_master_model_container: 18
2024-05-24 15:42:22,479:INFO:_display_container: 2
2024-05-24 15:42:22,479:INFO:DummyRegressor()
2024-05-24 15:42:22,479:INFO:create_model() successfully completed......................................
2024-05-24 15:42:22,626:INFO:SubProcess create_model() end ==================================
2024-05-24 15:42:22,627:INFO:Creating metrics dataframe
2024-05-24 15:42:22,640:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:42:22,651:INFO:Initializing create_model()
2024-05-24 15:42:22,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=AdaBoostRegressor(random_state=7578), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:42:22,651:INFO:Checking exceptions
2024-05-24 15:42:22,653:INFO:Importing libraries
2024-05-24 15:42:22,653:INFO:Copying training dataset
2024-05-24 15:42:22,661:INFO:Defining folds
2024-05-24 15:42:22,661:INFO:Declaring metric variables
2024-05-24 15:42:22,661:INFO:Importing untrained model
2024-05-24 15:42:22,662:INFO:Declaring custom model
2024-05-24 15:42:22,662:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:42:22,666:INFO:Cross validation set to False
2024-05-24 15:42:22,666:INFO:Fitting Model
2024-05-24 15:42:22,836:INFO:AdaBoostRegressor(random_state=7578)
2024-05-24 15:42:22,836:INFO:create_model() successfully completed......................................
2024-05-24 15:42:23,023:INFO:_master_model_container: 18
2024-05-24 15:42:23,023:INFO:_display_container: 2
2024-05-24 15:42:23,024:INFO:AdaBoostRegressor(random_state=7578)
2024-05-24 15:42:23,024:INFO:compare_models() successfully completed......................................
2024-05-24 15:42:23,055:INFO:Initializing evaluate_model()
2024-05-24 15:42:23,055:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, estimator=AdaBoostRegressor(random_state=7578), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 15:42:23,068:INFO:Initializing plot_model()
2024-05-24 15:42:23,068:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=AdaBoostRegressor(random_state=7578), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, system=True)
2024-05-24 15:42:23,068:INFO:Checking exceptions
2024-05-24 15:42:23,074:INFO:Preloading libraries
2024-05-24 15:42:23,081:INFO:Copying training dataset
2024-05-24 15:42:23,081:INFO:Plot type: pipeline
2024-05-24 15:42:23,220:INFO:Visual Rendered Successfully
2024-05-24 15:42:23,379:INFO:plot_model() successfully completed......................................
2024-05-24 15:45:51,557:INFO:PyCaret RegressionExperiment
2024-05-24 15:45:51,557:INFO:Logging name: reg-default-name
2024-05-24 15:45:51,557:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:45:51,557:INFO:version 3.3.2
2024-05-24 15:45:51,557:INFO:Initializing setup()
2024-05-24 15:45:51,558:INFO:self.USI: 00da
2024-05-24 15:45:51,558:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:45:51,558:INFO:Checking environment
2024-05-24 15:45:51,558:INFO:python_version: 3.10.14
2024-05-24 15:45:51,558:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:45:51,558:INFO:machine: AMD64
2024-05-24 15:45:51,558:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:45:51,558:INFO:Memory: svmem(total=16541802496, available=2027819008, percent=87.7, used=14513983488, free=2027819008)
2024-05-24 15:45:51,558:INFO:Physical Core: 6
2024-05-24 15:45:51,558:INFO:Logical Core: 12
2024-05-24 15:45:51,558:INFO:Checking libraries
2024-05-24 15:45:51,558:INFO:System:
2024-05-24 15:45:51,558:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:45:51,559:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:45:51,559:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:45:51,559:INFO:PyCaret required dependencies:
2024-05-24 15:45:51,559:INFO:                 pip: 24.0
2024-05-24 15:45:51,559:INFO:          setuptools: 69.5.1
2024-05-24 15:45:51,559:INFO:             pycaret: 3.3.2
2024-05-24 15:45:51,559:INFO:             IPython: 8.20.0
2024-05-24 15:45:51,559:INFO:          ipywidgets: 8.1.2
2024-05-24 15:45:51,559:INFO:                tqdm: 4.66.4
2024-05-24 15:45:51,559:INFO:               numpy: 1.26.4
2024-05-24 15:45:51,559:INFO:              pandas: 2.1.4
2024-05-24 15:45:51,559:INFO:              jinja2: 3.1.3
2024-05-24 15:45:51,559:INFO:               scipy: 1.11.4
2024-05-24 15:45:51,560:INFO:              joblib: 1.3.2
2024-05-24 15:45:51,560:INFO:             sklearn: 1.4.2
2024-05-24 15:45:51,560:INFO:                pyod: 1.1.3
2024-05-24 15:45:51,560:INFO:            imblearn: 0.12.2
2024-05-24 15:45:51,560:INFO:   category_encoders: 2.6.3
2024-05-24 15:45:51,560:INFO:            lightgbm: 4.3.0
2024-05-24 15:45:51,560:INFO:               numba: 0.59.1
2024-05-24 15:45:51,560:INFO:            requests: 2.32.2
2024-05-24 15:45:51,560:INFO:          matplotlib: 3.7.5
2024-05-24 15:45:51,560:INFO:          scikitplot: 0.3.7
2024-05-24 15:45:51,560:INFO:         yellowbrick: 1.5
2024-05-24 15:45:51,560:INFO:              plotly: 5.22.0
2024-05-24 15:45:51,560:INFO:    plotly-resampler: Not installed
2024-05-24 15:45:51,560:INFO:             kaleido: 0.2.1
2024-05-24 15:45:51,560:INFO:           schemdraw: 0.15
2024-05-24 15:45:51,560:INFO:         statsmodels: 0.14.2
2024-05-24 15:45:51,560:INFO:              sktime: 0.26.0
2024-05-24 15:45:51,561:INFO:               tbats: 1.1.3
2024-05-24 15:45:51,561:INFO:            pmdarima: 2.0.4
2024-05-24 15:45:51,561:INFO:              psutil: 5.9.0
2024-05-24 15:45:51,561:INFO:          markupsafe: 2.1.3
2024-05-24 15:45:51,561:INFO:             pickle5: Not installed
2024-05-24 15:45:51,561:INFO:         cloudpickle: 3.0.0
2024-05-24 15:45:51,561:INFO:         deprecation: 2.1.0
2024-05-24 15:45:51,561:INFO:              xxhash: 3.4.1
2024-05-24 15:45:51,561:INFO:           wurlitzer: Not installed
2024-05-24 15:45:51,561:INFO:PyCaret optional dependencies:
2024-05-24 15:45:51,561:INFO:                shap: Not installed
2024-05-24 15:45:51,561:INFO:           interpret: Not installed
2024-05-24 15:45:51,561:INFO:                umap: Not installed
2024-05-24 15:45:51,561:INFO:     ydata_profiling: Not installed
2024-05-24 15:45:51,561:INFO:  explainerdashboard: Not installed
2024-05-24 15:45:51,561:INFO:             autoviz: Not installed
2024-05-24 15:45:51,562:INFO:           fairlearn: Not installed
2024-05-24 15:45:51,562:INFO:          deepchecks: Not installed
2024-05-24 15:45:51,562:INFO:             xgboost: Not installed
2024-05-24 15:45:51,562:INFO:            catboost: Not installed
2024-05-24 15:45:51,563:INFO:              kmodes: Not installed
2024-05-24 15:45:51,563:INFO:             mlxtend: Not installed
2024-05-24 15:45:51,563:INFO:       statsforecast: Not installed
2024-05-24 15:45:51,563:INFO:        tune_sklearn: Not installed
2024-05-24 15:45:51,563:INFO:                 ray: Not installed
2024-05-24 15:45:51,563:INFO:            hyperopt: Not installed
2024-05-24 15:45:51,563:INFO:              optuna: Not installed
2024-05-24 15:45:51,563:INFO:               skopt: Not installed
2024-05-24 15:45:51,563:INFO:              mlflow: Not installed
2024-05-24 15:45:51,563:INFO:              gradio: Not installed
2024-05-24 15:45:51,563:INFO:             fastapi: Not installed
2024-05-24 15:45:51,563:INFO:             uvicorn: Not installed
2024-05-24 15:45:51,563:INFO:              m2cgen: Not installed
2024-05-24 15:45:51,564:INFO:           evidently: Not installed
2024-05-24 15:45:51,564:INFO:               fugue: Not installed
2024-05-24 15:45:51,564:INFO:           streamlit: Not installed
2024-05-24 15:45:51,564:INFO:             prophet: Not installed
2024-05-24 15:45:51,564:INFO:None
2024-05-24 15:45:51,564:INFO:Set up data.
2024-05-24 15:45:51,577:INFO:Set up folding strategy.
2024-05-24 15:45:51,578:INFO:Set up train/test split.
2024-05-24 15:45:51,587:INFO:Set up index.
2024-05-24 15:45:51,588:INFO:Assigning column types.
2024-05-24 15:45:51,596:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:45:51,596:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,603:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,609:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:51,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:51,726:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,730:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:51,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:51,851:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:45:51,855:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,861:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:51,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:51,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:45:51,982:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,045:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,093:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:45:52,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,222:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,354:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:45:52,444:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,569:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,621:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,622:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:45:52,701:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,823:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:45:52,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:52,875:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:45:53,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:53,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:53,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:53,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:53,136:INFO:Preparing preprocessing pipeline...
2024-05-24 15:45:53,136:INFO:Set up target transformation.
2024-05-24 15:45:53,136:INFO:Set up simple imputation.
2024-05-24 15:45:53,141:INFO:Set up encoding of ordinal features.
2024-05-24 15:45:53,147:INFO:Set up encoding of categorical features.
2024-05-24 15:45:53,148:INFO:Set up removing multicollinearity.
2024-05-24 15:45:53,397:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:45:53,466:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesiz...
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:45:53,466:INFO:Creating final display dataframe.
2024-05-24 15:45:54,101:INFO:Setup _display_container:                     Description             Value
0                    Session id              6449
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape         (205, 43)
5   Transformed train set shape         (143, 43)
6    Transformed test set shape          (62, 43)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              00da
2024-05-24 15:45:54,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:54,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:54,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:54,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:45:54,344:INFO:setup() successfully completed in 2.79s...............
2024-05-24 15:45:58,059:INFO:Initializing compare_models()
2024-05-24 15:45:58,059:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:45:58,059:INFO:Checking exceptions
2024-05-24 15:45:58,064:INFO:Preparing display monitor
2024-05-24 15:45:58,096:INFO:Initializing Linear Regression
2024-05-24 15:45:58,096:INFO:Total runtime is 1.6526381174723306e-05 minutes
2024-05-24 15:45:58,101:INFO:SubProcess create_model() called ==================================
2024-05-24 15:45:58,101:INFO:Initializing create_model()
2024-05-24 15:45:58,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:45:58,102:INFO:Checking exceptions
2024-05-24 15:45:58,102:INFO:Importing libraries
2024-05-24 15:45:58,102:INFO:Copying training dataset
2024-05-24 15:45:58,109:INFO:Defining folds
2024-05-24 15:45:58,110:INFO:Declaring metric variables
2024-05-24 15:45:58,114:INFO:Importing untrained model
2024-05-24 15:45:58,130:INFO:Linear Regression Imported successfully
2024-05-24 15:45:58,146:INFO:Starting cross validation
2024-05-24 15:45:58,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:45:58,550:INFO:Calculating mean and std
2024-05-24 15:45:58,551:INFO:Creating metrics dataframe
2024-05-24 15:45:58,554:INFO:Uploading results into container
2024-05-24 15:45:58,555:INFO:Uploading model into container now
2024-05-24 15:45:58,555:INFO:_master_model_container: 1
2024-05-24 15:45:58,555:INFO:_display_container: 2
2024-05-24 15:45:58,555:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:45:58,555:INFO:create_model() successfully completed......................................
2024-05-24 15:45:58,947:INFO:SubProcess create_model() end ==================================
2024-05-24 15:45:58,947:INFO:Creating metrics dataframe
2024-05-24 15:45:58,956:INFO:Initializing Lasso Regression
2024-05-24 15:45:58,956:INFO:Total runtime is 0.01435560385386149 minutes
2024-05-24 15:45:58,961:INFO:SubProcess create_model() called ==================================
2024-05-24 15:45:58,961:INFO:Initializing create_model()
2024-05-24 15:45:58,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:45:58,961:INFO:Checking exceptions
2024-05-24 15:45:58,962:INFO:Importing libraries
2024-05-24 15:45:58,962:INFO:Copying training dataset
2024-05-24 15:45:58,968:INFO:Defining folds
2024-05-24 15:45:58,968:INFO:Declaring metric variables
2024-05-24 15:45:58,972:INFO:Importing untrained model
2024-05-24 15:45:58,979:INFO:Lasso Regression Imported successfully
2024-05-24 15:45:58,988:INFO:Starting cross validation
2024-05-24 15:45:58,993:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:45:59,378:INFO:Calculating mean and std
2024-05-24 15:45:59,380:INFO:Creating metrics dataframe
2024-05-24 15:45:59,382:INFO:Uploading results into container
2024-05-24 15:45:59,384:INFO:Uploading model into container now
2024-05-24 15:45:59,385:INFO:_master_model_container: 2
2024-05-24 15:45:59,385:INFO:_display_container: 2
2024-05-24 15:45:59,386:INFO:Lasso(random_state=6449)
2024-05-24 15:45:59,386:INFO:create_model() successfully completed......................................
2024-05-24 15:45:59,742:INFO:SubProcess create_model() end ==================================
2024-05-24 15:45:59,742:INFO:Creating metrics dataframe
2024-05-24 15:45:59,753:INFO:Initializing Ridge Regression
2024-05-24 15:45:59,753:INFO:Total runtime is 0.02763127088546753 minutes
2024-05-24 15:45:59,757:INFO:SubProcess create_model() called ==================================
2024-05-24 15:45:59,757:INFO:Initializing create_model()
2024-05-24 15:45:59,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:45:59,758:INFO:Checking exceptions
2024-05-24 15:45:59,758:INFO:Importing libraries
2024-05-24 15:45:59,758:INFO:Copying training dataset
2024-05-24 15:45:59,766:INFO:Defining folds
2024-05-24 15:45:59,767:INFO:Declaring metric variables
2024-05-24 15:45:59,773:INFO:Importing untrained model
2024-05-24 15:45:59,779:INFO:Ridge Regression Imported successfully
2024-05-24 15:45:59,787:INFO:Starting cross validation
2024-05-24 15:45:59,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:00,159:INFO:Calculating mean and std
2024-05-24 15:46:00,160:INFO:Creating metrics dataframe
2024-05-24 15:46:00,164:INFO:Uploading results into container
2024-05-24 15:46:00,164:INFO:Uploading model into container now
2024-05-24 15:46:00,165:INFO:_master_model_container: 3
2024-05-24 15:46:00,165:INFO:_display_container: 2
2024-05-24 15:46:00,165:INFO:Ridge(random_state=6449)
2024-05-24 15:46:00,165:INFO:create_model() successfully completed......................................
2024-05-24 15:46:00,322:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:00,322:INFO:Creating metrics dataframe
2024-05-24 15:46:00,331:INFO:Initializing Elastic Net
2024-05-24 15:46:00,331:INFO:Total runtime is 0.03726506233215332 minutes
2024-05-24 15:46:00,334:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:00,335:INFO:Initializing create_model()
2024-05-24 15:46:00,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:00,335:INFO:Checking exceptions
2024-05-24 15:46:00,335:INFO:Importing libraries
2024-05-24 15:46:00,335:INFO:Copying training dataset
2024-05-24 15:46:00,343:INFO:Defining folds
2024-05-24 15:46:00,343:INFO:Declaring metric variables
2024-05-24 15:46:00,347:INFO:Importing untrained model
2024-05-24 15:46:00,352:INFO:Elastic Net Imported successfully
2024-05-24 15:46:00,360:INFO:Starting cross validation
2024-05-24 15:46:00,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:00,718:INFO:Calculating mean and std
2024-05-24 15:46:00,720:INFO:Creating metrics dataframe
2024-05-24 15:46:00,723:INFO:Uploading results into container
2024-05-24 15:46:00,724:INFO:Uploading model into container now
2024-05-24 15:46:00,725:INFO:_master_model_container: 4
2024-05-24 15:46:00,725:INFO:_display_container: 2
2024-05-24 15:46:00,725:INFO:ElasticNet(random_state=6449)
2024-05-24 15:46:00,725:INFO:create_model() successfully completed......................................
2024-05-24 15:46:00,880:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:00,880:INFO:Creating metrics dataframe
2024-05-24 15:46:00,887:INFO:Initializing Least Angle Regression
2024-05-24 15:46:00,887:INFO:Total runtime is 0.0465386430422465 minutes
2024-05-24 15:46:00,891:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:00,892:INFO:Initializing create_model()
2024-05-24 15:46:00,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:00,892:INFO:Checking exceptions
2024-05-24 15:46:00,893:INFO:Importing libraries
2024-05-24 15:46:00,893:INFO:Copying training dataset
2024-05-24 15:46:00,899:INFO:Defining folds
2024-05-24 15:46:00,899:INFO:Declaring metric variables
2024-05-24 15:46:00,903:INFO:Importing untrained model
2024-05-24 15:46:00,907:INFO:Least Angle Regression Imported successfully
2024-05-24 15:46:00,917:INFO:Starting cross validation
2024-05-24 15:46:00,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:01,132:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=7.754e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,133:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=5.279e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,134:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.576e-06, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=1.637e-06, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,136:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.473e-06, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,136:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=8.458e-07, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,137:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.174e-07, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,137:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.736e-07, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,137:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.939e-07, with an active set of 34 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,141:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.101e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,142:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.515e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,143:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=9.978e-06, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=2.544e-06, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=1.745e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.408e-06, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.247e-06, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=8.354e-07, with an active set of 36 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.051e-06, with an active set of 37 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.351e-07, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=5.764e-07, with an active set of 37 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.698e-07, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.634e-07, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.617e-04, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=4.970e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.391e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.351e-05, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.508e-05, with an active set of 23 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=8.774e-06, with an active set of 25 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,159:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.895e-06, with an active set of 28 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,159:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.748e-06, with an active set of 28 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,159:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.553e-06, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,160:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.617e-06, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.642e-06, with an active set of 33 regressors, and the smallest cholesky pivot element being 9.541e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.435e-06, with an active set of 33 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.426e-06, with an active set of 33 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.263e-06, with an active set of 33 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.942e-06, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.554e-07, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.493e-06, with an active set of 39 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,167:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.393e-06, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.073e-04, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.909e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,169:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.943e-05, with an active set of 37 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=5.739e-06, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.139e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.006e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=8.914e-06, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.254e-06, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,182:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.079e-05, with an active set of 24 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,185:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.232e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,185:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=6.356e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,186:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=8.677e-05, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,186:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.836e-07, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,198:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=7.158e-06, with an active set of 29 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,199:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=4.339e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,199:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.297e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,200:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.599e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,200:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.089e-06, with an active set of 34 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,200:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=4.306e-07, with an active set of 35 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,200:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.998e-07, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,201:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.769e-07, with an active set of 36 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=9.069e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,211:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=5.642e-06, with an active set of 23 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,213:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.816e-06, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,217:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.527e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,217:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.071e-05, with an active set of 40 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:01,244:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,246:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,250:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,251:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,253:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,258:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,259:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,260:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,260:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,260:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,261:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,263:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,264:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,265:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,265:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,265:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,265:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,284:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,285:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,286:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,297:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,297:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,298:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,298:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,298:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,298:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:01,312:INFO:Calculating mean and std
2024-05-24 15:46:01,314:INFO:Creating metrics dataframe
2024-05-24 15:46:01,318:INFO:Uploading results into container
2024-05-24 15:46:01,319:INFO:Uploading model into container now
2024-05-24 15:46:01,319:INFO:_master_model_container: 5
2024-05-24 15:46:01,319:INFO:_display_container: 2
2024-05-24 15:46:01,320:INFO:Lars(random_state=6449)
2024-05-24 15:46:01,320:INFO:create_model() successfully completed......................................
2024-05-24 15:46:01,483:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:01,484:INFO:Creating metrics dataframe
2024-05-24 15:46:01,492:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:46:01,493:INFO:Total runtime is 0.05663821697235108 minutes
2024-05-24 15:46:01,497:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:01,498:INFO:Initializing create_model()
2024-05-24 15:46:01,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:01,498:INFO:Checking exceptions
2024-05-24 15:46:01,498:INFO:Importing libraries
2024-05-24 15:46:01,499:INFO:Copying training dataset
2024-05-24 15:46:01,505:INFO:Defining folds
2024-05-24 15:46:01,505:INFO:Declaring metric variables
2024-05-24 15:46:01,510:INFO:Importing untrained model
2024-05-24 15:46:01,514:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:46:01,524:INFO:Starting cross validation
2024-05-24 15:46:01,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:01,893:INFO:Calculating mean and std
2024-05-24 15:46:01,894:INFO:Creating metrics dataframe
2024-05-24 15:46:01,896:INFO:Uploading results into container
2024-05-24 15:46:01,897:INFO:Uploading model into container now
2024-05-24 15:46:01,897:INFO:_master_model_container: 6
2024-05-24 15:46:01,898:INFO:_display_container: 2
2024-05-24 15:46:01,898:INFO:LassoLars(random_state=6449)
2024-05-24 15:46:01,898:INFO:create_model() successfully completed......................................
2024-05-24 15:46:02,070:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:02,070:INFO:Creating metrics dataframe
2024-05-24 15:46:02,079:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:46:02,079:INFO:Total runtime is 0.06640469630559286 minutes
2024-05-24 15:46:02,084:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:02,084:INFO:Initializing create_model()
2024-05-24 15:46:02,084:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:02,084:INFO:Checking exceptions
2024-05-24 15:46:02,084:INFO:Importing libraries
2024-05-24 15:46:02,084:INFO:Copying training dataset
2024-05-24 15:46:02,091:INFO:Defining folds
2024-05-24 15:46:02,091:INFO:Declaring metric variables
2024-05-24 15:46:02,096:INFO:Importing untrained model
2024-05-24 15:46:02,100:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:46:02,109:INFO:Starting cross validation
2024-05-24 15:46:02,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:02,469:INFO:Calculating mean and std
2024-05-24 15:46:02,472:INFO:Creating metrics dataframe
2024-05-24 15:46:02,474:INFO:Uploading results into container
2024-05-24 15:46:02,475:INFO:Uploading model into container now
2024-05-24 15:46:02,475:INFO:_master_model_container: 7
2024-05-24 15:46:02,475:INFO:_display_container: 2
2024-05-24 15:46:02,475:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:46:02,477:INFO:create_model() successfully completed......................................
2024-05-24 15:46:02,638:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:02,639:INFO:Creating metrics dataframe
2024-05-24 15:46:02,648:INFO:Initializing Bayesian Ridge
2024-05-24 15:46:02,648:INFO:Total runtime is 0.07589134375254314 minutes
2024-05-24 15:46:02,652:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:02,653:INFO:Initializing create_model()
2024-05-24 15:46:02,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:02,653:INFO:Checking exceptions
2024-05-24 15:46:02,653:INFO:Importing libraries
2024-05-24 15:46:02,653:INFO:Copying training dataset
2024-05-24 15:46:02,660:INFO:Defining folds
2024-05-24 15:46:02,660:INFO:Declaring metric variables
2024-05-24 15:46:02,664:INFO:Importing untrained model
2024-05-24 15:46:02,669:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:46:02,677:INFO:Starting cross validation
2024-05-24 15:46:02,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:03,032:INFO:Calculating mean and std
2024-05-24 15:46:03,035:INFO:Creating metrics dataframe
2024-05-24 15:46:03,037:INFO:Uploading results into container
2024-05-24 15:46:03,038:INFO:Uploading model into container now
2024-05-24 15:46:03,038:INFO:_master_model_container: 8
2024-05-24 15:46:03,038:INFO:_display_container: 2
2024-05-24 15:46:03,039:INFO:BayesianRidge()
2024-05-24 15:46:03,039:INFO:create_model() successfully completed......................................
2024-05-24 15:46:03,198:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:03,198:INFO:Creating metrics dataframe
2024-05-24 15:46:03,207:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:46:03,207:INFO:Total runtime is 0.08520970344543458 minutes
2024-05-24 15:46:03,212:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:03,212:INFO:Initializing create_model()
2024-05-24 15:46:03,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:03,212:INFO:Checking exceptions
2024-05-24 15:46:03,213:INFO:Importing libraries
2024-05-24 15:46:03,213:INFO:Copying training dataset
2024-05-24 15:46:03,220:INFO:Defining folds
2024-05-24 15:46:03,220:INFO:Declaring metric variables
2024-05-24 15:46:03,224:INFO:Importing untrained model
2024-05-24 15:46:03,230:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:46:03,238:INFO:Starting cross validation
2024-05-24 15:46:03,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:03,553:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,572:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,573:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,573:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,573:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,573:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,574:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,583:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,589:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,591:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,597:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,598:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,600:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,600:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,600:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,600:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,600:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,601:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,602:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,602:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,602:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,602:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,604:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,605:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,605:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,605:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,605:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,605:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,609:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,609:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,609:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,610:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,610:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,610:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,614:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,616:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,617:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,617:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,617:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,617:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,631:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,632:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,632:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,632:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,632:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,632:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:03,645:INFO:Calculating mean and std
2024-05-24 15:46:03,648:INFO:Creating metrics dataframe
2024-05-24 15:46:03,649:INFO:Uploading results into container
2024-05-24 15:46:03,650:INFO:Uploading model into container now
2024-05-24 15:46:03,650:INFO:_master_model_container: 9
2024-05-24 15:46:03,651:INFO:_display_container: 2
2024-05-24 15:46:03,651:INFO:PassiveAggressiveRegressor(random_state=6449)
2024-05-24 15:46:03,651:INFO:create_model() successfully completed......................................
2024-05-24 15:46:03,814:WARNING:create_model() for PassiveAggressiveRegressor(random_state=6449) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-24 15:46:03,814:WARNING:Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-24 15:46:03,815:INFO:Initializing create_model()
2024-05-24 15:46:03,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:03,815:INFO:Checking exceptions
2024-05-24 15:46:03,815:INFO:Importing libraries
2024-05-24 15:46:03,815:INFO:Copying training dataset
2024-05-24 15:46:03,820:INFO:Defining folds
2024-05-24 15:46:03,821:INFO:Declaring metric variables
2024-05-24 15:46:03,825:INFO:Importing untrained model
2024-05-24 15:46:03,830:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:46:03,838:INFO:Starting cross validation
2024-05-24 15:46:03,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:04,143:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,144:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,152:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,153:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,153:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,153:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,153:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,153:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,156:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,156:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,157:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,174:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,174:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

ine 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,189:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,193:INFO:Calculating mean and std
2024-05-24 15:46:04,194:INFO:Creating metrics dataframe
2024-05-24 15:46:04,196:INFO:Uploading results into container
2024-05-24 15:46:04,197:INFO:Uploading model into container now
2024-05-24 15:46:04,197:INFO:_master_model_container: 10
2024-05-24 15:46:04,197:INFO:_display_container: 2
2024-05-24 15:46:04,198:INFO:PassiveAggressiveRegressor(random_state=6449)
2024-05-24 15:46:04,198:INFO:create_model() successfully completed......................................
2024-05-24 15:46:04,361:ERROR:create_model() for PassiveAggressiveRegressor(random_state=6449) raised an exception or returned all 0.0:
2024-05-24 15:46:04,361:ERROR:Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-24 15:46:04,361:INFO:Initializing Huber Regressor
2024-05-24 15:46:04,361:INFO:Total runtime is 0.10444341897964478 minutes
2024-05-24 15:46:04,366:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:04,366:INFO:Initializing create_model()
2024-05-24 15:46:04,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:04,366:INFO:Checking exceptions
2024-05-24 15:46:04,366:INFO:Importing libraries
2024-05-24 15:46:04,367:INFO:Copying training dataset
2024-05-24 15:46:04,374:INFO:Defining folds
2024-05-24 15:46:04,375:INFO:Declaring metric variables
2024-05-24 15:46:04,380:INFO:Importing untrained model
2024-05-24 15:46:04,385:INFO:Huber Regressor Imported successfully
2024-05-24 15:46:04,393:INFO:Starting cross validation
2024-05-24 15:46:04,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:04,657:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,664:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,673:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,677:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,681:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,693:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,698:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,703:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,707:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:04,742:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,744:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,744:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,744:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,744:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,744:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,745:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,759:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,759:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,760:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,760:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,760:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,760:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,763:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,763:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,768:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,769:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,769:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,769:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,769:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,769:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,776:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,776:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,776:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,779:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,781:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,782:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,782:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,782:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,782:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,782:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:04,786:INFO:Calculating mean and std
2024-05-24 15:46:04,788:INFO:Creating metrics dataframe
2024-05-24 15:46:04,789:INFO:Uploading results into container
2024-05-24 15:46:04,790:INFO:Uploading model into container now
2024-05-24 15:46:04,791:INFO:_master_model_container: 11
2024-05-24 15:46:04,791:INFO:_display_container: 2
2024-05-24 15:46:04,791:INFO:HuberRegressor()
2024-05-24 15:46:04,791:INFO:create_model() successfully completed......................................
2024-05-24 15:46:04,952:WARNING:create_model() for HuberRegressor() raised an exception or returned all 0.0, trying without fit_kwargs:
2024-05-24 15:46:04,953:WARNING:Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-05-24 15:46:04,954:INFO:Initializing create_model()
2024-05-24 15:46:04,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:04,954:INFO:Checking exceptions
2024-05-24 15:46:04,954:INFO:Importing libraries
2024-05-24 15:46:04,954:INFO:Copying training dataset
2024-05-24 15:46:04,961:INFO:Defining folds
2024-05-24 15:46:04,961:INFO:Declaring metric variables
2024-05-24 15:46:04,965:INFO:Importing untrained model
2024-05-24 15:46:04,970:INFO:Huber Regressor Imported successfully
2024-05-24 15:46:04,978:INFO:Starting cross validation
2024-05-24 15:46:04,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:05,231:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,238:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,247:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,249:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,253:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,267:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,270:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:05,308:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,318:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,318:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,318:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,319:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,319:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,319:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,322:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,330:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,332:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,335:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,336:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,339:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,339:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,339:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,339:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,341:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,341:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,345:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,348:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,349:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,349:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,349:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,349:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,349:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-24 15:46:05,364:INFO:Calculating mean and std
2024-05-24 15:46:05,367:INFO:Creating metrics dataframe
2024-05-24 15:46:05,369:INFO:Uploading results into container
2024-05-24 15:46:05,369:INFO:Uploading model into container now
2024-05-24 15:46:05,370:INFO:_master_model_container: 12
2024-05-24 15:46:05,370:INFO:_display_container: 2
2024-05-24 15:46:05,370:INFO:HuberRegressor()
2024-05-24 15:46:05,371:INFO:create_model() successfully completed......................................
2024-05-24 15:46:05,536:ERROR:create_model() for HuberRegressor() raised an exception or returned all 0.0:
2024-05-24 15:46:05,537:ERROR:Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2024-05-24 15:46:05,537:INFO:Initializing K Neighbors Regressor
2024-05-24 15:46:05,537:INFO:Total runtime is 0.12403295437494914 minutes
2024-05-24 15:46:05,541:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:05,541:INFO:Initializing create_model()
2024-05-24 15:46:05,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:05,542:INFO:Checking exceptions
2024-05-24 15:46:05,542:INFO:Importing libraries
2024-05-24 15:46:05,542:INFO:Copying training dataset
2024-05-24 15:46:05,549:INFO:Defining folds
2024-05-24 15:46:05,549:INFO:Declaring metric variables
2024-05-24 15:46:05,553:INFO:Importing untrained model
2024-05-24 15:46:05,558:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:46:05,566:INFO:Starting cross validation
2024-05-24 15:46:05,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:05,986:INFO:Calculating mean and std
2024-05-24 15:46:05,987:INFO:Creating metrics dataframe
2024-05-24 15:46:05,989:INFO:Uploading results into container
2024-05-24 15:46:05,990:INFO:Uploading model into container now
2024-05-24 15:46:05,990:INFO:_master_model_container: 13
2024-05-24 15:46:05,990:INFO:_display_container: 2
2024-05-24 15:46:05,990:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:46:05,990:INFO:create_model() successfully completed......................................
2024-05-24 15:46:06,162:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:06,162:INFO:Creating metrics dataframe
2024-05-24 15:46:06,173:INFO:Initializing Decision Tree Regressor
2024-05-24 15:46:06,173:INFO:Total runtime is 0.1346452037493388 minutes
2024-05-24 15:46:06,178:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:06,180:INFO:Initializing create_model()
2024-05-24 15:46:06,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:06,180:INFO:Checking exceptions
2024-05-24 15:46:06,180:INFO:Importing libraries
2024-05-24 15:46:06,180:INFO:Copying training dataset
2024-05-24 15:46:06,186:INFO:Defining folds
2024-05-24 15:46:06,186:INFO:Declaring metric variables
2024-05-24 15:46:06,191:INFO:Importing untrained model
2024-05-24 15:46:06,196:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:46:06,205:INFO:Starting cross validation
2024-05-24 15:46:06,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:06,578:INFO:Calculating mean and std
2024-05-24 15:46:06,580:INFO:Creating metrics dataframe
2024-05-24 15:46:06,581:INFO:Uploading results into container
2024-05-24 15:46:06,583:INFO:Uploading model into container now
2024-05-24 15:46:06,583:INFO:_master_model_container: 14
2024-05-24 15:46:06,583:INFO:_display_container: 2
2024-05-24 15:46:06,584:INFO:DecisionTreeRegressor(random_state=6449)
2024-05-24 15:46:06,584:INFO:create_model() successfully completed......................................
2024-05-24 15:46:06,755:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:06,755:INFO:Creating metrics dataframe
2024-05-24 15:46:06,766:INFO:Initializing Random Forest Regressor
2024-05-24 15:46:06,766:INFO:Total runtime is 0.14452090660730998 minutes
2024-05-24 15:46:06,770:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:06,770:INFO:Initializing create_model()
2024-05-24 15:46:06,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:06,770:INFO:Checking exceptions
2024-05-24 15:46:06,770:INFO:Importing libraries
2024-05-24 15:46:06,771:INFO:Copying training dataset
2024-05-24 15:46:06,778:INFO:Defining folds
2024-05-24 15:46:06,778:INFO:Declaring metric variables
2024-05-24 15:46:06,783:INFO:Importing untrained model
2024-05-24 15:46:06,787:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:46:06,796:INFO:Starting cross validation
2024-05-24 15:46:06,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:07,544:INFO:Calculating mean and std
2024-05-24 15:46:07,546:INFO:Creating metrics dataframe
2024-05-24 15:46:07,547:INFO:Uploading results into container
2024-05-24 15:46:07,548:INFO:Uploading model into container now
2024-05-24 15:46:07,548:INFO:_master_model_container: 15
2024-05-24 15:46:07,548:INFO:_display_container: 2
2024-05-24 15:46:07,549:INFO:RandomForestRegressor(n_jobs=-1, random_state=6449)
2024-05-24 15:46:07,549:INFO:create_model() successfully completed......................................
2024-05-24 15:46:07,712:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:07,712:INFO:Creating metrics dataframe
2024-05-24 15:46:07,724:INFO:Initializing Extra Trees Regressor
2024-05-24 15:46:07,724:INFO:Total runtime is 0.16049540440241497 minutes
2024-05-24 15:46:07,730:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:07,730:INFO:Initializing create_model()
2024-05-24 15:46:07,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:07,730:INFO:Checking exceptions
2024-05-24 15:46:07,730:INFO:Importing libraries
2024-05-24 15:46:07,731:INFO:Copying training dataset
2024-05-24 15:46:07,737:INFO:Defining folds
2024-05-24 15:46:07,737:INFO:Declaring metric variables
2024-05-24 15:46:07,741:INFO:Importing untrained model
2024-05-24 15:46:07,746:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:46:07,756:INFO:Starting cross validation
2024-05-24 15:46:07,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:08,432:INFO:Calculating mean and std
2024-05-24 15:46:08,433:INFO:Creating metrics dataframe
2024-05-24 15:46:08,435:INFO:Uploading results into container
2024-05-24 15:46:08,435:INFO:Uploading model into container now
2024-05-24 15:46:08,436:INFO:_master_model_container: 16
2024-05-24 15:46:08,436:INFO:_display_container: 2
2024-05-24 15:46:08,436:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6449)
2024-05-24 15:46:08,437:INFO:create_model() successfully completed......................................
2024-05-24 15:46:08,600:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:08,600:INFO:Creating metrics dataframe
2024-05-24 15:46:08,612:INFO:Initializing AdaBoost Regressor
2024-05-24 15:46:08,612:INFO:Total runtime is 0.17528946399688722 minutes
2024-05-24 15:46:08,617:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:08,617:INFO:Initializing create_model()
2024-05-24 15:46:08,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:08,618:INFO:Checking exceptions
2024-05-24 15:46:08,618:INFO:Importing libraries
2024-05-24 15:46:08,618:INFO:Copying training dataset
2024-05-24 15:46:08,625:INFO:Defining folds
2024-05-24 15:46:08,625:INFO:Declaring metric variables
2024-05-24 15:46:08,630:INFO:Importing untrained model
2024-05-24 15:46:08,635:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:46:08,643:INFO:Starting cross validation
2024-05-24 15:46:08,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:09,216:INFO:Calculating mean and std
2024-05-24 15:46:09,217:INFO:Creating metrics dataframe
2024-05-24 15:46:09,219:INFO:Uploading results into container
2024-05-24 15:46:09,220:INFO:Uploading model into container now
2024-05-24 15:46:09,220:INFO:_master_model_container: 17
2024-05-24 15:46:09,221:INFO:_display_container: 2
2024-05-24 15:46:09,221:INFO:AdaBoostRegressor(random_state=6449)
2024-05-24 15:46:09,222:INFO:create_model() successfully completed......................................
2024-05-24 15:46:09,395:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:09,395:INFO:Creating metrics dataframe
2024-05-24 15:46:09,407:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:46:09,407:INFO:Total runtime is 0.18854310909907024 minutes
2024-05-24 15:46:09,412:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:09,412:INFO:Initializing create_model()
2024-05-24 15:46:09,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:09,413:INFO:Checking exceptions
2024-05-24 15:46:09,413:INFO:Importing libraries
2024-05-24 15:46:09,413:INFO:Copying training dataset
2024-05-24 15:46:09,425:INFO:Defining folds
2024-05-24 15:46:09,425:INFO:Declaring metric variables
2024-05-24 15:46:09,430:INFO:Importing untrained model
2024-05-24 15:46:09,435:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:46:09,444:INFO:Starting cross validation
2024-05-24 15:46:09,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:09,931:INFO:Calculating mean and std
2024-05-24 15:46:09,933:INFO:Creating metrics dataframe
2024-05-24 15:46:09,935:INFO:Uploading results into container
2024-05-24 15:46:09,936:INFO:Uploading model into container now
2024-05-24 15:46:09,937:INFO:_master_model_container: 18
2024-05-24 15:46:09,937:INFO:_display_container: 2
2024-05-24 15:46:09,939:INFO:GradientBoostingRegressor(random_state=6449)
2024-05-24 15:46:09,939:INFO:create_model() successfully completed......................................
2024-05-24 15:46:10,097:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:10,098:INFO:Creating metrics dataframe
2024-05-24 15:46:10,108:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:46:10,108:INFO:Total runtime is 0.20022726853688558 minutes
2024-05-24 15:46:10,112:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:10,112:INFO:Initializing create_model()
2024-05-24 15:46:10,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:10,112:INFO:Checking exceptions
2024-05-24 15:46:10,112:INFO:Importing libraries
2024-05-24 15:46:10,113:INFO:Copying training dataset
2024-05-24 15:46:10,119:INFO:Defining folds
2024-05-24 15:46:10,120:INFO:Declaring metric variables
2024-05-24 15:46:10,125:INFO:Importing untrained model
2024-05-24 15:46:10,128:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:46:10,137:INFO:Starting cross validation
2024-05-24 15:46:10,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:10,809:INFO:Calculating mean and std
2024-05-24 15:46:10,817:INFO:Creating metrics dataframe
2024-05-24 15:46:10,821:INFO:Uploading results into container
2024-05-24 15:46:10,822:INFO:Uploading model into container now
2024-05-24 15:46:10,822:INFO:_master_model_container: 19
2024-05-24 15:46:10,823:INFO:_display_container: 2
2024-05-24 15:46:10,824:INFO:LGBMRegressor(n_jobs=-1, random_state=6449)
2024-05-24 15:46:10,824:INFO:create_model() successfully completed......................................
2024-05-24 15:46:11,030:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:11,030:INFO:Creating metrics dataframe
2024-05-24 15:46:11,040:INFO:Initializing Dummy Regressor
2024-05-24 15:46:11,040:INFO:Total runtime is 0.21575212478637695 minutes
2024-05-24 15:46:11,044:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:11,045:INFO:Initializing create_model()
2024-05-24 15:46:11,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB44D0C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:11,045:INFO:Checking exceptions
2024-05-24 15:46:11,045:INFO:Importing libraries
2024-05-24 15:46:11,045:INFO:Copying training dataset
2024-05-24 15:46:11,050:INFO:Defining folds
2024-05-24 15:46:11,050:INFO:Declaring metric variables
2024-05-24 15:46:11,053:INFO:Importing untrained model
2024-05-24 15:46:11,058:INFO:Dummy Regressor Imported successfully
2024-05-24 15:46:11,067:INFO:Starting cross validation
2024-05-24 15:46:11,071:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:11,436:INFO:Calculating mean and std
2024-05-24 15:46:11,436:INFO:Creating metrics dataframe
2024-05-24 15:46:11,438:INFO:Uploading results into container
2024-05-24 15:46:11,438:INFO:Uploading model into container now
2024-05-24 15:46:11,439:INFO:_master_model_container: 20
2024-05-24 15:46:11,439:INFO:_display_container: 2
2024-05-24 15:46:11,439:INFO:DummyRegressor()
2024-05-24 15:46:11,439:INFO:create_model() successfully completed......................................
2024-05-24 15:46:11,632:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:11,632:INFO:Creating metrics dataframe
2024-05-24 15:46:11,651:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:46:11,661:INFO:Initializing create_model()
2024-05-24 15:46:11,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAE4A5C0>, estimator=Ridge(random_state=6449), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:11,661:INFO:Checking exceptions
2024-05-24 15:46:11,664:INFO:Importing libraries
2024-05-24 15:46:11,664:INFO:Copying training dataset
2024-05-24 15:46:11,672:INFO:Defining folds
2024-05-24 15:46:11,672:INFO:Declaring metric variables
2024-05-24 15:46:11,672:INFO:Importing untrained model
2024-05-24 15:46:11,672:INFO:Declaring custom model
2024-05-24 15:46:11,673:INFO:Ridge Regression Imported successfully
2024-05-24 15:46:11,676:INFO:Cross validation set to False
2024-05-24 15:46:11,676:INFO:Fitting Model
2024-05-24 15:46:11,799:INFO:Ridge(random_state=6449)
2024-05-24 15:46:11,799:INFO:create_model() successfully completed......................................
2024-05-24 15:46:12,002:INFO:_master_model_container: 20
2024-05-24 15:46:12,002:INFO:_display_container: 2
2024-05-24 15:46:12,003:INFO:Ridge(random_state=6449)
2024-05-24 15:46:12,003:INFO:compare_models() successfully completed......................................
2024-05-24 15:46:19,874:INFO:PyCaret RegressionExperiment
2024-05-24 15:46:19,874:INFO:Logging name: reg-default-name
2024-05-24 15:46:19,874:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:46:19,874:INFO:version 3.3.2
2024-05-24 15:46:19,874:INFO:Initializing setup()
2024-05-24 15:46:19,874:INFO:self.USI: 43d5
2024-05-24 15:46:19,874:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:46:19,874:INFO:Checking environment
2024-05-24 15:46:19,874:INFO:python_version: 3.10.14
2024-05-24 15:46:19,874:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:46:19,874:INFO:machine: AMD64
2024-05-24 15:46:19,874:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:46:19,874:INFO:Memory: svmem(total=16541802496, available=2168725504, percent=86.9, used=14373076992, free=2168725504)
2024-05-24 15:46:19,875:INFO:Physical Core: 6
2024-05-24 15:46:19,875:INFO:Logical Core: 12
2024-05-24 15:46:19,875:INFO:Checking libraries
2024-05-24 15:46:19,875:INFO:System:
2024-05-24 15:46:19,875:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:46:19,875:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:46:19,875:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:46:19,875:INFO:PyCaret required dependencies:
2024-05-24 15:46:19,875:INFO:                 pip: 24.0
2024-05-24 15:46:19,875:INFO:          setuptools: 69.5.1
2024-05-24 15:46:19,875:INFO:             pycaret: 3.3.2
2024-05-24 15:46:19,875:INFO:             IPython: 8.20.0
2024-05-24 15:46:19,875:INFO:          ipywidgets: 8.1.2
2024-05-24 15:46:19,875:INFO:                tqdm: 4.66.4
2024-05-24 15:46:19,875:INFO:               numpy: 1.26.4
2024-05-24 15:46:19,875:INFO:              pandas: 2.1.4
2024-05-24 15:46:19,875:INFO:              jinja2: 3.1.3
2024-05-24 15:46:19,875:INFO:               scipy: 1.11.4
2024-05-24 15:46:19,875:INFO:              joblib: 1.3.2
2024-05-24 15:46:19,875:INFO:             sklearn: 1.4.2
2024-05-24 15:46:19,876:INFO:                pyod: 1.1.3
2024-05-24 15:46:19,876:INFO:            imblearn: 0.12.2
2024-05-24 15:46:19,876:INFO:   category_encoders: 2.6.3
2024-05-24 15:46:19,876:INFO:            lightgbm: 4.3.0
2024-05-24 15:46:19,876:INFO:               numba: 0.59.1
2024-05-24 15:46:19,876:INFO:            requests: 2.32.2
2024-05-24 15:46:19,876:INFO:          matplotlib: 3.7.5
2024-05-24 15:46:19,876:INFO:          scikitplot: 0.3.7
2024-05-24 15:46:19,876:INFO:         yellowbrick: 1.5
2024-05-24 15:46:19,876:INFO:              plotly: 5.22.0
2024-05-24 15:46:19,876:INFO:    plotly-resampler: Not installed
2024-05-24 15:46:19,876:INFO:             kaleido: 0.2.1
2024-05-24 15:46:19,876:INFO:           schemdraw: 0.15
2024-05-24 15:46:19,876:INFO:         statsmodels: 0.14.2
2024-05-24 15:46:19,876:INFO:              sktime: 0.26.0
2024-05-24 15:46:19,876:INFO:               tbats: 1.1.3
2024-05-24 15:46:19,876:INFO:            pmdarima: 2.0.4
2024-05-24 15:46:19,876:INFO:              psutil: 5.9.0
2024-05-24 15:46:19,876:INFO:          markupsafe: 2.1.3
2024-05-24 15:46:19,876:INFO:             pickle5: Not installed
2024-05-24 15:46:19,877:INFO:         cloudpickle: 3.0.0
2024-05-24 15:46:19,877:INFO:         deprecation: 2.1.0
2024-05-24 15:46:19,877:INFO:              xxhash: 3.4.1
2024-05-24 15:46:19,877:INFO:           wurlitzer: Not installed
2024-05-24 15:46:19,877:INFO:PyCaret optional dependencies:
2024-05-24 15:46:19,877:INFO:                shap: Not installed
2024-05-24 15:46:19,877:INFO:           interpret: Not installed
2024-05-24 15:46:19,877:INFO:                umap: Not installed
2024-05-24 15:46:19,877:INFO:     ydata_profiling: Not installed
2024-05-24 15:46:19,877:INFO:  explainerdashboard: Not installed
2024-05-24 15:46:19,877:INFO:             autoviz: Not installed
2024-05-24 15:46:19,877:INFO:           fairlearn: Not installed
2024-05-24 15:46:19,877:INFO:          deepchecks: Not installed
2024-05-24 15:46:19,877:INFO:             xgboost: Not installed
2024-05-24 15:46:19,877:INFO:            catboost: Not installed
2024-05-24 15:46:19,877:INFO:              kmodes: Not installed
2024-05-24 15:46:19,877:INFO:             mlxtend: Not installed
2024-05-24 15:46:19,877:INFO:       statsforecast: Not installed
2024-05-24 15:46:19,877:INFO:        tune_sklearn: Not installed
2024-05-24 15:46:19,877:INFO:                 ray: Not installed
2024-05-24 15:46:19,877:INFO:            hyperopt: Not installed
2024-05-24 15:46:19,877:INFO:              optuna: Not installed
2024-05-24 15:46:19,878:INFO:               skopt: Not installed
2024-05-24 15:46:19,878:INFO:              mlflow: Not installed
2024-05-24 15:46:19,878:INFO:              gradio: Not installed
2024-05-24 15:46:19,878:INFO:             fastapi: Not installed
2024-05-24 15:46:19,878:INFO:             uvicorn: Not installed
2024-05-24 15:46:19,878:INFO:              m2cgen: Not installed
2024-05-24 15:46:19,878:INFO:           evidently: Not installed
2024-05-24 15:46:19,878:INFO:               fugue: Not installed
2024-05-24 15:46:19,878:INFO:           streamlit: Not installed
2024-05-24 15:46:19,878:INFO:             prophet: Not installed
2024-05-24 15:46:19,878:INFO:None
2024-05-24 15:46:19,878:INFO:Set up data.
2024-05-24 15:46:19,890:INFO:Set up folding strategy.
2024-05-24 15:46:19,890:INFO:Set up train/test split.
2024-05-24 15:46:19,898:INFO:Set up index.
2024-05-24 15:46:19,898:INFO:Assigning column types.
2024-05-24 15:46:19,903:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:46:19,903:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:46:19,908:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:46:19,914:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:46:19,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,027:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,032:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,098:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,147:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:46:20,152:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,218:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,270:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,387:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:46:20,397:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,463:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,518:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,623:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:46:20,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,854:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:46:20,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:20,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:20,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:46:21,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,090:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:46:21,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:21,327:INFO:Preparing preprocessing pipeline...
2024-05-24 15:46:21,327:INFO:Set up simple imputation.
2024-05-24 15:46:21,332:INFO:Set up encoding of ordinal features.
2024-05-24 15:46:21,338:INFO:Set up encoding of categorical features.
2024-05-24 15:46:21,338:INFO:Set up removing multicollinearity.
2024-05-24 15:46:21,538:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:46:21,599:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=OneHotEncoder(cols=['carbody',
                                                                    'drivewheel',
                                                                    'enginetype',
                                                                    'cylindernumber',
                                                                    'fuelsystem'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:46:21,599:INFO:Creating final display dataframe.
2024-05-24 15:46:22,088:INFO:Setup _display_container:                     Description             Value
0                    Session id              7064
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape         (205, 45)
5   Transformed train set shape         (143, 45)
6    Transformed test set shape          (62, 45)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.9
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              43d5
2024-05-24 15:46:22,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:22,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:22,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:22,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:46:22,378:INFO:setup() successfully completed in 2.51s...............
2024-05-24 15:46:22,405:INFO:Initializing compare_models()
2024-05-24 15:46:22,405:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:46:22,405:INFO:Checking exceptions
2024-05-24 15:46:22,410:INFO:Preparing display monitor
2024-05-24 15:46:22,448:INFO:Initializing Linear Regression
2024-05-24 15:46:22,448:INFO:Total runtime is 0.0 minutes
2024-05-24 15:46:22,454:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:22,454:INFO:Initializing create_model()
2024-05-24 15:46:22,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:22,454:INFO:Checking exceptions
2024-05-24 15:46:22,455:INFO:Importing libraries
2024-05-24 15:46:22,455:INFO:Copying training dataset
2024-05-24 15:46:22,467:INFO:Defining folds
2024-05-24 15:46:22,467:INFO:Declaring metric variables
2024-05-24 15:46:22,472:INFO:Importing untrained model
2024-05-24 15:46:22,477:INFO:Linear Regression Imported successfully
2024-05-24 15:46:22,487:INFO:Starting cross validation
2024-05-24 15:46:22,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:22,843:INFO:Calculating mean and std
2024-05-24 15:46:22,845:INFO:Creating metrics dataframe
2024-05-24 15:46:22,847:INFO:Uploading results into container
2024-05-24 15:46:22,847:INFO:Uploading model into container now
2024-05-24 15:46:22,847:INFO:_master_model_container: 1
2024-05-24 15:46:22,847:INFO:_display_container: 2
2024-05-24 15:46:22,848:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:46:22,848:INFO:create_model() successfully completed......................................
2024-05-24 15:46:23,006:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:23,006:INFO:Creating metrics dataframe
2024-05-24 15:46:23,014:INFO:Initializing Lasso Regression
2024-05-24 15:46:23,014:INFO:Total runtime is 0.009431175390879313 minutes
2024-05-24 15:46:23,018:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:23,019:INFO:Initializing create_model()
2024-05-24 15:46:23,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:23,019:INFO:Checking exceptions
2024-05-24 15:46:23,019:INFO:Importing libraries
2024-05-24 15:46:23,019:INFO:Copying training dataset
2024-05-24 15:46:23,025:INFO:Defining folds
2024-05-24 15:46:23,025:INFO:Declaring metric variables
2024-05-24 15:46:23,030:INFO:Importing untrained model
2024-05-24 15:46:23,033:INFO:Lasso Regression Imported successfully
2024-05-24 15:46:23,042:INFO:Starting cross validation
2024-05-24 15:46:23,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:23,296:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.921e+06, tolerance: 1.013e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:46:23,420:INFO:Calculating mean and std
2024-05-24 15:46:23,422:INFO:Creating metrics dataframe
2024-05-24 15:46:23,424:INFO:Uploading results into container
2024-05-24 15:46:23,425:INFO:Uploading model into container now
2024-05-24 15:46:23,425:INFO:_master_model_container: 2
2024-05-24 15:46:23,425:INFO:_display_container: 2
2024-05-24 15:46:23,426:INFO:Lasso(random_state=7064)
2024-05-24 15:46:23,426:INFO:create_model() successfully completed......................................
2024-05-24 15:46:23,597:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:23,597:INFO:Creating metrics dataframe
2024-05-24 15:46:23,604:INFO:Initializing Ridge Regression
2024-05-24 15:46:23,604:INFO:Total runtime is 0.019264288743336994 minutes
2024-05-24 15:46:23,607:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:23,608:INFO:Initializing create_model()
2024-05-24 15:46:23,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:23,610:INFO:Checking exceptions
2024-05-24 15:46:23,610:INFO:Importing libraries
2024-05-24 15:46:23,610:INFO:Copying training dataset
2024-05-24 15:46:23,617:INFO:Defining folds
2024-05-24 15:46:23,617:INFO:Declaring metric variables
2024-05-24 15:46:23,621:INFO:Importing untrained model
2024-05-24 15:46:23,625:INFO:Ridge Regression Imported successfully
2024-05-24 15:46:23,634:INFO:Starting cross validation
2024-05-24 15:46:23,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:23,967:INFO:Calculating mean and std
2024-05-24 15:46:23,968:INFO:Creating metrics dataframe
2024-05-24 15:46:23,970:INFO:Uploading results into container
2024-05-24 15:46:23,971:INFO:Uploading model into container now
2024-05-24 15:46:23,971:INFO:_master_model_container: 3
2024-05-24 15:46:23,972:INFO:_display_container: 2
2024-05-24 15:46:23,972:INFO:Ridge(random_state=7064)
2024-05-24 15:46:23,972:INFO:create_model() successfully completed......................................
2024-05-24 15:46:24,130:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:24,130:INFO:Creating metrics dataframe
2024-05-24 15:46:24,139:INFO:Initializing Elastic Net
2024-05-24 15:46:24,139:INFO:Total runtime is 0.02819005250930786 minutes
2024-05-24 15:46:24,143:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:24,143:INFO:Initializing create_model()
2024-05-24 15:46:24,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:24,143:INFO:Checking exceptions
2024-05-24 15:46:24,145:INFO:Importing libraries
2024-05-24 15:46:24,145:INFO:Copying training dataset
2024-05-24 15:46:24,150:INFO:Defining folds
2024-05-24 15:46:24,150:INFO:Declaring metric variables
2024-05-24 15:46:24,154:INFO:Importing untrained model
2024-05-24 15:46:24,158:INFO:Elastic Net Imported successfully
2024-05-24 15:46:24,168:INFO:Starting cross validation
2024-05-24 15:46:24,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:24,513:INFO:Calculating mean and std
2024-05-24 15:46:24,515:INFO:Creating metrics dataframe
2024-05-24 15:46:24,517:INFO:Uploading results into container
2024-05-24 15:46:24,517:INFO:Uploading model into container now
2024-05-24 15:46:24,518:INFO:_master_model_container: 4
2024-05-24 15:46:24,518:INFO:_display_container: 2
2024-05-24 15:46:24,518:INFO:ElasticNet(random_state=7064)
2024-05-24 15:46:24,519:INFO:create_model() successfully completed......................................
2024-05-24 15:46:24,672:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:24,672:INFO:Creating metrics dataframe
2024-05-24 15:46:24,681:INFO:Initializing Least Angle Regression
2024-05-24 15:46:24,682:INFO:Total runtime is 0.03722844123840332 minutes
2024-05-24 15:46:24,686:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:24,686:INFO:Initializing create_model()
2024-05-24 15:46:24,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:24,686:INFO:Checking exceptions
2024-05-24 15:46:24,686:INFO:Importing libraries
2024-05-24 15:46:24,687:INFO:Copying training dataset
2024-05-24 15:46:24,694:INFO:Defining folds
2024-05-24 15:46:24,695:INFO:Declaring metric variables
2024-05-24 15:46:24,699:INFO:Importing untrained model
2024-05-24 15:46:24,704:INFO:Least Angle Regression Imported successfully
2024-05-24 15:46:24,713:INFO:Starting cross validation
2024-05-24 15:46:24,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:24,926:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.444e+01, with an active set of 34 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,926:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.263e+01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,928:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.602e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,928:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.464e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.806e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.992e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.956e+01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.125e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.450e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=6.688e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,930:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.600e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,930:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.126e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=9.652e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.865e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.537e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.357e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,933:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.725e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,938:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=6.424e+00, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,939:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.000e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,940:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.865e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,941:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=2.681e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,941:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.856e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,942:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.309e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,942:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.133e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,943:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.688e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,943:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.605e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,943:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.406e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,944:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.869e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,944:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.730e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 9.599e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,963:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.494e+01, with an active set of 32 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,964:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.077e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,965:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.122e+01, with an active set of 31 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,966:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=4.627e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,966:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=2.055e+01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.558e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=3.699e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=3.081e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.591e+01, with an active set of 37 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,982:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.224e+04, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,984:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.140e+01, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,985:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.094e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.783e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.980e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.002e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.974e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.134e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.349e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.749e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,987:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=5.731e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,987:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.647e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,988:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.144e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.025e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,988:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.113e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:24,988:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.501e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,076:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-05-24 15:46:25,077:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-05-24 15:46:25,077:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-05-24 15:46:25,089:INFO:Calculating mean and std
2024-05-24 15:46:25,097:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-24 15:46:25,098:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2024-05-24 15:46:25,100:INFO:Creating metrics dataframe
2024-05-24 15:46:25,101:INFO:Uploading results into container
2024-05-24 15:46:25,102:INFO:Uploading model into container now
2024-05-24 15:46:25,103:INFO:_master_model_container: 5
2024-05-24 15:46:25,103:INFO:_display_container: 2
2024-05-24 15:46:25,104:INFO:Lars(random_state=7064)
2024-05-24 15:46:25,105:INFO:create_model() successfully completed......................................
2024-05-24 15:46:25,265:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:25,265:INFO:Creating metrics dataframe
2024-05-24 15:46:25,274:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:46:25,274:INFO:Total runtime is 0.04709943930308024 minutes
2024-05-24 15:46:25,279:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:25,279:INFO:Initializing create_model()
2024-05-24 15:46:25,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:25,280:INFO:Checking exceptions
2024-05-24 15:46:25,280:INFO:Importing libraries
2024-05-24 15:46:25,280:INFO:Copying training dataset
2024-05-24 15:46:25,287:INFO:Defining folds
2024-05-24 15:46:25,287:INFO:Declaring metric variables
2024-05-24 15:46:25,291:INFO:Importing untrained model
2024-05-24 15:46:25,295:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:46:25,311:INFO:Starting cross validation
2024-05-24 15:46:25,316:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:25,553:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=4.194e+00, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=3.830e+00, with an active set of 34 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,555:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.444e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,555:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.934e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,555:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.075e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,556:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.057e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=6.140e+00, previous alpha=4.615e+00, with an active set of 35 regressors.
  warnings.warn(

2024-05-24 15:46:25,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.935e+00, with an active set of 35 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,598:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=8.451e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,603:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.748e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,603:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.274e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:46:25,681:INFO:Calculating mean and std
2024-05-24 15:46:25,682:INFO:Creating metrics dataframe
2024-05-24 15:46:25,684:INFO:Uploading results into container
2024-05-24 15:46:25,685:INFO:Uploading model into container now
2024-05-24 15:46:25,686:INFO:_master_model_container: 6
2024-05-24 15:46:25,686:INFO:_display_container: 2
2024-05-24 15:46:25,686:INFO:LassoLars(random_state=7064)
2024-05-24 15:46:25,686:INFO:create_model() successfully completed......................................
2024-05-24 15:46:25,851:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:25,851:INFO:Creating metrics dataframe
2024-05-24 15:46:25,859:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:46:25,859:INFO:Total runtime is 0.05685813029607137 minutes
2024-05-24 15:46:25,865:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:25,865:INFO:Initializing create_model()
2024-05-24 15:46:25,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:25,866:INFO:Checking exceptions
2024-05-24 15:46:25,866:INFO:Importing libraries
2024-05-24 15:46:25,866:INFO:Copying training dataset
2024-05-24 15:46:25,873:INFO:Defining folds
2024-05-24 15:46:25,873:INFO:Declaring metric variables
2024-05-24 15:46:25,878:INFO:Importing untrained model
2024-05-24 15:46:25,883:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:46:25,892:INFO:Starting cross validation
2024-05-24 15:46:25,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:26,228:INFO:Calculating mean and std
2024-05-24 15:46:26,230:INFO:Creating metrics dataframe
2024-05-24 15:46:26,232:INFO:Uploading results into container
2024-05-24 15:46:26,232:INFO:Uploading model into container now
2024-05-24 15:46:26,233:INFO:_master_model_container: 7
2024-05-24 15:46:26,233:INFO:_display_container: 2
2024-05-24 15:46:26,233:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:46:26,234:INFO:create_model() successfully completed......................................
2024-05-24 15:46:26,394:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:26,394:INFO:Creating metrics dataframe
2024-05-24 15:46:26,403:INFO:Initializing Bayesian Ridge
2024-05-24 15:46:26,403:INFO:Total runtime is 0.06591873168945313 minutes
2024-05-24 15:46:26,406:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:26,406:INFO:Initializing create_model()
2024-05-24 15:46:26,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:26,407:INFO:Checking exceptions
2024-05-24 15:46:26,407:INFO:Importing libraries
2024-05-24 15:46:26,407:INFO:Copying training dataset
2024-05-24 15:46:26,415:INFO:Defining folds
2024-05-24 15:46:26,416:INFO:Declaring metric variables
2024-05-24 15:46:26,419:INFO:Importing untrained model
2024-05-24 15:46:26,424:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:46:26,433:INFO:Starting cross validation
2024-05-24 15:46:26,437:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:26,793:INFO:Calculating mean and std
2024-05-24 15:46:26,794:INFO:Creating metrics dataframe
2024-05-24 15:46:26,796:INFO:Uploading results into container
2024-05-24 15:46:26,797:INFO:Uploading model into container now
2024-05-24 15:46:26,798:INFO:_master_model_container: 8
2024-05-24 15:46:26,798:INFO:_display_container: 2
2024-05-24 15:46:26,798:INFO:BayesianRidge()
2024-05-24 15:46:26,799:INFO:create_model() successfully completed......................................
2024-05-24 15:46:26,980:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:26,980:INFO:Creating metrics dataframe
2024-05-24 15:46:26,990:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:46:26,990:INFO:Total runtime is 0.07570516665776571 minutes
2024-05-24 15:46:26,995:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:26,995:INFO:Initializing create_model()
2024-05-24 15:46:26,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:26,996:INFO:Checking exceptions
2024-05-24 15:46:26,996:INFO:Importing libraries
2024-05-24 15:46:26,996:INFO:Copying training dataset
2024-05-24 15:46:27,005:INFO:Defining folds
2024-05-24 15:46:27,005:INFO:Declaring metric variables
2024-05-24 15:46:27,009:INFO:Importing untrained model
2024-05-24 15:46:27,015:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:46:27,024:INFO:Starting cross validation
2024-05-24 15:46:27,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:27,404:INFO:Calculating mean and std
2024-05-24 15:46:27,407:INFO:Creating metrics dataframe
2024-05-24 15:46:27,409:INFO:Uploading results into container
2024-05-24 15:46:27,410:INFO:Uploading model into container now
2024-05-24 15:46:27,410:INFO:_master_model_container: 9
2024-05-24 15:46:27,410:INFO:_display_container: 2
2024-05-24 15:46:27,411:INFO:PassiveAggressiveRegressor(random_state=7064)
2024-05-24 15:46:27,411:INFO:create_model() successfully completed......................................
2024-05-24 15:46:27,581:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:27,581:INFO:Creating metrics dataframe
2024-05-24 15:46:27,590:INFO:Initializing Huber Regressor
2024-05-24 15:46:27,590:INFO:Total runtime is 0.0857044259707133 minutes
2024-05-24 15:46:27,595:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:27,595:INFO:Initializing create_model()
2024-05-24 15:46:27,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:27,596:INFO:Checking exceptions
2024-05-24 15:46:27,596:INFO:Importing libraries
2024-05-24 15:46:27,596:INFO:Copying training dataset
2024-05-24 15:46:27,603:INFO:Defining folds
2024-05-24 15:46:27,604:INFO:Declaring metric variables
2024-05-24 15:46:27,608:INFO:Importing untrained model
2024-05-24 15:46:27,612:INFO:Huber Regressor Imported successfully
2024-05-24 15:46:27,626:INFO:Starting cross validation
2024-05-24 15:46:27,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:27,904:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,904:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,908:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,912:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,919:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,925:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,930:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,933:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,951:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:27,974:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:28,032:INFO:Calculating mean and std
2024-05-24 15:46:28,033:INFO:Creating metrics dataframe
2024-05-24 15:46:28,035:INFO:Uploading results into container
2024-05-24 15:46:28,036:INFO:Uploading model into container now
2024-05-24 15:46:28,037:INFO:_master_model_container: 10
2024-05-24 15:46:28,037:INFO:_display_container: 2
2024-05-24 15:46:28,037:INFO:HuberRegressor()
2024-05-24 15:46:28,037:INFO:create_model() successfully completed......................................
2024-05-24 15:46:28,202:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:28,203:INFO:Creating metrics dataframe
2024-05-24 15:46:28,212:INFO:Initializing K Neighbors Regressor
2024-05-24 15:46:28,212:INFO:Total runtime is 0.09607439438501994 minutes
2024-05-24 15:46:28,216:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:28,216:INFO:Initializing create_model()
2024-05-24 15:46:28,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:28,217:INFO:Checking exceptions
2024-05-24 15:46:28,217:INFO:Importing libraries
2024-05-24 15:46:28,217:INFO:Copying training dataset
2024-05-24 15:46:28,224:INFO:Defining folds
2024-05-24 15:46:28,224:INFO:Declaring metric variables
2024-05-24 15:46:28,229:INFO:Importing untrained model
2024-05-24 15:46:28,234:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:46:28,243:INFO:Starting cross validation
2024-05-24 15:46:28,247:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:28,578:INFO:Calculating mean and std
2024-05-24 15:46:28,579:INFO:Creating metrics dataframe
2024-05-24 15:46:28,581:INFO:Uploading results into container
2024-05-24 15:46:28,582:INFO:Uploading model into container now
2024-05-24 15:46:28,582:INFO:_master_model_container: 11
2024-05-24 15:46:28,582:INFO:_display_container: 2
2024-05-24 15:46:28,582:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:46:28,583:INFO:create_model() successfully completed......................................
2024-05-24 15:46:28,736:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:28,736:INFO:Creating metrics dataframe
2024-05-24 15:46:28,746:INFO:Initializing Decision Tree Regressor
2024-05-24 15:46:28,746:INFO:Total runtime is 0.10496707757314047 minutes
2024-05-24 15:46:28,751:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:28,751:INFO:Initializing create_model()
2024-05-24 15:46:28,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:28,751:INFO:Checking exceptions
2024-05-24 15:46:28,752:INFO:Importing libraries
2024-05-24 15:46:28,752:INFO:Copying training dataset
2024-05-24 15:46:28,758:INFO:Defining folds
2024-05-24 15:46:28,758:INFO:Declaring metric variables
2024-05-24 15:46:28,762:INFO:Importing untrained model
2024-05-24 15:46:28,767:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:46:28,776:INFO:Starting cross validation
2024-05-24 15:46:28,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:29,127:INFO:Calculating mean and std
2024-05-24 15:46:29,128:INFO:Creating metrics dataframe
2024-05-24 15:46:29,130:INFO:Uploading results into container
2024-05-24 15:46:29,131:INFO:Uploading model into container now
2024-05-24 15:46:29,131:INFO:_master_model_container: 12
2024-05-24 15:46:29,131:INFO:_display_container: 2
2024-05-24 15:46:29,131:INFO:DecisionTreeRegressor(random_state=7064)
2024-05-24 15:46:29,132:INFO:create_model() successfully completed......................................
2024-05-24 15:46:29,294:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:29,294:INFO:Creating metrics dataframe
2024-05-24 15:46:29,306:INFO:Initializing Random Forest Regressor
2024-05-24 15:46:29,306:INFO:Total runtime is 0.11429402033487956 minutes
2024-05-24 15:46:29,310:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:29,311:INFO:Initializing create_model()
2024-05-24 15:46:29,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:29,311:INFO:Checking exceptions
2024-05-24 15:46:29,311:INFO:Importing libraries
2024-05-24 15:46:29,311:INFO:Copying training dataset
2024-05-24 15:46:29,319:INFO:Defining folds
2024-05-24 15:46:29,319:INFO:Declaring metric variables
2024-05-24 15:46:29,323:INFO:Importing untrained model
2024-05-24 15:46:29,328:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:46:29,337:INFO:Starting cross validation
2024-05-24 15:46:29,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:30,122:INFO:Calculating mean and std
2024-05-24 15:46:30,123:INFO:Creating metrics dataframe
2024-05-24 15:46:30,126:INFO:Uploading results into container
2024-05-24 15:46:30,126:INFO:Uploading model into container now
2024-05-24 15:46:30,127:INFO:_master_model_container: 13
2024-05-24 15:46:30,127:INFO:_display_container: 2
2024-05-24 15:46:30,127:INFO:RandomForestRegressor(n_jobs=-1, random_state=7064)
2024-05-24 15:46:30,127:INFO:create_model() successfully completed......................................
2024-05-24 15:46:30,297:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:30,297:INFO:Creating metrics dataframe
2024-05-24 15:46:30,309:INFO:Initializing Extra Trees Regressor
2024-05-24 15:46:30,309:INFO:Total runtime is 0.1310174584388733 minutes
2024-05-24 15:46:30,315:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:30,315:INFO:Initializing create_model()
2024-05-24 15:46:30,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:30,317:INFO:Checking exceptions
2024-05-24 15:46:30,317:INFO:Importing libraries
2024-05-24 15:46:30,317:INFO:Copying training dataset
2024-05-24 15:46:30,324:INFO:Defining folds
2024-05-24 15:46:30,324:INFO:Declaring metric variables
2024-05-24 15:46:30,330:INFO:Importing untrained model
2024-05-24 15:46:30,335:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:46:30,344:INFO:Starting cross validation
2024-05-24 15:46:30,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:31,055:INFO:Calculating mean and std
2024-05-24 15:46:31,057:INFO:Creating metrics dataframe
2024-05-24 15:46:31,059:INFO:Uploading results into container
2024-05-24 15:46:31,060:INFO:Uploading model into container now
2024-05-24 15:46:31,060:INFO:_master_model_container: 14
2024-05-24 15:46:31,061:INFO:_display_container: 2
2024-05-24 15:46:31,061:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7064)
2024-05-24 15:46:31,061:INFO:create_model() successfully completed......................................
2024-05-24 15:46:31,227:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:31,227:INFO:Creating metrics dataframe
2024-05-24 15:46:31,238:INFO:Initializing AdaBoost Regressor
2024-05-24 15:46:31,238:INFO:Total runtime is 0.14650514523188274 minutes
2024-05-24 15:46:31,243:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:31,244:INFO:Initializing create_model()
2024-05-24 15:46:31,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:31,244:INFO:Checking exceptions
2024-05-24 15:46:31,244:INFO:Importing libraries
2024-05-24 15:46:31,245:INFO:Copying training dataset
2024-05-24 15:46:31,251:INFO:Defining folds
2024-05-24 15:46:31,251:INFO:Declaring metric variables
2024-05-24 15:46:31,255:INFO:Importing untrained model
2024-05-24 15:46:31,260:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:46:31,268:INFO:Starting cross validation
2024-05-24 15:46:31,273:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:31,740:INFO:Calculating mean and std
2024-05-24 15:46:31,742:INFO:Creating metrics dataframe
2024-05-24 15:46:31,745:INFO:Uploading results into container
2024-05-24 15:46:31,745:INFO:Uploading model into container now
2024-05-24 15:46:31,746:INFO:_master_model_container: 15
2024-05-24 15:46:31,746:INFO:_display_container: 2
2024-05-24 15:46:31,746:INFO:AdaBoostRegressor(random_state=7064)
2024-05-24 15:46:31,747:INFO:create_model() successfully completed......................................
2024-05-24 15:46:31,909:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:31,909:INFO:Creating metrics dataframe
2024-05-24 15:46:31,925:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:46:31,925:INFO:Total runtime is 0.1579576849937439 minutes
2024-05-24 15:46:31,930:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:31,930:INFO:Initializing create_model()
2024-05-24 15:46:31,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:31,931:INFO:Checking exceptions
2024-05-24 15:46:31,931:INFO:Importing libraries
2024-05-24 15:46:31,931:INFO:Copying training dataset
2024-05-24 15:46:31,940:INFO:Defining folds
2024-05-24 15:46:31,940:INFO:Declaring metric variables
2024-05-24 15:46:31,945:INFO:Importing untrained model
2024-05-24 15:46:31,950:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:46:31,961:INFO:Starting cross validation
2024-05-24 15:46:31,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:32,512:INFO:Calculating mean and std
2024-05-24 15:46:32,515:INFO:Creating metrics dataframe
2024-05-24 15:46:32,518:INFO:Uploading results into container
2024-05-24 15:46:32,518:INFO:Uploading model into container now
2024-05-24 15:46:32,519:INFO:_master_model_container: 16
2024-05-24 15:46:32,519:INFO:_display_container: 2
2024-05-24 15:46:32,519:INFO:GradientBoostingRegressor(random_state=7064)
2024-05-24 15:46:32,520:INFO:create_model() successfully completed......................................
2024-05-24 15:46:32,739:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:32,740:INFO:Creating metrics dataframe
2024-05-24 15:46:32,755:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:46:32,755:INFO:Total runtime is 0.17177948951721192 minutes
2024-05-24 15:46:32,759:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:32,759:INFO:Initializing create_model()
2024-05-24 15:46:32,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:32,759:INFO:Checking exceptions
2024-05-24 15:46:32,761:INFO:Importing libraries
2024-05-24 15:46:32,761:INFO:Copying training dataset
2024-05-24 15:46:32,767:INFO:Defining folds
2024-05-24 15:46:32,767:INFO:Declaring metric variables
2024-05-24 15:46:32,774:INFO:Importing untrained model
2024-05-24 15:46:32,779:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:46:32,791:INFO:Starting cross validation
2024-05-24 15:46:32,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:33,920:INFO:Calculating mean and std
2024-05-24 15:46:33,922:INFO:Creating metrics dataframe
2024-05-24 15:46:33,925:INFO:Uploading results into container
2024-05-24 15:46:33,926:INFO:Uploading model into container now
2024-05-24 15:46:33,927:INFO:_master_model_container: 17
2024-05-24 15:46:33,927:INFO:_display_container: 2
2024-05-24 15:46:33,928:INFO:LGBMRegressor(n_jobs=-1, random_state=7064)
2024-05-24 15:46:33,928:INFO:create_model() successfully completed......................................
2024-05-24 15:46:34,127:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:34,127:INFO:Creating metrics dataframe
2024-05-24 15:46:34,142:INFO:Initializing Dummy Regressor
2024-05-24 15:46:34,143:INFO:Total runtime is 0.19491579135258993 minutes
2024-05-24 15:46:34,148:INFO:SubProcess create_model() called ==================================
2024-05-24 15:46:34,149:INFO:Initializing create_model()
2024-05-24 15:46:34,149:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6ECB550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:34,149:INFO:Checking exceptions
2024-05-24 15:46:34,149:INFO:Importing libraries
2024-05-24 15:46:34,150:INFO:Copying training dataset
2024-05-24 15:46:34,156:INFO:Defining folds
2024-05-24 15:46:34,156:INFO:Declaring metric variables
2024-05-24 15:46:34,161:INFO:Importing untrained model
2024-05-24 15:46:34,167:INFO:Dummy Regressor Imported successfully
2024-05-24 15:46:34,176:INFO:Starting cross validation
2024-05-24 15:46:34,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:46:34,572:INFO:Calculating mean and std
2024-05-24 15:46:34,574:INFO:Creating metrics dataframe
2024-05-24 15:46:34,577:INFO:Uploading results into container
2024-05-24 15:46:34,578:INFO:Uploading model into container now
2024-05-24 15:46:34,578:INFO:_master_model_container: 18
2024-05-24 15:46:34,578:INFO:_display_container: 2
2024-05-24 15:46:34,579:INFO:DummyRegressor()
2024-05-24 15:46:34,579:INFO:create_model() successfully completed......................................
2024-05-24 15:46:34,761:INFO:SubProcess create_model() end ==================================
2024-05-24 15:46:34,761:INFO:Creating metrics dataframe
2024-05-24 15:46:34,783:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:46:34,796:INFO:Initializing create_model()
2024-05-24 15:46:34,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67DB9A0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:46:34,796:INFO:Checking exceptions
2024-05-24 15:46:34,799:INFO:Importing libraries
2024-05-24 15:46:34,799:INFO:Copying training dataset
2024-05-24 15:46:34,809:INFO:Defining folds
2024-05-24 15:46:34,809:INFO:Declaring metric variables
2024-05-24 15:46:34,809:INFO:Importing untrained model
2024-05-24 15:46:34,809:INFO:Declaring custom model
2024-05-24 15:46:34,811:INFO:Huber Regressor Imported successfully
2024-05-24 15:46:34,814:INFO:Cross validation set to False
2024-05-24 15:46:34,814:INFO:Fitting Model
2024-05-24 15:46:35,002:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:46:35,003:INFO:HuberRegressor()
2024-05-24 15:46:35,003:INFO:create_model() successfully completed......................................
2024-05-24 15:46:35,228:INFO:_master_model_container: 18
2024-05-24 15:46:35,228:INFO:_display_container: 2
2024-05-24 15:46:35,229:INFO:HuberRegressor()
2024-05-24 15:46:35,229:INFO:compare_models() successfully completed......................................
2024-05-24 15:47:13,467:INFO:PyCaret RegressionExperiment
2024-05-24 15:47:13,467:INFO:Logging name: reg-default-name
2024-05-24 15:47:13,467:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:47:13,467:INFO:version 3.3.2
2024-05-24 15:47:13,467:INFO:Initializing setup()
2024-05-24 15:47:13,467:INFO:self.USI: aa98
2024-05-24 15:47:13,467:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:47:13,467:INFO:Checking environment
2024-05-24 15:47:13,467:INFO:python_version: 3.10.14
2024-05-24 15:47:13,467:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:47:13,467:INFO:machine: AMD64
2024-05-24 15:47:13,467:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:47:13,467:INFO:Memory: svmem(total=16541802496, available=2163437568, percent=86.9, used=14378364928, free=2163437568)
2024-05-24 15:47:13,468:INFO:Physical Core: 6
2024-05-24 15:47:13,468:INFO:Logical Core: 12
2024-05-24 15:47:13,468:INFO:Checking libraries
2024-05-24 15:47:13,468:INFO:System:
2024-05-24 15:47:13,468:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:47:13,468:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:47:13,468:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:47:13,468:INFO:PyCaret required dependencies:
2024-05-24 15:47:13,468:INFO:                 pip: 24.0
2024-05-24 15:47:13,468:INFO:          setuptools: 69.5.1
2024-05-24 15:47:13,469:INFO:             pycaret: 3.3.2
2024-05-24 15:47:13,469:INFO:             IPython: 8.20.0
2024-05-24 15:47:13,469:INFO:          ipywidgets: 8.1.2
2024-05-24 15:47:13,469:INFO:                tqdm: 4.66.4
2024-05-24 15:47:13,469:INFO:               numpy: 1.26.4
2024-05-24 15:47:13,469:INFO:              pandas: 2.1.4
2024-05-24 15:47:13,469:INFO:              jinja2: 3.1.3
2024-05-24 15:47:13,469:INFO:               scipy: 1.11.4
2024-05-24 15:47:13,469:INFO:              joblib: 1.3.2
2024-05-24 15:47:13,469:INFO:             sklearn: 1.4.2
2024-05-24 15:47:13,469:INFO:                pyod: 1.1.3
2024-05-24 15:47:13,470:INFO:            imblearn: 0.12.2
2024-05-24 15:47:13,470:INFO:   category_encoders: 2.6.3
2024-05-24 15:47:13,470:INFO:            lightgbm: 4.3.0
2024-05-24 15:47:13,470:INFO:               numba: 0.59.1
2024-05-24 15:47:13,470:INFO:            requests: 2.32.2
2024-05-24 15:47:13,470:INFO:          matplotlib: 3.7.5
2024-05-24 15:47:13,470:INFO:          scikitplot: 0.3.7
2024-05-24 15:47:13,470:INFO:         yellowbrick: 1.5
2024-05-24 15:47:13,470:INFO:              plotly: 5.22.0
2024-05-24 15:47:13,470:INFO:    plotly-resampler: Not installed
2024-05-24 15:47:13,470:INFO:             kaleido: 0.2.1
2024-05-24 15:47:13,470:INFO:           schemdraw: 0.15
2024-05-24 15:47:13,471:INFO:         statsmodels: 0.14.2
2024-05-24 15:47:13,471:INFO:              sktime: 0.26.0
2024-05-24 15:47:13,471:INFO:               tbats: 1.1.3
2024-05-24 15:47:13,471:INFO:            pmdarima: 2.0.4
2024-05-24 15:47:13,471:INFO:              psutil: 5.9.0
2024-05-24 15:47:13,471:INFO:          markupsafe: 2.1.3
2024-05-24 15:47:13,471:INFO:             pickle5: Not installed
2024-05-24 15:47:13,471:INFO:         cloudpickle: 3.0.0
2024-05-24 15:47:13,471:INFO:         deprecation: 2.1.0
2024-05-24 15:47:13,471:INFO:              xxhash: 3.4.1
2024-05-24 15:47:13,471:INFO:           wurlitzer: Not installed
2024-05-24 15:47:13,471:INFO:PyCaret optional dependencies:
2024-05-24 15:47:13,471:INFO:                shap: Not installed
2024-05-24 15:47:13,471:INFO:           interpret: Not installed
2024-05-24 15:47:13,471:INFO:                umap: Not installed
2024-05-24 15:47:13,472:INFO:     ydata_profiling: Not installed
2024-05-24 15:47:13,472:INFO:  explainerdashboard: Not installed
2024-05-24 15:47:13,472:INFO:             autoviz: Not installed
2024-05-24 15:47:13,472:INFO:           fairlearn: Not installed
2024-05-24 15:47:13,472:INFO:          deepchecks: Not installed
2024-05-24 15:47:13,472:INFO:             xgboost: Not installed
2024-05-24 15:47:13,472:INFO:            catboost: Not installed
2024-05-24 15:47:13,472:INFO:              kmodes: Not installed
2024-05-24 15:47:13,472:INFO:             mlxtend: Not installed
2024-05-24 15:47:13,472:INFO:       statsforecast: Not installed
2024-05-24 15:47:13,472:INFO:        tune_sklearn: Not installed
2024-05-24 15:47:13,472:INFO:                 ray: Not installed
2024-05-24 15:47:13,472:INFO:            hyperopt: Not installed
2024-05-24 15:47:13,472:INFO:              optuna: Not installed
2024-05-24 15:47:13,472:INFO:               skopt: Not installed
2024-05-24 15:47:13,472:INFO:              mlflow: Not installed
2024-05-24 15:47:13,472:INFO:              gradio: Not installed
2024-05-24 15:47:13,472:INFO:             fastapi: Not installed
2024-05-24 15:47:13,472:INFO:             uvicorn: Not installed
2024-05-24 15:47:13,472:INFO:              m2cgen: Not installed
2024-05-24 15:47:13,472:INFO:           evidently: Not installed
2024-05-24 15:47:13,472:INFO:               fugue: Not installed
2024-05-24 15:47:13,472:INFO:           streamlit: Not installed
2024-05-24 15:47:13,472:INFO:             prophet: Not installed
2024-05-24 15:47:13,472:INFO:None
2024-05-24 15:47:13,473:INFO:Set up data.
2024-05-24 15:47:13,484:INFO:Set up folding strategy.
2024-05-24 15:47:13,484:INFO:Set up train/test split.
2024-05-24 15:47:13,493:INFO:Set up index.
2024-05-24 15:47:13,494:INFO:Assigning column types.
2024-05-24 15:47:13,501:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:47:13,501:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,508:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,513:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,584:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,632:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,636:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,750:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:47:13,755:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,760:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,822:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,874:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:13,993:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:13,994:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:47:14,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,071:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,128:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,192:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,241:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:47:14,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,481:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:47:14,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:47:14,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,715:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:47:14,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:14,951:INFO:Preparing preprocessing pipeline...
2024-05-24 15:47:14,951:INFO:Set up simple imputation.
2024-05-24 15:47:14,956:INFO:Set up encoding of ordinal features.
2024-05-24 15:47:14,962:INFO:Set up encoding of categorical features.
2024-05-24 15:47:14,962:INFO:Set up polynomial features.
2024-05-24 15:47:14,962:INFO:Set up removing multicollinearity.
2024-05-24 15:47:16,201:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:47:16,266:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:47:16,266:INFO:Creating final display dataframe.
2024-05-24 15:47:17,438:INFO:Setup _display_container:                     Description             Value
0                    Session id               422
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (205, 473)
5   Transformed train set shape        (143, 473)
6    Transformed test set shape         (62, 473)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              aa98
2024-05-24 15:47:17,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:17,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:17,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:17,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:47:17,695:INFO:setup() successfully completed in 4.24s...............
2024-05-24 15:47:17,734:INFO:Initializing compare_models()
2024-05-24 15:47:17,734:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:47:17,735:INFO:Checking exceptions
2024-05-24 15:47:17,738:INFO:Preparing display monitor
2024-05-24 15:47:17,773:INFO:Initializing Linear Regression
2024-05-24 15:47:17,773:INFO:Total runtime is 0.0 minutes
2024-05-24 15:47:17,782:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:17,782:INFO:Initializing create_model()
2024-05-24 15:47:17,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:17,782:INFO:Checking exceptions
2024-05-24 15:47:17,783:INFO:Importing libraries
2024-05-24 15:47:17,783:INFO:Copying training dataset
2024-05-24 15:47:17,791:INFO:Defining folds
2024-05-24 15:47:17,792:INFO:Declaring metric variables
2024-05-24 15:47:17,798:INFO:Importing untrained model
2024-05-24 15:47:17,804:INFO:Linear Regression Imported successfully
2024-05-24 15:47:17,813:INFO:Starting cross validation
2024-05-24 15:47:17,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:19,863:INFO:Calculating mean and std
2024-05-24 15:47:19,865:INFO:Creating metrics dataframe
2024-05-24 15:47:19,868:INFO:Uploading results into container
2024-05-24 15:47:19,869:INFO:Uploading model into container now
2024-05-24 15:47:19,869:INFO:_master_model_container: 1
2024-05-24 15:47:19,869:INFO:_display_container: 2
2024-05-24 15:47:19,870:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:47:19,870:INFO:create_model() successfully completed......................................
2024-05-24 15:47:20,046:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:20,048:INFO:Creating metrics dataframe
2024-05-24 15:47:20,055:INFO:Initializing Lasso Regression
2024-05-24 15:47:20,055:INFO:Total runtime is 0.03802363475163777 minutes
2024-05-24 15:47:20,059:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:20,060:INFO:Initializing create_model()
2024-05-24 15:47:20,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:20,060:INFO:Checking exceptions
2024-05-24 15:47:20,060:INFO:Importing libraries
2024-05-24 15:47:20,060:INFO:Copying training dataset
2024-05-24 15:47:20,067:INFO:Defining folds
2024-05-24 15:47:20,068:INFO:Declaring metric variables
2024-05-24 15:47:20,072:INFO:Importing untrained model
2024-05-24 15:47:20,076:INFO:Lasso Regression Imported successfully
2024-05-24 15:47:20,085:INFO:Starting cross validation
2024-05-24 15:47:20,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:21,944:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 6.858e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:21,971:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e+07, tolerance: 6.563e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,015:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.549e+07, tolerance: 7.400e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,032:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+07, tolerance: 7.207e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,062:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e+07, tolerance: 7.887e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,088:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+07, tolerance: 6.977e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,089:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.361e+07, tolerance: 8.157e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,116:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e+07, tolerance: 7.650e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,116:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+07, tolerance: 7.992e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e+07, tolerance: 8.098e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:22,206:INFO:Calculating mean and std
2024-05-24 15:47:22,208:INFO:Creating metrics dataframe
2024-05-24 15:47:22,212:INFO:Uploading results into container
2024-05-24 15:47:22,212:INFO:Uploading model into container now
2024-05-24 15:47:22,213:INFO:_master_model_container: 2
2024-05-24 15:47:22,213:INFO:_display_container: 2
2024-05-24 15:47:22,214:INFO:Lasso(random_state=422)
2024-05-24 15:47:22,214:INFO:create_model() successfully completed......................................
2024-05-24 15:47:22,390:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:22,390:INFO:Creating metrics dataframe
2024-05-24 15:47:22,399:INFO:Initializing Ridge Regression
2024-05-24 15:47:22,399:INFO:Total runtime is 0.07708855470021565 minutes
2024-05-24 15:47:22,403:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:22,404:INFO:Initializing create_model()
2024-05-24 15:47:22,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:22,404:INFO:Checking exceptions
2024-05-24 15:47:22,405:INFO:Importing libraries
2024-05-24 15:47:22,405:INFO:Copying training dataset
2024-05-24 15:47:22,411:INFO:Defining folds
2024-05-24 15:47:22,412:INFO:Declaring metric variables
2024-05-24 15:47:22,417:INFO:Importing untrained model
2024-05-24 15:47:22,422:INFO:Ridge Regression Imported successfully
2024-05-24 15:47:22,431:INFO:Starting cross validation
2024-05-24 15:47:22,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:24,073:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,184:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,225:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,226:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,232:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,263:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,268:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,319:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:47:24,409:INFO:Calculating mean and std
2024-05-24 15:47:24,412:INFO:Creating metrics dataframe
2024-05-24 15:47:24,414:INFO:Uploading results into container
2024-05-24 15:47:24,414:INFO:Uploading model into container now
2024-05-24 15:47:24,415:INFO:_master_model_container: 3
2024-05-24 15:47:24,415:INFO:_display_container: 2
2024-05-24 15:47:24,415:INFO:Ridge(random_state=422)
2024-05-24 15:47:24,415:INFO:create_model() successfully completed......................................
2024-05-24 15:47:24,571:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:24,571:INFO:Creating metrics dataframe
2024-05-24 15:47:24,580:INFO:Initializing Elastic Net
2024-05-24 15:47:24,580:INFO:Total runtime is 0.11344375212987264 minutes
2024-05-24 15:47:24,585:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:24,585:INFO:Initializing create_model()
2024-05-24 15:47:24,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:24,585:INFO:Checking exceptions
2024-05-24 15:47:24,586:INFO:Importing libraries
2024-05-24 15:47:24,586:INFO:Copying training dataset
2024-05-24 15:47:24,592:INFO:Defining folds
2024-05-24 15:47:24,592:INFO:Declaring metric variables
2024-05-24 15:47:24,596:INFO:Importing untrained model
2024-05-24 15:47:24,602:INFO:Elastic Net Imported successfully
2024-05-24 15:47:24,610:INFO:Starting cross validation
2024-05-24 15:47:24,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:26,367:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.581e+07, tolerance: 6.858e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,367:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.897e+07, tolerance: 6.563e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,402:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.531e+07, tolerance: 7.207e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,431:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.543e+07, tolerance: 7.887e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,445:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.463e+07, tolerance: 6.977e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,451:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.402e+07, tolerance: 7.400e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,457:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e+07, tolerance: 7.992e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,467:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e+07, tolerance: 7.650e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,476:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.979e+07, tolerance: 8.157e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,490:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.870e+07, tolerance: 8.098e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:47:26,577:INFO:Calculating mean and std
2024-05-24 15:47:26,579:INFO:Creating metrics dataframe
2024-05-24 15:47:26,581:INFO:Uploading results into container
2024-05-24 15:47:26,582:INFO:Uploading model into container now
2024-05-24 15:47:26,583:INFO:_master_model_container: 4
2024-05-24 15:47:26,583:INFO:_display_container: 2
2024-05-24 15:47:26,583:INFO:ElasticNet(random_state=422)
2024-05-24 15:47:26,584:INFO:create_model() successfully completed......................................
2024-05-24 15:47:26,755:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:26,755:INFO:Creating metrics dataframe
2024-05-24 15:47:26,762:INFO:Initializing Least Angle Regression
2024-05-24 15:47:26,762:INFO:Total runtime is 0.14980880419413248 minutes
2024-05-24 15:47:26,766:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:26,767:INFO:Initializing create_model()
2024-05-24 15:47:26,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:26,767:INFO:Checking exceptions
2024-05-24 15:47:26,768:INFO:Importing libraries
2024-05-24 15:47:26,768:INFO:Copying training dataset
2024-05-24 15:47:26,773:INFO:Defining folds
2024-05-24 15:47:26,773:INFO:Declaring metric variables
2024-05-24 15:47:26,777:INFO:Importing untrained model
2024-05-24 15:47:26,782:INFO:Least Angle Regression Imported successfully
2024-05-24 15:47:26,790:INFO:Starting cross validation
2024-05-24 15:47:26,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:28,470:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=3.815e+06, with an active set of 109 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:47:28,506:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=1.945e+05, with an active set of 112 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:47:28,650:INFO:Calculating mean and std
2024-05-24 15:47:28,652:INFO:Creating metrics dataframe
2024-05-24 15:47:28,654:INFO:Uploading results into container
2024-05-24 15:47:28,654:INFO:Uploading model into container now
2024-05-24 15:47:28,655:INFO:_master_model_container: 5
2024-05-24 15:47:28,655:INFO:_display_container: 2
2024-05-24 15:47:28,655:INFO:Lars(random_state=422)
2024-05-24 15:47:28,655:INFO:create_model() successfully completed......................................
2024-05-24 15:47:28,813:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:28,813:INFO:Creating metrics dataframe
2024-05-24 15:47:28,821:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:47:28,823:INFO:Total runtime is 0.18415402571360268 minutes
2024-05-24 15:47:28,826:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:28,826:INFO:Initializing create_model()
2024-05-24 15:47:28,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:28,826:INFO:Checking exceptions
2024-05-24 15:47:28,826:INFO:Importing libraries
2024-05-24 15:47:28,826:INFO:Copying training dataset
2024-05-24 15:47:28,834:INFO:Defining folds
2024-05-24 15:47:28,834:INFO:Declaring metric variables
2024-05-24 15:47:28,838:INFO:Importing untrained model
2024-05-24 15:47:28,842:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:47:28,851:INFO:Starting cross validation
2024-05-24 15:47:28,861:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:30,829:INFO:Calculating mean and std
2024-05-24 15:47:30,831:INFO:Creating metrics dataframe
2024-05-24 15:47:30,833:INFO:Uploading results into container
2024-05-24 15:47:30,834:INFO:Uploading model into container now
2024-05-24 15:47:30,834:INFO:_master_model_container: 6
2024-05-24 15:47:30,835:INFO:_display_container: 2
2024-05-24 15:47:30,836:INFO:LassoLars(random_state=422)
2024-05-24 15:47:30,836:INFO:create_model() successfully completed......................................
2024-05-24 15:47:30,996:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:30,997:INFO:Creating metrics dataframe
2024-05-24 15:47:31,006:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:47:31,006:INFO:Total runtime is 0.22054743766784665 minutes
2024-05-24 15:47:31,012:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:31,012:INFO:Initializing create_model()
2024-05-24 15:47:31,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:31,013:INFO:Checking exceptions
2024-05-24 15:47:31,013:INFO:Importing libraries
2024-05-24 15:47:31,013:INFO:Copying training dataset
2024-05-24 15:47:31,021:INFO:Defining folds
2024-05-24 15:47:31,021:INFO:Declaring metric variables
2024-05-24 15:47:31,025:INFO:Importing untrained model
2024-05-24 15:47:31,030:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:47:31,040:INFO:Starting cross validation
2024-05-24 15:47:31,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:33,111:INFO:Calculating mean and std
2024-05-24 15:47:33,112:INFO:Creating metrics dataframe
2024-05-24 15:47:33,116:INFO:Uploading results into container
2024-05-24 15:47:33,117:INFO:Uploading model into container now
2024-05-24 15:47:33,117:INFO:_master_model_container: 7
2024-05-24 15:47:33,117:INFO:_display_container: 2
2024-05-24 15:47:33,117:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:47:33,117:INFO:create_model() successfully completed......................................
2024-05-24 15:47:33,280:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:33,280:INFO:Creating metrics dataframe
2024-05-24 15:47:33,290:INFO:Initializing Bayesian Ridge
2024-05-24 15:47:33,290:INFO:Total runtime is 0.25861623287200924 minutes
2024-05-24 15:47:33,294:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:33,294:INFO:Initializing create_model()
2024-05-24 15:47:33,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:33,294:INFO:Checking exceptions
2024-05-24 15:47:33,295:INFO:Importing libraries
2024-05-24 15:47:33,295:INFO:Copying training dataset
2024-05-24 15:47:33,302:INFO:Defining folds
2024-05-24 15:47:33,302:INFO:Declaring metric variables
2024-05-24 15:47:33,307:INFO:Importing untrained model
2024-05-24 15:47:33,311:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:47:33,323:INFO:Starting cross validation
2024-05-24 15:47:33,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:35,281:INFO:Calculating mean and std
2024-05-24 15:47:35,283:INFO:Creating metrics dataframe
2024-05-24 15:47:35,285:INFO:Uploading results into container
2024-05-24 15:47:35,285:INFO:Uploading model into container now
2024-05-24 15:47:35,287:INFO:_master_model_container: 8
2024-05-24 15:47:35,287:INFO:_display_container: 2
2024-05-24 15:47:35,288:INFO:BayesianRidge()
2024-05-24 15:47:35,288:INFO:create_model() successfully completed......................................
2024-05-24 15:47:35,450:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:35,451:INFO:Creating metrics dataframe
2024-05-24 15:47:35,461:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:47:35,462:INFO:Total runtime is 0.294802717367808 minutes
2024-05-24 15:47:35,466:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:35,467:INFO:Initializing create_model()
2024-05-24 15:47:35,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:35,467:INFO:Checking exceptions
2024-05-24 15:47:35,467:INFO:Importing libraries
2024-05-24 15:47:35,467:INFO:Copying training dataset
2024-05-24 15:47:35,473:INFO:Defining folds
2024-05-24 15:47:35,473:INFO:Declaring metric variables
2024-05-24 15:47:35,477:INFO:Importing untrained model
2024-05-24 15:47:35,482:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:47:35,491:INFO:Starting cross validation
2024-05-24 15:47:35,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:37,377:INFO:Calculating mean and std
2024-05-24 15:47:37,380:INFO:Creating metrics dataframe
2024-05-24 15:47:37,383:INFO:Uploading results into container
2024-05-24 15:47:37,383:INFO:Uploading model into container now
2024-05-24 15:47:37,384:INFO:_master_model_container: 9
2024-05-24 15:47:37,384:INFO:_display_container: 2
2024-05-24 15:47:37,384:INFO:PassiveAggressiveRegressor(random_state=422)
2024-05-24 15:47:37,384:INFO:create_model() successfully completed......................................
2024-05-24 15:47:37,535:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:37,535:INFO:Creating metrics dataframe
2024-05-24 15:47:37,542:INFO:Initializing Huber Regressor
2024-05-24 15:47:37,543:INFO:Total runtime is 0.32948937813440954 minutes
2024-05-24 15:47:37,545:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:37,546:INFO:Initializing create_model()
2024-05-24 15:47:37,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:37,546:INFO:Checking exceptions
2024-05-24 15:47:37,546:INFO:Importing libraries
2024-05-24 15:47:37,546:INFO:Copying training dataset
2024-05-24 15:47:37,554:INFO:Defining folds
2024-05-24 15:47:37,554:INFO:Declaring metric variables
2024-05-24 15:47:37,560:INFO:Importing untrained model
2024-05-24 15:47:37,563:INFO:Huber Regressor Imported successfully
2024-05-24 15:47:37,572:INFO:Starting cross validation
2024-05-24 15:47:37,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:39,362:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,542:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,558:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,589:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,608:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:47:39,789:INFO:Calculating mean and std
2024-05-24 15:47:39,791:INFO:Creating metrics dataframe
2024-05-24 15:47:39,793:INFO:Uploading results into container
2024-05-24 15:47:39,794:INFO:Uploading model into container now
2024-05-24 15:47:39,794:INFO:_master_model_container: 10
2024-05-24 15:47:39,794:INFO:_display_container: 2
2024-05-24 15:47:39,795:INFO:HuberRegressor()
2024-05-24 15:47:39,795:INFO:create_model() successfully completed......................................
2024-05-24 15:47:39,996:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:39,996:INFO:Creating metrics dataframe
2024-05-24 15:47:40,006:INFO:Initializing K Neighbors Regressor
2024-05-24 15:47:40,006:INFO:Total runtime is 0.3705499172210693 minutes
2024-05-24 15:47:40,011:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:40,011:INFO:Initializing create_model()
2024-05-24 15:47:40,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:40,012:INFO:Checking exceptions
2024-05-24 15:47:40,012:INFO:Importing libraries
2024-05-24 15:47:40,012:INFO:Copying training dataset
2024-05-24 15:47:40,021:INFO:Defining folds
2024-05-24 15:47:40,021:INFO:Declaring metric variables
2024-05-24 15:47:40,026:INFO:Importing untrained model
2024-05-24 15:47:40,032:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:47:40,043:INFO:Starting cross validation
2024-05-24 15:47:40,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:42,297:INFO:Calculating mean and std
2024-05-24 15:47:42,298:INFO:Creating metrics dataframe
2024-05-24 15:47:42,302:INFO:Uploading results into container
2024-05-24 15:47:42,302:INFO:Uploading model into container now
2024-05-24 15:47:42,303:INFO:_master_model_container: 11
2024-05-24 15:47:42,303:INFO:_display_container: 2
2024-05-24 15:47:42,303:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:47:42,303:INFO:create_model() successfully completed......................................
2024-05-24 15:47:42,519:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:42,520:INFO:Creating metrics dataframe
2024-05-24 15:47:42,539:INFO:Initializing Decision Tree Regressor
2024-05-24 15:47:42,539:INFO:Total runtime is 0.4127607623736063 minutes
2024-05-24 15:47:42,545:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:42,546:INFO:Initializing create_model()
2024-05-24 15:47:42,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:42,546:INFO:Checking exceptions
2024-05-24 15:47:42,547:INFO:Importing libraries
2024-05-24 15:47:42,547:INFO:Copying training dataset
2024-05-24 15:47:42,557:INFO:Defining folds
2024-05-24 15:47:42,558:INFO:Declaring metric variables
2024-05-24 15:47:42,564:INFO:Importing untrained model
2024-05-24 15:47:42,570:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:47:42,582:INFO:Starting cross validation
2024-05-24 15:47:42,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:44,539:INFO:Calculating mean and std
2024-05-24 15:47:44,540:INFO:Creating metrics dataframe
2024-05-24 15:47:44,542:INFO:Uploading results into container
2024-05-24 15:47:44,543:INFO:Uploading model into container now
2024-05-24 15:47:44,544:INFO:_master_model_container: 12
2024-05-24 15:47:44,544:INFO:_display_container: 2
2024-05-24 15:47:44,544:INFO:DecisionTreeRegressor(random_state=422)
2024-05-24 15:47:44,545:INFO:create_model() successfully completed......................................
2024-05-24 15:47:44,729:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:44,730:INFO:Creating metrics dataframe
2024-05-24 15:47:44,741:INFO:Initializing Random Forest Regressor
2024-05-24 15:47:44,741:INFO:Total runtime is 0.44946341514587396 minutes
2024-05-24 15:47:44,746:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:44,746:INFO:Initializing create_model()
2024-05-24 15:47:44,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:44,746:INFO:Checking exceptions
2024-05-24 15:47:44,746:INFO:Importing libraries
2024-05-24 15:47:44,747:INFO:Copying training dataset
2024-05-24 15:47:44,755:INFO:Defining folds
2024-05-24 15:47:44,755:INFO:Declaring metric variables
2024-05-24 15:47:44,759:INFO:Importing untrained model
2024-05-24 15:47:44,764:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:47:44,773:INFO:Starting cross validation
2024-05-24 15:47:44,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:47,547:INFO:Calculating mean and std
2024-05-24 15:47:47,548:INFO:Creating metrics dataframe
2024-05-24 15:47:47,551:INFO:Uploading results into container
2024-05-24 15:47:47,552:INFO:Uploading model into container now
2024-05-24 15:47:47,553:INFO:_master_model_container: 13
2024-05-24 15:47:47,553:INFO:_display_container: 2
2024-05-24 15:47:47,553:INFO:RandomForestRegressor(n_jobs=-1, random_state=422)
2024-05-24 15:47:47,553:INFO:create_model() successfully completed......................................
2024-05-24 15:47:47,720:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:47,721:INFO:Creating metrics dataframe
2024-05-24 15:47:47,731:INFO:Initializing Extra Trees Regressor
2024-05-24 15:47:47,731:INFO:Total runtime is 0.49929755131403597 minutes
2024-05-24 15:47:47,736:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:47,736:INFO:Initializing create_model()
2024-05-24 15:47:47,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:47,736:INFO:Checking exceptions
2024-05-24 15:47:47,737:INFO:Importing libraries
2024-05-24 15:47:47,737:INFO:Copying training dataset
2024-05-24 15:47:47,743:INFO:Defining folds
2024-05-24 15:47:47,743:INFO:Declaring metric variables
2024-05-24 15:47:47,749:INFO:Importing untrained model
2024-05-24 15:47:47,753:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:47:47,763:INFO:Starting cross validation
2024-05-24 15:47:47,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:50,110:INFO:Calculating mean and std
2024-05-24 15:47:50,112:INFO:Creating metrics dataframe
2024-05-24 15:47:50,114:INFO:Uploading results into container
2024-05-24 15:47:50,115:INFO:Uploading model into container now
2024-05-24 15:47:50,115:INFO:_master_model_container: 14
2024-05-24 15:47:50,115:INFO:_display_container: 2
2024-05-24 15:47:50,117:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=422)
2024-05-24 15:47:50,117:INFO:create_model() successfully completed......................................
2024-05-24 15:47:50,283:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:50,284:INFO:Creating metrics dataframe
2024-05-24 15:47:50,296:INFO:Initializing AdaBoost Regressor
2024-05-24 15:47:50,297:INFO:Total runtime is 0.5420573552449544 minutes
2024-05-24 15:47:50,301:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:50,301:INFO:Initializing create_model()
2024-05-24 15:47:50,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:50,301:INFO:Checking exceptions
2024-05-24 15:47:50,301:INFO:Importing libraries
2024-05-24 15:47:50,301:INFO:Copying training dataset
2024-05-24 15:47:50,308:INFO:Defining folds
2024-05-24 15:47:50,308:INFO:Declaring metric variables
2024-05-24 15:47:50,312:INFO:Importing untrained model
2024-05-24 15:47:50,316:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:47:50,325:INFO:Starting cross validation
2024-05-24 15:47:50,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:52,328:INFO:Calculating mean and std
2024-05-24 15:47:52,329:INFO:Creating metrics dataframe
2024-05-24 15:47:52,331:INFO:Uploading results into container
2024-05-24 15:47:52,332:INFO:Uploading model into container now
2024-05-24 15:47:52,332:INFO:_master_model_container: 15
2024-05-24 15:47:52,332:INFO:_display_container: 2
2024-05-24 15:47:52,333:INFO:AdaBoostRegressor(random_state=422)
2024-05-24 15:47:52,333:INFO:create_model() successfully completed......................................
2024-05-24 15:47:52,498:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:52,498:INFO:Creating metrics dataframe
2024-05-24 15:47:52,514:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:47:52,514:INFO:Total runtime is 0.5790171066919961 minutes
2024-05-24 15:47:52,519:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:52,520:INFO:Initializing create_model()
2024-05-24 15:47:52,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:52,520:INFO:Checking exceptions
2024-05-24 15:47:52,520:INFO:Importing libraries
2024-05-24 15:47:52,520:INFO:Copying training dataset
2024-05-24 15:47:52,526:INFO:Defining folds
2024-05-24 15:47:52,526:INFO:Declaring metric variables
2024-05-24 15:47:52,531:INFO:Importing untrained model
2024-05-24 15:47:52,537:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:47:52,546:INFO:Starting cross validation
2024-05-24 15:47:52,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:54,705:INFO:Calculating mean and std
2024-05-24 15:47:54,706:INFO:Creating metrics dataframe
2024-05-24 15:47:54,709:INFO:Uploading results into container
2024-05-24 15:47:54,709:INFO:Uploading model into container now
2024-05-24 15:47:54,710:INFO:_master_model_container: 16
2024-05-24 15:47:54,710:INFO:_display_container: 2
2024-05-24 15:47:54,710:INFO:GradientBoostingRegressor(random_state=422)
2024-05-24 15:47:54,711:INFO:create_model() successfully completed......................................
2024-05-24 15:47:54,879:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:54,879:INFO:Creating metrics dataframe
2024-05-24 15:47:54,893:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:47:54,893:INFO:Total runtime is 0.6186688105265298 minutes
2024-05-24 15:47:54,898:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:54,898:INFO:Initializing create_model()
2024-05-24 15:47:54,899:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:54,899:INFO:Checking exceptions
2024-05-24 15:47:54,899:INFO:Importing libraries
2024-05-24 15:47:54,899:INFO:Copying training dataset
2024-05-24 15:47:54,906:INFO:Defining folds
2024-05-24 15:47:54,906:INFO:Declaring metric variables
2024-05-24 15:47:54,910:INFO:Importing untrained model
2024-05-24 15:47:54,915:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:47:54,924:INFO:Starting cross validation
2024-05-24 15:47:54,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:57,074:INFO:Calculating mean and std
2024-05-24 15:47:57,076:INFO:Creating metrics dataframe
2024-05-24 15:47:57,079:INFO:Uploading results into container
2024-05-24 15:47:57,079:INFO:Uploading model into container now
2024-05-24 15:47:57,080:INFO:_master_model_container: 17
2024-05-24 15:47:57,080:INFO:_display_container: 2
2024-05-24 15:47:57,081:INFO:LGBMRegressor(n_jobs=-1, random_state=422)
2024-05-24 15:47:57,081:INFO:create_model() successfully completed......................................
2024-05-24 15:47:57,279:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:57,280:INFO:Creating metrics dataframe
2024-05-24 15:47:57,291:INFO:Initializing Dummy Regressor
2024-05-24 15:47:57,292:INFO:Total runtime is 0.6586373805999755 minutes
2024-05-24 15:47:57,296:INFO:SubProcess create_model() called ==================================
2024-05-24 15:47:57,297:INFO:Initializing create_model()
2024-05-24 15:47:57,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C00965F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:57,297:INFO:Checking exceptions
2024-05-24 15:47:57,298:INFO:Importing libraries
2024-05-24 15:47:57,298:INFO:Copying training dataset
2024-05-24 15:47:57,303:INFO:Defining folds
2024-05-24 15:47:57,304:INFO:Declaring metric variables
2024-05-24 15:47:57,308:INFO:Importing untrained model
2024-05-24 15:47:57,313:INFO:Dummy Regressor Imported successfully
2024-05-24 15:47:57,322:INFO:Starting cross validation
2024-05-24 15:47:57,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:47:59,228:INFO:Calculating mean and std
2024-05-24 15:47:59,230:INFO:Creating metrics dataframe
2024-05-24 15:47:59,232:INFO:Uploading results into container
2024-05-24 15:47:59,232:INFO:Uploading model into container now
2024-05-24 15:47:59,233:INFO:_master_model_container: 18
2024-05-24 15:47:59,233:INFO:_display_container: 2
2024-05-24 15:47:59,233:INFO:DummyRegressor()
2024-05-24 15:47:59,233:INFO:create_model() successfully completed......................................
2024-05-24 15:47:59,386:INFO:SubProcess create_model() end ==================================
2024-05-24 15:47:59,386:INFO:Creating metrics dataframe
2024-05-24 15:47:59,398:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:47:59,406:INFO:Initializing create_model()
2024-05-24 15:47:59,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6A80220>, estimator=Lasso(random_state=422), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:47:59,407:INFO:Checking exceptions
2024-05-24 15:47:59,408:INFO:Importing libraries
2024-05-24 15:47:59,408:INFO:Copying training dataset
2024-05-24 15:47:59,416:INFO:Defining folds
2024-05-24 15:47:59,416:INFO:Declaring metric variables
2024-05-24 15:47:59,416:INFO:Importing untrained model
2024-05-24 15:47:59,417:INFO:Declaring custom model
2024-05-24 15:47:59,417:INFO:Lasso Regression Imported successfully
2024-05-24 15:47:59,430:INFO:Cross validation set to False
2024-05-24 15:47:59,430:INFO:Fitting Model
2024-05-24 15:48:00,397:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+07, tolerance: 8.313e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:00,397:INFO:Lasso(random_state=422)
2024-05-24 15:48:00,397:INFO:create_model() successfully completed......................................
2024-05-24 15:48:00,584:INFO:_master_model_container: 18
2024-05-24 15:48:00,584:INFO:_display_container: 2
2024-05-24 15:48:00,584:INFO:Lasso(random_state=422)
2024-05-24 15:48:00,584:INFO:compare_models() successfully completed......................................
2024-05-24 15:48:37,929:INFO:PyCaret RegressionExperiment
2024-05-24 15:48:37,929:INFO:Logging name: reg-default-name
2024-05-24 15:48:37,929:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:48:37,929:INFO:version 3.3.2
2024-05-24 15:48:37,929:INFO:Initializing setup()
2024-05-24 15:48:37,929:INFO:self.USI: d118
2024-05-24 15:48:37,929:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:48:37,929:INFO:Checking environment
2024-05-24 15:48:37,929:INFO:python_version: 3.10.14
2024-05-24 15:48:37,929:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:48:37,929:INFO:machine: AMD64
2024-05-24 15:48:37,929:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:48:37,930:INFO:Memory: svmem(total=16541802496, available=2048671744, percent=87.6, used=14493130752, free=2048671744)
2024-05-24 15:48:37,930:INFO:Physical Core: 6
2024-05-24 15:48:37,930:INFO:Logical Core: 12
2024-05-24 15:48:37,930:INFO:Checking libraries
2024-05-24 15:48:37,930:INFO:System:
2024-05-24 15:48:37,930:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:48:37,930:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:48:37,930:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:48:37,930:INFO:PyCaret required dependencies:
2024-05-24 15:48:37,930:INFO:                 pip: 24.0
2024-05-24 15:48:37,930:INFO:          setuptools: 69.5.1
2024-05-24 15:48:37,930:INFO:             pycaret: 3.3.2
2024-05-24 15:48:37,930:INFO:             IPython: 8.20.0
2024-05-24 15:48:37,930:INFO:          ipywidgets: 8.1.2
2024-05-24 15:48:37,930:INFO:                tqdm: 4.66.4
2024-05-24 15:48:37,930:INFO:               numpy: 1.26.4
2024-05-24 15:48:37,930:INFO:              pandas: 2.1.4
2024-05-24 15:48:37,931:INFO:              jinja2: 3.1.3
2024-05-24 15:48:37,931:INFO:               scipy: 1.11.4
2024-05-24 15:48:37,931:INFO:              joblib: 1.3.2
2024-05-24 15:48:37,931:INFO:             sklearn: 1.4.2
2024-05-24 15:48:37,931:INFO:                pyod: 1.1.3
2024-05-24 15:48:37,931:INFO:            imblearn: 0.12.2
2024-05-24 15:48:37,931:INFO:   category_encoders: 2.6.3
2024-05-24 15:48:37,931:INFO:            lightgbm: 4.3.0
2024-05-24 15:48:37,931:INFO:               numba: 0.59.1
2024-05-24 15:48:37,931:INFO:            requests: 2.32.2
2024-05-24 15:48:37,931:INFO:          matplotlib: 3.7.5
2024-05-24 15:48:37,931:INFO:          scikitplot: 0.3.7
2024-05-24 15:48:37,931:INFO:         yellowbrick: 1.5
2024-05-24 15:48:37,931:INFO:              plotly: 5.22.0
2024-05-24 15:48:37,931:INFO:    plotly-resampler: Not installed
2024-05-24 15:48:37,931:INFO:             kaleido: 0.2.1
2024-05-24 15:48:37,931:INFO:           schemdraw: 0.15
2024-05-24 15:48:37,931:INFO:         statsmodels: 0.14.2
2024-05-24 15:48:37,931:INFO:              sktime: 0.26.0
2024-05-24 15:48:37,931:INFO:               tbats: 1.1.3
2024-05-24 15:48:37,931:INFO:            pmdarima: 2.0.4
2024-05-24 15:48:37,931:INFO:              psutil: 5.9.0
2024-05-24 15:48:37,931:INFO:          markupsafe: 2.1.3
2024-05-24 15:48:37,931:INFO:             pickle5: Not installed
2024-05-24 15:48:37,931:INFO:         cloudpickle: 3.0.0
2024-05-24 15:48:37,931:INFO:         deprecation: 2.1.0
2024-05-24 15:48:37,932:INFO:              xxhash: 3.4.1
2024-05-24 15:48:37,932:INFO:           wurlitzer: Not installed
2024-05-24 15:48:37,932:INFO:PyCaret optional dependencies:
2024-05-24 15:48:37,932:INFO:                shap: Not installed
2024-05-24 15:48:37,932:INFO:           interpret: Not installed
2024-05-24 15:48:37,932:INFO:                umap: Not installed
2024-05-24 15:48:37,932:INFO:     ydata_profiling: Not installed
2024-05-24 15:48:37,932:INFO:  explainerdashboard: Not installed
2024-05-24 15:48:37,932:INFO:             autoviz: Not installed
2024-05-24 15:48:37,932:INFO:           fairlearn: Not installed
2024-05-24 15:48:37,932:INFO:          deepchecks: Not installed
2024-05-24 15:48:37,932:INFO:             xgboost: Not installed
2024-05-24 15:48:37,932:INFO:            catboost: Not installed
2024-05-24 15:48:37,932:INFO:              kmodes: Not installed
2024-05-24 15:48:37,932:INFO:             mlxtend: Not installed
2024-05-24 15:48:37,932:INFO:       statsforecast: Not installed
2024-05-24 15:48:37,932:INFO:        tune_sklearn: Not installed
2024-05-24 15:48:37,932:INFO:                 ray: Not installed
2024-05-24 15:48:37,932:INFO:            hyperopt: Not installed
2024-05-24 15:48:37,932:INFO:              optuna: Not installed
2024-05-24 15:48:37,932:INFO:               skopt: Not installed
2024-05-24 15:48:37,932:INFO:              mlflow: Not installed
2024-05-24 15:48:37,932:INFO:              gradio: Not installed
2024-05-24 15:48:37,932:INFO:             fastapi: Not installed
2024-05-24 15:48:37,933:INFO:             uvicorn: Not installed
2024-05-24 15:48:37,933:INFO:              m2cgen: Not installed
2024-05-24 15:48:37,933:INFO:           evidently: Not installed
2024-05-24 15:48:37,933:INFO:               fugue: Not installed
2024-05-24 15:48:37,933:INFO:           streamlit: Not installed
2024-05-24 15:48:37,933:INFO:             prophet: Not installed
2024-05-24 15:48:37,933:INFO:None
2024-05-24 15:48:37,933:INFO:Set up data.
2024-05-24 15:48:37,944:INFO:Set up folding strategy.
2024-05-24 15:48:37,944:INFO:Set up train/test split.
2024-05-24 15:48:37,952:INFO:Set up index.
2024-05-24 15:48:37,952:INFO:Assigning column types.
2024-05-24 15:48:37,957:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:48:37,957:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:48:37,962:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:48:37,967:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,078:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,083:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,087:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,196:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:48:38,201:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,319:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,324:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,433:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:48:38,442:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,564:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,677:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:48:38,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:48:38,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:38,935:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:48:39,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:39,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,128:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:48:39,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,176:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:48:39,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:39,417:INFO:Preparing preprocessing pipeline...
2024-05-24 15:48:39,417:INFO:Set up simple imputation.
2024-05-24 15:48:39,422:INFO:Set up encoding of ordinal features.
2024-05-24 15:48:39,428:INFO:Set up encoding of categorical features.
2024-05-24 15:48:39,428:INFO:Set up polynomial features.
2024-05-24 15:48:39,428:INFO:Set up removing multicollinearity.
2024-05-24 15:48:40,599:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:48:40,665:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:48:40,665:INFO:Creating final display dataframe.
2024-05-24 15:48:41,779:INFO:Setup _display_container:                     Description             Value
0                    Session id              6616
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (205, 437)
5   Transformed train set shape        (143, 437)
6    Transformed test set shape         (62, 437)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Fold Generator             KFold
20                  Fold Number                 3
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              d118
2024-05-24 15:48:41,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:41,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:42,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:42,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:48:42,047:INFO:setup() successfully completed in 4.13s...............
2024-05-24 15:48:42,085:INFO:Initializing compare_models()
2024-05-24 15:48:42,085:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:48:42,086:INFO:Checking exceptions
2024-05-24 15:48:42,091:INFO:Preparing display monitor
2024-05-24 15:48:42,120:INFO:Initializing Linear Regression
2024-05-24 15:48:42,120:INFO:Total runtime is 0.0 minutes
2024-05-24 15:48:42,124:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:42,124:INFO:Initializing create_model()
2024-05-24 15:48:42,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=lr, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:42,124:INFO:Checking exceptions
2024-05-24 15:48:42,124:INFO:Importing libraries
2024-05-24 15:48:42,125:INFO:Copying training dataset
2024-05-24 15:48:42,132:INFO:Defining folds
2024-05-24 15:48:42,132:INFO:Declaring metric variables
2024-05-24 15:48:42,138:INFO:Importing untrained model
2024-05-24 15:48:42,144:INFO:Linear Regression Imported successfully
2024-05-24 15:48:42,153:INFO:Starting cross validation
2024-05-24 15:48:42,168:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:43,153:INFO:Calculating mean and std
2024-05-24 15:48:43,154:INFO:Creating metrics dataframe
2024-05-24 15:48:43,157:INFO:Uploading results into container
2024-05-24 15:48:43,158:INFO:Uploading model into container now
2024-05-24 15:48:43,158:INFO:_master_model_container: 1
2024-05-24 15:48:43,158:INFO:_display_container: 2
2024-05-24 15:48:43,159:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:48:43,159:INFO:create_model() successfully completed......................................
2024-05-24 15:48:43,370:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:43,370:INFO:Creating metrics dataframe
2024-05-24 15:48:43,380:INFO:Initializing Lasso Regression
2024-05-24 15:48:43,380:INFO:Total runtime is 0.02100522518157959 minutes
2024-05-24 15:48:43,384:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:43,385:INFO:Initializing create_model()
2024-05-24 15:48:43,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=lasso, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:43,385:INFO:Checking exceptions
2024-05-24 15:48:43,385:INFO:Importing libraries
2024-05-24 15:48:43,385:INFO:Copying training dataset
2024-05-24 15:48:43,394:INFO:Defining folds
2024-05-24 15:48:43,394:INFO:Declaring metric variables
2024-05-24 15:48:43,397:INFO:Importing untrained model
2024-05-24 15:48:43,402:INFO:Lasso Regression Imported successfully
2024-05-24 15:48:43,411:INFO:Starting cross validation
2024-05-24 15:48:43,423:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:44,523:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+07, tolerance: 5.194e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:44,648:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+07, tolerance: 6.310e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:44,674:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+07, tolerance: 7.719e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:44,773:INFO:Calculating mean and std
2024-05-24 15:48:44,775:INFO:Creating metrics dataframe
2024-05-24 15:48:44,778:INFO:Uploading results into container
2024-05-24 15:48:44,778:INFO:Uploading model into container now
2024-05-24 15:48:44,779:INFO:_master_model_container: 2
2024-05-24 15:48:44,779:INFO:_display_container: 2
2024-05-24 15:48:44,780:INFO:Lasso(random_state=6616)
2024-05-24 15:48:44,780:INFO:create_model() successfully completed......................................
2024-05-24 15:48:44,991:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:44,991:INFO:Creating metrics dataframe
2024-05-24 15:48:45,001:INFO:Initializing Ridge Regression
2024-05-24 15:48:45,001:INFO:Total runtime is 0.0480174978574117 minutes
2024-05-24 15:48:45,006:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:45,006:INFO:Initializing create_model()
2024-05-24 15:48:45,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=ridge, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:45,007:INFO:Checking exceptions
2024-05-24 15:48:45,007:INFO:Importing libraries
2024-05-24 15:48:45,007:INFO:Copying training dataset
2024-05-24 15:48:45,017:INFO:Defining folds
2024-05-24 15:48:45,017:INFO:Declaring metric variables
2024-05-24 15:48:45,022:INFO:Importing untrained model
2024-05-24 15:48:45,030:INFO:Ridge Regression Imported successfully
2024-05-24 15:48:45,041:INFO:Starting cross validation
2024-05-24 15:48:45,054:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:45,978:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=3.89956e-18): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 15:48:46,010:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:48:46,065:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=1.16685e-17): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 15:48:46,143:INFO:Calculating mean and std
2024-05-24 15:48:46,145:INFO:Creating metrics dataframe
2024-05-24 15:48:46,147:INFO:Uploading results into container
2024-05-24 15:48:46,148:INFO:Uploading model into container now
2024-05-24 15:48:46,149:INFO:_master_model_container: 3
2024-05-24 15:48:46,149:INFO:_display_container: 2
2024-05-24 15:48:46,149:INFO:Ridge(random_state=6616)
2024-05-24 15:48:46,149:INFO:create_model() successfully completed......................................
2024-05-24 15:48:46,331:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:46,331:INFO:Creating metrics dataframe
2024-05-24 15:48:46,339:INFO:Initializing Elastic Net
2024-05-24 15:48:46,339:INFO:Total runtime is 0.07032636404037476 minutes
2024-05-24 15:48:46,344:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:46,345:INFO:Initializing create_model()
2024-05-24 15:48:46,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=en, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:46,345:INFO:Checking exceptions
2024-05-24 15:48:46,345:INFO:Importing libraries
2024-05-24 15:48:46,345:INFO:Copying training dataset
2024-05-24 15:48:46,353:INFO:Defining folds
2024-05-24 15:48:46,353:INFO:Declaring metric variables
2024-05-24 15:48:46,357:INFO:Importing untrained model
2024-05-24 15:48:46,362:INFO:Elastic Net Imported successfully
2024-05-24 15:48:46,372:INFO:Starting cross validation
2024-05-24 15:48:46,388:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:47,321:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e+07, tolerance: 5.194e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:47,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.950e+07, tolerance: 7.719e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:47,362:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+07, tolerance: 6.310e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:48:47,420:INFO:Calculating mean and std
2024-05-24 15:48:47,422:INFO:Creating metrics dataframe
2024-05-24 15:48:47,423:INFO:Uploading results into container
2024-05-24 15:48:47,424:INFO:Uploading model into container now
2024-05-24 15:48:47,424:INFO:_master_model_container: 4
2024-05-24 15:48:47,424:INFO:_display_container: 2
2024-05-24 15:48:47,425:INFO:ElasticNet(random_state=6616)
2024-05-24 15:48:47,425:INFO:create_model() successfully completed......................................
2024-05-24 15:48:47,588:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:47,588:INFO:Creating metrics dataframe
2024-05-24 15:48:47,600:INFO:Initializing Least Angle Regression
2024-05-24 15:48:47,600:INFO:Total runtime is 0.09133501052856446 minutes
2024-05-24 15:48:47,606:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:47,607:INFO:Initializing create_model()
2024-05-24 15:48:47,607:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=lar, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:47,607:INFO:Checking exceptions
2024-05-24 15:48:47,607:INFO:Importing libraries
2024-05-24 15:48:47,608:INFO:Copying training dataset
2024-05-24 15:48:47,618:INFO:Defining folds
2024-05-24 15:48:47,618:INFO:Declaring metric variables
2024-05-24 15:48:47,624:INFO:Importing untrained model
2024-05-24 15:48:47,630:INFO:Least Angle Regression Imported successfully
2024-05-24 15:48:47,642:INFO:Starting cross validation
2024-05-24 15:48:47,659:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:48,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:815: RuntimeWarning: overflow encountered in multiply
  Cov -= gamma_ * corr_eq_dir

2024-05-24 15:48:48,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: invalid value encountered in subtract
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-05-24 15:48:48,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: invalid value encountered in add
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-05-24 15:48:48,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-05-24 15:48:48,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:815: RuntimeWarning: overflow encountered in subtract
  Cov -= gamma_ * corr_eq_dir

2024-05-24 15:48:48,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:815: RuntimeWarning: invalid value encountered in subtract
  Cov -= gamma_ * corr_eq_dir

2024-05-24 15:48:48,706:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 162 iterations, i.e. alpha=3.551e+03, with an active set of 96 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:48:48,810:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 3.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1161, in fit
    self._fit(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py", line 1068, in _fit
    alphas, active, coef_path, n_iter_ = lars_path(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py", line 199, in lars_path
    return _lars_path_solver(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py", line 649, in _lars_path_solver
    sign_active[n_active] = np.sign(C_)
ValueError: cannot convert float NaN to integer

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 15:48:48,812:INFO:Calculating mean and std
2024-05-24 15:48:48,813:INFO:Creating metrics dataframe
2024-05-24 15:48:48,816:INFO:Uploading results into container
2024-05-24 15:48:48,816:INFO:Uploading model into container now
2024-05-24 15:48:48,817:INFO:_master_model_container: 5
2024-05-24 15:48:48,817:INFO:_display_container: 2
2024-05-24 15:48:48,817:INFO:Lars(random_state=6616)
2024-05-24 15:48:48,817:INFO:create_model() successfully completed......................................
2024-05-24 15:48:49,008:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:49,008:INFO:Creating metrics dataframe
2024-05-24 15:48:49,018:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:48:49,018:INFO:Total runtime is 0.11497063636779786 minutes
2024-05-24 15:48:49,022:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:49,023:INFO:Initializing create_model()
2024-05-24 15:48:49,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=llar, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:49,023:INFO:Checking exceptions
2024-05-24 15:48:49,023:INFO:Importing libraries
2024-05-24 15:48:49,023:INFO:Copying training dataset
2024-05-24 15:48:49,030:INFO:Defining folds
2024-05-24 15:48:49,030:INFO:Declaring metric variables
2024-05-24 15:48:49,034:INFO:Importing untrained model
2024-05-24 15:48:49,038:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:48:49,047:INFO:Starting cross validation
2024-05-24 15:48:49,058:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:50,070:INFO:Calculating mean and std
2024-05-24 15:48:50,073:INFO:Creating metrics dataframe
2024-05-24 15:48:50,075:INFO:Uploading results into container
2024-05-24 15:48:50,075:INFO:Uploading model into container now
2024-05-24 15:48:50,075:INFO:_master_model_container: 6
2024-05-24 15:48:50,075:INFO:_display_container: 2
2024-05-24 15:48:50,076:INFO:LassoLars(random_state=6616)
2024-05-24 15:48:50,076:INFO:create_model() successfully completed......................................
2024-05-24 15:48:50,231:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:50,231:INFO:Creating metrics dataframe
2024-05-24 15:48:50,240:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:48:50,240:INFO:Total runtime is 0.13534216880798342 minutes
2024-05-24 15:48:50,245:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:50,245:INFO:Initializing create_model()
2024-05-24 15:48:50,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=omp, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:50,246:INFO:Checking exceptions
2024-05-24 15:48:50,246:INFO:Importing libraries
2024-05-24 15:48:50,246:INFO:Copying training dataset
2024-05-24 15:48:50,253:INFO:Defining folds
2024-05-24 15:48:50,253:INFO:Declaring metric variables
2024-05-24 15:48:50,258:INFO:Importing untrained model
2024-05-24 15:48:50,261:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:48:50,269:INFO:Starting cross validation
2024-05-24 15:48:50,281:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:51,185:INFO:Calculating mean and std
2024-05-24 15:48:51,187:INFO:Creating metrics dataframe
2024-05-24 15:48:51,189:INFO:Uploading results into container
2024-05-24 15:48:51,190:INFO:Uploading model into container now
2024-05-24 15:48:51,190:INFO:_master_model_container: 7
2024-05-24 15:48:51,190:INFO:_display_container: 2
2024-05-24 15:48:51,190:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:48:51,191:INFO:create_model() successfully completed......................................
2024-05-24 15:48:51,346:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:51,346:INFO:Creating metrics dataframe
2024-05-24 15:48:51,355:INFO:Initializing Bayesian Ridge
2024-05-24 15:48:51,355:INFO:Total runtime is 0.15392051935195925 minutes
2024-05-24 15:48:51,359:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:51,360:INFO:Initializing create_model()
2024-05-24 15:48:51,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=br, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:51,360:INFO:Checking exceptions
2024-05-24 15:48:51,360:INFO:Importing libraries
2024-05-24 15:48:51,360:INFO:Copying training dataset
2024-05-24 15:48:51,367:INFO:Defining folds
2024-05-24 15:48:51,367:INFO:Declaring metric variables
2024-05-24 15:48:51,373:INFO:Importing untrained model
2024-05-24 15:48:51,378:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:48:51,387:INFO:Starting cross validation
2024-05-24 15:48:51,405:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:52,272:INFO:Calculating mean and std
2024-05-24 15:48:52,274:INFO:Creating metrics dataframe
2024-05-24 15:48:52,277:INFO:Uploading results into container
2024-05-24 15:48:52,277:INFO:Uploading model into container now
2024-05-24 15:48:52,278:INFO:_master_model_container: 8
2024-05-24 15:48:52,278:INFO:_display_container: 2
2024-05-24 15:48:52,278:INFO:BayesianRidge()
2024-05-24 15:48:52,278:INFO:create_model() successfully completed......................................
2024-05-24 15:48:52,432:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:52,432:INFO:Creating metrics dataframe
2024-05-24 15:48:52,442:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:48:52,442:INFO:Total runtime is 0.1720487912495931 minutes
2024-05-24 15:48:52,447:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:52,447:INFO:Initializing create_model()
2024-05-24 15:48:52,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=par, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:52,447:INFO:Checking exceptions
2024-05-24 15:48:52,447:INFO:Importing libraries
2024-05-24 15:48:52,447:INFO:Copying training dataset
2024-05-24 15:48:52,455:INFO:Defining folds
2024-05-24 15:48:52,455:INFO:Declaring metric variables
2024-05-24 15:48:52,460:INFO:Importing untrained model
2024-05-24 15:48:52,464:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:48:52,472:INFO:Starting cross validation
2024-05-24 15:48:52,486:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:53,387:INFO:Calculating mean and std
2024-05-24 15:48:53,389:INFO:Creating metrics dataframe
2024-05-24 15:48:53,390:INFO:Uploading results into container
2024-05-24 15:48:53,391:INFO:Uploading model into container now
2024-05-24 15:48:53,391:INFO:_master_model_container: 9
2024-05-24 15:48:53,391:INFO:_display_container: 2
2024-05-24 15:48:53,392:INFO:PassiveAggressiveRegressor(random_state=6616)
2024-05-24 15:48:53,392:INFO:create_model() successfully completed......................................
2024-05-24 15:48:53,552:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:53,553:INFO:Creating metrics dataframe
2024-05-24 15:48:53,563:INFO:Initializing Huber Regressor
2024-05-24 15:48:53,563:INFO:Total runtime is 0.1907239079475403 minutes
2024-05-24 15:48:53,566:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:53,567:INFO:Initializing create_model()
2024-05-24 15:48:53,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=huber, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:53,567:INFO:Checking exceptions
2024-05-24 15:48:53,567:INFO:Importing libraries
2024-05-24 15:48:53,567:INFO:Copying training dataset
2024-05-24 15:48:53,575:INFO:Defining folds
2024-05-24 15:48:53,575:INFO:Declaring metric variables
2024-05-24 15:48:53,579:INFO:Importing untrained model
2024-05-24 15:48:53,582:INFO:Huber Regressor Imported successfully
2024-05-24 15:48:53,592:INFO:Starting cross validation
2024-05-24 15:48:53,602:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:54,571:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:48:54,652:INFO:Calculating mean and std
2024-05-24 15:48:54,653:INFO:Creating metrics dataframe
2024-05-24 15:48:54,656:INFO:Uploading results into container
2024-05-24 15:48:54,656:INFO:Uploading model into container now
2024-05-24 15:48:54,657:INFO:_master_model_container: 10
2024-05-24 15:48:54,657:INFO:_display_container: 2
2024-05-24 15:48:54,657:INFO:HuberRegressor()
2024-05-24 15:48:54,657:INFO:create_model() successfully completed......................................
2024-05-24 15:48:54,854:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:54,855:INFO:Creating metrics dataframe
2024-05-24 15:48:54,871:INFO:Initializing K Neighbors Regressor
2024-05-24 15:48:54,871:INFO:Total runtime is 0.21251952648162842 minutes
2024-05-24 15:48:54,876:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:54,877:INFO:Initializing create_model()
2024-05-24 15:48:54,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=knn, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:54,877:INFO:Checking exceptions
2024-05-24 15:48:54,877:INFO:Importing libraries
2024-05-24 15:48:54,877:INFO:Copying training dataset
2024-05-24 15:48:54,884:INFO:Defining folds
2024-05-24 15:48:54,884:INFO:Declaring metric variables
2024-05-24 15:48:54,888:INFO:Importing untrained model
2024-05-24 15:48:54,894:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:48:54,902:INFO:Starting cross validation
2024-05-24 15:48:54,915:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:55,956:INFO:Calculating mean and std
2024-05-24 15:48:55,958:INFO:Creating metrics dataframe
2024-05-24 15:48:55,961:INFO:Uploading results into container
2024-05-24 15:48:55,962:INFO:Uploading model into container now
2024-05-24 15:48:55,962:INFO:_master_model_container: 11
2024-05-24 15:48:55,962:INFO:_display_container: 2
2024-05-24 15:48:55,962:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:48:55,962:INFO:create_model() successfully completed......................................
2024-05-24 15:48:56,140:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:56,140:INFO:Creating metrics dataframe
2024-05-24 15:48:56,152:INFO:Initializing Decision Tree Regressor
2024-05-24 15:48:56,152:INFO:Total runtime is 0.2338775634765625 minutes
2024-05-24 15:48:56,156:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:56,156:INFO:Initializing create_model()
2024-05-24 15:48:56,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=dt, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:56,157:INFO:Checking exceptions
2024-05-24 15:48:56,157:INFO:Importing libraries
2024-05-24 15:48:56,157:INFO:Copying training dataset
2024-05-24 15:48:56,166:INFO:Defining folds
2024-05-24 15:48:56,166:INFO:Declaring metric variables
2024-05-24 15:48:56,170:INFO:Importing untrained model
2024-05-24 15:48:56,177:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:48:56,186:INFO:Starting cross validation
2024-05-24 15:48:56,198:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:57,190:INFO:Calculating mean and std
2024-05-24 15:48:57,191:INFO:Creating metrics dataframe
2024-05-24 15:48:57,193:INFO:Uploading results into container
2024-05-24 15:48:57,194:INFO:Uploading model into container now
2024-05-24 15:48:57,194:INFO:_master_model_container: 12
2024-05-24 15:48:57,194:INFO:_display_container: 2
2024-05-24 15:48:57,195:INFO:DecisionTreeRegressor(random_state=6616)
2024-05-24 15:48:57,195:INFO:create_model() successfully completed......................................
2024-05-24 15:48:57,354:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:57,354:INFO:Creating metrics dataframe
2024-05-24 15:48:57,365:INFO:Initializing Random Forest Regressor
2024-05-24 15:48:57,365:INFO:Total runtime is 0.254085099697113 minutes
2024-05-24 15:48:57,368:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:57,368:INFO:Initializing create_model()
2024-05-24 15:48:57,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=rf, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:57,369:INFO:Checking exceptions
2024-05-24 15:48:57,369:INFO:Importing libraries
2024-05-24 15:48:57,369:INFO:Copying training dataset
2024-05-24 15:48:57,376:INFO:Defining folds
2024-05-24 15:48:57,376:INFO:Declaring metric variables
2024-05-24 15:48:57,382:INFO:Importing untrained model
2024-05-24 15:48:57,386:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:48:57,397:INFO:Starting cross validation
2024-05-24 15:48:57,418:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:48:58,659:INFO:Calculating mean and std
2024-05-24 15:48:58,660:INFO:Creating metrics dataframe
2024-05-24 15:48:58,663:INFO:Uploading results into container
2024-05-24 15:48:58,664:INFO:Uploading model into container now
2024-05-24 15:48:58,664:INFO:_master_model_container: 13
2024-05-24 15:48:58,664:INFO:_display_container: 2
2024-05-24 15:48:58,665:INFO:RandomForestRegressor(n_jobs=-1, random_state=6616)
2024-05-24 15:48:58,665:INFO:create_model() successfully completed......................................
2024-05-24 15:48:58,852:INFO:SubProcess create_model() end ==================================
2024-05-24 15:48:58,852:INFO:Creating metrics dataframe
2024-05-24 15:48:58,864:INFO:Initializing Extra Trees Regressor
2024-05-24 15:48:58,865:INFO:Total runtime is 0.27909802993138627 minutes
2024-05-24 15:48:58,870:INFO:SubProcess create_model() called ==================================
2024-05-24 15:48:58,870:INFO:Initializing create_model()
2024-05-24 15:48:58,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=et, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:48:58,870:INFO:Checking exceptions
2024-05-24 15:48:58,871:INFO:Importing libraries
2024-05-24 15:48:58,871:INFO:Copying training dataset
2024-05-24 15:48:58,877:INFO:Defining folds
2024-05-24 15:48:58,879:INFO:Declaring metric variables
2024-05-24 15:48:58,883:INFO:Importing untrained model
2024-05-24 15:48:58,886:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:48:58,895:INFO:Starting cross validation
2024-05-24 15:48:58,907:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:00,193:INFO:Calculating mean and std
2024-05-24 15:49:00,194:INFO:Creating metrics dataframe
2024-05-24 15:49:00,197:INFO:Uploading results into container
2024-05-24 15:49:00,197:INFO:Uploading model into container now
2024-05-24 15:49:00,198:INFO:_master_model_container: 14
2024-05-24 15:49:00,198:INFO:_display_container: 2
2024-05-24 15:49:00,198:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6616)
2024-05-24 15:49:00,198:INFO:create_model() successfully completed......................................
2024-05-24 15:49:00,382:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:00,383:INFO:Creating metrics dataframe
2024-05-24 15:49:00,399:INFO:Initializing AdaBoost Regressor
2024-05-24 15:49:00,399:INFO:Total runtime is 0.30465820233027135 minutes
2024-05-24 15:49:00,403:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:00,404:INFO:Initializing create_model()
2024-05-24 15:49:00,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=ada, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:00,404:INFO:Checking exceptions
2024-05-24 15:49:00,404:INFO:Importing libraries
2024-05-24 15:49:00,405:INFO:Copying training dataset
2024-05-24 15:49:00,413:INFO:Defining folds
2024-05-24 15:49:00,415:INFO:Declaring metric variables
2024-05-24 15:49:00,420:INFO:Importing untrained model
2024-05-24 15:49:00,425:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:49:00,434:INFO:Starting cross validation
2024-05-24 15:49:00,446:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:01,610:INFO:Calculating mean and std
2024-05-24 15:49:01,612:INFO:Creating metrics dataframe
2024-05-24 15:49:01,614:INFO:Uploading results into container
2024-05-24 15:49:01,614:INFO:Uploading model into container now
2024-05-24 15:49:01,615:INFO:_master_model_container: 15
2024-05-24 15:49:01,615:INFO:_display_container: 2
2024-05-24 15:49:01,615:INFO:AdaBoostRegressor(random_state=6616)
2024-05-24 15:49:01,615:INFO:create_model() successfully completed......................................
2024-05-24 15:49:01,796:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:01,796:INFO:Creating metrics dataframe
2024-05-24 15:49:01,808:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:49:01,808:INFO:Total runtime is 0.328149660428365 minutes
2024-05-24 15:49:01,814:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:01,815:INFO:Initializing create_model()
2024-05-24 15:49:01,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=gbr, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:01,815:INFO:Checking exceptions
2024-05-24 15:49:01,815:INFO:Importing libraries
2024-05-24 15:49:01,815:INFO:Copying training dataset
2024-05-24 15:49:01,823:INFO:Defining folds
2024-05-24 15:49:01,823:INFO:Declaring metric variables
2024-05-24 15:49:01,828:INFO:Importing untrained model
2024-05-24 15:49:01,833:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:49:01,842:INFO:Starting cross validation
2024-05-24 15:49:01,854:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:02,900:INFO:Calculating mean and std
2024-05-24 15:49:02,903:INFO:Creating metrics dataframe
2024-05-24 15:49:02,905:INFO:Uploading results into container
2024-05-24 15:49:02,905:INFO:Uploading model into container now
2024-05-24 15:49:02,906:INFO:_master_model_container: 16
2024-05-24 15:49:02,906:INFO:_display_container: 2
2024-05-24 15:49:02,906:INFO:GradientBoostingRegressor(random_state=6616)
2024-05-24 15:49:02,906:INFO:create_model() successfully completed......................................
2024-05-24 15:49:03,068:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:03,069:INFO:Creating metrics dataframe
2024-05-24 15:49:03,080:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:49:03,081:INFO:Total runtime is 0.34935446977615353 minutes
2024-05-24 15:49:03,084:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:03,085:INFO:Initializing create_model()
2024-05-24 15:49:03,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=lightgbm, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:03,085:INFO:Checking exceptions
2024-05-24 15:49:03,085:INFO:Importing libraries
2024-05-24 15:49:03,085:INFO:Copying training dataset
2024-05-24 15:49:03,093:INFO:Defining folds
2024-05-24 15:49:03,093:INFO:Declaring metric variables
2024-05-24 15:49:03,098:INFO:Importing untrained model
2024-05-24 15:49:03,102:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:49:03,111:INFO:Starting cross validation
2024-05-24 15:49:03,124:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:04,197:INFO:Calculating mean and std
2024-05-24 15:49:04,199:INFO:Creating metrics dataframe
2024-05-24 15:49:04,201:INFO:Uploading results into container
2024-05-24 15:49:04,202:INFO:Uploading model into container now
2024-05-24 15:49:04,203:INFO:_master_model_container: 17
2024-05-24 15:49:04,204:INFO:_display_container: 2
2024-05-24 15:49:04,205:INFO:LGBMRegressor(n_jobs=-1, random_state=6616)
2024-05-24 15:49:04,205:INFO:create_model() successfully completed......................................
2024-05-24 15:49:04,389:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:04,389:INFO:Creating metrics dataframe
2024-05-24 15:49:04,402:INFO:Initializing Dummy Regressor
2024-05-24 15:49:04,406:INFO:Total runtime is 0.37144979635874426 minutes
2024-05-24 15:49:04,412:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:04,413:INFO:Initializing create_model()
2024-05-24 15:49:04,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=dummy, fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5E97E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:04,413:INFO:Checking exceptions
2024-05-24 15:49:04,413:INFO:Importing libraries
2024-05-24 15:49:04,413:INFO:Copying training dataset
2024-05-24 15:49:04,421:INFO:Defining folds
2024-05-24 15:49:04,421:INFO:Declaring metric variables
2024-05-24 15:49:04,426:INFO:Importing untrained model
2024-05-24 15:49:04,432:INFO:Dummy Regressor Imported successfully
2024-05-24 15:49:04,445:INFO:Starting cross validation
2024-05-24 15:49:04,463:INFO:Cross validating with KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:05,429:INFO:Calculating mean and std
2024-05-24 15:49:05,430:INFO:Creating metrics dataframe
2024-05-24 15:49:05,433:INFO:Uploading results into container
2024-05-24 15:49:05,433:INFO:Uploading model into container now
2024-05-24 15:49:05,433:INFO:_master_model_container: 18
2024-05-24 15:49:05,434:INFO:_display_container: 2
2024-05-24 15:49:05,434:INFO:DummyRegressor()
2024-05-24 15:49:05,434:INFO:create_model() successfully completed......................................
2024-05-24 15:49:05,602:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:05,602:INFO:Creating metrics dataframe
2024-05-24 15:49:05,616:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:49:05,627:INFO:Initializing create_model()
2024-05-24 15:49:05,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221BAC9C0A0>, estimator=LGBMRegressor(n_jobs=-1, random_state=6616), fold=KFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:05,628:INFO:Checking exceptions
2024-05-24 15:49:05,630:INFO:Importing libraries
2024-05-24 15:49:05,630:INFO:Copying training dataset
2024-05-24 15:49:05,635:INFO:Defining folds
2024-05-24 15:49:05,635:INFO:Declaring metric variables
2024-05-24 15:49:05,635:INFO:Importing untrained model
2024-05-24 15:49:05,635:INFO:Declaring custom model
2024-05-24 15:49:05,636:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:49:05,657:INFO:Cross validation set to False
2024-05-24 15:49:05,657:INFO:Fitting Model
2024-05-24 15:49:06,620:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-24 15:49:06,622:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2024-05-24 15:49:06,622:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-24 15:49:06,623:INFO:[LightGBM] [Info] Total Bins 947
2024-05-24 15:49:06,623:INFO:[LightGBM] [Info] Number of data points in the train set: 143, number of used features: 68
2024-05-24 15:49:06,623:INFO:[LightGBM] [Info] Start training from score 13100.146853
2024-05-24 15:49:06,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:49:06,649:INFO:LGBMRegressor(n_jobs=-1, random_state=6616)
2024-05-24 15:49:06,649:INFO:create_model() successfully completed......................................
2024-05-24 15:49:06,865:INFO:_master_model_container: 18
2024-05-24 15:49:06,866:INFO:_display_container: 2
2024-05-24 15:49:06,866:INFO:LGBMRegressor(n_jobs=-1, random_state=6616)
2024-05-24 15:49:06,866:INFO:compare_models() successfully completed......................................
2024-05-24 15:49:06,887:INFO:Initializing plot_model()
2024-05-24 15:49:06,888:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=AdaBoostRegressor(random_state=7578), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, system=True)
2024-05-24 15:49:06,888:INFO:Checking exceptions
2024-05-24 15:49:06,894:INFO:Preloading libraries
2024-05-24 15:49:06,900:INFO:Copying training dataset
2024-05-24 15:49:06,900:INFO:Plot type: cooks
2024-05-24 15:49:07,456:INFO:Fitting Model
2024-05-24 15:49:07,482:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pandas\core\arraylike.py:396: RuntimeWarning: invalid value encountered in sqrt
  result = getattr(ufunc, method)(*inputs, **kwargs)

2024-05-24 15:49:07,824:INFO:Visual Rendered Successfully
2024-05-24 15:49:08,001:INFO:plot_model() successfully completed......................................
2024-05-24 15:49:17,470:INFO:PyCaret RegressionExperiment
2024-05-24 15:49:17,470:INFO:Logging name: reg-default-name
2024-05-24 15:49:17,470:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:49:17,470:INFO:version 3.3.2
2024-05-24 15:49:17,470:INFO:Initializing setup()
2024-05-24 15:49:17,470:INFO:self.USI: aef7
2024-05-24 15:49:17,470:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:49:17,470:INFO:Checking environment
2024-05-24 15:49:17,470:INFO:python_version: 3.10.14
2024-05-24 15:49:17,470:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:49:17,471:INFO:machine: AMD64
2024-05-24 15:49:17,471:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:49:17,471:INFO:Memory: svmem(total=16541802496, available=2107408384, percent=87.3, used=14434394112, free=2107408384)
2024-05-24 15:49:17,471:INFO:Physical Core: 6
2024-05-24 15:49:17,471:INFO:Logical Core: 12
2024-05-24 15:49:17,471:INFO:Checking libraries
2024-05-24 15:49:17,471:INFO:System:
2024-05-24 15:49:17,472:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:49:17,472:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:49:17,472:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:49:17,472:INFO:PyCaret required dependencies:
2024-05-24 15:49:17,472:INFO:                 pip: 24.0
2024-05-24 15:49:17,472:INFO:          setuptools: 69.5.1
2024-05-24 15:49:17,472:INFO:             pycaret: 3.3.2
2024-05-24 15:49:17,472:INFO:             IPython: 8.20.0
2024-05-24 15:49:17,472:INFO:          ipywidgets: 8.1.2
2024-05-24 15:49:17,472:INFO:                tqdm: 4.66.4
2024-05-24 15:49:17,472:INFO:               numpy: 1.26.4
2024-05-24 15:49:17,472:INFO:              pandas: 2.1.4
2024-05-24 15:49:17,473:INFO:              jinja2: 3.1.3
2024-05-24 15:49:17,473:INFO:               scipy: 1.11.4
2024-05-24 15:49:17,473:INFO:              joblib: 1.3.2
2024-05-24 15:49:17,473:INFO:             sklearn: 1.4.2
2024-05-24 15:49:17,473:INFO:                pyod: 1.1.3
2024-05-24 15:49:17,473:INFO:            imblearn: 0.12.2
2024-05-24 15:49:17,473:INFO:   category_encoders: 2.6.3
2024-05-24 15:49:17,473:INFO:            lightgbm: 4.3.0
2024-05-24 15:49:17,473:INFO:               numba: 0.59.1
2024-05-24 15:49:17,473:INFO:            requests: 2.32.2
2024-05-24 15:49:17,473:INFO:          matplotlib: 3.7.5
2024-05-24 15:49:17,473:INFO:          scikitplot: 0.3.7
2024-05-24 15:49:17,473:INFO:         yellowbrick: 1.5
2024-05-24 15:49:17,473:INFO:              plotly: 5.22.0
2024-05-24 15:49:17,474:INFO:    plotly-resampler: Not installed
2024-05-24 15:49:17,474:INFO:             kaleido: 0.2.1
2024-05-24 15:49:17,474:INFO:           schemdraw: 0.15
2024-05-24 15:49:17,474:INFO:         statsmodels: 0.14.2
2024-05-24 15:49:17,474:INFO:              sktime: 0.26.0
2024-05-24 15:49:17,474:INFO:               tbats: 1.1.3
2024-05-24 15:49:17,474:INFO:            pmdarima: 2.0.4
2024-05-24 15:49:17,474:INFO:              psutil: 5.9.0
2024-05-24 15:49:17,474:INFO:          markupsafe: 2.1.3
2024-05-24 15:49:17,474:INFO:             pickle5: Not installed
2024-05-24 15:49:17,474:INFO:         cloudpickle: 3.0.0
2024-05-24 15:49:17,474:INFO:         deprecation: 2.1.0
2024-05-24 15:49:17,474:INFO:              xxhash: 3.4.1
2024-05-24 15:49:17,474:INFO:           wurlitzer: Not installed
2024-05-24 15:49:17,474:INFO:PyCaret optional dependencies:
2024-05-24 15:49:17,475:INFO:                shap: Not installed
2024-05-24 15:49:17,475:INFO:           interpret: Not installed
2024-05-24 15:49:17,475:INFO:                umap: Not installed
2024-05-24 15:49:17,475:INFO:     ydata_profiling: Not installed
2024-05-24 15:49:17,475:INFO:  explainerdashboard: Not installed
2024-05-24 15:49:17,475:INFO:             autoviz: Not installed
2024-05-24 15:49:17,475:INFO:           fairlearn: Not installed
2024-05-24 15:49:17,475:INFO:          deepchecks: Not installed
2024-05-24 15:49:17,475:INFO:             xgboost: Not installed
2024-05-24 15:49:17,475:INFO:            catboost: Not installed
2024-05-24 15:49:17,475:INFO:              kmodes: Not installed
2024-05-24 15:49:17,475:INFO:             mlxtend: Not installed
2024-05-24 15:49:17,475:INFO:       statsforecast: Not installed
2024-05-24 15:49:17,475:INFO:        tune_sklearn: Not installed
2024-05-24 15:49:17,475:INFO:                 ray: Not installed
2024-05-24 15:49:17,475:INFO:            hyperopt: Not installed
2024-05-24 15:49:17,475:INFO:              optuna: Not installed
2024-05-24 15:49:17,475:INFO:               skopt: Not installed
2024-05-24 15:49:17,476:INFO:              mlflow: Not installed
2024-05-24 15:49:17,476:INFO:              gradio: Not installed
2024-05-24 15:49:17,476:INFO:             fastapi: Not installed
2024-05-24 15:49:17,476:INFO:             uvicorn: Not installed
2024-05-24 15:49:17,476:INFO:              m2cgen: Not installed
2024-05-24 15:49:17,476:INFO:           evidently: Not installed
2024-05-24 15:49:17,476:INFO:               fugue: Not installed
2024-05-24 15:49:17,476:INFO:           streamlit: Not installed
2024-05-24 15:49:17,476:INFO:             prophet: Not installed
2024-05-24 15:49:17,476:INFO:None
2024-05-24 15:49:17,476:INFO:Set up data.
2024-05-24 15:49:17,491:INFO:Set up folding strategy.
2024-05-24 15:49:17,491:INFO:Set up train/test split.
2024-05-24 15:49:17,500:INFO:Set up index.
2024-05-24 15:49:17,501:INFO:Assigning column types.
2024-05-24 15:49:17,506:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:49:17,506:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,511:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,517:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:17,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:17,641:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,645:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:17,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:17,759:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:49:17,763:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,768:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,881:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:17,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:17,887:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,891:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:17,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,001:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:49:18,011:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,074:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,132:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,241:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:49:18,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,477:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:49:18,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,666:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:49:18,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,713:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:49:18,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:18,960:INFO:Preparing preprocessing pipeline...
2024-05-24 15:49:18,960:INFO:Set up simple imputation.
2024-05-24 15:49:18,966:INFO:Set up encoding of ordinal features.
2024-05-24 15:49:18,971:INFO:Set up encoding of categorical features.
2024-05-24 15:49:18,971:INFO:Set up polynomial features.
2024-05-24 15:49:18,971:INFO:Set up removing multicollinearity.
2024-05-24 15:49:20,236:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:49:20,316:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:49:20,316:INFO:Creating final display dataframe.
2024-05-24 15:49:21,500:INFO:Setup _display_container:                     Description             Value
0                    Session id              2136
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (205, 466)
5   Transformed train set shape        (143, 466)
6    Transformed test set shape         (62, 466)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              aef7
2024-05-24 15:49:21,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:21,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:21,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:21,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:49:21,747:INFO:setup() successfully completed in 4.29s...............
2024-05-24 15:49:21,768:INFO:Initializing compare_models()
2024-05-24 15:49:21,768:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:49:21,768:INFO:Checking exceptions
2024-05-24 15:49:21,771:INFO:Preparing display monitor
2024-05-24 15:49:21,800:INFO:Initializing Linear Regression
2024-05-24 15:49:21,800:INFO:Total runtime is 0.0 minutes
2024-05-24 15:49:21,804:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:21,805:INFO:Initializing create_model()
2024-05-24 15:49:21,805:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:21,805:INFO:Checking exceptions
2024-05-24 15:49:21,805:INFO:Importing libraries
2024-05-24 15:49:21,805:INFO:Copying training dataset
2024-05-24 15:49:21,813:INFO:Defining folds
2024-05-24 15:49:21,813:INFO:Declaring metric variables
2024-05-24 15:49:21,817:INFO:Importing untrained model
2024-05-24 15:49:21,821:INFO:Linear Regression Imported successfully
2024-05-24 15:49:21,831:INFO:Starting cross validation
2024-05-24 15:49:21,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:23,988:INFO:Calculating mean and std
2024-05-24 15:49:23,989:INFO:Creating metrics dataframe
2024-05-24 15:49:23,992:INFO:Uploading results into container
2024-05-24 15:49:23,993:INFO:Uploading model into container now
2024-05-24 15:49:23,994:INFO:_master_model_container: 1
2024-05-24 15:49:23,994:INFO:_display_container: 2
2024-05-24 15:49:23,994:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:49:23,994:INFO:create_model() successfully completed......................................
2024-05-24 15:49:24,170:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:24,170:INFO:Creating metrics dataframe
2024-05-24 15:49:24,179:INFO:Initializing Lasso Regression
2024-05-24 15:49:24,179:INFO:Total runtime is 0.03966125249862671 minutes
2024-05-24 15:49:24,183:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:24,185:INFO:Initializing create_model()
2024-05-24 15:49:24,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:24,185:INFO:Checking exceptions
2024-05-24 15:49:24,185:INFO:Importing libraries
2024-05-24 15:49:24,185:INFO:Copying training dataset
2024-05-24 15:49:24,195:INFO:Defining folds
2024-05-24 15:49:24,195:INFO:Declaring metric variables
2024-05-24 15:49:24,200:INFO:Importing untrained model
2024-05-24 15:49:24,204:INFO:Lasso Regression Imported successfully
2024-05-24 15:49:24,214:INFO:Starting cross validation
2024-05-24 15:49:24,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:25,834:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+07, tolerance: 6.228e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,038:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+07, tolerance: 6.379e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,080:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+07, tolerance: 7.313e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,109:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+07, tolerance: 6.965e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,125:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e+07, tolerance: 6.793e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,132:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+07, tolerance: 6.559e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,137:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.942e+07, tolerance: 7.365e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,139:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.896e+07, tolerance: 6.747e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,149:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+07, tolerance: 7.202e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.459e+07, tolerance: 6.948e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:26,247:INFO:Calculating mean and std
2024-05-24 15:49:26,248:INFO:Creating metrics dataframe
2024-05-24 15:49:26,251:INFO:Uploading results into container
2024-05-24 15:49:26,251:INFO:Uploading model into container now
2024-05-24 15:49:26,252:INFO:_master_model_container: 2
2024-05-24 15:49:26,252:INFO:_display_container: 2
2024-05-24 15:49:26,253:INFO:Lasso(random_state=2136)
2024-05-24 15:49:26,253:INFO:create_model() successfully completed......................................
2024-05-24 15:49:26,456:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:26,456:INFO:Creating metrics dataframe
2024-05-24 15:49:26,465:INFO:Initializing Ridge Regression
2024-05-24 15:49:26,465:INFO:Total runtime is 0.07775720357894897 minutes
2024-05-24 15:49:26,469:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:26,469:INFO:Initializing create_model()
2024-05-24 15:49:26,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:26,470:INFO:Checking exceptions
2024-05-24 15:49:26,470:INFO:Importing libraries
2024-05-24 15:49:26,470:INFO:Copying training dataset
2024-05-24 15:49:26,478:INFO:Defining folds
2024-05-24 15:49:26,479:INFO:Declaring metric variables
2024-05-24 15:49:26,484:INFO:Importing untrained model
2024-05-24 15:49:26,488:INFO:Ridge Regression Imported successfully
2024-05-24 15:49:26,497:INFO:Starting cross validation
2024-05-24 15:49:26,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:28,152:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=1.12122e-17): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 15:49:28,265:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=8.39115e-18): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 15:49:28,285:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,298:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,312:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,340:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,369:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=6.11955e-18): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 15:49:28,373:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:49:28,445:INFO:Calculating mean and std
2024-05-24 15:49:28,446:INFO:Creating metrics dataframe
2024-05-24 15:49:28,450:INFO:Uploading results into container
2024-05-24 15:49:28,451:INFO:Uploading model into container now
2024-05-24 15:49:28,452:INFO:_master_model_container: 3
2024-05-24 15:49:28,452:INFO:_display_container: 2
2024-05-24 15:49:28,452:INFO:Ridge(random_state=2136)
2024-05-24 15:49:28,453:INFO:create_model() successfully completed......................................
2024-05-24 15:49:28,607:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:28,607:INFO:Creating metrics dataframe
2024-05-24 15:49:28,616:INFO:Initializing Elastic Net
2024-05-24 15:49:28,616:INFO:Total runtime is 0.11361027558644612 minutes
2024-05-24 15:49:28,620:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:28,620:INFO:Initializing create_model()
2024-05-24 15:49:28,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:28,620:INFO:Checking exceptions
2024-05-24 15:49:28,622:INFO:Importing libraries
2024-05-24 15:49:28,622:INFO:Copying training dataset
2024-05-24 15:49:28,630:INFO:Defining folds
2024-05-24 15:49:28,630:INFO:Declaring metric variables
2024-05-24 15:49:28,634:INFO:Importing untrained model
2024-05-24 15:49:28,638:INFO:Elastic Net Imported successfully
2024-05-24 15:49:28,647:INFO:Starting cross validation
2024-05-24 15:49:28,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:30,037:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.222e+07, tolerance: 6.228e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.317e+07, tolerance: 6.379e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,268:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.169e+07, tolerance: 6.965e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,268:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.265e+07, tolerance: 7.313e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,271:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.129e+07, tolerance: 6.793e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.366e+07, tolerance: 6.559e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,308:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.343e+07, tolerance: 7.202e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,401:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.775e+07, tolerance: 7.365e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,423:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e+07, tolerance: 6.747e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,425:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.742e+07, tolerance: 6.948e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:49:30,484:INFO:Calculating mean and std
2024-05-24 15:49:30,486:INFO:Creating metrics dataframe
2024-05-24 15:49:30,488:INFO:Uploading results into container
2024-05-24 15:49:30,488:INFO:Uploading model into container now
2024-05-24 15:49:30,489:INFO:_master_model_container: 4
2024-05-24 15:49:30,489:INFO:_display_container: 2
2024-05-24 15:49:30,489:INFO:ElasticNet(random_state=2136)
2024-05-24 15:49:30,491:INFO:create_model() successfully completed......................................
2024-05-24 15:49:30,656:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:30,656:INFO:Creating metrics dataframe
2024-05-24 15:49:30,665:INFO:Initializing Least Angle Regression
2024-05-24 15:49:30,665:INFO:Total runtime is 0.14774608612060547 minutes
2024-05-24 15:49:30,668:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:30,668:INFO:Initializing create_model()
2024-05-24 15:49:30,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:30,670:INFO:Checking exceptions
2024-05-24 15:49:30,670:INFO:Importing libraries
2024-05-24 15:49:30,670:INFO:Copying training dataset
2024-05-24 15:49:30,675:INFO:Defining folds
2024-05-24 15:49:30,675:INFO:Declaring metric variables
2024-05-24 15:49:30,679:INFO:Importing untrained model
2024-05-24 15:49:30,684:INFO:Least Angle Regression Imported successfully
2024-05-24 15:49:30,693:INFO:Starting cross validation
2024-05-24 15:49:30,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:32,434:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=1.161e+04, with an active set of 114 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:49:32,435:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=1.075e+04, with an active set of 114 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:49:32,435:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=1.051e+04, with an active set of 114 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:49:32,729:INFO:Calculating mean and std
2024-05-24 15:49:32,730:INFO:Creating metrics dataframe
2024-05-24 15:49:32,732:INFO:Uploading results into container
2024-05-24 15:49:32,732:INFO:Uploading model into container now
2024-05-24 15:49:32,733:INFO:_master_model_container: 5
2024-05-24 15:49:32,733:INFO:_display_container: 2
2024-05-24 15:49:32,733:INFO:Lars(random_state=2136)
2024-05-24 15:49:32,734:INFO:create_model() successfully completed......................................
2024-05-24 15:49:32,888:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:32,889:INFO:Creating metrics dataframe
2024-05-24 15:49:32,898:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:49:32,898:INFO:Total runtime is 0.18497124910354615 minutes
2024-05-24 15:49:32,901:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:32,902:INFO:Initializing create_model()
2024-05-24 15:49:32,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:32,902:INFO:Checking exceptions
2024-05-24 15:49:32,903:INFO:Importing libraries
2024-05-24 15:49:32,903:INFO:Copying training dataset
2024-05-24 15:49:32,913:INFO:Defining folds
2024-05-24 15:49:32,914:INFO:Declaring metric variables
2024-05-24 15:49:32,919:INFO:Importing untrained model
2024-05-24 15:49:32,923:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:49:32,933:INFO:Starting cross validation
2024-05-24 15:49:32,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:34,770:INFO:Calculating mean and std
2024-05-24 15:49:34,772:INFO:Creating metrics dataframe
2024-05-24 15:49:34,775:INFO:Uploading results into container
2024-05-24 15:49:34,776:INFO:Uploading model into container now
2024-05-24 15:49:34,776:INFO:_master_model_container: 6
2024-05-24 15:49:34,776:INFO:_display_container: 2
2024-05-24 15:49:34,777:INFO:LassoLars(random_state=2136)
2024-05-24 15:49:34,777:INFO:create_model() successfully completed......................................
2024-05-24 15:49:34,935:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:34,936:INFO:Creating metrics dataframe
2024-05-24 15:49:34,944:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:49:34,944:INFO:Total runtime is 0.2190736452738444 minutes
2024-05-24 15:49:34,948:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:34,948:INFO:Initializing create_model()
2024-05-24 15:49:34,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:34,948:INFO:Checking exceptions
2024-05-24 15:49:34,948:INFO:Importing libraries
2024-05-24 15:49:34,950:INFO:Copying training dataset
2024-05-24 15:49:34,956:INFO:Defining folds
2024-05-24 15:49:34,956:INFO:Declaring metric variables
2024-05-24 15:49:34,960:INFO:Importing untrained model
2024-05-24 15:49:34,964:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:49:34,973:INFO:Starting cross validation
2024-05-24 15:49:34,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:36,884:INFO:Calculating mean and std
2024-05-24 15:49:36,886:INFO:Creating metrics dataframe
2024-05-24 15:49:36,889:INFO:Uploading results into container
2024-05-24 15:49:36,889:INFO:Uploading model into container now
2024-05-24 15:49:36,889:INFO:_master_model_container: 7
2024-05-24 15:49:36,889:INFO:_display_container: 2
2024-05-24 15:49:36,890:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:49:36,890:INFO:create_model() successfully completed......................................
2024-05-24 15:49:37,052:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:37,052:INFO:Creating metrics dataframe
2024-05-24 15:49:37,061:INFO:Initializing Bayesian Ridge
2024-05-24 15:49:37,061:INFO:Total runtime is 0.25436110496520997 minutes
2024-05-24 15:49:37,066:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:37,066:INFO:Initializing create_model()
2024-05-24 15:49:37,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:37,066:INFO:Checking exceptions
2024-05-24 15:49:37,066:INFO:Importing libraries
2024-05-24 15:49:37,067:INFO:Copying training dataset
2024-05-24 15:49:37,073:INFO:Defining folds
2024-05-24 15:49:37,073:INFO:Declaring metric variables
2024-05-24 15:49:37,078:INFO:Importing untrained model
2024-05-24 15:49:37,082:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:49:37,088:INFO:Starting cross validation
2024-05-24 15:49:37,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:38,882:INFO:Calculating mean and std
2024-05-24 15:49:38,883:INFO:Creating metrics dataframe
2024-05-24 15:49:38,886:INFO:Uploading results into container
2024-05-24 15:49:38,886:INFO:Uploading model into container now
2024-05-24 15:49:38,887:INFO:_master_model_container: 8
2024-05-24 15:49:38,887:INFO:_display_container: 2
2024-05-24 15:49:38,888:INFO:BayesianRidge()
2024-05-24 15:49:38,888:INFO:create_model() successfully completed......................................
2024-05-24 15:49:39,050:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:39,050:INFO:Creating metrics dataframe
2024-05-24 15:49:39,059:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:49:39,060:INFO:Total runtime is 0.2876482884089152 minutes
2024-05-24 15:49:39,064:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:39,064:INFO:Initializing create_model()
2024-05-24 15:49:39,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:39,064:INFO:Checking exceptions
2024-05-24 15:49:39,065:INFO:Importing libraries
2024-05-24 15:49:39,065:INFO:Copying training dataset
2024-05-24 15:49:39,071:INFO:Defining folds
2024-05-24 15:49:39,071:INFO:Declaring metric variables
2024-05-24 15:49:39,075:INFO:Importing untrained model
2024-05-24 15:49:39,081:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:49:39,089:INFO:Starting cross validation
2024-05-24 15:49:39,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:40,890:INFO:Calculating mean and std
2024-05-24 15:49:40,892:INFO:Creating metrics dataframe
2024-05-24 15:49:40,894:INFO:Uploading results into container
2024-05-24 15:49:40,896:INFO:Uploading model into container now
2024-05-24 15:49:40,896:INFO:_master_model_container: 9
2024-05-24 15:49:40,896:INFO:_display_container: 2
2024-05-24 15:49:40,897:INFO:PassiveAggressiveRegressor(random_state=2136)
2024-05-24 15:49:40,897:INFO:create_model() successfully completed......................................
2024-05-24 15:49:41,048:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:41,049:INFO:Creating metrics dataframe
2024-05-24 15:49:41,057:INFO:Initializing Huber Regressor
2024-05-24 15:49:41,058:INFO:Total runtime is 0.3209661920865377 minutes
2024-05-24 15:49:41,063:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:41,063:INFO:Initializing create_model()
2024-05-24 15:49:41,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:41,063:INFO:Checking exceptions
2024-05-24 15:49:41,063:INFO:Importing libraries
2024-05-24 15:49:41,063:INFO:Copying training dataset
2024-05-24 15:49:41,070:INFO:Defining folds
2024-05-24 15:49:41,070:INFO:Declaring metric variables
2024-05-24 15:49:41,075:INFO:Importing untrained model
2024-05-24 15:49:41,079:INFO:Huber Regressor Imported successfully
2024-05-24 15:49:41,086:INFO:Starting cross validation
2024-05-24 15:49:41,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:42,694:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:49:42,823:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:49:42,938:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:49:42,995:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:49:43,076:INFO:Calculating mean and std
2024-05-24 15:49:43,077:INFO:Creating metrics dataframe
2024-05-24 15:49:43,081:INFO:Uploading results into container
2024-05-24 15:49:43,081:INFO:Uploading model into container now
2024-05-24 15:49:43,082:INFO:_master_model_container: 10
2024-05-24 15:49:43,082:INFO:_display_container: 2
2024-05-24 15:49:43,082:INFO:HuberRegressor()
2024-05-24 15:49:43,082:INFO:create_model() successfully completed......................................
2024-05-24 15:49:43,251:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:43,252:INFO:Creating metrics dataframe
2024-05-24 15:49:43,261:INFO:Initializing K Neighbors Regressor
2024-05-24 15:49:43,262:INFO:Total runtime is 0.3577081600824992 minutes
2024-05-24 15:49:43,266:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:43,268:INFO:Initializing create_model()
2024-05-24 15:49:43,268:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:43,268:INFO:Checking exceptions
2024-05-24 15:49:43,268:INFO:Importing libraries
2024-05-24 15:49:43,268:INFO:Copying training dataset
2024-05-24 15:49:43,274:INFO:Defining folds
2024-05-24 15:49:43,274:INFO:Declaring metric variables
2024-05-24 15:49:43,279:INFO:Importing untrained model
2024-05-24 15:49:43,283:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:49:43,291:INFO:Starting cross validation
2024-05-24 15:49:43,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:45,102:INFO:Calculating mean and std
2024-05-24 15:49:45,104:INFO:Creating metrics dataframe
2024-05-24 15:49:45,107:INFO:Uploading results into container
2024-05-24 15:49:45,108:INFO:Uploading model into container now
2024-05-24 15:49:45,109:INFO:_master_model_container: 11
2024-05-24 15:49:45,109:INFO:_display_container: 2
2024-05-24 15:49:45,109:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:49:45,109:INFO:create_model() successfully completed......................................
2024-05-24 15:49:45,283:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:45,283:INFO:Creating metrics dataframe
2024-05-24 15:49:45,300:INFO:Initializing Decision Tree Regressor
2024-05-24 15:49:45,301:INFO:Total runtime is 0.39168151219685876 minutes
2024-05-24 15:49:45,306:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:45,307:INFO:Initializing create_model()
2024-05-24 15:49:45,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:45,307:INFO:Checking exceptions
2024-05-24 15:49:45,308:INFO:Importing libraries
2024-05-24 15:49:45,308:INFO:Copying training dataset
2024-05-24 15:49:45,316:INFO:Defining folds
2024-05-24 15:49:45,316:INFO:Declaring metric variables
2024-05-24 15:49:45,321:INFO:Importing untrained model
2024-05-24 15:49:45,330:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:49:45,340:INFO:Starting cross validation
2024-05-24 15:49:45,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:47,229:INFO:Calculating mean and std
2024-05-24 15:49:47,230:INFO:Creating metrics dataframe
2024-05-24 15:49:47,232:INFO:Uploading results into container
2024-05-24 15:49:47,232:INFO:Uploading model into container now
2024-05-24 15:49:47,233:INFO:_master_model_container: 12
2024-05-24 15:49:47,233:INFO:_display_container: 2
2024-05-24 15:49:47,233:INFO:DecisionTreeRegressor(random_state=2136)
2024-05-24 15:49:47,233:INFO:create_model() successfully completed......................................
2024-05-24 15:49:47,392:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:47,392:INFO:Creating metrics dataframe
2024-05-24 15:49:47,403:INFO:Initializing Random Forest Regressor
2024-05-24 15:49:47,404:INFO:Total runtime is 0.4267331043879191 minutes
2024-05-24 15:49:47,407:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:47,408:INFO:Initializing create_model()
2024-05-24 15:49:47,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:47,408:INFO:Checking exceptions
2024-05-24 15:49:47,408:INFO:Importing libraries
2024-05-24 15:49:47,408:INFO:Copying training dataset
2024-05-24 15:49:47,416:INFO:Defining folds
2024-05-24 15:49:47,416:INFO:Declaring metric variables
2024-05-24 15:49:47,420:INFO:Importing untrained model
2024-05-24 15:49:47,423:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:49:47,431:INFO:Starting cross validation
2024-05-24 15:49:47,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:50,045:INFO:Calculating mean and std
2024-05-24 15:49:50,046:INFO:Creating metrics dataframe
2024-05-24 15:49:50,048:INFO:Uploading results into container
2024-05-24 15:49:50,049:INFO:Uploading model into container now
2024-05-24 15:49:50,050:INFO:_master_model_container: 13
2024-05-24 15:49:50,050:INFO:_display_container: 2
2024-05-24 15:49:50,050:INFO:RandomForestRegressor(n_jobs=-1, random_state=2136)
2024-05-24 15:49:50,050:INFO:create_model() successfully completed......................................
2024-05-24 15:49:50,280:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:50,280:INFO:Creating metrics dataframe
2024-05-24 15:49:50,296:INFO:Initializing Extra Trees Regressor
2024-05-24 15:49:50,296:INFO:Total runtime is 0.47493410110473633 minutes
2024-05-24 15:49:50,300:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:50,301:INFO:Initializing create_model()
2024-05-24 15:49:50,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:50,301:INFO:Checking exceptions
2024-05-24 15:49:50,301:INFO:Importing libraries
2024-05-24 15:49:50,302:INFO:Copying training dataset
2024-05-24 15:49:50,312:INFO:Defining folds
2024-05-24 15:49:50,312:INFO:Declaring metric variables
2024-05-24 15:49:50,318:INFO:Importing untrained model
2024-05-24 15:49:50,323:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:49:50,333:INFO:Starting cross validation
2024-05-24 15:49:50,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:53,192:INFO:Calculating mean and std
2024-05-24 15:49:53,194:INFO:Creating metrics dataframe
2024-05-24 15:49:53,198:INFO:Uploading results into container
2024-05-24 15:49:53,198:INFO:Uploading model into container now
2024-05-24 15:49:53,199:INFO:_master_model_container: 14
2024-05-24 15:49:53,199:INFO:_display_container: 2
2024-05-24 15:49:53,200:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=2136)
2024-05-24 15:49:53,200:INFO:create_model() successfully completed......................................
2024-05-24 15:49:53,387:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:53,387:INFO:Creating metrics dataframe
2024-05-24 15:49:53,400:INFO:Initializing AdaBoost Regressor
2024-05-24 15:49:53,400:INFO:Total runtime is 0.5266733606656392 minutes
2024-05-24 15:49:53,405:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:53,405:INFO:Initializing create_model()
2024-05-24 15:49:53,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:53,405:INFO:Checking exceptions
2024-05-24 15:49:53,405:INFO:Importing libraries
2024-05-24 15:49:53,405:INFO:Copying training dataset
2024-05-24 15:49:53,414:INFO:Defining folds
2024-05-24 15:49:53,414:INFO:Declaring metric variables
2024-05-24 15:49:53,418:INFO:Importing untrained model
2024-05-24 15:49:53,423:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:49:53,432:INFO:Starting cross validation
2024-05-24 15:49:53,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:55,842:INFO:Calculating mean and std
2024-05-24 15:49:55,844:INFO:Creating metrics dataframe
2024-05-24 15:49:55,847:INFO:Uploading results into container
2024-05-24 15:49:55,847:INFO:Uploading model into container now
2024-05-24 15:49:55,848:INFO:_master_model_container: 15
2024-05-24 15:49:55,848:INFO:_display_container: 2
2024-05-24 15:49:55,849:INFO:AdaBoostRegressor(random_state=2136)
2024-05-24 15:49:55,849:INFO:create_model() successfully completed......................................
2024-05-24 15:49:56,038:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:56,038:INFO:Creating metrics dataframe
2024-05-24 15:49:56,050:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:49:56,050:INFO:Total runtime is 0.5708393295605977 minutes
2024-05-24 15:49:56,054:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:56,054:INFO:Initializing create_model()
2024-05-24 15:49:56,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:56,054:INFO:Checking exceptions
2024-05-24 15:49:56,055:INFO:Importing libraries
2024-05-24 15:49:56,055:INFO:Copying training dataset
2024-05-24 15:49:56,062:INFO:Defining folds
2024-05-24 15:49:56,064:INFO:Declaring metric variables
2024-05-24 15:49:56,067:INFO:Importing untrained model
2024-05-24 15:49:56,071:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:49:56,081:INFO:Starting cross validation
2024-05-24 15:49:56,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:49:58,331:INFO:Calculating mean and std
2024-05-24 15:49:58,333:INFO:Creating metrics dataframe
2024-05-24 15:49:58,335:INFO:Uploading results into container
2024-05-24 15:49:58,335:INFO:Uploading model into container now
2024-05-24 15:49:58,335:INFO:_master_model_container: 16
2024-05-24 15:49:58,335:INFO:_display_container: 2
2024-05-24 15:49:58,335:INFO:GradientBoostingRegressor(random_state=2136)
2024-05-24 15:49:58,336:INFO:create_model() successfully completed......................................
2024-05-24 15:49:58,500:INFO:SubProcess create_model() end ==================================
2024-05-24 15:49:58,500:INFO:Creating metrics dataframe
2024-05-24 15:49:58,512:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:49:58,514:INFO:Total runtime is 0.6118974765141805 minutes
2024-05-24 15:49:58,518:INFO:SubProcess create_model() called ==================================
2024-05-24 15:49:58,518:INFO:Initializing create_model()
2024-05-24 15:49:58,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:49:58,518:INFO:Checking exceptions
2024-05-24 15:49:58,519:INFO:Importing libraries
2024-05-24 15:49:58,519:INFO:Copying training dataset
2024-05-24 15:49:58,525:INFO:Defining folds
2024-05-24 15:49:58,526:INFO:Declaring metric variables
2024-05-24 15:49:58,530:INFO:Importing untrained model
2024-05-24 15:49:58,535:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:49:58,544:INFO:Starting cross validation
2024-05-24 15:49:58,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:50:00,776:INFO:Calculating mean and std
2024-05-24 15:50:00,778:INFO:Creating metrics dataframe
2024-05-24 15:50:00,781:INFO:Uploading results into container
2024-05-24 15:50:00,781:INFO:Uploading model into container now
2024-05-24 15:50:00,782:INFO:_master_model_container: 17
2024-05-24 15:50:00,782:INFO:_display_container: 2
2024-05-24 15:50:00,783:INFO:LGBMRegressor(n_jobs=-1, random_state=2136)
2024-05-24 15:50:00,783:INFO:create_model() successfully completed......................................
2024-05-24 15:50:00,959:INFO:SubProcess create_model() end ==================================
2024-05-24 15:50:00,959:INFO:Creating metrics dataframe
2024-05-24 15:50:00,970:INFO:Initializing Dummy Regressor
2024-05-24 15:50:00,970:INFO:Total runtime is 0.6528451323509216 minutes
2024-05-24 15:50:00,974:INFO:SubProcess create_model() called ==================================
2024-05-24 15:50:00,975:INFO:Initializing create_model()
2024-05-24 15:50:00,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BAC9DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:50:00,975:INFO:Checking exceptions
2024-05-24 15:50:00,975:INFO:Importing libraries
2024-05-24 15:50:00,976:INFO:Copying training dataset
2024-05-24 15:50:00,985:INFO:Defining folds
2024-05-24 15:50:00,985:INFO:Declaring metric variables
2024-05-24 15:50:00,990:INFO:Importing untrained model
2024-05-24 15:50:00,995:INFO:Dummy Regressor Imported successfully
2024-05-24 15:50:01,006:INFO:Starting cross validation
2024-05-24 15:50:01,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:50:03,065:INFO:Calculating mean and std
2024-05-24 15:50:03,067:INFO:Creating metrics dataframe
2024-05-24 15:50:03,068:INFO:Uploading results into container
2024-05-24 15:50:03,069:INFO:Uploading model into container now
2024-05-24 15:50:03,070:INFO:_master_model_container: 18
2024-05-24 15:50:03,070:INFO:_display_container: 2
2024-05-24 15:50:03,070:INFO:DummyRegressor()
2024-05-24 15:50:03,070:INFO:create_model() successfully completed......................................
2024-05-24 15:50:03,264:INFO:SubProcess create_model() end ==================================
2024-05-24 15:50:03,264:INFO:Creating metrics dataframe
2024-05-24 15:50:03,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:50:03,288:INFO:Initializing create_model()
2024-05-24 15:50:03,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=AdaBoostRegressor(random_state=2136), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:50:03,288:INFO:Checking exceptions
2024-05-24 15:50:03,290:INFO:Importing libraries
2024-05-24 15:50:03,290:INFO:Copying training dataset
2024-05-24 15:50:03,298:INFO:Defining folds
2024-05-24 15:50:03,298:INFO:Declaring metric variables
2024-05-24 15:50:03,299:INFO:Importing untrained model
2024-05-24 15:50:03,299:INFO:Declaring custom model
2024-05-24 15:50:03,300:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:50:03,310:INFO:Cross validation set to False
2024-05-24 15:50:03,311:INFO:Fitting Model
2024-05-24 15:50:04,454:INFO:AdaBoostRegressor(random_state=2136)
2024-05-24 15:50:04,454:INFO:create_model() successfully completed......................................
2024-05-24 15:50:04,659:INFO:_master_model_container: 18
2024-05-24 15:50:04,660:INFO:_display_container: 2
2024-05-24 15:50:04,660:INFO:AdaBoostRegressor(random_state=2136)
2024-05-24 15:50:04,660:INFO:compare_models() successfully completed......................................
2024-05-24 15:50:04,679:INFO:Initializing plot_model()
2024-05-24 15:50:04,679:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=AdaBoostRegressor(random_state=7578), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, system=True)
2024-05-24 15:50:04,679:INFO:Checking exceptions
2024-05-24 15:50:04,684:INFO:Preloading libraries
2024-05-24 15:50:04,689:INFO:Copying training dataset
2024-05-24 15:50:04,689:INFO:Plot type: pipeline
2024-05-24 15:50:04,837:INFO:Visual Rendered Successfully
2024-05-24 15:50:04,998:INFO:plot_model() successfully completed......................................
2024-05-24 15:50:13,732:INFO:Initializing plot_model()
2024-05-24 15:50:13,732:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=AdaBoostRegressor(random_state=7578), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C67BBAC0>, system=True)
2024-05-24 15:50:13,732:INFO:Checking exceptions
2024-05-24 15:50:13,738:INFO:Preloading libraries
2024-05-24 15:50:13,743:INFO:Copying training dataset
2024-05-24 15:50:13,743:INFO:Plot type: vc
2024-05-24 15:50:13,743:INFO:Determining param_name
2024-05-24 15:50:13,744:INFO:param_name: n_estimators
2024-05-24 15:50:14,241:INFO:Fitting Model
2024-05-24 15:51:11,291:INFO:Initializing evaluate_model()
2024-05-24 15:51:11,292:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, estimator=AdaBoostRegressor(random_state=2136), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 15:51:11,306:INFO:Initializing plot_model()
2024-05-24 15:51:11,306:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=AdaBoostRegressor(random_state=2136), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C00962F0>, system=True)
2024-05-24 15:51:11,306:INFO:Checking exceptions
2024-05-24 15:51:11,311:INFO:Preloading libraries
2024-05-24 15:51:11,315:INFO:Copying training dataset
2024-05-24 15:51:11,315:INFO:Plot type: pipeline
2024-05-24 15:51:11,517:INFO:Visual Rendered Successfully
2024-05-24 15:51:11,707:INFO:plot_model() successfully completed......................................
2024-05-24 15:51:15,946:INFO:PyCaret RegressionExperiment
2024-05-24 15:51:15,946:INFO:Logging name: reg-default-name
2024-05-24 15:51:15,947:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:51:15,947:INFO:version 3.3.2
2024-05-24 15:51:15,947:INFO:Initializing setup()
2024-05-24 15:51:15,947:INFO:self.USI: d7eb
2024-05-24 15:51:15,947:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:51:15,947:INFO:Checking environment
2024-05-24 15:51:15,947:INFO:python_version: 3.10.14
2024-05-24 15:51:15,947:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:51:15,947:INFO:machine: AMD64
2024-05-24 15:51:15,947:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:51:15,947:INFO:Memory: svmem(total=16541802496, available=4073873408, percent=75.4, used=12467929088, free=4073873408)
2024-05-24 15:51:15,947:INFO:Physical Core: 6
2024-05-24 15:51:15,947:INFO:Logical Core: 12
2024-05-24 15:51:15,947:INFO:Checking libraries
2024-05-24 15:51:15,947:INFO:System:
2024-05-24 15:51:15,948:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:51:15,948:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:51:15,948:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:51:15,948:INFO:PyCaret required dependencies:
2024-05-24 15:51:15,948:INFO:                 pip: 24.0
2024-05-24 15:51:15,948:INFO:          setuptools: 69.5.1
2024-05-24 15:51:15,948:INFO:             pycaret: 3.3.2
2024-05-24 15:51:15,948:INFO:             IPython: 8.20.0
2024-05-24 15:51:15,948:INFO:          ipywidgets: 8.1.2
2024-05-24 15:51:15,948:INFO:                tqdm: 4.66.4
2024-05-24 15:51:15,948:INFO:               numpy: 1.26.4
2024-05-24 15:51:15,948:INFO:              pandas: 2.1.4
2024-05-24 15:51:15,948:INFO:              jinja2: 3.1.3
2024-05-24 15:51:15,948:INFO:               scipy: 1.11.4
2024-05-24 15:51:15,948:INFO:              joblib: 1.3.2
2024-05-24 15:51:15,948:INFO:             sklearn: 1.4.2
2024-05-24 15:51:15,948:INFO:                pyod: 1.1.3
2024-05-24 15:51:15,948:INFO:            imblearn: 0.12.2
2024-05-24 15:51:15,948:INFO:   category_encoders: 2.6.3
2024-05-24 15:51:15,948:INFO:            lightgbm: 4.3.0
2024-05-24 15:51:15,948:INFO:               numba: 0.59.1
2024-05-24 15:51:15,948:INFO:            requests: 2.32.2
2024-05-24 15:51:15,948:INFO:          matplotlib: 3.7.5
2024-05-24 15:51:15,948:INFO:          scikitplot: 0.3.7
2024-05-24 15:51:15,948:INFO:         yellowbrick: 1.5
2024-05-24 15:51:15,948:INFO:              plotly: 5.22.0
2024-05-24 15:51:15,948:INFO:    plotly-resampler: Not installed
2024-05-24 15:51:15,948:INFO:             kaleido: 0.2.1
2024-05-24 15:51:15,948:INFO:           schemdraw: 0.15
2024-05-24 15:51:15,950:INFO:         statsmodels: 0.14.2
2024-05-24 15:51:15,950:INFO:              sktime: 0.26.0
2024-05-24 15:51:15,950:INFO:               tbats: 1.1.3
2024-05-24 15:51:15,950:INFO:            pmdarima: 2.0.4
2024-05-24 15:51:15,950:INFO:              psutil: 5.9.0
2024-05-24 15:51:15,950:INFO:          markupsafe: 2.1.3
2024-05-24 15:51:15,950:INFO:             pickle5: Not installed
2024-05-24 15:51:15,950:INFO:         cloudpickle: 3.0.0
2024-05-24 15:51:15,950:INFO:         deprecation: 2.1.0
2024-05-24 15:51:15,950:INFO:              xxhash: 3.4.1
2024-05-24 15:51:15,950:INFO:           wurlitzer: Not installed
2024-05-24 15:51:15,950:INFO:PyCaret optional dependencies:
2024-05-24 15:51:15,950:INFO:                shap: Not installed
2024-05-24 15:51:15,950:INFO:           interpret: Not installed
2024-05-24 15:51:15,950:INFO:                umap: Not installed
2024-05-24 15:51:15,950:INFO:     ydata_profiling: Not installed
2024-05-24 15:51:15,950:INFO:  explainerdashboard: Not installed
2024-05-24 15:51:15,950:INFO:             autoviz: Not installed
2024-05-24 15:51:15,950:INFO:           fairlearn: Not installed
2024-05-24 15:51:15,950:INFO:          deepchecks: Not installed
2024-05-24 15:51:15,950:INFO:             xgboost: Not installed
2024-05-24 15:51:15,950:INFO:            catboost: Not installed
2024-05-24 15:51:15,950:INFO:              kmodes: Not installed
2024-05-24 15:51:15,950:INFO:             mlxtend: Not installed
2024-05-24 15:51:15,951:INFO:       statsforecast: Not installed
2024-05-24 15:51:15,951:INFO:        tune_sklearn: Not installed
2024-05-24 15:51:15,951:INFO:                 ray: Not installed
2024-05-24 15:51:15,951:INFO:            hyperopt: Not installed
2024-05-24 15:51:15,951:INFO:              optuna: Not installed
2024-05-24 15:51:15,951:INFO:               skopt: Not installed
2024-05-24 15:51:15,951:INFO:              mlflow: Not installed
2024-05-24 15:51:15,951:INFO:              gradio: Not installed
2024-05-24 15:51:15,951:INFO:             fastapi: Not installed
2024-05-24 15:51:15,951:INFO:             uvicorn: Not installed
2024-05-24 15:51:15,951:INFO:              m2cgen: Not installed
2024-05-24 15:51:15,952:INFO:           evidently: Not installed
2024-05-24 15:51:15,952:INFO:               fugue: Not installed
2024-05-24 15:51:15,952:INFO:           streamlit: Not installed
2024-05-24 15:51:15,952:INFO:             prophet: Not installed
2024-05-24 15:51:15,952:INFO:None
2024-05-24 15:51:15,952:INFO:Set up data.
2024-05-24 15:51:15,961:INFO:Set up folding strategy.
2024-05-24 15:51:15,962:INFO:Set up train/test split.
2024-05-24 15:51:15,969:INFO:Set up index.
2024-05-24 15:51:15,969:INFO:Assigning column types.
2024-05-24 15:51:15,974:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:51:15,975:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:51:15,979:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:51:15,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,096:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,097:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,101:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,106:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,168:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,215:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:51:16,220:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,287:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,333:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,339:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,451:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,452:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:51:16,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,523:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,645:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,691:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:51:16,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,916:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:51:16,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:16,917:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:51:16,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:17,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:51:17,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,147:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:51:17,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:17,379:INFO:Preparing preprocessing pipeline...
2024-05-24 15:51:17,379:INFO:Set up simple imputation.
2024-05-24 15:51:17,384:INFO:Set up encoding of ordinal features.
2024-05-24 15:51:17,389:INFO:Set up encoding of categorical features.
2024-05-24 15:51:17,390:INFO:Set up polynomial features.
2024-05-24 15:51:17,390:INFO:Set up removing multicollinearity.
2024-05-24 15:51:18,506:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:51:18,568:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:51:18,568:INFO:Creating final display dataframe.
2024-05-24 15:51:19,617:INFO:Setup _display_container:                     Description             Value
0                    Session id              6314
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (205, 453)
5   Transformed train set shape        (143, 453)
6    Transformed test set shape         (62, 453)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              d7eb
2024-05-24 15:51:19,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:19,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:19,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:19,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:51:19,851:INFO:setup() successfully completed in 3.91s...............
2024-05-24 15:51:19,877:INFO:Initializing compare_models()
2024-05-24 15:51:19,878:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:51:19,878:INFO:Checking exceptions
2024-05-24 15:51:19,881:INFO:Preparing display monitor
2024-05-24 15:51:19,907:INFO:Initializing Linear Regression
2024-05-24 15:51:19,908:INFO:Total runtime is 1.6542275746663413e-05 minutes
2024-05-24 15:51:19,911:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:19,911:INFO:Initializing create_model()
2024-05-24 15:51:19,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:19,912:INFO:Checking exceptions
2024-05-24 15:51:19,912:INFO:Importing libraries
2024-05-24 15:51:19,912:INFO:Copying training dataset
2024-05-24 15:51:19,919:INFO:Defining folds
2024-05-24 15:51:19,919:INFO:Declaring metric variables
2024-05-24 15:51:19,924:INFO:Importing untrained model
2024-05-24 15:51:19,927:INFO:Linear Regression Imported successfully
2024-05-24 15:51:19,938:INFO:Starting cross validation
2024-05-24 15:51:19,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:25,409:INFO:Calculating mean and std
2024-05-24 15:51:25,411:INFO:Creating metrics dataframe
2024-05-24 15:51:25,414:INFO:Uploading results into container
2024-05-24 15:51:25,415:INFO:Uploading model into container now
2024-05-24 15:51:25,415:INFO:_master_model_container: 1
2024-05-24 15:51:25,415:INFO:_display_container: 2
2024-05-24 15:51:25,416:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:51:25,416:INFO:create_model() successfully completed......................................
2024-05-24 15:51:25,641:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:25,641:INFO:Creating metrics dataframe
2024-05-24 15:51:25,648:INFO:Initializing Lasso Regression
2024-05-24 15:51:25,648:INFO:Total runtime is 0.09568807681401571 minutes
2024-05-24 15:51:25,653:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:25,653:INFO:Initializing create_model()
2024-05-24 15:51:25,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:25,654:INFO:Checking exceptions
2024-05-24 15:51:25,654:INFO:Importing libraries
2024-05-24 15:51:25,654:INFO:Copying training dataset
2024-05-24 15:51:25,660:INFO:Defining folds
2024-05-24 15:51:25,660:INFO:Declaring metric variables
2024-05-24 15:51:25,665:INFO:Importing untrained model
2024-05-24 15:51:25,669:INFO:Lasso Regression Imported successfully
2024-05-24 15:51:25,678:INFO:Starting cross validation
2024-05-24 15:51:25,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:27,305:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.379e+07, tolerance: 7.018e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,341:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+07, tolerance: 7.934e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,423:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+07, tolerance: 7.902e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,460:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e+07, tolerance: 7.630e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,468:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+07, tolerance: 6.998e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,472:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+07, tolerance: 8.087e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,477:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e+07, tolerance: 7.628e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:27,489:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e+07, tolerance: 7.332e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:29,066:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+07, tolerance: 7.462e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:29,143:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+07, tolerance: 6.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:29,200:INFO:Calculating mean and std
2024-05-24 15:51:29,201:INFO:Creating metrics dataframe
2024-05-24 15:51:29,203:INFO:Uploading results into container
2024-05-24 15:51:29,204:INFO:Uploading model into container now
2024-05-24 15:51:29,205:INFO:_master_model_container: 2
2024-05-24 15:51:29,205:INFO:_display_container: 2
2024-05-24 15:51:29,205:INFO:Lasso(random_state=6314)
2024-05-24 15:51:29,205:INFO:create_model() successfully completed......................................
2024-05-24 15:51:29,388:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:29,388:INFO:Creating metrics dataframe
2024-05-24 15:51:29,395:INFO:Initializing Ridge Regression
2024-05-24 15:51:29,395:INFO:Total runtime is 0.15813152790069582 minutes
2024-05-24 15:51:29,399:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:29,400:INFO:Initializing create_model()
2024-05-24 15:51:29,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:29,400:INFO:Checking exceptions
2024-05-24 15:51:29,400:INFO:Importing libraries
2024-05-24 15:51:29,400:INFO:Copying training dataset
2024-05-24 15:51:29,409:INFO:Defining folds
2024-05-24 15:51:29,409:INFO:Declaring metric variables
2024-05-24 15:51:29,413:INFO:Importing untrained model
2024-05-24 15:51:29,418:INFO:Ridge Regression Imported successfully
2024-05-24 15:51:29,428:INFO:Starting cross validation
2024-05-24 15:51:29,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:30,841:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:30,878:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=1.18175e-17): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 15:51:30,916:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:30,919:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:30,990:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:30,991:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:31,006:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:31,011:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:31,016:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:31,050:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:51:31,128:INFO:Calculating mean and std
2024-05-24 15:51:31,129:INFO:Creating metrics dataframe
2024-05-24 15:51:31,132:INFO:Uploading results into container
2024-05-24 15:51:31,132:INFO:Uploading model into container now
2024-05-24 15:51:31,133:INFO:_master_model_container: 3
2024-05-24 15:51:31,133:INFO:_display_container: 2
2024-05-24 15:51:31,133:INFO:Ridge(random_state=6314)
2024-05-24 15:51:31,134:INFO:create_model() successfully completed......................................
2024-05-24 15:51:31,335:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:31,335:INFO:Creating metrics dataframe
2024-05-24 15:51:31,342:INFO:Initializing Elastic Net
2024-05-24 15:51:31,342:INFO:Total runtime is 0.19058696031570438 minutes
2024-05-24 15:51:31,346:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:31,347:INFO:Initializing create_model()
2024-05-24 15:51:31,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:31,347:INFO:Checking exceptions
2024-05-24 15:51:31,347:INFO:Importing libraries
2024-05-24 15:51:31,347:INFO:Copying training dataset
2024-05-24 15:51:31,353:INFO:Defining folds
2024-05-24 15:51:31,353:INFO:Declaring metric variables
2024-05-24 15:51:31,358:INFO:Importing untrained model
2024-05-24 15:51:31,363:INFO:Elastic Net Imported successfully
2024-05-24 15:51:31,371:INFO:Starting cross validation
2024-05-24 15:51:31,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:32,875:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.156e+07, tolerance: 7.018e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:32,912:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.197e+07, tolerance: 7.934e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:32,946:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.205e+07, tolerance: 7.462e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:32,953:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.235e+07, tolerance: 6.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:32,999:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.034e+07, tolerance: 8.087e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:33,051:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.497e+07, tolerance: 7.332e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:33,052:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.731e+07, tolerance: 7.630e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:33,052:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.497e+07, tolerance: 7.628e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:33,060:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.448e+07, tolerance: 7.902e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:33,107:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.401e+07, tolerance: 6.998e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:51:33,218:INFO:Calculating mean and std
2024-05-24 15:51:33,224:INFO:Creating metrics dataframe
2024-05-24 15:51:33,226:INFO:Uploading results into container
2024-05-24 15:51:33,227:INFO:Uploading model into container now
2024-05-24 15:51:33,227:INFO:_master_model_container: 4
2024-05-24 15:51:33,227:INFO:_display_container: 2
2024-05-24 15:51:33,227:INFO:ElasticNet(random_state=6314)
2024-05-24 15:51:33,227:INFO:create_model() successfully completed......................................
2024-05-24 15:51:33,434:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:33,435:INFO:Creating metrics dataframe
2024-05-24 15:51:33,445:INFO:Initializing Least Angle Regression
2024-05-24 15:51:33,445:INFO:Total runtime is 0.2256316939989726 minutes
2024-05-24 15:51:33,449:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:33,449:INFO:Initializing create_model()
2024-05-24 15:51:33,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:33,451:INFO:Checking exceptions
2024-05-24 15:51:33,451:INFO:Importing libraries
2024-05-24 15:51:33,451:INFO:Copying training dataset
2024-05-24 15:51:33,458:INFO:Defining folds
2024-05-24 15:51:33,458:INFO:Declaring metric variables
2024-05-24 15:51:33,463:INFO:Importing untrained model
2024-05-24 15:51:33,466:INFO:Least Angle Regression Imported successfully
2024-05-24 15:51:33,475:INFO:Starting cross validation
2024-05-24 15:51:33,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:34,964:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=3.416e+05, with an active set of 112 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:51:35,064:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=3.083e+06, with an active set of 115 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:51:35,138:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=5.312e+05, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:51:35,185:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.141e+11, with an active set of 114 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:51:35,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-05-24 15:51:35,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-05-24 15:51:35,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-05-24 15:51:35,291:INFO:Calculating mean and std
2024-05-24 15:51:35,293:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-24 15:51:35,293:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2024-05-24 15:51:35,294:INFO:Creating metrics dataframe
2024-05-24 15:51:35,296:INFO:Uploading results into container
2024-05-24 15:51:35,296:INFO:Uploading model into container now
2024-05-24 15:51:35,297:INFO:_master_model_container: 5
2024-05-24 15:51:35,297:INFO:_display_container: 2
2024-05-24 15:51:35,297:INFO:Lars(random_state=6314)
2024-05-24 15:51:35,297:INFO:create_model() successfully completed......................................
2024-05-24 15:51:35,480:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:35,481:INFO:Creating metrics dataframe
2024-05-24 15:51:35,489:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:51:35,489:INFO:Total runtime is 0.25969368616739913 minutes
2024-05-24 15:51:35,494:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:35,494:INFO:Initializing create_model()
2024-05-24 15:51:35,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:35,494:INFO:Checking exceptions
2024-05-24 15:51:35,494:INFO:Importing libraries
2024-05-24 15:51:35,494:INFO:Copying training dataset
2024-05-24 15:51:35,501:INFO:Defining folds
2024-05-24 15:51:35,501:INFO:Declaring metric variables
2024-05-24 15:51:35,505:INFO:Importing untrained model
2024-05-24 15:51:35,509:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:51:35,517:INFO:Starting cross validation
2024-05-24 15:51:35,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:37,133:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.209e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:51:37,134:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=1.205e+00, with an active set of 93 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:51:37,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 243 iterations, alpha=1.204e+00, previous alpha=1.181e+00, with an active set of 94 regressors.
  warnings.warn(

2024-05-24 15:51:37,408:INFO:Calculating mean and std
2024-05-24 15:51:37,409:INFO:Creating metrics dataframe
2024-05-24 15:51:37,411:INFO:Uploading results into container
2024-05-24 15:51:37,412:INFO:Uploading model into container now
2024-05-24 15:51:37,412:INFO:_master_model_container: 6
2024-05-24 15:51:37,412:INFO:_display_container: 2
2024-05-24 15:51:37,413:INFO:LassoLars(random_state=6314)
2024-05-24 15:51:37,413:INFO:create_model() successfully completed......................................
2024-05-24 15:51:37,605:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:37,605:INFO:Creating metrics dataframe
2024-05-24 15:51:37,613:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:51:37,613:INFO:Total runtime is 0.2951042453447978 minutes
2024-05-24 15:51:37,617:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:37,618:INFO:Initializing create_model()
2024-05-24 15:51:37,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:37,618:INFO:Checking exceptions
2024-05-24 15:51:37,618:INFO:Importing libraries
2024-05-24 15:51:37,619:INFO:Copying training dataset
2024-05-24 15:51:37,625:INFO:Defining folds
2024-05-24 15:51:37,625:INFO:Declaring metric variables
2024-05-24 15:51:37,630:INFO:Importing untrained model
2024-05-24 15:51:37,634:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:51:37,644:INFO:Starting cross validation
2024-05-24 15:51:37,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:39,453:INFO:Calculating mean and std
2024-05-24 15:51:39,454:INFO:Creating metrics dataframe
2024-05-24 15:51:39,456:INFO:Uploading results into container
2024-05-24 15:51:39,456:INFO:Uploading model into container now
2024-05-24 15:51:39,457:INFO:_master_model_container: 7
2024-05-24 15:51:39,457:INFO:_display_container: 2
2024-05-24 15:51:39,457:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:51:39,457:INFO:create_model() successfully completed......................................
2024-05-24 15:51:39,641:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:39,641:INFO:Creating metrics dataframe
2024-05-24 15:51:39,651:INFO:Initializing Bayesian Ridge
2024-05-24 15:51:39,651:INFO:Total runtime is 0.3290739178657532 minutes
2024-05-24 15:51:39,655:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:39,655:INFO:Initializing create_model()
2024-05-24 15:51:39,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:39,656:INFO:Checking exceptions
2024-05-24 15:51:39,656:INFO:Importing libraries
2024-05-24 15:51:39,656:INFO:Copying training dataset
2024-05-24 15:51:39,663:INFO:Defining folds
2024-05-24 15:51:39,663:INFO:Declaring metric variables
2024-05-24 15:51:39,666:INFO:Importing untrained model
2024-05-24 15:51:39,672:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:51:39,680:INFO:Starting cross validation
2024-05-24 15:51:39,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:41,476:INFO:Calculating mean and std
2024-05-24 15:51:41,478:INFO:Creating metrics dataframe
2024-05-24 15:51:41,480:INFO:Uploading results into container
2024-05-24 15:51:41,480:INFO:Uploading model into container now
2024-05-24 15:51:41,481:INFO:_master_model_container: 8
2024-05-24 15:51:41,481:INFO:_display_container: 2
2024-05-24 15:51:41,481:INFO:BayesianRidge()
2024-05-24 15:51:41,482:INFO:create_model() successfully completed......................................
2024-05-24 15:51:41,667:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:41,667:INFO:Creating metrics dataframe
2024-05-24 15:51:41,676:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:51:41,676:INFO:Total runtime is 0.3628239631652832 minutes
2024-05-24 15:51:41,680:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:41,681:INFO:Initializing create_model()
2024-05-24 15:51:41,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:41,681:INFO:Checking exceptions
2024-05-24 15:51:41,681:INFO:Importing libraries
2024-05-24 15:51:41,681:INFO:Copying training dataset
2024-05-24 15:51:41,688:INFO:Defining folds
2024-05-24 15:51:41,688:INFO:Declaring metric variables
2024-05-24 15:51:41,694:INFO:Importing untrained model
2024-05-24 15:51:41,698:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:51:41,706:INFO:Starting cross validation
2024-05-24 15:51:41,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:43,453:INFO:Calculating mean and std
2024-05-24 15:51:43,455:INFO:Creating metrics dataframe
2024-05-24 15:51:43,457:INFO:Uploading results into container
2024-05-24 15:51:43,457:INFO:Uploading model into container now
2024-05-24 15:51:43,458:INFO:_master_model_container: 9
2024-05-24 15:51:43,458:INFO:_display_container: 2
2024-05-24 15:51:43,458:INFO:PassiveAggressiveRegressor(random_state=6314)
2024-05-24 15:51:43,458:INFO:create_model() successfully completed......................................
2024-05-24 15:51:43,645:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:43,645:INFO:Creating metrics dataframe
2024-05-24 15:51:43,656:INFO:Initializing Huber Regressor
2024-05-24 15:51:43,656:INFO:Total runtime is 0.39581413666407267 minutes
2024-05-24 15:51:43,660:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:43,661:INFO:Initializing create_model()
2024-05-24 15:51:43,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:43,661:INFO:Checking exceptions
2024-05-24 15:51:43,661:INFO:Importing libraries
2024-05-24 15:51:43,661:INFO:Copying training dataset
2024-05-24 15:51:43,668:INFO:Defining folds
2024-05-24 15:51:43,668:INFO:Declaring metric variables
2024-05-24 15:51:43,674:INFO:Importing untrained model
2024-05-24 15:51:43,679:INFO:Huber Regressor Imported successfully
2024-05-24 15:51:43,689:INFO:Starting cross validation
2024-05-24 15:51:43,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:45,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:51:45,358:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:51:45,454:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:51:45,469:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:51:45,488:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:51:45,538:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:51:45,617:INFO:Calculating mean and std
2024-05-24 15:51:45,619:INFO:Creating metrics dataframe
2024-05-24 15:51:45,621:INFO:Uploading results into container
2024-05-24 15:51:45,621:INFO:Uploading model into container now
2024-05-24 15:51:45,622:INFO:_master_model_container: 10
2024-05-24 15:51:45,622:INFO:_display_container: 2
2024-05-24 15:51:45,623:INFO:HuberRegressor()
2024-05-24 15:51:45,623:INFO:create_model() successfully completed......................................
2024-05-24 15:51:45,823:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:45,824:INFO:Creating metrics dataframe
2024-05-24 15:51:45,835:INFO:Initializing K Neighbors Regressor
2024-05-24 15:51:45,837:INFO:Total runtime is 0.4321620583534241 minutes
2024-05-24 15:51:45,841:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:45,841:INFO:Initializing create_model()
2024-05-24 15:51:45,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:45,842:INFO:Checking exceptions
2024-05-24 15:51:45,842:INFO:Importing libraries
2024-05-24 15:51:45,842:INFO:Copying training dataset
2024-05-24 15:51:45,848:INFO:Defining folds
2024-05-24 15:51:45,848:INFO:Declaring metric variables
2024-05-24 15:51:45,852:INFO:Importing untrained model
2024-05-24 15:51:45,858:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:51:45,865:INFO:Starting cross validation
2024-05-24 15:51:45,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:47,791:INFO:Calculating mean and std
2024-05-24 15:51:47,792:INFO:Creating metrics dataframe
2024-05-24 15:51:47,794:INFO:Uploading results into container
2024-05-24 15:51:47,795:INFO:Uploading model into container now
2024-05-24 15:51:47,795:INFO:_master_model_container: 11
2024-05-24 15:51:47,795:INFO:_display_container: 2
2024-05-24 15:51:47,796:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:51:47,796:INFO:create_model() successfully completed......................................
2024-05-24 15:51:47,994:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:47,995:INFO:Creating metrics dataframe
2024-05-24 15:51:48,008:INFO:Initializing Decision Tree Regressor
2024-05-24 15:51:48,008:INFO:Total runtime is 0.4683495759963989 minutes
2024-05-24 15:51:48,013:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:48,014:INFO:Initializing create_model()
2024-05-24 15:51:48,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:48,014:INFO:Checking exceptions
2024-05-24 15:51:48,014:INFO:Importing libraries
2024-05-24 15:51:48,014:INFO:Copying training dataset
2024-05-24 15:51:48,023:INFO:Defining folds
2024-05-24 15:51:48,023:INFO:Declaring metric variables
2024-05-24 15:51:48,027:INFO:Importing untrained model
2024-05-24 15:51:48,033:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:51:48,041:INFO:Starting cross validation
2024-05-24 15:51:48,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:50,022:INFO:Calculating mean and std
2024-05-24 15:51:50,024:INFO:Creating metrics dataframe
2024-05-24 15:51:50,027:INFO:Uploading results into container
2024-05-24 15:51:50,029:INFO:Uploading model into container now
2024-05-24 15:51:50,029:INFO:_master_model_container: 12
2024-05-24 15:51:50,029:INFO:_display_container: 2
2024-05-24 15:51:50,030:INFO:DecisionTreeRegressor(random_state=6314)
2024-05-24 15:51:50,030:INFO:create_model() successfully completed......................................
2024-05-24 15:51:50,233:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:50,234:INFO:Creating metrics dataframe
2024-05-24 15:51:50,246:INFO:Initializing Random Forest Regressor
2024-05-24 15:51:50,247:INFO:Total runtime is 0.5056641062100729 minutes
2024-05-24 15:51:50,250:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:50,251:INFO:Initializing create_model()
2024-05-24 15:51:50,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:50,252:INFO:Checking exceptions
2024-05-24 15:51:50,252:INFO:Importing libraries
2024-05-24 15:51:50,252:INFO:Copying training dataset
2024-05-24 15:51:50,258:INFO:Defining folds
2024-05-24 15:51:50,259:INFO:Declaring metric variables
2024-05-24 15:51:50,263:INFO:Importing untrained model
2024-05-24 15:51:50,268:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:51:50,278:INFO:Starting cross validation
2024-05-24 15:51:50,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:52,820:INFO:Calculating mean and std
2024-05-24 15:51:52,821:INFO:Creating metrics dataframe
2024-05-24 15:51:52,824:INFO:Uploading results into container
2024-05-24 15:51:52,824:INFO:Uploading model into container now
2024-05-24 15:51:52,825:INFO:_master_model_container: 13
2024-05-24 15:51:52,825:INFO:_display_container: 2
2024-05-24 15:51:52,825:INFO:RandomForestRegressor(n_jobs=-1, random_state=6314)
2024-05-24 15:51:52,827:INFO:create_model() successfully completed......................................
2024-05-24 15:51:53,035:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:53,036:INFO:Creating metrics dataframe
2024-05-24 15:51:53,055:INFO:Initializing Extra Trees Regressor
2024-05-24 15:51:53,055:INFO:Total runtime is 0.5524603843688966 minutes
2024-05-24 15:51:53,059:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:53,060:INFO:Initializing create_model()
2024-05-24 15:51:53,060:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:53,060:INFO:Checking exceptions
2024-05-24 15:51:53,060:INFO:Importing libraries
2024-05-24 15:51:53,060:INFO:Copying training dataset
2024-05-24 15:51:53,069:INFO:Defining folds
2024-05-24 15:51:53,070:INFO:Declaring metric variables
2024-05-24 15:51:53,075:INFO:Importing untrained model
2024-05-24 15:51:53,079:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:51:53,088:INFO:Starting cross validation
2024-05-24 15:51:53,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:55,513:INFO:Calculating mean and std
2024-05-24 15:51:55,515:INFO:Creating metrics dataframe
2024-05-24 15:51:55,518:INFO:Uploading results into container
2024-05-24 15:51:55,520:INFO:Uploading model into container now
2024-05-24 15:51:55,520:INFO:_master_model_container: 14
2024-05-24 15:51:55,520:INFO:_display_container: 2
2024-05-24 15:51:55,521:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6314)
2024-05-24 15:51:55,521:INFO:create_model() successfully completed......................................
2024-05-24 15:51:55,741:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:55,741:INFO:Creating metrics dataframe
2024-05-24 15:51:55,754:INFO:Initializing AdaBoost Regressor
2024-05-24 15:51:55,755:INFO:Total runtime is 0.5974625945091249 minutes
2024-05-24 15:51:55,759:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:55,760:INFO:Initializing create_model()
2024-05-24 15:51:55,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:55,761:INFO:Checking exceptions
2024-05-24 15:51:55,761:INFO:Importing libraries
2024-05-24 15:51:55,761:INFO:Copying training dataset
2024-05-24 15:51:55,768:INFO:Defining folds
2024-05-24 15:51:55,768:INFO:Declaring metric variables
2024-05-24 15:51:55,774:INFO:Importing untrained model
2024-05-24 15:51:55,778:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:51:55,789:INFO:Starting cross validation
2024-05-24 15:51:55,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:51:57,889:INFO:Calculating mean and std
2024-05-24 15:51:57,890:INFO:Creating metrics dataframe
2024-05-24 15:51:57,892:INFO:Uploading results into container
2024-05-24 15:51:57,892:INFO:Uploading model into container now
2024-05-24 15:51:57,893:INFO:_master_model_container: 15
2024-05-24 15:51:57,893:INFO:_display_container: 2
2024-05-24 15:51:57,893:INFO:AdaBoostRegressor(random_state=6314)
2024-05-24 15:51:57,893:INFO:create_model() successfully completed......................................
2024-05-24 15:51:58,092:INFO:SubProcess create_model() end ==================================
2024-05-24 15:51:58,092:INFO:Creating metrics dataframe
2024-05-24 15:51:58,105:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:51:58,105:INFO:Total runtime is 0.6366391380627952 minutes
2024-05-24 15:51:58,110:INFO:SubProcess create_model() called ==================================
2024-05-24 15:51:58,111:INFO:Initializing create_model()
2024-05-24 15:51:58,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:51:58,111:INFO:Checking exceptions
2024-05-24 15:51:58,111:INFO:Importing libraries
2024-05-24 15:51:58,111:INFO:Copying training dataset
2024-05-24 15:51:58,118:INFO:Defining folds
2024-05-24 15:51:58,118:INFO:Declaring metric variables
2024-05-24 15:51:58,123:INFO:Importing untrained model
2024-05-24 15:51:58,128:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:51:58,137:INFO:Starting cross validation
2024-05-24 15:51:58,155:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:52:00,347:INFO:Calculating mean and std
2024-05-24 15:52:00,349:INFO:Creating metrics dataframe
2024-05-24 15:52:00,351:INFO:Uploading results into container
2024-05-24 15:52:00,352:INFO:Uploading model into container now
2024-05-24 15:52:00,353:INFO:_master_model_container: 16
2024-05-24 15:52:00,353:INFO:_display_container: 2
2024-05-24 15:52:00,354:INFO:GradientBoostingRegressor(random_state=6314)
2024-05-24 15:52:00,354:INFO:create_model() successfully completed......................................
2024-05-24 15:52:00,552:INFO:SubProcess create_model() end ==================================
2024-05-24 15:52:00,553:INFO:Creating metrics dataframe
2024-05-24 15:52:00,565:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:52:00,566:INFO:Total runtime is 0.6776487549146017 minutes
2024-05-24 15:52:00,570:INFO:SubProcess create_model() called ==================================
2024-05-24 15:52:00,570:INFO:Initializing create_model()
2024-05-24 15:52:00,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:52:00,571:INFO:Checking exceptions
2024-05-24 15:52:00,571:INFO:Importing libraries
2024-05-24 15:52:00,571:INFO:Copying training dataset
2024-05-24 15:52:00,579:INFO:Defining folds
2024-05-24 15:52:00,579:INFO:Declaring metric variables
2024-05-24 15:52:00,583:INFO:Importing untrained model
2024-05-24 15:52:00,588:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:52:00,598:INFO:Starting cross validation
2024-05-24 15:52:00,609:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:52:03,404:INFO:Calculating mean and std
2024-05-24 15:52:03,406:INFO:Creating metrics dataframe
2024-05-24 15:52:03,410:INFO:Uploading results into container
2024-05-24 15:52:03,410:INFO:Uploading model into container now
2024-05-24 15:52:03,411:INFO:_master_model_container: 17
2024-05-24 15:52:03,411:INFO:_display_container: 2
2024-05-24 15:52:03,412:INFO:LGBMRegressor(n_jobs=-1, random_state=6314)
2024-05-24 15:52:03,412:INFO:create_model() successfully completed......................................
2024-05-24 15:52:03,638:INFO:SubProcess create_model() end ==================================
2024-05-24 15:52:03,638:INFO:Creating metrics dataframe
2024-05-24 15:52:03,657:INFO:Initializing Dummy Regressor
2024-05-24 15:52:03,657:INFO:Total runtime is 0.729161826769511 minutes
2024-05-24 15:52:03,662:INFO:SubProcess create_model() called ==================================
2024-05-24 15:52:03,663:INFO:Initializing create_model()
2024-05-24 15:52:03,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C872B340>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:52:03,663:INFO:Checking exceptions
2024-05-24 15:52:03,663:INFO:Importing libraries
2024-05-24 15:52:03,663:INFO:Copying training dataset
2024-05-24 15:52:03,674:INFO:Defining folds
2024-05-24 15:52:03,674:INFO:Declaring metric variables
2024-05-24 15:52:03,680:INFO:Importing untrained model
2024-05-24 15:52:03,686:INFO:Dummy Regressor Imported successfully
2024-05-24 15:52:03,698:INFO:Starting cross validation
2024-05-24 15:52:03,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:52:05,671:INFO:Calculating mean and std
2024-05-24 15:52:05,672:INFO:Creating metrics dataframe
2024-05-24 15:52:05,675:INFO:Uploading results into container
2024-05-24 15:52:05,676:INFO:Uploading model into container now
2024-05-24 15:52:05,676:INFO:_master_model_container: 18
2024-05-24 15:52:05,676:INFO:_display_container: 2
2024-05-24 15:52:05,678:INFO:DummyRegressor()
2024-05-24 15:52:05,678:INFO:create_model() successfully completed......................................
2024-05-24 15:52:05,884:INFO:SubProcess create_model() end ==================================
2024-05-24 15:52:05,884:INFO:Creating metrics dataframe
2024-05-24 15:52:05,898:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:52:05,908:INFO:Initializing create_model()
2024-05-24 15:52:05,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:52:05,908:INFO:Checking exceptions
2024-05-24 15:52:05,910:INFO:Importing libraries
2024-05-24 15:52:05,910:INFO:Copying training dataset
2024-05-24 15:52:05,917:INFO:Defining folds
2024-05-24 15:52:05,917:INFO:Declaring metric variables
2024-05-24 15:52:05,917:INFO:Importing untrained model
2024-05-24 15:52:05,917:INFO:Declaring custom model
2024-05-24 15:52:05,918:INFO:Huber Regressor Imported successfully
2024-05-24 15:52:05,928:INFO:Cross validation set to False
2024-05-24 15:52:05,928:INFO:Fitting Model
2024-05-24 15:52:06,891:INFO:HuberRegressor()
2024-05-24 15:52:06,892:INFO:create_model() successfully completed......................................
2024-05-24 15:52:07,116:INFO:_master_model_container: 18
2024-05-24 15:52:07,116:INFO:_display_container: 2
2024-05-24 15:52:07,116:INFO:HuberRegressor()
2024-05-24 15:52:07,116:INFO:compare_models() successfully completed......................................
2024-05-24 15:52:07,152:INFO:Initializing evaluate_model()
2024-05-24 15:52:07,152:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 15:52:07,166:INFO:Initializing plot_model()
2024-05-24 15:52:07,166:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, system=True)
2024-05-24 15:52:07,166:INFO:Checking exceptions
2024-05-24 15:52:07,170:INFO:Preloading libraries
2024-05-24 15:52:07,171:INFO:Copying training dataset
2024-05-24 15:52:07,171:INFO:Plot type: pipeline
2024-05-24 15:52:07,386:INFO:Visual Rendered Successfully
2024-05-24 15:52:07,595:INFO:plot_model() successfully completed......................................
2024-05-24 15:52:13,686:INFO:Initializing plot_model()
2024-05-24 15:52:13,686:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6E7D1E0>, system=True)
2024-05-24 15:52:13,686:INFO:Checking exceptions
2024-05-24 15:52:13,690:INFO:Preloading libraries
2024-05-24 15:52:13,691:INFO:Copying training dataset
2024-05-24 15:52:13,691:INFO:Plot type: learning
2024-05-24 15:52:14,086:INFO:Fitting Model
2024-05-24 15:52:14,228:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,229:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,233:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,238:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,251:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,261:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,261:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,348:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,359:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,375:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,443:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,451:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,486:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,521:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,522:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,578:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,608:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,623:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,781:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,801:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,808:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,816:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,851:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,873:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,903:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,923:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:14,947:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,033:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,037:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,087:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,092:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,116:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,136:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,139:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,179:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,185:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:52:15,220:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 15:52:15,394:INFO:Visual Rendered Successfully
2024-05-24 15:52:15,584:INFO:plot_model() successfully completed......................................
2024-05-24 15:53:15,005:INFO:PyCaret RegressionExperiment
2024-05-24 15:53:15,005:INFO:Logging name: reg-default-name
2024-05-24 15:53:15,005:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:53:15,005:INFO:version 3.3.2
2024-05-24 15:53:15,005:INFO:Initializing setup()
2024-05-24 15:53:15,005:INFO:self.USI: efea
2024-05-24 15:53:15,005:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:53:15,005:INFO:Checking environment
2024-05-24 15:53:15,005:INFO:python_version: 3.10.14
2024-05-24 15:53:15,005:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:53:15,005:INFO:machine: AMD64
2024-05-24 15:53:15,005:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:53:15,006:INFO:Memory: svmem(total=16541802496, available=2527563776, percent=84.7, used=14014238720, free=2527563776)
2024-05-24 15:53:15,006:INFO:Physical Core: 6
2024-05-24 15:53:15,006:INFO:Logical Core: 12
2024-05-24 15:53:15,006:INFO:Checking libraries
2024-05-24 15:53:15,006:INFO:System:
2024-05-24 15:53:15,006:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:53:15,006:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:53:15,007:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:53:15,007:INFO:PyCaret required dependencies:
2024-05-24 15:53:15,007:INFO:                 pip: 24.0
2024-05-24 15:53:15,007:INFO:          setuptools: 69.5.1
2024-05-24 15:53:15,007:INFO:             pycaret: 3.3.2
2024-05-24 15:53:15,007:INFO:             IPython: 8.20.0
2024-05-24 15:53:15,007:INFO:          ipywidgets: 8.1.2
2024-05-24 15:53:15,007:INFO:                tqdm: 4.66.4
2024-05-24 15:53:15,007:INFO:               numpy: 1.26.4
2024-05-24 15:53:15,007:INFO:              pandas: 2.1.4
2024-05-24 15:53:15,007:INFO:              jinja2: 3.1.3
2024-05-24 15:53:15,007:INFO:               scipy: 1.11.4
2024-05-24 15:53:15,007:INFO:              joblib: 1.3.2
2024-05-24 15:53:15,007:INFO:             sklearn: 1.4.2
2024-05-24 15:53:15,007:INFO:                pyod: 1.1.3
2024-05-24 15:53:15,007:INFO:            imblearn: 0.12.2
2024-05-24 15:53:15,007:INFO:   category_encoders: 2.6.3
2024-05-24 15:53:15,007:INFO:            lightgbm: 4.3.0
2024-05-24 15:53:15,007:INFO:               numba: 0.59.1
2024-05-24 15:53:15,008:INFO:            requests: 2.32.2
2024-05-24 15:53:15,008:INFO:          matplotlib: 3.7.5
2024-05-24 15:53:15,008:INFO:          scikitplot: 0.3.7
2024-05-24 15:53:15,008:INFO:         yellowbrick: 1.5
2024-05-24 15:53:15,008:INFO:              plotly: 5.22.0
2024-05-24 15:53:15,008:INFO:    plotly-resampler: Not installed
2024-05-24 15:53:15,008:INFO:             kaleido: 0.2.1
2024-05-24 15:53:15,008:INFO:           schemdraw: 0.15
2024-05-24 15:53:15,008:INFO:         statsmodels: 0.14.2
2024-05-24 15:53:15,008:INFO:              sktime: 0.26.0
2024-05-24 15:53:15,008:INFO:               tbats: 1.1.3
2024-05-24 15:53:15,008:INFO:            pmdarima: 2.0.4
2024-05-24 15:53:15,008:INFO:              psutil: 5.9.0
2024-05-24 15:53:15,008:INFO:          markupsafe: 2.1.3
2024-05-24 15:53:15,008:INFO:             pickle5: Not installed
2024-05-24 15:53:15,008:INFO:         cloudpickle: 3.0.0
2024-05-24 15:53:15,008:INFO:         deprecation: 2.1.0
2024-05-24 15:53:15,008:INFO:              xxhash: 3.4.1
2024-05-24 15:53:15,008:INFO:           wurlitzer: Not installed
2024-05-24 15:53:15,009:INFO:PyCaret optional dependencies:
2024-05-24 15:53:15,009:INFO:                shap: Not installed
2024-05-24 15:53:15,009:INFO:           interpret: Not installed
2024-05-24 15:53:15,009:INFO:                umap: Not installed
2024-05-24 15:53:15,009:INFO:     ydata_profiling: Not installed
2024-05-24 15:53:15,009:INFO:  explainerdashboard: Not installed
2024-05-24 15:53:15,009:INFO:             autoviz: Not installed
2024-05-24 15:53:15,009:INFO:           fairlearn: Not installed
2024-05-24 15:53:15,009:INFO:          deepchecks: Not installed
2024-05-24 15:53:15,009:INFO:             xgboost: Not installed
2024-05-24 15:53:15,009:INFO:            catboost: Not installed
2024-05-24 15:53:15,009:INFO:              kmodes: Not installed
2024-05-24 15:53:15,009:INFO:             mlxtend: Not installed
2024-05-24 15:53:15,009:INFO:       statsforecast: Not installed
2024-05-24 15:53:15,009:INFO:        tune_sklearn: Not installed
2024-05-24 15:53:15,009:INFO:                 ray: Not installed
2024-05-24 15:53:15,009:INFO:            hyperopt: Not installed
2024-05-24 15:53:15,009:INFO:              optuna: Not installed
2024-05-24 15:53:15,010:INFO:               skopt: Not installed
2024-05-24 15:53:15,010:INFO:              mlflow: Not installed
2024-05-24 15:53:15,010:INFO:              gradio: Not installed
2024-05-24 15:53:15,010:INFO:             fastapi: Not installed
2024-05-24 15:53:15,010:INFO:             uvicorn: Not installed
2024-05-24 15:53:15,010:INFO:              m2cgen: Not installed
2024-05-24 15:53:15,010:INFO:           evidently: Not installed
2024-05-24 15:53:15,010:INFO:               fugue: Not installed
2024-05-24 15:53:15,010:INFO:           streamlit: Not installed
2024-05-24 15:53:15,010:INFO:             prophet: Not installed
2024-05-24 15:53:15,010:INFO:None
2024-05-24 15:53:15,010:INFO:Set up data.
2024-05-24 15:53:15,019:INFO:Set up folding strategy.
2024-05-24 15:53:15,020:INFO:Set up train/test split.
2024-05-24 15:53:15,025:INFO:Set up index.
2024-05-24 15:53:15,026:INFO:Assigning column types.
2024-05-24 15:53:15,032:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:53:15,033:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,037:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,042:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,173:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,177:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,182:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,289:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:53:15,294:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,298:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,405:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,406:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,411:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,415:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,525:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:53:15,534:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,641:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,642:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,712:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,760:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:53:15,832:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:53:15,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:15,999:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:53:16,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:16,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,115:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:53:16,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,227:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:53:16,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,459:INFO:Preparing preprocessing pipeline...
2024-05-24 15:53:16,459:INFO:Set up simple imputation.
2024-05-24 15:53:16,459:INFO:Set up polynomial features.
2024-05-24 15:53:16,459:INFO:Set up removing multicollinearity.
2024-05-24 15:53:16,661:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:53:16,668:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'aspiration_std',
                                             'carbody', 'drivewheel_fwd',
                                             'wheelbase', 'carlength',
                                             'carwidth', 'carheight',
                                             'curbweight', 'enginetype',
                                             'cylindernumber', 'enginesize',
                                             'fuelsystem', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'hor...
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:53:16,668:INFO:Creating final display dataframe.
2024-05-24 15:53:16,863:INFO:Setup _display_container:                     Description             Value
0                    Session id              1315
1                        Target             price
2                   Target type        Regression
3           Original data shape         (202, 21)
4        Transformed data shape         (202, 46)
5   Transformed train set shape         (141, 46)
6    Transformed test set shape          (61, 46)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              efea
2024-05-24 15:53:16,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:16,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:17,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:17,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:53:17,103:INFO:setup() successfully completed in 2.11s...............
2024-05-24 15:53:17,214:INFO:Initializing compare_models()
2024-05-24 15:53:17,215:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:53:17,215:INFO:Checking exceptions
2024-05-24 15:53:17,218:INFO:Preparing display monitor
2024-05-24 15:53:17,246:INFO:Initializing Linear Regression
2024-05-24 15:53:17,246:INFO:Total runtime is 0.0 minutes
2024-05-24 15:53:17,251:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:17,251:INFO:Initializing create_model()
2024-05-24 15:53:17,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:17,251:INFO:Checking exceptions
2024-05-24 15:53:17,252:INFO:Importing libraries
2024-05-24 15:53:17,252:INFO:Copying training dataset
2024-05-24 15:53:17,260:INFO:Defining folds
2024-05-24 15:53:17,260:INFO:Declaring metric variables
2024-05-24 15:53:17,266:INFO:Importing untrained model
2024-05-24 15:53:17,272:INFO:Linear Regression Imported successfully
2024-05-24 15:53:17,282:INFO:Starting cross validation
2024-05-24 15:53:17,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:17,592:INFO:Calculating mean and std
2024-05-24 15:53:17,592:INFO:Creating metrics dataframe
2024-05-24 15:53:17,594:INFO:Uploading results into container
2024-05-24 15:53:17,595:INFO:Uploading model into container now
2024-05-24 15:53:17,595:INFO:_master_model_container: 1
2024-05-24 15:53:17,595:INFO:_display_container: 2
2024-05-24 15:53:17,596:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:53:17,596:INFO:create_model() successfully completed......................................
2024-05-24 15:53:17,829:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:17,829:INFO:Creating metrics dataframe
2024-05-24 15:53:17,838:INFO:Initializing Lasso Regression
2024-05-24 15:53:17,838:INFO:Total runtime is 0.009873513380686443 minutes
2024-05-24 15:53:17,843:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:17,844:INFO:Initializing create_model()
2024-05-24 15:53:17,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:17,844:INFO:Checking exceptions
2024-05-24 15:53:17,844:INFO:Importing libraries
2024-05-24 15:53:17,845:INFO:Copying training dataset
2024-05-24 15:53:17,851:INFO:Defining folds
2024-05-24 15:53:17,851:INFO:Declaring metric variables
2024-05-24 15:53:17,855:INFO:Importing untrained model
2024-05-24 15:53:17,859:INFO:Lasso Regression Imported successfully
2024-05-24 15:53:17,868:INFO:Starting cross validation
2024-05-24 15:53:17,875:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:18,146:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.069e+08, tolerance: 7.232e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,163:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+08, tolerance: 6.655e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,166:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+08, tolerance: 7.844e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,167:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+08, tolerance: 6.850e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e+08, tolerance: 7.386e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+08, tolerance: 6.669e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,184:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+08, tolerance: 7.686e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,184:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e+08, tolerance: 7.520e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,192:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e+08, tolerance: 7.167e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,194:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e+08, tolerance: 7.634e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:18,216:INFO:Calculating mean and std
2024-05-24 15:53:18,217:INFO:Creating metrics dataframe
2024-05-24 15:53:18,219:INFO:Uploading results into container
2024-05-24 15:53:18,219:INFO:Uploading model into container now
2024-05-24 15:53:18,220:INFO:_master_model_container: 2
2024-05-24 15:53:18,220:INFO:_display_container: 2
2024-05-24 15:53:18,220:INFO:Lasso(random_state=1315)
2024-05-24 15:53:18,220:INFO:create_model() successfully completed......................................
2024-05-24 15:53:18,408:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:18,408:INFO:Creating metrics dataframe
2024-05-24 15:53:18,416:INFO:Initializing Ridge Regression
2024-05-24 15:53:18,416:INFO:Total runtime is 0.019505234559377034 minutes
2024-05-24 15:53:18,421:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:18,422:INFO:Initializing create_model()
2024-05-24 15:53:18,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:18,422:INFO:Checking exceptions
2024-05-24 15:53:18,422:INFO:Importing libraries
2024-05-24 15:53:18,422:INFO:Copying training dataset
2024-05-24 15:53:18,429:INFO:Defining folds
2024-05-24 15:53:18,429:INFO:Declaring metric variables
2024-05-24 15:53:18,433:INFO:Importing untrained model
2024-05-24 15:53:18,439:INFO:Ridge Regression Imported successfully
2024-05-24 15:53:18,449:INFO:Starting cross validation
2024-05-24 15:53:18,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:18,744:INFO:Calculating mean and std
2024-05-24 15:53:18,745:INFO:Creating metrics dataframe
2024-05-24 15:53:18,748:INFO:Uploading results into container
2024-05-24 15:53:18,748:INFO:Uploading model into container now
2024-05-24 15:53:18,749:INFO:_master_model_container: 3
2024-05-24 15:53:18,749:INFO:_display_container: 2
2024-05-24 15:53:18,749:INFO:Ridge(random_state=1315)
2024-05-24 15:53:18,749:INFO:create_model() successfully completed......................................
2024-05-24 15:53:18,942:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:18,943:INFO:Creating metrics dataframe
2024-05-24 15:53:18,952:INFO:Initializing Elastic Net
2024-05-24 15:53:18,952:INFO:Total runtime is 0.028435866038004555 minutes
2024-05-24 15:53:18,955:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:18,956:INFO:Initializing create_model()
2024-05-24 15:53:18,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:18,956:INFO:Checking exceptions
2024-05-24 15:53:18,956:INFO:Importing libraries
2024-05-24 15:53:18,956:INFO:Copying training dataset
2024-05-24 15:53:18,963:INFO:Defining folds
2024-05-24 15:53:18,963:INFO:Declaring metric variables
2024-05-24 15:53:18,968:INFO:Importing untrained model
2024-05-24 15:53:18,971:INFO:Elastic Net Imported successfully
2024-05-24 15:53:18,980:INFO:Starting cross validation
2024-05-24 15:53:18,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:19,221:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+08, tolerance: 7.232e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,239:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e+08, tolerance: 6.850e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,240:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.030e+08, tolerance: 7.520e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,242:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+08, tolerance: 6.655e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,242:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e+08, tolerance: 7.386e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,245:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.057e+08, tolerance: 7.844e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,247:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+08, tolerance: 6.669e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,253:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.782e+08, tolerance: 7.167e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,257:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.885e+08, tolerance: 7.686e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,266:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e+08, tolerance: 7.634e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:53:19,280:INFO:Calculating mean and std
2024-05-24 15:53:19,281:INFO:Creating metrics dataframe
2024-05-24 15:53:19,283:INFO:Uploading results into container
2024-05-24 15:53:19,284:INFO:Uploading model into container now
2024-05-24 15:53:19,285:INFO:_master_model_container: 4
2024-05-24 15:53:19,285:INFO:_display_container: 2
2024-05-24 15:53:19,286:INFO:ElasticNet(random_state=1315)
2024-05-24 15:53:19,286:INFO:create_model() successfully completed......................................
2024-05-24 15:53:19,482:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:19,482:INFO:Creating metrics dataframe
2024-05-24 15:53:19,490:INFO:Initializing Least Angle Regression
2024-05-24 15:53:19,491:INFO:Total runtime is 0.03742134173711141 minutes
2024-05-24 15:53:19,495:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:19,496:INFO:Initializing create_model()
2024-05-24 15:53:19,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:19,496:INFO:Checking exceptions
2024-05-24 15:53:19,496:INFO:Importing libraries
2024-05-24 15:53:19,497:INFO:Copying training dataset
2024-05-24 15:53:19,502:INFO:Defining folds
2024-05-24 15:53:19,503:INFO:Declaring metric variables
2024-05-24 15:53:19,506:INFO:Importing untrained model
2024-05-24 15:53:19,510:INFO:Least Angle Regression Imported successfully
2024-05-24 15:53:19,518:INFO:Starting cross validation
2024-05-24 15:53:19,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:19,871:INFO:Calculating mean and std
2024-05-24 15:53:19,873:INFO:Creating metrics dataframe
2024-05-24 15:53:19,876:INFO:Uploading results into container
2024-05-24 15:53:19,877:INFO:Uploading model into container now
2024-05-24 15:53:19,877:INFO:_master_model_container: 5
2024-05-24 15:53:19,877:INFO:_display_container: 2
2024-05-24 15:53:19,878:INFO:Lars(random_state=1315)
2024-05-24 15:53:19,878:INFO:create_model() successfully completed......................................
2024-05-24 15:53:20,069:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:20,070:INFO:Creating metrics dataframe
2024-05-24 15:53:20,081:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:53:20,081:INFO:Total runtime is 0.047247672080993654 minutes
2024-05-24 15:53:20,085:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:20,085:INFO:Initializing create_model()
2024-05-24 15:53:20,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:20,086:INFO:Checking exceptions
2024-05-24 15:53:20,086:INFO:Importing libraries
2024-05-24 15:53:20,086:INFO:Copying training dataset
2024-05-24 15:53:20,092:INFO:Defining folds
2024-05-24 15:53:20,092:INFO:Declaring metric variables
2024-05-24 15:53:20,097:INFO:Importing untrained model
2024-05-24 15:53:20,101:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:53:20,110:INFO:Starting cross validation
2024-05-24 15:53:20,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:20,478:INFO:Calculating mean and std
2024-05-24 15:53:20,480:INFO:Creating metrics dataframe
2024-05-24 15:53:20,483:INFO:Uploading results into container
2024-05-24 15:53:20,483:INFO:Uploading model into container now
2024-05-24 15:53:20,484:INFO:_master_model_container: 6
2024-05-24 15:53:20,484:INFO:_display_container: 2
2024-05-24 15:53:20,485:INFO:LassoLars(random_state=1315)
2024-05-24 15:53:20,485:INFO:create_model() successfully completed......................................
2024-05-24 15:53:20,697:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:20,697:INFO:Creating metrics dataframe
2024-05-24 15:53:20,707:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:53:20,708:INFO:Total runtime is 0.05770076513290405 minutes
2024-05-24 15:53:20,713:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:20,713:INFO:Initializing create_model()
2024-05-24 15:53:20,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:20,714:INFO:Checking exceptions
2024-05-24 15:53:20,714:INFO:Importing libraries
2024-05-24 15:53:20,714:INFO:Copying training dataset
2024-05-24 15:53:20,721:INFO:Defining folds
2024-05-24 15:53:20,721:INFO:Declaring metric variables
2024-05-24 15:53:20,726:INFO:Importing untrained model
2024-05-24 15:53:20,732:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:53:20,740:INFO:Starting cross validation
2024-05-24 15:53:20,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:21,102:INFO:Calculating mean and std
2024-05-24 15:53:21,103:INFO:Creating metrics dataframe
2024-05-24 15:53:21,105:INFO:Uploading results into container
2024-05-24 15:53:21,106:INFO:Uploading model into container now
2024-05-24 15:53:21,106:INFO:_master_model_container: 7
2024-05-24 15:53:21,106:INFO:_display_container: 2
2024-05-24 15:53:21,107:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:53:21,107:INFO:create_model() successfully completed......................................
2024-05-24 15:53:21,334:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:21,334:INFO:Creating metrics dataframe
2024-05-24 15:53:21,344:INFO:Initializing Bayesian Ridge
2024-05-24 15:53:21,344:INFO:Total runtime is 0.06830031871795654 minutes
2024-05-24 15:53:21,349:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:21,349:INFO:Initializing create_model()
2024-05-24 15:53:21,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:21,350:INFO:Checking exceptions
2024-05-24 15:53:21,350:INFO:Importing libraries
2024-05-24 15:53:21,350:INFO:Copying training dataset
2024-05-24 15:53:21,355:INFO:Defining folds
2024-05-24 15:53:21,356:INFO:Declaring metric variables
2024-05-24 15:53:21,360:INFO:Importing untrained model
2024-05-24 15:53:21,365:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:53:21,372:INFO:Starting cross validation
2024-05-24 15:53:21,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:21,680:INFO:Calculating mean and std
2024-05-24 15:53:21,681:INFO:Creating metrics dataframe
2024-05-24 15:53:21,684:INFO:Uploading results into container
2024-05-24 15:53:21,684:INFO:Uploading model into container now
2024-05-24 15:53:21,685:INFO:_master_model_container: 8
2024-05-24 15:53:21,685:INFO:_display_container: 2
2024-05-24 15:53:21,685:INFO:BayesianRidge()
2024-05-24 15:53:21,685:INFO:create_model() successfully completed......................................
2024-05-24 15:53:21,888:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:21,888:INFO:Creating metrics dataframe
2024-05-24 15:53:21,899:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:53:21,899:INFO:Total runtime is 0.07755287090937296 minutes
2024-05-24 15:53:21,902:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:21,903:INFO:Initializing create_model()
2024-05-24 15:53:21,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:21,903:INFO:Checking exceptions
2024-05-24 15:53:21,903:INFO:Importing libraries
2024-05-24 15:53:21,903:INFO:Copying training dataset
2024-05-24 15:53:21,910:INFO:Defining folds
2024-05-24 15:53:21,910:INFO:Declaring metric variables
2024-05-24 15:53:21,916:INFO:Importing untrained model
2024-05-24 15:53:21,919:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:53:21,928:INFO:Starting cross validation
2024-05-24 15:53:21,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:22,309:INFO:Calculating mean and std
2024-05-24 15:53:22,311:INFO:Creating metrics dataframe
2024-05-24 15:53:22,314:INFO:Uploading results into container
2024-05-24 15:53:22,314:INFO:Uploading model into container now
2024-05-24 15:53:22,315:INFO:_master_model_container: 9
2024-05-24 15:53:22,315:INFO:_display_container: 2
2024-05-24 15:53:22,316:INFO:PassiveAggressiveRegressor(random_state=1315)
2024-05-24 15:53:22,316:INFO:create_model() successfully completed......................................
2024-05-24 15:53:22,531:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:22,531:INFO:Creating metrics dataframe
2024-05-24 15:53:22,540:INFO:Initializing Huber Regressor
2024-05-24 15:53:22,540:INFO:Total runtime is 0.08823169469833374 minutes
2024-05-24 15:53:22,545:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:22,546:INFO:Initializing create_model()
2024-05-24 15:53:22,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:22,546:INFO:Checking exceptions
2024-05-24 15:53:22,547:INFO:Importing libraries
2024-05-24 15:53:22,547:INFO:Copying training dataset
2024-05-24 15:53:22,553:INFO:Defining folds
2024-05-24 15:53:22,553:INFO:Declaring metric variables
2024-05-24 15:53:22,558:INFO:Importing untrained model
2024-05-24 15:53:22,564:INFO:Huber Regressor Imported successfully
2024-05-24 15:53:22,573:INFO:Starting cross validation
2024-05-24 15:53:22,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:22,869:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:53:22,891:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:53:22,896:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:53:22,907:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:53:22,964:INFO:Calculating mean and std
2024-05-24 15:53:22,965:INFO:Creating metrics dataframe
2024-05-24 15:53:22,967:INFO:Uploading results into container
2024-05-24 15:53:22,967:INFO:Uploading model into container now
2024-05-24 15:53:22,968:INFO:_master_model_container: 10
2024-05-24 15:53:22,968:INFO:_display_container: 2
2024-05-24 15:53:22,968:INFO:HuberRegressor()
2024-05-24 15:53:22,968:INFO:create_model() successfully completed......................................
2024-05-24 15:53:23,162:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:23,162:INFO:Creating metrics dataframe
2024-05-24 15:53:23,173:INFO:Initializing K Neighbors Regressor
2024-05-24 15:53:23,173:INFO:Total runtime is 0.09878590504328409 minutes
2024-05-24 15:53:23,177:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:23,179:INFO:Initializing create_model()
2024-05-24 15:53:23,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:23,179:INFO:Checking exceptions
2024-05-24 15:53:23,179:INFO:Importing libraries
2024-05-24 15:53:23,179:INFO:Copying training dataset
2024-05-24 15:53:23,185:INFO:Defining folds
2024-05-24 15:53:23,185:INFO:Declaring metric variables
2024-05-24 15:53:23,190:INFO:Importing untrained model
2024-05-24 15:53:23,194:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:53:23,208:INFO:Starting cross validation
2024-05-24 15:53:23,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:23,573:INFO:Calculating mean and std
2024-05-24 15:53:23,575:INFO:Creating metrics dataframe
2024-05-24 15:53:23,578:INFO:Uploading results into container
2024-05-24 15:53:23,579:INFO:Uploading model into container now
2024-05-24 15:53:23,580:INFO:_master_model_container: 11
2024-05-24 15:53:23,580:INFO:_display_container: 2
2024-05-24 15:53:23,580:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:53:23,580:INFO:create_model() successfully completed......................................
2024-05-24 15:53:23,763:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:23,764:INFO:Creating metrics dataframe
2024-05-24 15:53:23,774:INFO:Initializing Decision Tree Regressor
2024-05-24 15:53:23,774:INFO:Total runtime is 0.10880294243494669 minutes
2024-05-24 15:53:23,779:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:23,780:INFO:Initializing create_model()
2024-05-24 15:53:23,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:23,780:INFO:Checking exceptions
2024-05-24 15:53:23,780:INFO:Importing libraries
2024-05-24 15:53:23,780:INFO:Copying training dataset
2024-05-24 15:53:23,786:INFO:Defining folds
2024-05-24 15:53:23,786:INFO:Declaring metric variables
2024-05-24 15:53:23,791:INFO:Importing untrained model
2024-05-24 15:53:23,796:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:53:23,804:INFO:Starting cross validation
2024-05-24 15:53:23,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:24,092:INFO:Calculating mean and std
2024-05-24 15:53:24,093:INFO:Creating metrics dataframe
2024-05-24 15:53:24,095:INFO:Uploading results into container
2024-05-24 15:53:24,096:INFO:Uploading model into container now
2024-05-24 15:53:24,097:INFO:_master_model_container: 12
2024-05-24 15:53:24,097:INFO:_display_container: 2
2024-05-24 15:53:24,098:INFO:DecisionTreeRegressor(random_state=1315)
2024-05-24 15:53:24,098:INFO:create_model() successfully completed......................................
2024-05-24 15:53:24,282:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:24,282:INFO:Creating metrics dataframe
2024-05-24 15:53:24,290:INFO:Initializing Random Forest Regressor
2024-05-24 15:53:24,290:INFO:Total runtime is 0.11740200916926065 minutes
2024-05-24 15:53:24,294:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:24,295:INFO:Initializing create_model()
2024-05-24 15:53:24,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:24,295:INFO:Checking exceptions
2024-05-24 15:53:24,295:INFO:Importing libraries
2024-05-24 15:53:24,295:INFO:Copying training dataset
2024-05-24 15:53:24,301:INFO:Defining folds
2024-05-24 15:53:24,301:INFO:Declaring metric variables
2024-05-24 15:53:24,306:INFO:Importing untrained model
2024-05-24 15:53:24,312:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:53:24,319:INFO:Starting cross validation
2024-05-24 15:53:24,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:25,152:INFO:Calculating mean and std
2024-05-24 15:53:25,153:INFO:Creating metrics dataframe
2024-05-24 15:53:25,156:INFO:Uploading results into container
2024-05-24 15:53:25,157:INFO:Uploading model into container now
2024-05-24 15:53:25,157:INFO:_master_model_container: 13
2024-05-24 15:53:25,157:INFO:_display_container: 2
2024-05-24 15:53:25,158:INFO:RandomForestRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:53:25,158:INFO:create_model() successfully completed......................................
2024-05-24 15:53:25,364:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:25,364:INFO:Creating metrics dataframe
2024-05-24 15:53:25,376:INFO:Initializing Extra Trees Regressor
2024-05-24 15:53:25,376:INFO:Total runtime is 0.1355057636896769 minutes
2024-05-24 15:53:25,382:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:25,382:INFO:Initializing create_model()
2024-05-24 15:53:25,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:25,383:INFO:Checking exceptions
2024-05-24 15:53:25,383:INFO:Importing libraries
2024-05-24 15:53:25,383:INFO:Copying training dataset
2024-05-24 15:53:25,390:INFO:Defining folds
2024-05-24 15:53:25,390:INFO:Declaring metric variables
2024-05-24 15:53:25,395:INFO:Importing untrained model
2024-05-24 15:53:25,399:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:53:25,409:INFO:Starting cross validation
2024-05-24 15:53:25,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:26,058:INFO:Calculating mean and std
2024-05-24 15:53:26,060:INFO:Creating metrics dataframe
2024-05-24 15:53:26,063:INFO:Uploading results into container
2024-05-24 15:53:26,064:INFO:Uploading model into container now
2024-05-24 15:53:26,064:INFO:_master_model_container: 14
2024-05-24 15:53:26,064:INFO:_display_container: 2
2024-05-24 15:53:26,065:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:53:26,065:INFO:create_model() successfully completed......................................
2024-05-24 15:53:26,268:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:26,269:INFO:Creating metrics dataframe
2024-05-24 15:53:26,280:INFO:Initializing AdaBoost Regressor
2024-05-24 15:53:26,280:INFO:Total runtime is 0.15056972106297808 minutes
2024-05-24 15:53:26,284:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:26,284:INFO:Initializing create_model()
2024-05-24 15:53:26,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:26,284:INFO:Checking exceptions
2024-05-24 15:53:26,285:INFO:Importing libraries
2024-05-24 15:53:26,285:INFO:Copying training dataset
2024-05-24 15:53:26,291:INFO:Defining folds
2024-05-24 15:53:26,291:INFO:Declaring metric variables
2024-05-24 15:53:26,296:INFO:Importing untrained model
2024-05-24 15:53:26,300:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:53:26,310:INFO:Starting cross validation
2024-05-24 15:53:26,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:26,759:INFO:Calculating mean and std
2024-05-24 15:53:26,761:INFO:Creating metrics dataframe
2024-05-24 15:53:26,764:INFO:Uploading results into container
2024-05-24 15:53:26,764:INFO:Uploading model into container now
2024-05-24 15:53:26,765:INFO:_master_model_container: 15
2024-05-24 15:53:26,765:INFO:_display_container: 2
2024-05-24 15:53:26,765:INFO:AdaBoostRegressor(random_state=1315)
2024-05-24 15:53:26,765:INFO:create_model() successfully completed......................................
2024-05-24 15:53:26,964:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:26,964:INFO:Creating metrics dataframe
2024-05-24 15:53:26,976:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:53:26,976:INFO:Total runtime is 0.16216788689295447 minutes
2024-05-24 15:53:26,980:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:26,981:INFO:Initializing create_model()
2024-05-24 15:53:26,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:26,981:INFO:Checking exceptions
2024-05-24 15:53:26,981:INFO:Importing libraries
2024-05-24 15:53:26,981:INFO:Copying training dataset
2024-05-24 15:53:26,987:INFO:Defining folds
2024-05-24 15:53:26,988:INFO:Declaring metric variables
2024-05-24 15:53:26,993:INFO:Importing untrained model
2024-05-24 15:53:26,997:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:53:27,005:INFO:Starting cross validation
2024-05-24 15:53:27,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:27,495:INFO:Calculating mean and std
2024-05-24 15:53:27,497:INFO:Creating metrics dataframe
2024-05-24 15:53:27,499:INFO:Uploading results into container
2024-05-24 15:53:27,499:INFO:Uploading model into container now
2024-05-24 15:53:27,500:INFO:_master_model_container: 16
2024-05-24 15:53:27,500:INFO:_display_container: 2
2024-05-24 15:53:27,500:INFO:GradientBoostingRegressor(random_state=1315)
2024-05-24 15:53:27,501:INFO:create_model() successfully completed......................................
2024-05-24 15:53:27,696:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:27,697:INFO:Creating metrics dataframe
2024-05-24 15:53:27,708:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:53:27,708:INFO:Total runtime is 0.17437556187311803 minutes
2024-05-24 15:53:27,713:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:27,713:INFO:Initializing create_model()
2024-05-24 15:53:27,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:27,714:INFO:Checking exceptions
2024-05-24 15:53:27,714:INFO:Importing libraries
2024-05-24 15:53:27,714:INFO:Copying training dataset
2024-05-24 15:53:27,721:INFO:Defining folds
2024-05-24 15:53:27,721:INFO:Declaring metric variables
2024-05-24 15:53:27,726:INFO:Importing untrained model
2024-05-24 15:53:27,730:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:53:27,738:INFO:Starting cross validation
2024-05-24 15:53:27,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:28,244:INFO:Calculating mean and std
2024-05-24 15:53:28,245:INFO:Creating metrics dataframe
2024-05-24 15:53:28,248:INFO:Uploading results into container
2024-05-24 15:53:28,249:INFO:Uploading model into container now
2024-05-24 15:53:28,250:INFO:_master_model_container: 17
2024-05-24 15:53:28,250:INFO:_display_container: 2
2024-05-24 15:53:28,251:INFO:LGBMRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:53:28,251:INFO:create_model() successfully completed......................................
2024-05-24 15:53:28,461:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:28,462:INFO:Creating metrics dataframe
2024-05-24 15:53:28,472:INFO:Initializing Dummy Regressor
2024-05-24 15:53:28,472:INFO:Total runtime is 0.187106438477834 minutes
2024-05-24 15:53:28,475:INFO:SubProcess create_model() called ==================================
2024-05-24 15:53:28,477:INFO:Initializing create_model()
2024-05-24 15:53:28,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69D20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:28,477:INFO:Checking exceptions
2024-05-24 15:53:28,477:INFO:Importing libraries
2024-05-24 15:53:28,477:INFO:Copying training dataset
2024-05-24 15:53:28,484:INFO:Defining folds
2024-05-24 15:53:28,484:INFO:Declaring metric variables
2024-05-24 15:53:28,487:INFO:Importing untrained model
2024-05-24 15:53:28,492:INFO:Dummy Regressor Imported successfully
2024-05-24 15:53:28,504:INFO:Starting cross validation
2024-05-24 15:53:28,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:53:28,793:INFO:Calculating mean and std
2024-05-24 15:53:28,795:INFO:Creating metrics dataframe
2024-05-24 15:53:28,797:INFO:Uploading results into container
2024-05-24 15:53:28,797:INFO:Uploading model into container now
2024-05-24 15:53:28,799:INFO:_master_model_container: 18
2024-05-24 15:53:28,799:INFO:_display_container: 2
2024-05-24 15:53:28,799:INFO:DummyRegressor()
2024-05-24 15:53:28,799:INFO:create_model() successfully completed......................................
2024-05-24 15:53:28,985:INFO:SubProcess create_model() end ==================================
2024-05-24 15:53:28,985:INFO:Creating metrics dataframe
2024-05-24 15:53:28,997:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:53:29,006:INFO:Initializing create_model()
2024-05-24 15:53:29,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:53:29,008:INFO:Checking exceptions
2024-05-24 15:53:29,009:INFO:Importing libraries
2024-05-24 15:53:29,010:INFO:Copying training dataset
2024-05-24 15:53:29,014:INFO:Defining folds
2024-05-24 15:53:29,015:INFO:Declaring metric variables
2024-05-24 15:53:29,015:INFO:Importing untrained model
2024-05-24 15:53:29,015:INFO:Declaring custom model
2024-05-24 15:53:29,015:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:53:29,017:INFO:Cross validation set to False
2024-05-24 15:53:29,017:INFO:Fitting Model
2024-05-24 15:53:29,252:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:53:29,252:INFO:create_model() successfully completed......................................
2024-05-24 15:53:29,496:INFO:_master_model_container: 18
2024-05-24 15:53:29,496:INFO:_display_container: 2
2024-05-24 15:53:29,497:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:53:29,497:INFO:compare_models() successfully completed......................................
2024-05-24 15:53:52,680:INFO:Initializing evaluate_model()
2024-05-24 15:53:52,680:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 15:53:52,695:INFO:Initializing plot_model()
2024-05-24 15:53:52,695:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, system=True)
2024-05-24 15:53:52,695:INFO:Checking exceptions
2024-05-24 15:53:52,726:INFO:Preloading libraries
2024-05-24 15:53:52,737:INFO:Copying training dataset
2024-05-24 15:53:52,738:INFO:Plot type: pipeline
2024-05-24 15:53:52,865:INFO:Visual Rendered Successfully
2024-05-24 15:53:53,314:INFO:plot_model() successfully completed......................................
2024-05-24 15:54:22,635:INFO:Initializing tune_model()
2024-05-24 15:54:22,635:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>)
2024-05-24 15:54:22,635:INFO:Checking exceptions
2024-05-24 15:54:22,661:INFO:Copying training dataset
2024-05-24 15:54:22,666:INFO:Checking base model
2024-05-24 15:54:22,666:INFO:Base model : Extra Trees Regressor
2024-05-24 15:54:22,673:INFO:Declaring metric variables
2024-05-24 15:54:22,678:INFO:Defining Hyperparameters
2024-05-24 15:54:23,159:INFO:Tuning with n_jobs=-1
2024-05-24 15:54:23,159:INFO:Initializing RandomizedSearchCV
2024-05-24 15:54:28,614:INFO:best_params: {'actual_estimator__n_estimators': 20, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': True}
2024-05-24 15:54:28,616:INFO:Hyperparameter search completed
2024-05-24 15:54:28,616:INFO:SubProcess create_model() called ==================================
2024-05-24 15:54:28,617:INFO:Initializing create_model()
2024-05-24 15:54:28,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6971990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 8, 'criterion': 'absolute_error', 'bootstrap': True})
2024-05-24 15:54:28,618:INFO:Checking exceptions
2024-05-24 15:54:28,618:INFO:Importing libraries
2024-05-24 15:54:28,618:INFO:Copying training dataset
2024-05-24 15:54:28,624:INFO:Defining folds
2024-05-24 15:54:28,624:INFO:Declaring metric variables
2024-05-24 15:54:28,628:INFO:Importing untrained model
2024-05-24 15:54:28,628:INFO:Declaring custom model
2024-05-24 15:54:28,633:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:54:28,642:INFO:Starting cross validation
2024-05-24 15:54:28,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:54:29,118:INFO:Calculating mean and std
2024-05-24 15:54:29,119:INFO:Creating metrics dataframe
2024-05-24 15:54:29,125:INFO:Finalizing model
2024-05-24 15:54:29,344:INFO:Uploading results into container
2024-05-24 15:54:29,345:INFO:Uploading model into container now
2024-05-24 15:54:29,345:INFO:_master_model_container: 19
2024-05-24 15:54:29,346:INFO:_display_container: 3
2024-05-24 15:54:29,347:INFO:ExtraTreesRegressor(bootstrap=True, criterion='absolute_error', max_depth=8,
                    min_impurity_decrease=0.0005, min_samples_leaf=2,
                    n_estimators=20, n_jobs=-1, random_state=1315)
2024-05-24 15:54:29,347:INFO:create_model() successfully completed......................................
2024-05-24 15:54:29,544:INFO:SubProcess create_model() end ==================================
2024-05-24 15:54:29,544:INFO:choose_better activated
2024-05-24 15:54:29,548:INFO:SubProcess create_model() called ==================================
2024-05-24 15:54:29,549:INFO:Initializing create_model()
2024-05-24 15:54:29,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:54:29,549:INFO:Checking exceptions
2024-05-24 15:54:29,551:INFO:Importing libraries
2024-05-24 15:54:29,551:INFO:Copying training dataset
2024-05-24 15:54:29,557:INFO:Defining folds
2024-05-24 15:54:29,557:INFO:Declaring metric variables
2024-05-24 15:54:29,557:INFO:Importing untrained model
2024-05-24 15:54:29,558:INFO:Declaring custom model
2024-05-24 15:54:29,558:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:54:29,558:INFO:Starting cross validation
2024-05-24 15:54:29,560:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:54:30,179:INFO:Calculating mean and std
2024-05-24 15:54:30,180:INFO:Creating metrics dataframe
2024-05-24 15:54:30,182:INFO:Finalizing model
2024-05-24 15:54:30,428:INFO:Uploading results into container
2024-05-24 15:54:30,429:INFO:Uploading model into container now
2024-05-24 15:54:30,429:INFO:_master_model_container: 20
2024-05-24 15:54:30,429:INFO:_display_container: 4
2024-05-24 15:54:30,430:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:54:30,430:INFO:create_model() successfully completed......................................
2024-05-24 15:54:30,624:INFO:SubProcess create_model() end ==================================
2024-05-24 15:54:30,624:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315) result for R2 is 0.8916
2024-05-24 15:54:30,625:INFO:ExtraTreesRegressor(bootstrap=True, criterion='absolute_error', max_depth=8,
                    min_impurity_decrease=0.0005, min_samples_leaf=2,
                    n_estimators=20, n_jobs=-1, random_state=1315) result for R2 is 0.8911
2024-05-24 15:54:30,625:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315) is best model
2024-05-24 15:54:30,625:INFO:choose_better completed
2024-05-24 15:54:30,626:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-24 15:54:30,640:INFO:_master_model_container: 20
2024-05-24 15:54:30,640:INFO:_display_container: 3
2024-05-24 15:54:30,640:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1315)
2024-05-24 15:54:30,640:INFO:tune_model() successfully completed......................................
2024-05-24 15:55:11,947:INFO:PyCaret RegressionExperiment
2024-05-24 15:55:11,947:INFO:Logging name: reg-default-name
2024-05-24 15:55:11,947:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:55:11,947:INFO:version 3.3.2
2024-05-24 15:55:11,947:INFO:Initializing setup()
2024-05-24 15:55:11,947:INFO:self.USI: 9c54
2024-05-24 15:55:11,947:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:55:11,947:INFO:Checking environment
2024-05-24 15:55:11,947:INFO:python_version: 3.10.14
2024-05-24 15:55:11,948:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:55:11,948:INFO:machine: AMD64
2024-05-24 15:55:11,948:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:55:11,948:INFO:Memory: svmem(total=16541802496, available=2399428608, percent=85.5, used=14142373888, free=2399428608)
2024-05-24 15:55:11,948:INFO:Physical Core: 6
2024-05-24 15:55:11,948:INFO:Logical Core: 12
2024-05-24 15:55:11,948:INFO:Checking libraries
2024-05-24 15:55:11,948:INFO:System:
2024-05-24 15:55:11,948:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:55:11,948:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:55:11,948:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:55:11,948:INFO:PyCaret required dependencies:
2024-05-24 15:55:11,948:INFO:                 pip: 24.0
2024-05-24 15:55:11,948:INFO:          setuptools: 69.5.1
2024-05-24 15:55:11,948:INFO:             pycaret: 3.3.2
2024-05-24 15:55:11,948:INFO:             IPython: 8.20.0
2024-05-24 15:55:11,948:INFO:          ipywidgets: 8.1.2
2024-05-24 15:55:11,948:INFO:                tqdm: 4.66.4
2024-05-24 15:55:11,949:INFO:               numpy: 1.26.4
2024-05-24 15:55:11,949:INFO:              pandas: 2.1.4
2024-05-24 15:55:11,949:INFO:              jinja2: 3.1.3
2024-05-24 15:55:11,949:INFO:               scipy: 1.11.4
2024-05-24 15:55:11,949:INFO:              joblib: 1.3.2
2024-05-24 15:55:11,949:INFO:             sklearn: 1.4.2
2024-05-24 15:55:11,949:INFO:                pyod: 1.1.3
2024-05-24 15:55:11,949:INFO:            imblearn: 0.12.2
2024-05-24 15:55:11,949:INFO:   category_encoders: 2.6.3
2024-05-24 15:55:11,949:INFO:            lightgbm: 4.3.0
2024-05-24 15:55:11,949:INFO:               numba: 0.59.1
2024-05-24 15:55:11,949:INFO:            requests: 2.32.2
2024-05-24 15:55:11,949:INFO:          matplotlib: 3.7.5
2024-05-24 15:55:11,949:INFO:          scikitplot: 0.3.7
2024-05-24 15:55:11,949:INFO:         yellowbrick: 1.5
2024-05-24 15:55:11,949:INFO:              plotly: 5.22.0
2024-05-24 15:55:11,949:INFO:    plotly-resampler: Not installed
2024-05-24 15:55:11,949:INFO:             kaleido: 0.2.1
2024-05-24 15:55:11,950:INFO:           schemdraw: 0.15
2024-05-24 15:55:11,950:INFO:         statsmodels: 0.14.2
2024-05-24 15:55:11,950:INFO:              sktime: 0.26.0
2024-05-24 15:55:11,950:INFO:               tbats: 1.1.3
2024-05-24 15:55:11,950:INFO:            pmdarima: 2.0.4
2024-05-24 15:55:11,950:INFO:              psutil: 5.9.0
2024-05-24 15:55:11,950:INFO:          markupsafe: 2.1.3
2024-05-24 15:55:11,950:INFO:             pickle5: Not installed
2024-05-24 15:55:11,950:INFO:         cloudpickle: 3.0.0
2024-05-24 15:55:11,950:INFO:         deprecation: 2.1.0
2024-05-24 15:55:11,950:INFO:              xxhash: 3.4.1
2024-05-24 15:55:11,950:INFO:           wurlitzer: Not installed
2024-05-24 15:55:11,950:INFO:PyCaret optional dependencies:
2024-05-24 15:55:11,950:INFO:                shap: Not installed
2024-05-24 15:55:11,950:INFO:           interpret: Not installed
2024-05-24 15:55:11,950:INFO:                umap: Not installed
2024-05-24 15:55:11,950:INFO:     ydata_profiling: Not installed
2024-05-24 15:55:11,950:INFO:  explainerdashboard: Not installed
2024-05-24 15:55:11,950:INFO:             autoviz: Not installed
2024-05-24 15:55:11,950:INFO:           fairlearn: Not installed
2024-05-24 15:55:11,950:INFO:          deepchecks: Not installed
2024-05-24 15:55:11,950:INFO:             xgboost: Not installed
2024-05-24 15:55:11,950:INFO:            catboost: Not installed
2024-05-24 15:55:11,952:INFO:              kmodes: Not installed
2024-05-24 15:55:11,952:INFO:             mlxtend: Not installed
2024-05-24 15:55:11,952:INFO:       statsforecast: Not installed
2024-05-24 15:55:11,952:INFO:        tune_sklearn: Not installed
2024-05-24 15:55:11,952:INFO:                 ray: Not installed
2024-05-24 15:55:11,952:INFO:            hyperopt: Not installed
2024-05-24 15:55:11,952:INFO:              optuna: Not installed
2024-05-24 15:55:11,952:INFO:               skopt: Not installed
2024-05-24 15:55:11,952:INFO:              mlflow: Not installed
2024-05-24 15:55:11,952:INFO:              gradio: Not installed
2024-05-24 15:55:11,952:INFO:             fastapi: Not installed
2024-05-24 15:55:11,952:INFO:             uvicorn: Not installed
2024-05-24 15:55:11,952:INFO:              m2cgen: Not installed
2024-05-24 15:55:11,952:INFO:           evidently: Not installed
2024-05-24 15:55:11,952:INFO:               fugue: Not installed
2024-05-24 15:55:11,952:INFO:           streamlit: Not installed
2024-05-24 15:55:11,952:INFO:             prophet: Not installed
2024-05-24 15:55:11,952:INFO:None
2024-05-24 15:55:11,952:INFO:Set up data.
2024-05-24 15:55:11,964:INFO:Set up folding strategy.
2024-05-24 15:55:11,964:INFO:Set up train/test split.
2024-05-24 15:55:11,971:INFO:Set up index.
2024-05-24 15:55:11,971:INFO:Assigning column types.
2024-05-24 15:55:11,977:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:55:11,977:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:55:11,982:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:55:11,988:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,051:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,127:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,132:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,250:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:55:12,255:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,379:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,385:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,390:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,512:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:55:12,521:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,753:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,756:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:55:12,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:12,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:12,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:55:13,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,000:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:55:13,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:13,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:55:13,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,248:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:55:13,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:13,499:INFO:Preparing preprocessing pipeline...
2024-05-24 15:55:13,499:INFO:Set up simple imputation.
2024-05-24 15:55:13,506:INFO:Set up encoding of ordinal features.
2024-05-24 15:55:13,512:INFO:Set up encoding of categorical features.
2024-05-24 15:55:13,512:INFO:Set up polynomial features.
2024-05-24 15:55:13,513:INFO:Set up removing multicollinearity.
2024-05-24 15:55:14,666:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:55:14,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['CarName'],
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9)))])
2024-05-24 15:55:14,732:INFO:Creating final display dataframe.
2024-05-24 15:55:15,815:INFO:Setup _display_container:                     Description             Value
0                    Session id              6837
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (205, 423)
5   Transformed train set shape        (143, 423)
6    Transformed test set shape         (62, 423)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              9c54
2024-05-24 15:55:15,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:15,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:16,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:16,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:55:16,059:INFO:setup() successfully completed in 4.12s...............
2024-05-24 15:55:16,084:INFO:Initializing compare_models()
2024-05-24 15:55:16,084:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:55:16,084:INFO:Checking exceptions
2024-05-24 15:55:16,088:INFO:Preparing display monitor
2024-05-24 15:55:16,116:INFO:Initializing Linear Regression
2024-05-24 15:55:16,116:INFO:Total runtime is 0.0 minutes
2024-05-24 15:55:16,120:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:16,121:INFO:Initializing create_model()
2024-05-24 15:55:16,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:16,121:INFO:Checking exceptions
2024-05-24 15:55:16,122:INFO:Importing libraries
2024-05-24 15:55:16,122:INFO:Copying training dataset
2024-05-24 15:55:16,128:INFO:Defining folds
2024-05-24 15:55:16,128:INFO:Declaring metric variables
2024-05-24 15:55:16,132:INFO:Importing untrained model
2024-05-24 15:55:16,144:INFO:Linear Regression Imported successfully
2024-05-24 15:55:16,157:INFO:Starting cross validation
2024-05-24 15:55:16,178:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:18,105:INFO:Calculating mean and std
2024-05-24 15:55:18,106:INFO:Creating metrics dataframe
2024-05-24 15:55:18,109:INFO:Uploading results into container
2024-05-24 15:55:18,110:INFO:Uploading model into container now
2024-05-24 15:55:18,110:INFO:_master_model_container: 1
2024-05-24 15:55:18,110:INFO:_display_container: 2
2024-05-24 15:55:18,111:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:55:18,111:INFO:create_model() successfully completed......................................
2024-05-24 15:55:18,361:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:18,361:INFO:Creating metrics dataframe
2024-05-24 15:55:18,371:INFO:Initializing Lasso Regression
2024-05-24 15:55:18,371:INFO:Total runtime is 0.037580831845601397 minutes
2024-05-24 15:55:18,376:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:18,378:INFO:Initializing create_model()
2024-05-24 15:55:18,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:18,378:INFO:Checking exceptions
2024-05-24 15:55:18,378:INFO:Importing libraries
2024-05-24 15:55:18,378:INFO:Copying training dataset
2024-05-24 15:55:18,387:INFO:Defining folds
2024-05-24 15:55:18,387:INFO:Declaring metric variables
2024-05-24 15:55:18,392:INFO:Importing untrained model
2024-05-24 15:55:18,397:INFO:Lasso Regression Imported successfully
2024-05-24 15:55:18,408:INFO:Starting cross validation
2024-05-24 15:55:18,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:20,105:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.749e+07, tolerance: 7.519e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+07, tolerance: 7.207e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,163:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+07, tolerance: 8.131e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,173:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+07, tolerance: 7.743e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,185:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+07, tolerance: 7.980e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,191:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.346e+07, tolerance: 8.564e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,269:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e+07, tolerance: 8.237e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,276:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+07, tolerance: 8.295e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+07, tolerance: 7.495e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,387:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e+07, tolerance: 7.839e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:20,466:INFO:Calculating mean and std
2024-05-24 15:55:20,468:INFO:Creating metrics dataframe
2024-05-24 15:55:20,471:INFO:Uploading results into container
2024-05-24 15:55:20,472:INFO:Uploading model into container now
2024-05-24 15:55:20,472:INFO:_master_model_container: 2
2024-05-24 15:55:20,472:INFO:_display_container: 2
2024-05-24 15:55:20,474:INFO:Lasso(random_state=6837)
2024-05-24 15:55:20,474:INFO:create_model() successfully completed......................................
2024-05-24 15:55:20,764:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:20,765:INFO:Creating metrics dataframe
2024-05-24 15:55:20,773:INFO:Initializing Ridge Regression
2024-05-24 15:55:20,774:INFO:Total runtime is 0.07763299544652302 minutes
2024-05-24 15:55:20,780:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:20,780:INFO:Initializing create_model()
2024-05-24 15:55:20,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:20,780:INFO:Checking exceptions
2024-05-24 15:55:20,781:INFO:Importing libraries
2024-05-24 15:55:20,781:INFO:Copying training dataset
2024-05-24 15:55:20,791:INFO:Defining folds
2024-05-24 15:55:20,791:INFO:Declaring metric variables
2024-05-24 15:55:20,797:INFO:Importing untrained model
2024-05-24 15:55:20,803:INFO:Ridge Regression Imported successfully
2024-05-24 15:55:20,814:INFO:Starting cross validation
2024-05-24 15:55:20,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:22,430:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,448:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,454:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,455:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,488:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,504:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,520:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,540:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,596:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,609:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:55:22,714:INFO:Calculating mean and std
2024-05-24 15:55:22,716:INFO:Creating metrics dataframe
2024-05-24 15:55:22,718:INFO:Uploading results into container
2024-05-24 15:55:22,719:INFO:Uploading model into container now
2024-05-24 15:55:22,720:INFO:_master_model_container: 3
2024-05-24 15:55:22,720:INFO:_display_container: 2
2024-05-24 15:55:22,720:INFO:Ridge(random_state=6837)
2024-05-24 15:55:22,721:INFO:create_model() successfully completed......................................
2024-05-24 15:55:22,932:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:22,932:INFO:Creating metrics dataframe
2024-05-24 15:55:22,944:INFO:Initializing Elastic Net
2024-05-24 15:55:22,944:INFO:Total runtime is 0.11379961570103962 minutes
2024-05-24 15:55:22,948:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:22,949:INFO:Initializing create_model()
2024-05-24 15:55:22,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:22,949:INFO:Checking exceptions
2024-05-24 15:55:22,949:INFO:Importing libraries
2024-05-24 15:55:22,949:INFO:Copying training dataset
2024-05-24 15:55:22,959:INFO:Defining folds
2024-05-24 15:55:22,959:INFO:Declaring metric variables
2024-05-24 15:55:22,964:INFO:Importing untrained model
2024-05-24 15:55:22,971:INFO:Elastic Net Imported successfully
2024-05-24 15:55:22,981:INFO:Starting cross validation
2024-05-24 15:55:22,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:24,507:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e+07, tolerance: 8.131e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,553:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.664e+07, tolerance: 8.237e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,558:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.729e+07, tolerance: 7.207e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,589:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.104e+07, tolerance: 7.519e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,596:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e+07, tolerance: 8.564e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,604:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.362e+07, tolerance: 7.495e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,608:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.551e+07, tolerance: 7.743e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,637:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.984e+07, tolerance: 8.295e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,694:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.207e+07, tolerance: 7.839e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,713:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e+07, tolerance: 7.980e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:55:24,773:INFO:Calculating mean and std
2024-05-24 15:55:24,774:INFO:Creating metrics dataframe
2024-05-24 15:55:24,777:INFO:Uploading results into container
2024-05-24 15:55:24,778:INFO:Uploading model into container now
2024-05-24 15:55:24,778:INFO:_master_model_container: 4
2024-05-24 15:55:24,778:INFO:_display_container: 2
2024-05-24 15:55:24,779:INFO:ElasticNet(random_state=6837)
2024-05-24 15:55:24,779:INFO:create_model() successfully completed......................................
2024-05-24 15:55:24,964:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:24,964:INFO:Creating metrics dataframe
2024-05-24 15:55:24,971:INFO:Initializing Least Angle Regression
2024-05-24 15:55:24,971:INFO:Total runtime is 0.1475907246271769 minutes
2024-05-24 15:55:24,976:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:24,976:INFO:Initializing create_model()
2024-05-24 15:55:24,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:24,976:INFO:Checking exceptions
2024-05-24 15:55:24,977:INFO:Importing libraries
2024-05-24 15:55:24,977:INFO:Copying training dataset
2024-05-24 15:55:24,983:INFO:Defining folds
2024-05-24 15:55:24,983:INFO:Declaring metric variables
2024-05-24 15:55:24,987:INFO:Importing untrained model
2024-05-24 15:55:24,991:INFO:Least Angle Regression Imported successfully
2024-05-24 15:55:24,999:INFO:Starting cross validation
2024-05-24 15:55:25,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:26,692:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=1.953e+03, with an active set of 103 regressors, and the smallest cholesky pivot element being 8.941e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:55:26,743:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=4.065e+04, with an active set of 112 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:55:26,745:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=3.759e+04, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:55:26,827:INFO:Calculating mean and std
2024-05-24 15:55:26,829:INFO:Creating metrics dataframe
2024-05-24 15:55:26,831:INFO:Uploading results into container
2024-05-24 15:55:26,832:INFO:Uploading model into container now
2024-05-24 15:55:26,832:INFO:_master_model_container: 5
2024-05-24 15:55:26,832:INFO:_display_container: 2
2024-05-24 15:55:26,833:INFO:Lars(random_state=6837)
2024-05-24 15:55:26,833:INFO:create_model() successfully completed......................................
2024-05-24 15:55:27,026:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:27,027:INFO:Creating metrics dataframe
2024-05-24 15:55:27,036:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:55:27,036:INFO:Total runtime is 0.18199360768000283 minutes
2024-05-24 15:55:27,041:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:27,042:INFO:Initializing create_model()
2024-05-24 15:55:27,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:27,042:INFO:Checking exceptions
2024-05-24 15:55:27,042:INFO:Importing libraries
2024-05-24 15:55:27,042:INFO:Copying training dataset
2024-05-24 15:55:27,050:INFO:Defining folds
2024-05-24 15:55:27,050:INFO:Declaring metric variables
2024-05-24 15:55:27,054:INFO:Importing untrained model
2024-05-24 15:55:27,059:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:55:27,070:INFO:Starting cross validation
2024-05-24 15:55:27,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:29,057:INFO:Calculating mean and std
2024-05-24 15:55:29,059:INFO:Creating metrics dataframe
2024-05-24 15:55:29,061:INFO:Uploading results into container
2024-05-24 15:55:29,061:INFO:Uploading model into container now
2024-05-24 15:55:29,062:INFO:_master_model_container: 6
2024-05-24 15:55:29,062:INFO:_display_container: 2
2024-05-24 15:55:29,062:INFO:LassoLars(random_state=6837)
2024-05-24 15:55:29,062:INFO:create_model() successfully completed......................................
2024-05-24 15:55:29,264:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:29,264:INFO:Creating metrics dataframe
2024-05-24 15:55:29,275:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:55:29,275:INFO:Total runtime is 0.2193109353383382 minutes
2024-05-24 15:55:29,280:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:29,280:INFO:Initializing create_model()
2024-05-24 15:55:29,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:29,280:INFO:Checking exceptions
2024-05-24 15:55:29,280:INFO:Importing libraries
2024-05-24 15:55:29,281:INFO:Copying training dataset
2024-05-24 15:55:29,288:INFO:Defining folds
2024-05-24 15:55:29,288:INFO:Declaring metric variables
2024-05-24 15:55:29,293:INFO:Importing untrained model
2024-05-24 15:55:29,297:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:55:29,307:INFO:Starting cross validation
2024-05-24 15:55:29,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:31,083:INFO:Calculating mean and std
2024-05-24 15:55:31,085:INFO:Creating metrics dataframe
2024-05-24 15:55:31,087:INFO:Uploading results into container
2024-05-24 15:55:31,088:INFO:Uploading model into container now
2024-05-24 15:55:31,089:INFO:_master_model_container: 7
2024-05-24 15:55:31,089:INFO:_display_container: 2
2024-05-24 15:55:31,089:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:55:31,089:INFO:create_model() successfully completed......................................
2024-05-24 15:55:31,286:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:31,286:INFO:Creating metrics dataframe
2024-05-24 15:55:31,296:INFO:Initializing Bayesian Ridge
2024-05-24 15:55:31,297:INFO:Total runtime is 0.253021772702535 minutes
2024-05-24 15:55:31,302:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:31,303:INFO:Initializing create_model()
2024-05-24 15:55:31,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:31,303:INFO:Checking exceptions
2024-05-24 15:55:31,303:INFO:Importing libraries
2024-05-24 15:55:31,303:INFO:Copying training dataset
2024-05-24 15:55:31,311:INFO:Defining folds
2024-05-24 15:55:31,311:INFO:Declaring metric variables
2024-05-24 15:55:31,316:INFO:Importing untrained model
2024-05-24 15:55:31,322:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:55:31,331:INFO:Starting cross validation
2024-05-24 15:55:31,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:33,069:INFO:Calculating mean and std
2024-05-24 15:55:33,071:INFO:Creating metrics dataframe
2024-05-24 15:55:33,074:INFO:Uploading results into container
2024-05-24 15:55:33,075:INFO:Uploading model into container now
2024-05-24 15:55:33,075:INFO:_master_model_container: 8
2024-05-24 15:55:33,075:INFO:_display_container: 2
2024-05-24 15:55:33,076:INFO:BayesianRidge()
2024-05-24 15:55:33,076:INFO:create_model() successfully completed......................................
2024-05-24 15:55:33,328:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:33,328:INFO:Creating metrics dataframe
2024-05-24 15:55:33,338:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:55:33,338:INFO:Total runtime is 0.2870311220486959 minutes
2024-05-24 15:55:33,344:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:33,344:INFO:Initializing create_model()
2024-05-24 15:55:33,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:33,344:INFO:Checking exceptions
2024-05-24 15:55:33,345:INFO:Importing libraries
2024-05-24 15:55:33,345:INFO:Copying training dataset
2024-05-24 15:55:33,351:INFO:Defining folds
2024-05-24 15:55:33,352:INFO:Declaring metric variables
2024-05-24 15:55:33,358:INFO:Importing untrained model
2024-05-24 15:55:33,362:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:55:33,371:INFO:Starting cross validation
2024-05-24 15:55:33,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:35,224:INFO:Calculating mean and std
2024-05-24 15:55:35,226:INFO:Creating metrics dataframe
2024-05-24 15:55:35,228:INFO:Uploading results into container
2024-05-24 15:55:35,228:INFO:Uploading model into container now
2024-05-24 15:55:35,229:INFO:_master_model_container: 9
2024-05-24 15:55:35,229:INFO:_display_container: 2
2024-05-24 15:55:35,229:INFO:PassiveAggressiveRegressor(random_state=6837)
2024-05-24 15:55:35,229:INFO:create_model() successfully completed......................................
2024-05-24 15:55:35,422:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:35,422:INFO:Creating metrics dataframe
2024-05-24 15:55:35,433:INFO:Initializing Huber Regressor
2024-05-24 15:55:35,433:INFO:Total runtime is 0.32194431622823083 minutes
2024-05-24 15:55:35,437:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:35,437:INFO:Initializing create_model()
2024-05-24 15:55:35,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:35,438:INFO:Checking exceptions
2024-05-24 15:55:35,438:INFO:Importing libraries
2024-05-24 15:55:35,438:INFO:Copying training dataset
2024-05-24 15:55:35,445:INFO:Defining folds
2024-05-24 15:55:35,445:INFO:Declaring metric variables
2024-05-24 15:55:35,449:INFO:Importing untrained model
2024-05-24 15:55:35,453:INFO:Huber Regressor Imported successfully
2024-05-24 15:55:35,460:INFO:Starting cross validation
2024-05-24 15:55:35,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:37,111:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:55:37,124:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:55:37,124:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:55:37,162:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:55:37,272:INFO:Calculating mean and std
2024-05-24 15:55:37,273:INFO:Creating metrics dataframe
2024-05-24 15:55:37,276:INFO:Uploading results into container
2024-05-24 15:55:37,277:INFO:Uploading model into container now
2024-05-24 15:55:37,278:INFO:_master_model_container: 10
2024-05-24 15:55:37,278:INFO:_display_container: 2
2024-05-24 15:55:37,278:INFO:HuberRegressor()
2024-05-24 15:55:37,278:INFO:create_model() successfully completed......................................
2024-05-24 15:55:37,479:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:37,479:INFO:Creating metrics dataframe
2024-05-24 15:55:37,489:INFO:Initializing K Neighbors Regressor
2024-05-24 15:55:37,491:INFO:Total runtime is 0.3562439680099488 minutes
2024-05-24 15:55:37,495:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:37,495:INFO:Initializing create_model()
2024-05-24 15:55:37,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:37,496:INFO:Checking exceptions
2024-05-24 15:55:37,496:INFO:Importing libraries
2024-05-24 15:55:37,496:INFO:Copying training dataset
2024-05-24 15:55:37,502:INFO:Defining folds
2024-05-24 15:55:37,502:INFO:Declaring metric variables
2024-05-24 15:55:37,507:INFO:Importing untrained model
2024-05-24 15:55:37,513:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:55:37,523:INFO:Starting cross validation
2024-05-24 15:55:37,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:39,223:INFO:Calculating mean and std
2024-05-24 15:55:39,224:INFO:Creating metrics dataframe
2024-05-24 15:55:39,228:INFO:Uploading results into container
2024-05-24 15:55:39,228:INFO:Uploading model into container now
2024-05-24 15:55:39,229:INFO:_master_model_container: 11
2024-05-24 15:55:39,229:INFO:_display_container: 2
2024-05-24 15:55:39,229:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:55:39,229:INFO:create_model() successfully completed......................................
2024-05-24 15:55:39,429:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:39,430:INFO:Creating metrics dataframe
2024-05-24 15:55:39,440:INFO:Initializing Decision Tree Regressor
2024-05-24 15:55:39,440:INFO:Total runtime is 0.3887309789657593 minutes
2024-05-24 15:55:39,445:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:39,445:INFO:Initializing create_model()
2024-05-24 15:55:39,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:39,445:INFO:Checking exceptions
2024-05-24 15:55:39,446:INFO:Importing libraries
2024-05-24 15:55:39,446:INFO:Copying training dataset
2024-05-24 15:55:39,452:INFO:Defining folds
2024-05-24 15:55:39,452:INFO:Declaring metric variables
2024-05-24 15:55:39,459:INFO:Importing untrained model
2024-05-24 15:55:39,464:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:55:39,475:INFO:Starting cross validation
2024-05-24 15:55:39,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:41,345:INFO:Calculating mean and std
2024-05-24 15:55:41,347:INFO:Creating metrics dataframe
2024-05-24 15:55:41,349:INFO:Uploading results into container
2024-05-24 15:55:41,350:INFO:Uploading model into container now
2024-05-24 15:55:41,350:INFO:_master_model_container: 12
2024-05-24 15:55:41,350:INFO:_display_container: 2
2024-05-24 15:55:41,351:INFO:DecisionTreeRegressor(random_state=6837)
2024-05-24 15:55:41,351:INFO:create_model() successfully completed......................................
2024-05-24 15:55:41,546:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:41,546:INFO:Creating metrics dataframe
2024-05-24 15:55:41,557:INFO:Initializing Random Forest Regressor
2024-05-24 15:55:41,557:INFO:Total runtime is 0.4240173260370891 minutes
2024-05-24 15:55:41,561:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:41,562:INFO:Initializing create_model()
2024-05-24 15:55:41,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:41,562:INFO:Checking exceptions
2024-05-24 15:55:41,562:INFO:Importing libraries
2024-05-24 15:55:41,563:INFO:Copying training dataset
2024-05-24 15:55:41,569:INFO:Defining folds
2024-05-24 15:55:41,569:INFO:Declaring metric variables
2024-05-24 15:55:41,577:INFO:Importing untrained model
2024-05-24 15:55:41,582:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:55:41,592:INFO:Starting cross validation
2024-05-24 15:55:41,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:44,003:INFO:Calculating mean and std
2024-05-24 15:55:44,005:INFO:Creating metrics dataframe
2024-05-24 15:55:44,007:INFO:Uploading results into container
2024-05-24 15:55:44,008:INFO:Uploading model into container now
2024-05-24 15:55:44,009:INFO:_master_model_container: 13
2024-05-24 15:55:44,009:INFO:_display_container: 2
2024-05-24 15:55:44,010:INFO:RandomForestRegressor(n_jobs=-1, random_state=6837)
2024-05-24 15:55:44,010:INFO:create_model() successfully completed......................................
2024-05-24 15:55:44,225:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:44,226:INFO:Creating metrics dataframe
2024-05-24 15:55:44,240:INFO:Initializing Extra Trees Regressor
2024-05-24 15:55:44,240:INFO:Total runtime is 0.4687288045883179 minutes
2024-05-24 15:55:44,243:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:44,244:INFO:Initializing create_model()
2024-05-24 15:55:44,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:44,244:INFO:Checking exceptions
2024-05-24 15:55:44,246:INFO:Importing libraries
2024-05-24 15:55:44,246:INFO:Copying training dataset
2024-05-24 15:55:44,252:INFO:Defining folds
2024-05-24 15:55:44,253:INFO:Declaring metric variables
2024-05-24 15:55:44,258:INFO:Importing untrained model
2024-05-24 15:55:44,264:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:55:44,275:INFO:Starting cross validation
2024-05-24 15:55:44,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:46,544:INFO:Calculating mean and std
2024-05-24 15:55:46,546:INFO:Creating metrics dataframe
2024-05-24 15:55:46,548:INFO:Uploading results into container
2024-05-24 15:55:46,549:INFO:Uploading model into container now
2024-05-24 15:55:46,549:INFO:_master_model_container: 14
2024-05-24 15:55:46,549:INFO:_display_container: 2
2024-05-24 15:55:46,550:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6837)
2024-05-24 15:55:46,550:INFO:create_model() successfully completed......................................
2024-05-24 15:55:46,749:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:46,749:INFO:Creating metrics dataframe
2024-05-24 15:55:46,764:INFO:Initializing AdaBoost Regressor
2024-05-24 15:55:46,764:INFO:Total runtime is 0.5108007510503133 minutes
2024-05-24 15:55:46,768:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:46,768:INFO:Initializing create_model()
2024-05-24 15:55:46,768:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:46,768:INFO:Checking exceptions
2024-05-24 15:55:46,769:INFO:Importing libraries
2024-05-24 15:55:46,769:INFO:Copying training dataset
2024-05-24 15:55:46,776:INFO:Defining folds
2024-05-24 15:55:46,776:INFO:Declaring metric variables
2024-05-24 15:55:46,781:INFO:Importing untrained model
2024-05-24 15:55:46,785:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:55:46,799:INFO:Starting cross validation
2024-05-24 15:55:46,812:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:48,688:INFO:Calculating mean and std
2024-05-24 15:55:48,689:INFO:Creating metrics dataframe
2024-05-24 15:55:48,692:INFO:Uploading results into container
2024-05-24 15:55:48,693:INFO:Uploading model into container now
2024-05-24 15:55:48,693:INFO:_master_model_container: 15
2024-05-24 15:55:48,693:INFO:_display_container: 2
2024-05-24 15:55:48,693:INFO:AdaBoostRegressor(random_state=6837)
2024-05-24 15:55:48,693:INFO:create_model() successfully completed......................................
2024-05-24 15:55:48,913:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:48,914:INFO:Creating metrics dataframe
2024-05-24 15:55:48,925:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:55:48,925:INFO:Total runtime is 0.5468175252278645 minutes
2024-05-24 15:55:48,929:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:48,930:INFO:Initializing create_model()
2024-05-24 15:55:48,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:48,931:INFO:Checking exceptions
2024-05-24 15:55:48,931:INFO:Importing libraries
2024-05-24 15:55:48,931:INFO:Copying training dataset
2024-05-24 15:55:48,938:INFO:Defining folds
2024-05-24 15:55:48,938:INFO:Declaring metric variables
2024-05-24 15:55:48,944:INFO:Importing untrained model
2024-05-24 15:55:48,950:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:55:48,961:INFO:Starting cross validation
2024-05-24 15:55:48,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:50,943:INFO:Calculating mean and std
2024-05-24 15:55:50,946:INFO:Creating metrics dataframe
2024-05-24 15:55:50,948:INFO:Uploading results into container
2024-05-24 15:55:50,949:INFO:Uploading model into container now
2024-05-24 15:55:50,950:INFO:_master_model_container: 16
2024-05-24 15:55:50,950:INFO:_display_container: 2
2024-05-24 15:55:50,951:INFO:GradientBoostingRegressor(random_state=6837)
2024-05-24 15:55:50,951:INFO:create_model() successfully completed......................................
2024-05-24 15:55:51,172:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:51,173:INFO:Creating metrics dataframe
2024-05-24 15:55:51,187:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:55:51,187:INFO:Total runtime is 0.5845158259073893 minutes
2024-05-24 15:55:51,191:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:51,192:INFO:Initializing create_model()
2024-05-24 15:55:51,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:51,192:INFO:Checking exceptions
2024-05-24 15:55:51,192:INFO:Importing libraries
2024-05-24 15:55:51,192:INFO:Copying training dataset
2024-05-24 15:55:51,200:INFO:Defining folds
2024-05-24 15:55:51,200:INFO:Declaring metric variables
2024-05-24 15:55:51,205:INFO:Importing untrained model
2024-05-24 15:55:51,210:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:55:51,222:INFO:Starting cross validation
2024-05-24 15:55:51,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:53,300:INFO:Calculating mean and std
2024-05-24 15:55:53,302:INFO:Creating metrics dataframe
2024-05-24 15:55:53,305:INFO:Uploading results into container
2024-05-24 15:55:53,307:INFO:Uploading model into container now
2024-05-24 15:55:53,307:INFO:_master_model_container: 17
2024-05-24 15:55:53,307:INFO:_display_container: 2
2024-05-24 15:55:53,308:INFO:LGBMRegressor(n_jobs=-1, random_state=6837)
2024-05-24 15:55:53,309:INFO:create_model() successfully completed......................................
2024-05-24 15:55:53,581:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:53,582:INFO:Creating metrics dataframe
2024-05-24 15:55:53,594:INFO:Initializing Dummy Regressor
2024-05-24 15:55:53,594:INFO:Total runtime is 0.6246411403020222 minutes
2024-05-24 15:55:53,598:INFO:SubProcess create_model() called ==================================
2024-05-24 15:55:53,599:INFO:Initializing create_model()
2024-05-24 15:55:53,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73E0850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:53,599:INFO:Checking exceptions
2024-05-24 15:55:53,599:INFO:Importing libraries
2024-05-24 15:55:53,600:INFO:Copying training dataset
2024-05-24 15:55:53,607:INFO:Defining folds
2024-05-24 15:55:53,608:INFO:Declaring metric variables
2024-05-24 15:55:53,613:INFO:Importing untrained model
2024-05-24 15:55:53,619:INFO:Dummy Regressor Imported successfully
2024-05-24 15:55:53,630:INFO:Starting cross validation
2024-05-24 15:55:53,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:55:55,344:INFO:Calculating mean and std
2024-05-24 15:55:55,346:INFO:Creating metrics dataframe
2024-05-24 15:55:55,349:INFO:Uploading results into container
2024-05-24 15:55:55,349:INFO:Uploading model into container now
2024-05-24 15:55:55,350:INFO:_master_model_container: 18
2024-05-24 15:55:55,350:INFO:_display_container: 2
2024-05-24 15:55:55,350:INFO:DummyRegressor()
2024-05-24 15:55:55,350:INFO:create_model() successfully completed......................................
2024-05-24 15:55:55,561:INFO:SubProcess create_model() end ==================================
2024-05-24 15:55:55,561:INFO:Creating metrics dataframe
2024-05-24 15:55:55,574:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:55:55,586:INFO:Initializing create_model()
2024-05-24 15:55:55,587:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=6837), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:55:55,587:INFO:Checking exceptions
2024-05-24 15:55:55,589:INFO:Importing libraries
2024-05-24 15:55:55,589:INFO:Copying training dataset
2024-05-24 15:55:55,598:INFO:Defining folds
2024-05-24 15:55:55,598:INFO:Declaring metric variables
2024-05-24 15:55:55,598:INFO:Importing untrained model
2024-05-24 15:55:55,598:INFO:Declaring custom model
2024-05-24 15:55:55,599:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:55:55,610:INFO:Cross validation set to False
2024-05-24 15:55:55,610:INFO:Fitting Model
2024-05-24 15:55:56,547:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-24 15:55:56,548:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-05-24 15:55:56,548:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-24 15:55:56,549:INFO:[LightGBM] [Info] Total Bins 1013
2024-05-24 15:55:56,549:INFO:[LightGBM] [Info] Number of data points in the train set: 143, number of used features: 65
2024-05-24 15:55:56,550:INFO:[LightGBM] [Info] Start training from score 13270.674825
2024-05-24 15:55:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:55:56,574:INFO:LGBMRegressor(n_jobs=-1, random_state=6837)
2024-05-24 15:55:56,574:INFO:create_model() successfully completed......................................
2024-05-24 15:55:56,815:INFO:_master_model_container: 18
2024-05-24 15:55:56,815:INFO:_display_container: 2
2024-05-24 15:55:56,816:INFO:LGBMRegressor(n_jobs=-1, random_state=6837)
2024-05-24 15:55:56,816:INFO:compare_models() successfully completed......................................
2024-05-24 15:55:56,857:INFO:Initializing tune_model()
2024-05-24 15:55:56,857:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=6837), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>)
2024-05-24 15:55:56,857:INFO:Checking exceptions
2024-05-24 15:55:56,884:INFO:Copying training dataset
2024-05-24 15:55:56,891:INFO:Checking base model
2024-05-24 15:55:56,891:INFO:Base model : Light Gradient Boosting Machine
2024-05-24 15:55:56,895:INFO:Declaring metric variables
2024-05-24 15:55:56,898:INFO:Defining Hyperparameters
2024-05-24 15:55:57,106:INFO:Tuning with n_jobs=-1
2024-05-24 15:55:57,106:INFO:Initializing RandomizedSearchCV
2024-05-24 15:56:39,414:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 1e-06, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 70, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 1.0}
2024-05-24 15:56:39,415:INFO:Hyperparameter search completed
2024-05-24 15:56:39,416:INFO:SubProcess create_model() called ==================================
2024-05-24 15:56:39,417:INFO:Initializing create_model()
2024-05-24 15:56:39,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=6837), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C8C609A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.05, 'reg_alpha': 1e-06, 'num_leaves': 40, 'n_estimators': 70, 'min_split_gain': 0.1, 'min_child_samples': 21, 'learning_rate': 0.3, 'feature_fraction': 0.5, 'bagging_freq': 4, 'bagging_fraction': 1.0})
2024-05-24 15:56:39,417:INFO:Checking exceptions
2024-05-24 15:56:39,417:INFO:Importing libraries
2024-05-24 15:56:39,417:INFO:Copying training dataset
2024-05-24 15:56:39,429:INFO:Defining folds
2024-05-24 15:56:39,429:INFO:Declaring metric variables
2024-05-24 15:56:39,434:INFO:Importing untrained model
2024-05-24 15:56:39,434:INFO:Declaring custom model
2024-05-24 15:56:39,440:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:56:39,450:INFO:Starting cross validation
2024-05-24 15:56:39,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:56:41,582:INFO:Calculating mean and std
2024-05-24 15:56:41,583:INFO:Creating metrics dataframe
2024-05-24 15:56:41,591:INFO:Finalizing model
2024-05-24 15:56:42,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-24 15:56:42,445:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-05-24 15:56:42,446:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-05-24 15:56:42,450:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-24 15:56:42,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-24 15:56:42,451:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2024-05-24 15:56:42,451:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2024-05-24 15:56:42,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-05-24 15:56:42,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-24 15:56:42,452:INFO:[LightGBM] [Info] Total Bins 1011
2024-05-24 15:56:42,452:INFO:[LightGBM] [Info] Number of data points in the train set: 143, number of used features: 64
2024-05-24 15:56:42,453:INFO:[LightGBM] [Info] Start training from score 13270.674825
2024-05-24 15:56:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:42,480:INFO:Uploading results into container
2024-05-24 15:56:42,481:INFO:Uploading model into container now
2024-05-24 15:56:42,482:INFO:_master_model_container: 19
2024-05-24 15:56:42,482:INFO:_display_container: 3
2024-05-24 15:56:42,483:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=21, min_split_gain=0.1,
              n_estimators=70, n_jobs=-1, num_leaves=40, random_state=6837,
              reg_alpha=1e-06, reg_lambda=0.05)
2024-05-24 15:56:42,483:INFO:create_model() successfully completed......................................
2024-05-24 15:56:42,703:INFO:SubProcess create_model() end ==================================
2024-05-24 15:56:42,703:INFO:choose_better activated
2024-05-24 15:56:42,706:INFO:SubProcess create_model() called ==================================
2024-05-24 15:56:42,707:INFO:Initializing create_model()
2024-05-24 15:56:42,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C73C80D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=6837), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:56:42,707:INFO:Checking exceptions
2024-05-24 15:56:42,710:INFO:Importing libraries
2024-05-24 15:56:42,710:INFO:Copying training dataset
2024-05-24 15:56:42,716:INFO:Defining folds
2024-05-24 15:56:42,716:INFO:Declaring metric variables
2024-05-24 15:56:42,716:INFO:Importing untrained model
2024-05-24 15:56:42,716:INFO:Declaring custom model
2024-05-24 15:56:42,717:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:56:42,717:INFO:Starting cross validation
2024-05-24 15:56:42,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:56:44,848:INFO:Calculating mean and std
2024-05-24 15:56:44,849:INFO:Creating metrics dataframe
2024-05-24 15:56:44,852:INFO:Finalizing model
2024-05-24 15:56:45,694:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-24 15:56:45,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2024-05-24 15:56:45,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-24 15:56:45,697:INFO:[LightGBM] [Info] Total Bins 1013
2024-05-24 15:56:45,697:INFO:[LightGBM] [Info] Number of data points in the train set: 143, number of used features: 65
2024-05-24 15:56:45,697:INFO:[LightGBM] [Info] Start training from score 13270.674825
2024-05-24 15:56:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-24 15:56:45,722:INFO:Uploading results into container
2024-05-24 15:56:45,722:INFO:Uploading model into container now
2024-05-24 15:56:45,723:INFO:_master_model_container: 20
2024-05-24 15:56:45,723:INFO:_display_container: 4
2024-05-24 15:56:45,723:INFO:LGBMRegressor(n_jobs=-1, random_state=6837)
2024-05-24 15:56:45,724:INFO:create_model() successfully completed......................................
2024-05-24 15:56:45,942:INFO:SubProcess create_model() end ==================================
2024-05-24 15:56:45,942:INFO:LGBMRegressor(n_jobs=-1, random_state=6837) result for R2 is 0.551
2024-05-24 15:56:45,944:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=21, min_split_gain=0.1,
              n_estimators=70, n_jobs=-1, num_leaves=40, random_state=6837,
              reg_alpha=1e-06, reg_lambda=0.05) result for R2 is 0.6006
2024-05-24 15:56:45,945:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=21, min_split_gain=0.1,
              n_estimators=70, n_jobs=-1, num_leaves=40, random_state=6837,
              reg_alpha=1e-06, reg_lambda=0.05) is best model
2024-05-24 15:56:45,945:INFO:choose_better completed
2024-05-24 15:56:45,960:INFO:_master_model_container: 20
2024-05-24 15:56:45,960:INFO:_display_container: 3
2024-05-24 15:56:45,962:INFO:LGBMRegressor(bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.5,
              learning_rate=0.3, min_child_samples=21, min_split_gain=0.1,
              n_estimators=70, n_jobs=-1, num_leaves=40, random_state=6837,
              reg_alpha=1e-06, reg_lambda=0.05)
2024-05-24 15:56:45,962:INFO:tune_model() successfully completed......................................
2024-05-24 15:57:38,273:INFO:PyCaret RegressionExperiment
2024-05-24 15:57:38,273:INFO:Logging name: reg-default-name
2024-05-24 15:57:38,273:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:57:38,273:INFO:version 3.3.2
2024-05-24 15:57:38,273:INFO:Initializing setup()
2024-05-24 15:57:38,273:INFO:self.USI: 0a1d
2024-05-24 15:57:38,274:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:57:38,274:INFO:Checking environment
2024-05-24 15:57:38,274:INFO:python_version: 3.10.14
2024-05-24 15:57:38,274:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:57:38,274:INFO:machine: AMD64
2024-05-24 15:57:38,274:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:57:38,274:INFO:Memory: svmem(total=16541802496, available=2492682240, percent=84.9, used=14049120256, free=2492682240)
2024-05-24 15:57:38,274:INFO:Physical Core: 6
2024-05-24 15:57:38,274:INFO:Logical Core: 12
2024-05-24 15:57:38,274:INFO:Checking libraries
2024-05-24 15:57:38,274:INFO:System:
2024-05-24 15:57:38,274:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:57:38,275:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:57:38,275:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:57:38,275:INFO:PyCaret required dependencies:
2024-05-24 15:57:38,275:INFO:                 pip: 24.0
2024-05-24 15:57:38,275:INFO:          setuptools: 69.5.1
2024-05-24 15:57:38,275:INFO:             pycaret: 3.3.2
2024-05-24 15:57:38,275:INFO:             IPython: 8.20.0
2024-05-24 15:57:38,275:INFO:          ipywidgets: 8.1.2
2024-05-24 15:57:38,275:INFO:                tqdm: 4.66.4
2024-05-24 15:57:38,275:INFO:               numpy: 1.26.4
2024-05-24 15:57:38,275:INFO:              pandas: 2.1.4
2024-05-24 15:57:38,275:INFO:              jinja2: 3.1.3
2024-05-24 15:57:38,275:INFO:               scipy: 1.11.4
2024-05-24 15:57:38,275:INFO:              joblib: 1.3.2
2024-05-24 15:57:38,275:INFO:             sklearn: 1.4.2
2024-05-24 15:57:38,275:INFO:                pyod: 1.1.3
2024-05-24 15:57:38,275:INFO:            imblearn: 0.12.2
2024-05-24 15:57:38,275:INFO:   category_encoders: 2.6.3
2024-05-24 15:57:38,275:INFO:            lightgbm: 4.3.0
2024-05-24 15:57:38,275:INFO:               numba: 0.59.1
2024-05-24 15:57:38,275:INFO:            requests: 2.32.2
2024-05-24 15:57:38,275:INFO:          matplotlib: 3.7.5
2024-05-24 15:57:38,276:INFO:          scikitplot: 0.3.7
2024-05-24 15:57:38,276:INFO:         yellowbrick: 1.5
2024-05-24 15:57:38,276:INFO:              plotly: 5.22.0
2024-05-24 15:57:38,276:INFO:    plotly-resampler: Not installed
2024-05-24 15:57:38,276:INFO:             kaleido: 0.2.1
2024-05-24 15:57:38,276:INFO:           schemdraw: 0.15
2024-05-24 15:57:38,276:INFO:         statsmodels: 0.14.2
2024-05-24 15:57:38,276:INFO:              sktime: 0.26.0
2024-05-24 15:57:38,276:INFO:               tbats: 1.1.3
2024-05-24 15:57:38,276:INFO:            pmdarima: 2.0.4
2024-05-24 15:57:38,276:INFO:              psutil: 5.9.0
2024-05-24 15:57:38,276:INFO:          markupsafe: 2.1.3
2024-05-24 15:57:38,276:INFO:             pickle5: Not installed
2024-05-24 15:57:38,276:INFO:         cloudpickle: 3.0.0
2024-05-24 15:57:38,276:INFO:         deprecation: 2.1.0
2024-05-24 15:57:38,276:INFO:              xxhash: 3.4.1
2024-05-24 15:57:38,276:INFO:           wurlitzer: Not installed
2024-05-24 15:57:38,276:INFO:PyCaret optional dependencies:
2024-05-24 15:57:38,276:INFO:                shap: Not installed
2024-05-24 15:57:38,277:INFO:           interpret: Not installed
2024-05-24 15:57:38,277:INFO:                umap: Not installed
2024-05-24 15:57:38,277:INFO:     ydata_profiling: Not installed
2024-05-24 15:57:38,277:INFO:  explainerdashboard: Not installed
2024-05-24 15:57:38,277:INFO:             autoviz: Not installed
2024-05-24 15:57:38,277:INFO:           fairlearn: Not installed
2024-05-24 15:57:38,277:INFO:          deepchecks: Not installed
2024-05-24 15:57:38,277:INFO:             xgboost: Not installed
2024-05-24 15:57:38,277:INFO:            catboost: Not installed
2024-05-24 15:57:38,277:INFO:              kmodes: Not installed
2024-05-24 15:57:38,277:INFO:             mlxtend: Not installed
2024-05-24 15:57:38,277:INFO:       statsforecast: Not installed
2024-05-24 15:57:38,277:INFO:        tune_sklearn: Not installed
2024-05-24 15:57:38,277:INFO:                 ray: Not installed
2024-05-24 15:57:38,277:INFO:            hyperopt: Not installed
2024-05-24 15:57:38,277:INFO:              optuna: Not installed
2024-05-24 15:57:38,277:INFO:               skopt: Not installed
2024-05-24 15:57:38,278:INFO:              mlflow: Not installed
2024-05-24 15:57:38,278:INFO:              gradio: Not installed
2024-05-24 15:57:38,278:INFO:             fastapi: Not installed
2024-05-24 15:57:38,278:INFO:             uvicorn: Not installed
2024-05-24 15:57:38,278:INFO:              m2cgen: Not installed
2024-05-24 15:57:38,278:INFO:           evidently: Not installed
2024-05-24 15:57:38,278:INFO:               fugue: Not installed
2024-05-24 15:57:38,278:INFO:           streamlit: Not installed
2024-05-24 15:57:38,278:INFO:             prophet: Not installed
2024-05-24 15:57:38,278:INFO:None
2024-05-24 15:57:38,278:INFO:Set up data.
2024-05-24 15:57:38,295:INFO:Set up folding strategy.
2024-05-24 15:57:38,296:INFO:Set up train/test split.
2024-05-24 15:57:38,308:INFO:Set up index.
2024-05-24 15:57:38,309:INFO:Assigning column types.
2024-05-24 15:57:38,316:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:57:38,316:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,321:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,397:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,450:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,455:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,460:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,575:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:57:38,581:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,703:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,707:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,819:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:57:38,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:38,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:38,947:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,057:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:57:39,130:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,298:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:57:39,371:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:57:39,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,532:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:57:39,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:39,775:INFO:Preparing preprocessing pipeline...
2024-05-24 15:57:39,775:INFO:Set up simple imputation.
2024-05-24 15:57:39,780:INFO:Set up encoding of ordinal features.
2024-05-24 15:57:39,786:INFO:Set up encoding of categorical features.
2024-05-24 15:57:39,786:INFO:Set up polynomial features.
2024-05-24 15:57:39,786:INFO:Set up removing multicollinearity.
2024-05-24 15:57:39,786:INFO:Set up PCA.
2024-05-24 15:57:41,109:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:57:41,176:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('pca',
                 TransformerWrapper(exclude=[],
                                    transformer=PCA(n_components=5)))])
2024-05-24 15:57:41,176:INFO:Creating final display dataframe.
2024-05-24 15:57:42,361:INFO:Setup _display_container:                     Description             Value
0                    Session id              3408
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape          (205, 6)
5   Transformed train set shape          (143, 6)
6    Transformed test set shape           (62, 6)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19                          PCA              True
20                   PCA method            linear
21               PCA components                 5
22               Fold Generator             KFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  reg-default-name
28                          USI              0a1d
2024-05-24 15:57:42,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:42,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:42,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:42,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:57:42,617:INFO:setup() successfully completed in 4.36s...............
2024-05-24 15:57:42,662:INFO:Initializing compare_models()
2024-05-24 15:57:42,663:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:57:42,663:INFO:Checking exceptions
2024-05-24 15:57:42,666:INFO:Preparing display monitor
2024-05-24 15:57:42,694:INFO:Initializing Linear Regression
2024-05-24 15:57:42,695:INFO:Total runtime is 1.668532689412435e-05 minutes
2024-05-24 15:57:42,710:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:42,711:INFO:Initializing create_model()
2024-05-24 15:57:42,711:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:42,711:INFO:Checking exceptions
2024-05-24 15:57:42,711:INFO:Importing libraries
2024-05-24 15:57:42,712:INFO:Copying training dataset
2024-05-24 15:57:42,721:INFO:Defining folds
2024-05-24 15:57:42,721:INFO:Declaring metric variables
2024-05-24 15:57:42,726:INFO:Importing untrained model
2024-05-24 15:57:42,732:INFO:Linear Regression Imported successfully
2024-05-24 15:57:42,744:INFO:Starting cross validation
2024-05-24 15:57:42,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:44,933:INFO:Calculating mean and std
2024-05-24 15:57:44,935:INFO:Creating metrics dataframe
2024-05-24 15:57:44,937:INFO:Uploading results into container
2024-05-24 15:57:44,937:INFO:Uploading model into container now
2024-05-24 15:57:44,937:INFO:_master_model_container: 1
2024-05-24 15:57:44,937:INFO:_display_container: 2
2024-05-24 15:57:44,938:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:57:44,938:INFO:create_model() successfully completed......................................
2024-05-24 15:57:45,145:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:45,145:INFO:Creating metrics dataframe
2024-05-24 15:57:45,154:INFO:Initializing Lasso Regression
2024-05-24 15:57:45,154:INFO:Total runtime is 0.0409973939259847 minutes
2024-05-24 15:57:45,158:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:45,158:INFO:Initializing create_model()
2024-05-24 15:57:45,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:45,158:INFO:Checking exceptions
2024-05-24 15:57:45,158:INFO:Importing libraries
2024-05-24 15:57:45,159:INFO:Copying training dataset
2024-05-24 15:57:45,165:INFO:Defining folds
2024-05-24 15:57:45,167:INFO:Declaring metric variables
2024-05-24 15:57:45,171:INFO:Importing untrained model
2024-05-24 15:57:45,176:INFO:Lasso Regression Imported successfully
2024-05-24 15:57:45,185:INFO:Starting cross validation
2024-05-24 15:57:45,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:47,202:INFO:Calculating mean and std
2024-05-24 15:57:47,204:INFO:Creating metrics dataframe
2024-05-24 15:57:47,206:INFO:Uploading results into container
2024-05-24 15:57:47,206:INFO:Uploading model into container now
2024-05-24 15:57:47,206:INFO:_master_model_container: 2
2024-05-24 15:57:47,206:INFO:_display_container: 2
2024-05-24 15:57:47,207:INFO:Lasso(random_state=3408)
2024-05-24 15:57:47,207:INFO:create_model() successfully completed......................................
2024-05-24 15:57:47,403:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:47,403:INFO:Creating metrics dataframe
2024-05-24 15:57:47,413:INFO:Initializing Ridge Regression
2024-05-24 15:57:47,413:INFO:Total runtime is 0.07864642937978109 minutes
2024-05-24 15:57:47,417:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:47,418:INFO:Initializing create_model()
2024-05-24 15:57:47,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:47,418:INFO:Checking exceptions
2024-05-24 15:57:47,418:INFO:Importing libraries
2024-05-24 15:57:47,418:INFO:Copying training dataset
2024-05-24 15:57:47,426:INFO:Defining folds
2024-05-24 15:57:47,426:INFO:Declaring metric variables
2024-05-24 15:57:47,431:INFO:Importing untrained model
2024-05-24 15:57:47,436:INFO:Ridge Regression Imported successfully
2024-05-24 15:57:47,444:INFO:Starting cross validation
2024-05-24 15:57:47,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:49,360:INFO:Calculating mean and std
2024-05-24 15:57:49,362:INFO:Creating metrics dataframe
2024-05-24 15:57:49,364:INFO:Uploading results into container
2024-05-24 15:57:49,365:INFO:Uploading model into container now
2024-05-24 15:57:49,366:INFO:_master_model_container: 3
2024-05-24 15:57:49,366:INFO:_display_container: 2
2024-05-24 15:57:49,367:INFO:Ridge(random_state=3408)
2024-05-24 15:57:49,367:INFO:create_model() successfully completed......................................
2024-05-24 15:57:49,560:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:49,561:INFO:Creating metrics dataframe
2024-05-24 15:57:49,569:INFO:Initializing Elastic Net
2024-05-24 15:57:49,570:INFO:Total runtime is 0.11460378964742024 minutes
2024-05-24 15:57:49,573:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:49,573:INFO:Initializing create_model()
2024-05-24 15:57:49,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:49,575:INFO:Checking exceptions
2024-05-24 15:57:49,575:INFO:Importing libraries
2024-05-24 15:57:49,575:INFO:Copying training dataset
2024-05-24 15:57:49,581:INFO:Defining folds
2024-05-24 15:57:49,582:INFO:Declaring metric variables
2024-05-24 15:57:49,586:INFO:Importing untrained model
2024-05-24 15:57:49,591:INFO:Elastic Net Imported successfully
2024-05-24 15:57:49,598:INFO:Starting cross validation
2024-05-24 15:57:49,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:51,448:INFO:Calculating mean and std
2024-05-24 15:57:51,450:INFO:Creating metrics dataframe
2024-05-24 15:57:51,452:INFO:Uploading results into container
2024-05-24 15:57:51,453:INFO:Uploading model into container now
2024-05-24 15:57:51,453:INFO:_master_model_container: 4
2024-05-24 15:57:51,453:INFO:_display_container: 2
2024-05-24 15:57:51,454:INFO:ElasticNet(random_state=3408)
2024-05-24 15:57:51,454:INFO:create_model() successfully completed......................................
2024-05-24 15:57:51,650:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:51,650:INFO:Creating metrics dataframe
2024-05-24 15:57:51,657:INFO:Initializing Least Angle Regression
2024-05-24 15:57:51,658:INFO:Total runtime is 0.14940669933954875 minutes
2024-05-24 15:57:51,661:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:51,661:INFO:Initializing create_model()
2024-05-24 15:57:51,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:51,662:INFO:Checking exceptions
2024-05-24 15:57:51,662:INFO:Importing libraries
2024-05-24 15:57:51,662:INFO:Copying training dataset
2024-05-24 15:57:51,669:INFO:Defining folds
2024-05-24 15:57:51,670:INFO:Declaring metric variables
2024-05-24 15:57:51,675:INFO:Importing untrained model
2024-05-24 15:57:51,680:INFO:Least Angle Regression Imported successfully
2024-05-24 15:57:51,689:INFO:Starting cross validation
2024-05-24 15:57:51,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:53,523:INFO:Calculating mean and std
2024-05-24 15:57:53,524:INFO:Creating metrics dataframe
2024-05-24 15:57:53,526:INFO:Uploading results into container
2024-05-24 15:57:53,527:INFO:Uploading model into container now
2024-05-24 15:57:53,527:INFO:_master_model_container: 5
2024-05-24 15:57:53,527:INFO:_display_container: 2
2024-05-24 15:57:53,528:INFO:Lars(random_state=3408)
2024-05-24 15:57:53,528:INFO:create_model() successfully completed......................................
2024-05-24 15:57:53,720:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:53,721:INFO:Creating metrics dataframe
2024-05-24 15:57:53,728:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:57:53,728:INFO:Total runtime is 0.18390844265619916 minutes
2024-05-24 15:57:53,732:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:53,733:INFO:Initializing create_model()
2024-05-24 15:57:53,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:53,733:INFO:Checking exceptions
2024-05-24 15:57:53,733:INFO:Importing libraries
2024-05-24 15:57:53,733:INFO:Copying training dataset
2024-05-24 15:57:53,741:INFO:Defining folds
2024-05-24 15:57:53,741:INFO:Declaring metric variables
2024-05-24 15:57:53,744:INFO:Importing untrained model
2024-05-24 15:57:53,748:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:57:53,756:INFO:Starting cross validation
2024-05-24 15:57:53,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:55,660:INFO:Calculating mean and std
2024-05-24 15:57:55,662:INFO:Creating metrics dataframe
2024-05-24 15:57:55,665:INFO:Uploading results into container
2024-05-24 15:57:55,666:INFO:Uploading model into container now
2024-05-24 15:57:55,666:INFO:_master_model_container: 6
2024-05-24 15:57:55,666:INFO:_display_container: 2
2024-05-24 15:57:55,667:INFO:LassoLars(random_state=3408)
2024-05-24 15:57:55,667:INFO:create_model() successfully completed......................................
2024-05-24 15:57:55,857:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:55,857:INFO:Creating metrics dataframe
2024-05-24 15:57:55,867:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:57:55,867:INFO:Total runtime is 0.21955027182896933 minutes
2024-05-24 15:57:55,870:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:55,871:INFO:Initializing create_model()
2024-05-24 15:57:55,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:55,871:INFO:Checking exceptions
2024-05-24 15:57:55,871:INFO:Importing libraries
2024-05-24 15:57:55,871:INFO:Copying training dataset
2024-05-24 15:57:55,878:INFO:Defining folds
2024-05-24 15:57:55,878:INFO:Declaring metric variables
2024-05-24 15:57:55,882:INFO:Importing untrained model
2024-05-24 15:57:55,885:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:57:55,893:INFO:Starting cross validation
2024-05-24 15:57:55,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:57,747:INFO:Calculating mean and std
2024-05-24 15:57:57,749:INFO:Creating metrics dataframe
2024-05-24 15:57:57,751:INFO:Uploading results into container
2024-05-24 15:57:57,752:INFO:Uploading model into container now
2024-05-24 15:57:57,753:INFO:_master_model_container: 7
2024-05-24 15:57:57,753:INFO:_display_container: 2
2024-05-24 15:57:57,753:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:57:57,753:INFO:create_model() successfully completed......................................
2024-05-24 15:57:57,943:INFO:SubProcess create_model() end ==================================
2024-05-24 15:57:57,943:INFO:Creating metrics dataframe
2024-05-24 15:57:57,954:INFO:Initializing Bayesian Ridge
2024-05-24 15:57:57,954:INFO:Total runtime is 0.2543448289235433 minutes
2024-05-24 15:57:57,959:INFO:SubProcess create_model() called ==================================
2024-05-24 15:57:57,959:INFO:Initializing create_model()
2024-05-24 15:57:57,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:57:57,960:INFO:Checking exceptions
2024-05-24 15:57:57,960:INFO:Importing libraries
2024-05-24 15:57:57,960:INFO:Copying training dataset
2024-05-24 15:57:57,967:INFO:Defining folds
2024-05-24 15:57:57,967:INFO:Declaring metric variables
2024-05-24 15:57:57,971:INFO:Importing untrained model
2024-05-24 15:57:57,977:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:57:57,987:INFO:Starting cross validation
2024-05-24 15:57:57,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:57:59,900:INFO:Calculating mean and std
2024-05-24 15:57:59,901:INFO:Creating metrics dataframe
2024-05-24 15:57:59,904:INFO:Uploading results into container
2024-05-24 15:57:59,904:INFO:Uploading model into container now
2024-05-24 15:57:59,904:INFO:_master_model_container: 8
2024-05-24 15:57:59,905:INFO:_display_container: 2
2024-05-24 15:57:59,905:INFO:BayesianRidge()
2024-05-24 15:57:59,905:INFO:create_model() successfully completed......................................
2024-05-24 15:58:00,099:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:00,099:INFO:Creating metrics dataframe
2024-05-24 15:58:00,108:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:58:00,108:INFO:Total runtime is 0.2902356823285421 minutes
2024-05-24 15:58:00,111:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:00,112:INFO:Initializing create_model()
2024-05-24 15:58:00,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:00,112:INFO:Checking exceptions
2024-05-24 15:58:00,112:INFO:Importing libraries
2024-05-24 15:58:00,114:INFO:Copying training dataset
2024-05-24 15:58:00,121:INFO:Defining folds
2024-05-24 15:58:00,121:INFO:Declaring metric variables
2024-05-24 15:58:00,126:INFO:Importing untrained model
2024-05-24 15:58:00,130:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:58:00,139:INFO:Starting cross validation
2024-05-24 15:58:00,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:01,980:INFO:Calculating mean and std
2024-05-24 15:58:01,982:INFO:Creating metrics dataframe
2024-05-24 15:58:01,985:INFO:Uploading results into container
2024-05-24 15:58:01,986:INFO:Uploading model into container now
2024-05-24 15:58:01,987:INFO:_master_model_container: 9
2024-05-24 15:58:01,987:INFO:_display_container: 2
2024-05-24 15:58:01,987:INFO:PassiveAggressiveRegressor(random_state=3408)
2024-05-24 15:58:01,988:INFO:create_model() successfully completed......................................
2024-05-24 15:58:02,183:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:02,183:INFO:Creating metrics dataframe
2024-05-24 15:58:02,194:INFO:Initializing Huber Regressor
2024-05-24 15:58:02,194:INFO:Total runtime is 0.3250045537948608 minutes
2024-05-24 15:58:02,199:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:02,199:INFO:Initializing create_model()
2024-05-24 15:58:02,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:02,199:INFO:Checking exceptions
2024-05-24 15:58:02,201:INFO:Importing libraries
2024-05-24 15:58:02,201:INFO:Copying training dataset
2024-05-24 15:58:02,208:INFO:Defining folds
2024-05-24 15:58:02,208:INFO:Declaring metric variables
2024-05-24 15:58:02,212:INFO:Importing untrained model
2024-05-24 15:58:02,217:INFO:Huber Regressor Imported successfully
2024-05-24 15:58:02,226:INFO:Starting cross validation
2024-05-24 15:58:02,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:04,142:INFO:Calculating mean and std
2024-05-24 15:58:04,144:INFO:Creating metrics dataframe
2024-05-24 15:58:04,146:INFO:Uploading results into container
2024-05-24 15:58:04,147:INFO:Uploading model into container now
2024-05-24 15:58:04,147:INFO:_master_model_container: 10
2024-05-24 15:58:04,148:INFO:_display_container: 2
2024-05-24 15:58:04,149:INFO:HuberRegressor()
2024-05-24 15:58:04,149:INFO:create_model() successfully completed......................................
2024-05-24 15:58:04,340:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:04,341:INFO:Creating metrics dataframe
2024-05-24 15:58:04,351:INFO:Initializing K Neighbors Regressor
2024-05-24 15:58:04,352:INFO:Total runtime is 0.3609624624252319 minutes
2024-05-24 15:58:04,357:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:04,357:INFO:Initializing create_model()
2024-05-24 15:58:04,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:04,357:INFO:Checking exceptions
2024-05-24 15:58:04,357:INFO:Importing libraries
2024-05-24 15:58:04,357:INFO:Copying training dataset
2024-05-24 15:58:04,365:INFO:Defining folds
2024-05-24 15:58:04,366:INFO:Declaring metric variables
2024-05-24 15:58:04,370:INFO:Importing untrained model
2024-05-24 15:58:04,375:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:58:04,387:INFO:Starting cross validation
2024-05-24 15:58:04,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:06,406:INFO:Calculating mean and std
2024-05-24 15:58:06,408:INFO:Creating metrics dataframe
2024-05-24 15:58:06,410:INFO:Uploading results into container
2024-05-24 15:58:06,411:INFO:Uploading model into container now
2024-05-24 15:58:06,411:INFO:_master_model_container: 11
2024-05-24 15:58:06,411:INFO:_display_container: 2
2024-05-24 15:58:06,412:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:58:06,412:INFO:create_model() successfully completed......................................
2024-05-24 15:58:06,607:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:06,607:INFO:Creating metrics dataframe
2024-05-24 15:58:06,618:INFO:Initializing Decision Tree Regressor
2024-05-24 15:58:06,618:INFO:Total runtime is 0.398745048046112 minutes
2024-05-24 15:58:06,623:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:06,623:INFO:Initializing create_model()
2024-05-24 15:58:06,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:06,623:INFO:Checking exceptions
2024-05-24 15:58:06,623:INFO:Importing libraries
2024-05-24 15:58:06,624:INFO:Copying training dataset
2024-05-24 15:58:06,629:INFO:Defining folds
2024-05-24 15:58:06,629:INFO:Declaring metric variables
2024-05-24 15:58:06,634:INFO:Importing untrained model
2024-05-24 15:58:06,638:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:58:06,647:INFO:Starting cross validation
2024-05-24 15:58:06,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:08,470:INFO:Calculating mean and std
2024-05-24 15:58:08,472:INFO:Creating metrics dataframe
2024-05-24 15:58:08,476:INFO:Uploading results into container
2024-05-24 15:58:08,478:INFO:Uploading model into container now
2024-05-24 15:58:08,478:INFO:_master_model_container: 12
2024-05-24 15:58:08,479:INFO:_display_container: 2
2024-05-24 15:58:08,479:INFO:DecisionTreeRegressor(random_state=3408)
2024-05-24 15:58:08,479:INFO:create_model() successfully completed......................................
2024-05-24 15:58:08,670:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:08,670:INFO:Creating metrics dataframe
2024-05-24 15:58:08,680:INFO:Initializing Random Forest Regressor
2024-05-24 15:58:08,680:INFO:Total runtime is 0.43310074408849075 minutes
2024-05-24 15:58:08,684:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:08,685:INFO:Initializing create_model()
2024-05-24 15:58:08,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:08,685:INFO:Checking exceptions
2024-05-24 15:58:08,685:INFO:Importing libraries
2024-05-24 15:58:08,685:INFO:Copying training dataset
2024-05-24 15:58:08,692:INFO:Defining folds
2024-05-24 15:58:08,692:INFO:Declaring metric variables
2024-05-24 15:58:08,697:INFO:Importing untrained model
2024-05-24 15:58:08,703:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:58:08,711:INFO:Starting cross validation
2024-05-24 15:58:08,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:10,970:INFO:Calculating mean and std
2024-05-24 15:58:10,971:INFO:Creating metrics dataframe
2024-05-24 15:58:10,973:INFO:Uploading results into container
2024-05-24 15:58:10,974:INFO:Uploading model into container now
2024-05-24 15:58:10,974:INFO:_master_model_container: 13
2024-05-24 15:58:10,974:INFO:_display_container: 2
2024-05-24 15:58:10,975:INFO:RandomForestRegressor(n_jobs=-1, random_state=3408)
2024-05-24 15:58:10,975:INFO:create_model() successfully completed......................................
2024-05-24 15:58:11,171:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:11,172:INFO:Creating metrics dataframe
2024-05-24 15:58:11,183:INFO:Initializing Extra Trees Regressor
2024-05-24 15:58:11,184:INFO:Total runtime is 0.4748374581336975 minutes
2024-05-24 15:58:11,189:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:11,189:INFO:Initializing create_model()
2024-05-24 15:58:11,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:11,190:INFO:Checking exceptions
2024-05-24 15:58:11,190:INFO:Importing libraries
2024-05-24 15:58:11,190:INFO:Copying training dataset
2024-05-24 15:58:11,195:INFO:Defining folds
2024-05-24 15:58:11,196:INFO:Declaring metric variables
2024-05-24 15:58:11,202:INFO:Importing untrained model
2024-05-24 15:58:11,206:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:58:11,213:INFO:Starting cross validation
2024-05-24 15:58:11,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:13,320:INFO:Calculating mean and std
2024-05-24 15:58:13,321:INFO:Creating metrics dataframe
2024-05-24 15:58:13,324:INFO:Uploading results into container
2024-05-24 15:58:13,325:INFO:Uploading model into container now
2024-05-24 15:58:13,325:INFO:_master_model_container: 14
2024-05-24 15:58:13,325:INFO:_display_container: 2
2024-05-24 15:58:13,326:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3408)
2024-05-24 15:58:13,326:INFO:create_model() successfully completed......................................
2024-05-24 15:58:13,520:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:13,520:INFO:Creating metrics dataframe
2024-05-24 15:58:13,532:INFO:Initializing AdaBoost Regressor
2024-05-24 15:58:13,533:INFO:Total runtime is 0.5139841794967651 minutes
2024-05-24 15:58:13,537:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:13,537:INFO:Initializing create_model()
2024-05-24 15:58:13,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:13,538:INFO:Checking exceptions
2024-05-24 15:58:13,538:INFO:Importing libraries
2024-05-24 15:58:13,538:INFO:Copying training dataset
2024-05-24 15:58:13,548:INFO:Defining folds
2024-05-24 15:58:13,548:INFO:Declaring metric variables
2024-05-24 15:58:13,556:INFO:Importing untrained model
2024-05-24 15:58:13,561:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:58:13,572:INFO:Starting cross validation
2024-05-24 15:58:13,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:15,531:INFO:Calculating mean and std
2024-05-24 15:58:15,532:INFO:Creating metrics dataframe
2024-05-24 15:58:15,535:INFO:Uploading results into container
2024-05-24 15:58:15,536:INFO:Uploading model into container now
2024-05-24 15:58:15,536:INFO:_master_model_container: 15
2024-05-24 15:58:15,536:INFO:_display_container: 2
2024-05-24 15:58:15,536:INFO:AdaBoostRegressor(random_state=3408)
2024-05-24 15:58:15,536:INFO:create_model() successfully completed......................................
2024-05-24 15:58:15,736:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:15,736:INFO:Creating metrics dataframe
2024-05-24 15:58:15,746:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:58:15,746:INFO:Total runtime is 0.5508768916130066 minutes
2024-05-24 15:58:15,751:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:15,751:INFO:Initializing create_model()
2024-05-24 15:58:15,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:15,751:INFO:Checking exceptions
2024-05-24 15:58:15,752:INFO:Importing libraries
2024-05-24 15:58:15,752:INFO:Copying training dataset
2024-05-24 15:58:15,758:INFO:Defining folds
2024-05-24 15:58:15,758:INFO:Declaring metric variables
2024-05-24 15:58:15,762:INFO:Importing untrained model
2024-05-24 15:58:15,768:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:58:15,778:INFO:Starting cross validation
2024-05-24 15:58:15,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:17,712:INFO:Calculating mean and std
2024-05-24 15:58:17,714:INFO:Creating metrics dataframe
2024-05-24 15:58:17,716:INFO:Uploading results into container
2024-05-24 15:58:17,717:INFO:Uploading model into container now
2024-05-24 15:58:17,718:INFO:_master_model_container: 16
2024-05-24 15:58:17,718:INFO:_display_container: 2
2024-05-24 15:58:17,719:INFO:GradientBoostingRegressor(random_state=3408)
2024-05-24 15:58:17,719:INFO:create_model() successfully completed......................................
2024-05-24 15:58:17,908:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:17,908:INFO:Creating metrics dataframe
2024-05-24 15:58:17,918:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:58:17,918:INFO:Total runtime is 0.5870757937431336 minutes
2024-05-24 15:58:17,922:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:17,923:INFO:Initializing create_model()
2024-05-24 15:58:17,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:17,923:INFO:Checking exceptions
2024-05-24 15:58:17,923:INFO:Importing libraries
2024-05-24 15:58:17,923:INFO:Copying training dataset
2024-05-24 15:58:17,930:INFO:Defining folds
2024-05-24 15:58:17,930:INFO:Declaring metric variables
2024-05-24 15:58:17,936:INFO:Importing untrained model
2024-05-24 15:58:17,940:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:58:17,947:INFO:Starting cross validation
2024-05-24 15:58:17,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:20,250:INFO:Calculating mean and std
2024-05-24 15:58:20,252:INFO:Creating metrics dataframe
2024-05-24 15:58:20,254:INFO:Uploading results into container
2024-05-24 15:58:20,255:INFO:Uploading model into container now
2024-05-24 15:58:20,256:INFO:_master_model_container: 17
2024-05-24 15:58:20,256:INFO:_display_container: 2
2024-05-24 15:58:20,257:INFO:LGBMRegressor(n_jobs=-1, random_state=3408)
2024-05-24 15:58:20,257:INFO:create_model() successfully completed......................................
2024-05-24 15:58:20,469:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:20,470:INFO:Creating metrics dataframe
2024-05-24 15:58:20,483:INFO:Initializing Dummy Regressor
2024-05-24 15:58:20,484:INFO:Total runtime is 0.6298422296841939 minutes
2024-05-24 15:58:20,487:INFO:SubProcess create_model() called ==================================
2024-05-24 15:58:20,488:INFO:Initializing create_model()
2024-05-24 15:58:20,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C913C280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:20,488:INFO:Checking exceptions
2024-05-24 15:58:20,488:INFO:Importing libraries
2024-05-24 15:58:20,488:INFO:Copying training dataset
2024-05-24 15:58:20,494:INFO:Defining folds
2024-05-24 15:58:20,494:INFO:Declaring metric variables
2024-05-24 15:58:20,497:INFO:Importing untrained model
2024-05-24 15:58:20,502:INFO:Dummy Regressor Imported successfully
2024-05-24 15:58:20,512:INFO:Starting cross validation
2024-05-24 15:58:20,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:58:22,444:INFO:Calculating mean and std
2024-05-24 15:58:22,446:INFO:Creating metrics dataframe
2024-05-24 15:58:22,448:INFO:Uploading results into container
2024-05-24 15:58:22,449:INFO:Uploading model into container now
2024-05-24 15:58:22,450:INFO:_master_model_container: 18
2024-05-24 15:58:22,450:INFO:_display_container: 2
2024-05-24 15:58:22,451:INFO:DummyRegressor()
2024-05-24 15:58:22,451:INFO:create_model() successfully completed......................................
2024-05-24 15:58:22,638:INFO:SubProcess create_model() end ==================================
2024-05-24 15:58:22,638:INFO:Creating metrics dataframe
2024-05-24 15:58:22,652:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:58:22,673:INFO:Initializing create_model()
2024-05-24 15:58:22,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C86644C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3408), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:58:22,674:INFO:Checking exceptions
2024-05-24 15:58:22,677:INFO:Importing libraries
2024-05-24 15:58:22,677:INFO:Copying training dataset
2024-05-24 15:58:22,688:INFO:Defining folds
2024-05-24 15:58:22,688:INFO:Declaring metric variables
2024-05-24 15:58:22,689:INFO:Importing untrained model
2024-05-24 15:58:22,689:INFO:Declaring custom model
2024-05-24 15:58:22,690:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:58:22,710:INFO:Cross validation set to False
2024-05-24 15:58:22,710:INFO:Fitting Model
2024-05-24 15:58:23,820:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3408)
2024-05-24 15:58:23,820:INFO:create_model() successfully completed......................................
2024-05-24 15:58:24,061:INFO:_master_model_container: 18
2024-05-24 15:58:24,061:INFO:_display_container: 2
2024-05-24 15:58:24,062:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3408)
2024-05-24 15:58:24,062:INFO:compare_models() successfully completed......................................
2024-05-24 15:58:58,454:INFO:PyCaret RegressionExperiment
2024-05-24 15:58:58,454:INFO:Logging name: reg-default-name
2024-05-24 15:58:58,454:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 15:58:58,454:INFO:version 3.3.2
2024-05-24 15:58:58,454:INFO:Initializing setup()
2024-05-24 15:58:58,454:INFO:self.USI: 47fc
2024-05-24 15:58:58,454:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 15:58:58,455:INFO:Checking environment
2024-05-24 15:58:58,455:INFO:python_version: 3.10.14
2024-05-24 15:58:58,455:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 15:58:58,455:INFO:machine: AMD64
2024-05-24 15:58:58,455:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 15:58:58,455:INFO:Memory: svmem(total=16541802496, available=2415992832, percent=85.4, used=14125809664, free=2415992832)
2024-05-24 15:58:58,455:INFO:Physical Core: 6
2024-05-24 15:58:58,455:INFO:Logical Core: 12
2024-05-24 15:58:58,455:INFO:Checking libraries
2024-05-24 15:58:58,455:INFO:System:
2024-05-24 15:58:58,455:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 15:58:58,455:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 15:58:58,456:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 15:58:58,456:INFO:PyCaret required dependencies:
2024-05-24 15:58:58,456:INFO:                 pip: 24.0
2024-05-24 15:58:58,456:INFO:          setuptools: 69.5.1
2024-05-24 15:58:58,456:INFO:             pycaret: 3.3.2
2024-05-24 15:58:58,456:INFO:             IPython: 8.20.0
2024-05-24 15:58:58,456:INFO:          ipywidgets: 8.1.2
2024-05-24 15:58:58,456:INFO:                tqdm: 4.66.4
2024-05-24 15:58:58,456:INFO:               numpy: 1.26.4
2024-05-24 15:58:58,456:INFO:              pandas: 2.1.4
2024-05-24 15:58:58,456:INFO:              jinja2: 3.1.3
2024-05-24 15:58:58,456:INFO:               scipy: 1.11.4
2024-05-24 15:58:58,456:INFO:              joblib: 1.3.2
2024-05-24 15:58:58,457:INFO:             sklearn: 1.4.2
2024-05-24 15:58:58,457:INFO:                pyod: 1.1.3
2024-05-24 15:58:58,457:INFO:            imblearn: 0.12.2
2024-05-24 15:58:58,457:INFO:   category_encoders: 2.6.3
2024-05-24 15:58:58,457:INFO:            lightgbm: 4.3.0
2024-05-24 15:58:58,457:INFO:               numba: 0.59.1
2024-05-24 15:58:58,457:INFO:            requests: 2.32.2
2024-05-24 15:58:58,457:INFO:          matplotlib: 3.7.5
2024-05-24 15:58:58,457:INFO:          scikitplot: 0.3.7
2024-05-24 15:58:58,457:INFO:         yellowbrick: 1.5
2024-05-24 15:58:58,457:INFO:              plotly: 5.22.0
2024-05-24 15:58:58,457:INFO:    plotly-resampler: Not installed
2024-05-24 15:58:58,457:INFO:             kaleido: 0.2.1
2024-05-24 15:58:58,457:INFO:           schemdraw: 0.15
2024-05-24 15:58:58,457:INFO:         statsmodels: 0.14.2
2024-05-24 15:58:58,457:INFO:              sktime: 0.26.0
2024-05-24 15:58:58,457:INFO:               tbats: 1.1.3
2024-05-24 15:58:58,458:INFO:            pmdarima: 2.0.4
2024-05-24 15:58:58,458:INFO:              psutil: 5.9.0
2024-05-24 15:58:58,458:INFO:          markupsafe: 2.1.3
2024-05-24 15:58:58,458:INFO:             pickle5: Not installed
2024-05-24 15:58:58,458:INFO:         cloudpickle: 3.0.0
2024-05-24 15:58:58,458:INFO:         deprecation: 2.1.0
2024-05-24 15:58:58,458:INFO:              xxhash: 3.4.1
2024-05-24 15:58:58,458:INFO:           wurlitzer: Not installed
2024-05-24 15:58:58,458:INFO:PyCaret optional dependencies:
2024-05-24 15:58:58,458:INFO:                shap: Not installed
2024-05-24 15:58:58,458:INFO:           interpret: Not installed
2024-05-24 15:58:58,458:INFO:                umap: Not installed
2024-05-24 15:58:58,458:INFO:     ydata_profiling: Not installed
2024-05-24 15:58:58,458:INFO:  explainerdashboard: Not installed
2024-05-24 15:58:58,458:INFO:             autoviz: Not installed
2024-05-24 15:58:58,458:INFO:           fairlearn: Not installed
2024-05-24 15:58:58,459:INFO:          deepchecks: Not installed
2024-05-24 15:58:58,459:INFO:             xgboost: Not installed
2024-05-24 15:58:58,459:INFO:            catboost: Not installed
2024-05-24 15:58:58,459:INFO:              kmodes: Not installed
2024-05-24 15:58:58,459:INFO:             mlxtend: Not installed
2024-05-24 15:58:58,459:INFO:       statsforecast: Not installed
2024-05-24 15:58:58,459:INFO:        tune_sklearn: Not installed
2024-05-24 15:58:58,459:INFO:                 ray: Not installed
2024-05-24 15:58:58,459:INFO:            hyperopt: Not installed
2024-05-24 15:58:58,459:INFO:              optuna: Not installed
2024-05-24 15:58:58,459:INFO:               skopt: Not installed
2024-05-24 15:58:58,459:INFO:              mlflow: Not installed
2024-05-24 15:58:58,459:INFO:              gradio: Not installed
2024-05-24 15:58:58,459:INFO:             fastapi: Not installed
2024-05-24 15:58:58,459:INFO:             uvicorn: Not installed
2024-05-24 15:58:58,459:INFO:              m2cgen: Not installed
2024-05-24 15:58:58,459:INFO:           evidently: Not installed
2024-05-24 15:58:58,460:INFO:               fugue: Not installed
2024-05-24 15:58:58,460:INFO:           streamlit: Not installed
2024-05-24 15:58:58,460:INFO:             prophet: Not installed
2024-05-24 15:58:58,460:INFO:None
2024-05-24 15:58:58,460:INFO:Set up data.
2024-05-24 15:58:58,474:INFO:Set up folding strategy.
2024-05-24 15:58:58,475:INFO:Set up train/test split.
2024-05-24 15:58:58,485:INFO:Set up index.
2024-05-24 15:58:58,485:INFO:Assigning column types.
2024-05-24 15:58:58,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 15:58:58,494:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,502:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,508:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,572:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,618:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,624:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,738:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 15:58:58,743:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,747:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,860:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,866:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,871:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:58,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:58,979:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 15:58:58,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,171:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,221:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 15:58:59,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,459:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 15:58:59,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 15:58:59,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,694:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 15:58:59,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:58:59,938:INFO:Preparing preprocessing pipeline...
2024-05-24 15:58:59,938:INFO:Set up simple imputation.
2024-05-24 15:58:59,942:INFO:Set up encoding of ordinal features.
2024-05-24 15:58:59,948:INFO:Set up encoding of categorical features.
2024-05-24 15:58:59,948:INFO:Set up polynomial features.
2024-05-24 15:58:59,948:INFO:Set up removing multicollinearity.
2024-05-24 15:58:59,948:INFO:Set up removing outliers.
2024-05-24 15:59:01,256:INFO:Finished creating preprocessing pipeline.
2024-05-24 15:59:01,325:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=5724)))])
2024-05-24 15:59:01,326:INFO:Creating final display dataframe.
2024-05-24 15:59:03,839:INFO:Setup _display_container:                     Description             Value
0                    Session id              5724
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 480)
5   Transformed train set shape        (135, 480)
6    Transformed test set shape         (62, 480)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              47fc
2024-05-24 15:59:03,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:59:03,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:59:04,093:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:59:04,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 15:59:04,094:INFO:setup() successfully completed in 5.66s...............
2024-05-24 15:59:04,130:INFO:Initializing compare_models()
2024-05-24 15:59:04,130:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 15:59:04,130:INFO:Checking exceptions
2024-05-24 15:59:04,135:INFO:Preparing display monitor
2024-05-24 15:59:04,162:INFO:Initializing Linear Regression
2024-05-24 15:59:04,162:INFO:Total runtime is 0.0 minutes
2024-05-24 15:59:04,165:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:04,166:INFO:Initializing create_model()
2024-05-24 15:59:04,166:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:04,166:INFO:Checking exceptions
2024-05-24 15:59:04,166:INFO:Importing libraries
2024-05-24 15:59:04,166:INFO:Copying training dataset
2024-05-24 15:59:04,175:INFO:Defining folds
2024-05-24 15:59:04,175:INFO:Declaring metric variables
2024-05-24 15:59:04,179:INFO:Importing untrained model
2024-05-24 15:59:04,183:INFO:Linear Regression Imported successfully
2024-05-24 15:59:04,196:INFO:Starting cross validation
2024-05-24 15:59:04,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:06,456:INFO:Calculating mean and std
2024-05-24 15:59:06,458:INFO:Creating metrics dataframe
2024-05-24 15:59:06,461:INFO:Uploading results into container
2024-05-24 15:59:06,461:INFO:Uploading model into container now
2024-05-24 15:59:06,463:INFO:_master_model_container: 1
2024-05-24 15:59:06,463:INFO:_display_container: 2
2024-05-24 15:59:06,464:INFO:LinearRegression(n_jobs=-1)
2024-05-24 15:59:06,464:INFO:create_model() successfully completed......................................
2024-05-24 15:59:06,682:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:06,682:INFO:Creating metrics dataframe
2024-05-24 15:59:06,691:INFO:Initializing Lasso Regression
2024-05-24 15:59:06,691:INFO:Total runtime is 0.04214596748352051 minutes
2024-05-24 15:59:06,696:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:06,696:INFO:Initializing create_model()
2024-05-24 15:59:06,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:06,697:INFO:Checking exceptions
2024-05-24 15:59:06,697:INFO:Importing libraries
2024-05-24 15:59:06,697:INFO:Copying training dataset
2024-05-24 15:59:06,703:INFO:Defining folds
2024-05-24 15:59:06,703:INFO:Declaring metric variables
2024-05-24 15:59:06,708:INFO:Importing untrained model
2024-05-24 15:59:06,714:INFO:Lasso Regression Imported successfully
2024-05-24 15:59:06,724:INFO:Starting cross validation
2024-05-24 15:59:06,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:08,659:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e+07, tolerance: 5.864e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,684:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+07, tolerance: 5.592e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,722:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+07, tolerance: 5.616e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,743:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+07, tolerance: 5.470e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,758:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.525e+07, tolerance: 5.460e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,784:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+07, tolerance: 5.689e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,791:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+07, tolerance: 4.974e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,840:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.917e+07, tolerance: 5.431e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,848:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.373e+07, tolerance: 4.867e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,889:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+07, tolerance: 5.263e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:08,956:INFO:Calculating mean and std
2024-05-24 15:59:08,958:INFO:Creating metrics dataframe
2024-05-24 15:59:08,960:INFO:Uploading results into container
2024-05-24 15:59:08,961:INFO:Uploading model into container now
2024-05-24 15:59:08,961:INFO:_master_model_container: 2
2024-05-24 15:59:08,961:INFO:_display_container: 2
2024-05-24 15:59:08,962:INFO:Lasso(random_state=5724)
2024-05-24 15:59:08,962:INFO:create_model() successfully completed......................................
2024-05-24 15:59:09,151:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:09,151:INFO:Creating metrics dataframe
2024-05-24 15:59:09,160:INFO:Initializing Ridge Regression
2024-05-24 15:59:09,161:INFO:Total runtime is 0.08331495523452759 minutes
2024-05-24 15:59:09,164:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:09,165:INFO:Initializing create_model()
2024-05-24 15:59:09,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:09,165:INFO:Checking exceptions
2024-05-24 15:59:09,165:INFO:Importing libraries
2024-05-24 15:59:09,165:INFO:Copying training dataset
2024-05-24 15:59:09,172:INFO:Defining folds
2024-05-24 15:59:09,172:INFO:Declaring metric variables
2024-05-24 15:59:09,177:INFO:Importing untrained model
2024-05-24 15:59:09,181:INFO:Ridge Regression Imported successfully
2024-05-24 15:59:09,190:INFO:Starting cross validation
2024-05-24 15:59:09,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:11,109:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,166:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,166:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,231:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,259:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,291:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,315:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,346:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,374:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,392:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 15:59:11,459:INFO:Calculating mean and std
2024-05-24 15:59:11,460:INFO:Creating metrics dataframe
2024-05-24 15:59:11,462:INFO:Uploading results into container
2024-05-24 15:59:11,463:INFO:Uploading model into container now
2024-05-24 15:59:11,464:INFO:_master_model_container: 3
2024-05-24 15:59:11,464:INFO:_display_container: 2
2024-05-24 15:59:11,464:INFO:Ridge(random_state=5724)
2024-05-24 15:59:11,465:INFO:create_model() successfully completed......................................
2024-05-24 15:59:11,661:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:11,661:INFO:Creating metrics dataframe
2024-05-24 15:59:11,669:INFO:Initializing Elastic Net
2024-05-24 15:59:11,669:INFO:Total runtime is 0.12512194315592448 minutes
2024-05-24 15:59:11,673:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:11,674:INFO:Initializing create_model()
2024-05-24 15:59:11,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:11,674:INFO:Checking exceptions
2024-05-24 15:59:11,674:INFO:Importing libraries
2024-05-24 15:59:11,674:INFO:Copying training dataset
2024-05-24 15:59:11,680:INFO:Defining folds
2024-05-24 15:59:11,683:INFO:Declaring metric variables
2024-05-24 15:59:11,687:INFO:Importing untrained model
2024-05-24 15:59:11,692:INFO:Elastic Net Imported successfully
2024-05-24 15:59:11,701:INFO:Starting cross validation
2024-05-24 15:59:11,725:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:13,540:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.178e+07, tolerance: 5.592e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,654:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.989e+07, tolerance: 5.460e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.680e+07, tolerance: 5.864e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+07, tolerance: 5.470e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,671:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.828e+07, tolerance: 4.974e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,684:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.517e+07, tolerance: 5.263e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,700:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.936e+07, tolerance: 4.867e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,713:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.444e+07, tolerance: 5.689e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,715:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.952e+07, tolerance: 5.431e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,750:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+07, tolerance: 5.616e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 15:59:13,842:INFO:Calculating mean and std
2024-05-24 15:59:13,844:INFO:Creating metrics dataframe
2024-05-24 15:59:13,847:INFO:Uploading results into container
2024-05-24 15:59:13,847:INFO:Uploading model into container now
2024-05-24 15:59:13,848:INFO:_master_model_container: 4
2024-05-24 15:59:13,848:INFO:_display_container: 2
2024-05-24 15:59:13,849:INFO:ElasticNet(random_state=5724)
2024-05-24 15:59:13,849:INFO:create_model() successfully completed......................................
2024-05-24 15:59:14,062:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:14,062:INFO:Creating metrics dataframe
2024-05-24 15:59:14,072:INFO:Initializing Least Angle Regression
2024-05-24 15:59:14,072:INFO:Total runtime is 0.16517497698465983 minutes
2024-05-24 15:59:14,077:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:14,077:INFO:Initializing create_model()
2024-05-24 15:59:14,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:14,078:INFO:Checking exceptions
2024-05-24 15:59:14,078:INFO:Importing libraries
2024-05-24 15:59:14,078:INFO:Copying training dataset
2024-05-24 15:59:14,083:INFO:Defining folds
2024-05-24 15:59:14,083:INFO:Declaring metric variables
2024-05-24 15:59:14,088:INFO:Importing untrained model
2024-05-24 15:59:14,093:INFO:Least Angle Regression Imported successfully
2024-05-24 15:59:14,101:INFO:Starting cross validation
2024-05-24 15:59:14,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:15,896:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=3.368e+05, with an active set of 113 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:59:16,035:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=3.486e+05, with an active set of 117 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:59:16,053:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=1.771e+08, with an active set of 110 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:59:16,080:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=2.420e+03, with an active set of 88 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:59:16,224:INFO:Calculating mean and std
2024-05-24 15:59:16,225:INFO:Creating metrics dataframe
2024-05-24 15:59:16,228:INFO:Uploading results into container
2024-05-24 15:59:16,228:INFO:Uploading model into container now
2024-05-24 15:59:16,229:INFO:_master_model_container: 5
2024-05-24 15:59:16,230:INFO:_display_container: 2
2024-05-24 15:59:16,230:INFO:Lars(random_state=5724)
2024-05-24 15:59:16,230:INFO:create_model() successfully completed......................................
2024-05-24 15:59:16,452:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:16,452:INFO:Creating metrics dataframe
2024-05-24 15:59:16,461:INFO:Initializing Lasso Least Angle Regression
2024-05-24 15:59:16,463:INFO:Total runtime is 0.20501427253087362 minutes
2024-05-24 15:59:16,466:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:16,468:INFO:Initializing create_model()
2024-05-24 15:59:16,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:16,468:INFO:Checking exceptions
2024-05-24 15:59:16,468:INFO:Importing libraries
2024-05-24 15:59:16,468:INFO:Copying training dataset
2024-05-24 15:59:16,477:INFO:Defining folds
2024-05-24 15:59:16,477:INFO:Declaring metric variables
2024-05-24 15:59:16,483:INFO:Importing untrained model
2024-05-24 15:59:16,487:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 15:59:16,496:INFO:Starting cross validation
2024-05-24 15:59:16,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:18,742:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.918e+00, with an active set of 79 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 15:59:18,916:INFO:Calculating mean and std
2024-05-24 15:59:18,918:INFO:Creating metrics dataframe
2024-05-24 15:59:18,921:INFO:Uploading results into container
2024-05-24 15:59:18,922:INFO:Uploading model into container now
2024-05-24 15:59:18,922:INFO:_master_model_container: 6
2024-05-24 15:59:18,922:INFO:_display_container: 2
2024-05-24 15:59:18,923:INFO:LassoLars(random_state=5724)
2024-05-24 15:59:18,923:INFO:create_model() successfully completed......................................
2024-05-24 15:59:19,126:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:19,126:INFO:Creating metrics dataframe
2024-05-24 15:59:19,134:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 15:59:19,134:INFO:Total runtime is 0.24953354199727376 minutes
2024-05-24 15:59:19,139:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:19,139:INFO:Initializing create_model()
2024-05-24 15:59:19,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:19,140:INFO:Checking exceptions
2024-05-24 15:59:19,140:INFO:Importing libraries
2024-05-24 15:59:19,140:INFO:Copying training dataset
2024-05-24 15:59:19,146:INFO:Defining folds
2024-05-24 15:59:19,146:INFO:Declaring metric variables
2024-05-24 15:59:19,152:INFO:Importing untrained model
2024-05-24 15:59:19,171:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 15:59:19,182:INFO:Starting cross validation
2024-05-24 15:59:19,216:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:21,290:INFO:Calculating mean and std
2024-05-24 15:59:21,292:INFO:Creating metrics dataframe
2024-05-24 15:59:21,295:INFO:Uploading results into container
2024-05-24 15:59:21,295:INFO:Uploading model into container now
2024-05-24 15:59:21,296:INFO:_master_model_container: 7
2024-05-24 15:59:21,296:INFO:_display_container: 2
2024-05-24 15:59:21,296:INFO:OrthogonalMatchingPursuit()
2024-05-24 15:59:21,296:INFO:create_model() successfully completed......................................
2024-05-24 15:59:21,510:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:21,510:INFO:Creating metrics dataframe
2024-05-24 15:59:21,520:INFO:Initializing Bayesian Ridge
2024-05-24 15:59:21,521:INFO:Total runtime is 0.2893284161885579 minutes
2024-05-24 15:59:21,526:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:21,527:INFO:Initializing create_model()
2024-05-24 15:59:21,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:21,527:INFO:Checking exceptions
2024-05-24 15:59:21,527:INFO:Importing libraries
2024-05-24 15:59:21,527:INFO:Copying training dataset
2024-05-24 15:59:21,534:INFO:Defining folds
2024-05-24 15:59:21,534:INFO:Declaring metric variables
2024-05-24 15:59:21,538:INFO:Importing untrained model
2024-05-24 15:59:21,543:INFO:Bayesian Ridge Imported successfully
2024-05-24 15:59:21,552:INFO:Starting cross validation
2024-05-24 15:59:21,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:23,855:INFO:Calculating mean and std
2024-05-24 15:59:23,857:INFO:Creating metrics dataframe
2024-05-24 15:59:23,860:INFO:Uploading results into container
2024-05-24 15:59:23,861:INFO:Uploading model into container now
2024-05-24 15:59:23,861:INFO:_master_model_container: 8
2024-05-24 15:59:23,861:INFO:_display_container: 2
2024-05-24 15:59:23,862:INFO:BayesianRidge()
2024-05-24 15:59:23,862:INFO:create_model() successfully completed......................................
2024-05-24 15:59:24,053:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:24,053:INFO:Creating metrics dataframe
2024-05-24 15:59:24,063:INFO:Initializing Passive Aggressive Regressor
2024-05-24 15:59:24,064:INFO:Total runtime is 0.33169890244801836 minutes
2024-05-24 15:59:24,067:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:24,068:INFO:Initializing create_model()
2024-05-24 15:59:24,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:24,068:INFO:Checking exceptions
2024-05-24 15:59:24,068:INFO:Importing libraries
2024-05-24 15:59:24,068:INFO:Copying training dataset
2024-05-24 15:59:24,075:INFO:Defining folds
2024-05-24 15:59:24,075:INFO:Declaring metric variables
2024-05-24 15:59:24,079:INFO:Importing untrained model
2024-05-24 15:59:24,085:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 15:59:24,094:INFO:Starting cross validation
2024-05-24 15:59:24,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:26,194:INFO:Calculating mean and std
2024-05-24 15:59:26,196:INFO:Creating metrics dataframe
2024-05-24 15:59:26,198:INFO:Uploading results into container
2024-05-24 15:59:26,198:INFO:Uploading model into container now
2024-05-24 15:59:26,199:INFO:_master_model_container: 9
2024-05-24 15:59:26,200:INFO:_display_container: 2
2024-05-24 15:59:26,200:INFO:PassiveAggressiveRegressor(random_state=5724)
2024-05-24 15:59:26,200:INFO:create_model() successfully completed......................................
2024-05-24 15:59:26,422:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:26,422:INFO:Creating metrics dataframe
2024-05-24 15:59:26,434:INFO:Initializing Huber Regressor
2024-05-24 15:59:26,434:INFO:Total runtime is 0.3712085405985514 minutes
2024-05-24 15:59:26,438:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:26,438:INFO:Initializing create_model()
2024-05-24 15:59:26,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:26,439:INFO:Checking exceptions
2024-05-24 15:59:26,440:INFO:Importing libraries
2024-05-24 15:59:26,440:INFO:Copying training dataset
2024-05-24 15:59:26,448:INFO:Defining folds
2024-05-24 15:59:26,448:INFO:Declaring metric variables
2024-05-24 15:59:26,452:INFO:Importing untrained model
2024-05-24 15:59:26,457:INFO:Huber Regressor Imported successfully
2024-05-24 15:59:26,466:INFO:Starting cross validation
2024-05-24 15:59:26,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:28,549:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:28,565:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:28,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:28,625:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:28,709:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:28,721:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:28,790:INFO:Calculating mean and std
2024-05-24 15:59:28,791:INFO:Creating metrics dataframe
2024-05-24 15:59:28,793:INFO:Uploading results into container
2024-05-24 15:59:28,795:INFO:Uploading model into container now
2024-05-24 15:59:28,795:INFO:_master_model_container: 10
2024-05-24 15:59:28,795:INFO:_display_container: 2
2024-05-24 15:59:28,795:INFO:HuberRegressor()
2024-05-24 15:59:28,795:INFO:create_model() successfully completed......................................
2024-05-24 15:59:28,992:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:28,992:INFO:Creating metrics dataframe
2024-05-24 15:59:29,004:INFO:Initializing K Neighbors Regressor
2024-05-24 15:59:29,004:INFO:Total runtime is 0.4140326937039693 minutes
2024-05-24 15:59:29,009:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:29,009:INFO:Initializing create_model()
2024-05-24 15:59:29,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:29,010:INFO:Checking exceptions
2024-05-24 15:59:29,010:INFO:Importing libraries
2024-05-24 15:59:29,010:INFO:Copying training dataset
2024-05-24 15:59:29,018:INFO:Defining folds
2024-05-24 15:59:29,018:INFO:Declaring metric variables
2024-05-24 15:59:29,022:INFO:Importing untrained model
2024-05-24 15:59:29,027:INFO:K Neighbors Regressor Imported successfully
2024-05-24 15:59:29,035:INFO:Starting cross validation
2024-05-24 15:59:29,060:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:31,214:INFO:Calculating mean and std
2024-05-24 15:59:31,215:INFO:Creating metrics dataframe
2024-05-24 15:59:31,218:INFO:Uploading results into container
2024-05-24 15:59:31,218:INFO:Uploading model into container now
2024-05-24 15:59:31,219:INFO:_master_model_container: 11
2024-05-24 15:59:31,219:INFO:_display_container: 2
2024-05-24 15:59:31,220:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 15:59:31,220:INFO:create_model() successfully completed......................................
2024-05-24 15:59:31,425:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:31,425:INFO:Creating metrics dataframe
2024-05-24 15:59:31,437:INFO:Initializing Decision Tree Regressor
2024-05-24 15:59:31,438:INFO:Total runtime is 0.4545960783958435 minutes
2024-05-24 15:59:31,442:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:31,443:INFO:Initializing create_model()
2024-05-24 15:59:31,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:31,443:INFO:Checking exceptions
2024-05-24 15:59:31,443:INFO:Importing libraries
2024-05-24 15:59:31,443:INFO:Copying training dataset
2024-05-24 15:59:31,451:INFO:Defining folds
2024-05-24 15:59:31,451:INFO:Declaring metric variables
2024-05-24 15:59:31,456:INFO:Importing untrained model
2024-05-24 15:59:31,461:INFO:Decision Tree Regressor Imported successfully
2024-05-24 15:59:31,476:INFO:Starting cross validation
2024-05-24 15:59:31,510:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:33,803:INFO:Calculating mean and std
2024-05-24 15:59:33,805:INFO:Creating metrics dataframe
2024-05-24 15:59:33,808:INFO:Uploading results into container
2024-05-24 15:59:33,809:INFO:Uploading model into container now
2024-05-24 15:59:33,809:INFO:_master_model_container: 12
2024-05-24 15:59:33,809:INFO:_display_container: 2
2024-05-24 15:59:33,810:INFO:DecisionTreeRegressor(random_state=5724)
2024-05-24 15:59:33,810:INFO:create_model() successfully completed......................................
2024-05-24 15:59:34,029:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:34,030:INFO:Creating metrics dataframe
2024-05-24 15:59:34,039:INFO:Initializing Random Forest Regressor
2024-05-24 15:59:34,040:INFO:Total runtime is 0.49797393480936686 minutes
2024-05-24 15:59:34,043:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:34,043:INFO:Initializing create_model()
2024-05-24 15:59:34,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:34,043:INFO:Checking exceptions
2024-05-24 15:59:34,045:INFO:Importing libraries
2024-05-24 15:59:34,045:INFO:Copying training dataset
2024-05-24 15:59:34,051:INFO:Defining folds
2024-05-24 15:59:34,051:INFO:Declaring metric variables
2024-05-24 15:59:34,057:INFO:Importing untrained model
2024-05-24 15:59:34,062:INFO:Random Forest Regressor Imported successfully
2024-05-24 15:59:34,071:INFO:Starting cross validation
2024-05-24 15:59:34,093:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:36,798:INFO:Calculating mean and std
2024-05-24 15:59:36,800:INFO:Creating metrics dataframe
2024-05-24 15:59:36,804:INFO:Uploading results into container
2024-05-24 15:59:36,805:INFO:Uploading model into container now
2024-05-24 15:59:36,806:INFO:_master_model_container: 13
2024-05-24 15:59:36,806:INFO:_display_container: 2
2024-05-24 15:59:36,806:INFO:RandomForestRegressor(n_jobs=-1, random_state=5724)
2024-05-24 15:59:36,806:INFO:create_model() successfully completed......................................
2024-05-24 15:59:37,010:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:37,010:INFO:Creating metrics dataframe
2024-05-24 15:59:37,023:INFO:Initializing Extra Trees Regressor
2024-05-24 15:59:37,023:INFO:Total runtime is 0.5476934353510539 minutes
2024-05-24 15:59:37,028:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:37,028:INFO:Initializing create_model()
2024-05-24 15:59:37,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:37,028:INFO:Checking exceptions
2024-05-24 15:59:37,029:INFO:Importing libraries
2024-05-24 15:59:37,029:INFO:Copying training dataset
2024-05-24 15:59:37,036:INFO:Defining folds
2024-05-24 15:59:37,036:INFO:Declaring metric variables
2024-05-24 15:59:37,041:INFO:Importing untrained model
2024-05-24 15:59:37,046:INFO:Extra Trees Regressor Imported successfully
2024-05-24 15:59:37,054:INFO:Starting cross validation
2024-05-24 15:59:37,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:39,794:INFO:Calculating mean and std
2024-05-24 15:59:39,796:INFO:Creating metrics dataframe
2024-05-24 15:59:39,800:INFO:Uploading results into container
2024-05-24 15:59:39,801:INFO:Uploading model into container now
2024-05-24 15:59:39,802:INFO:_master_model_container: 14
2024-05-24 15:59:39,802:INFO:_display_container: 2
2024-05-24 15:59:39,802:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5724)
2024-05-24 15:59:39,802:INFO:create_model() successfully completed......................................
2024-05-24 15:59:40,005:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:40,006:INFO:Creating metrics dataframe
2024-05-24 15:59:40,019:INFO:Initializing AdaBoost Regressor
2024-05-24 15:59:40,019:INFO:Total runtime is 0.5976287643114726 minutes
2024-05-24 15:59:40,024:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:40,025:INFO:Initializing create_model()
2024-05-24 15:59:40,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:40,026:INFO:Checking exceptions
2024-05-24 15:59:40,026:INFO:Importing libraries
2024-05-24 15:59:40,026:INFO:Copying training dataset
2024-05-24 15:59:40,032:INFO:Defining folds
2024-05-24 15:59:40,032:INFO:Declaring metric variables
2024-05-24 15:59:40,037:INFO:Importing untrained model
2024-05-24 15:59:40,042:INFO:AdaBoost Regressor Imported successfully
2024-05-24 15:59:40,049:INFO:Starting cross validation
2024-05-24 15:59:40,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:42,708:INFO:Calculating mean and std
2024-05-24 15:59:42,710:INFO:Creating metrics dataframe
2024-05-24 15:59:42,713:INFO:Uploading results into container
2024-05-24 15:59:42,713:INFO:Uploading model into container now
2024-05-24 15:59:42,714:INFO:_master_model_container: 15
2024-05-24 15:59:42,714:INFO:_display_container: 2
2024-05-24 15:59:42,714:INFO:AdaBoostRegressor(random_state=5724)
2024-05-24 15:59:42,715:INFO:create_model() successfully completed......................................
2024-05-24 15:59:42,937:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:42,937:INFO:Creating metrics dataframe
2024-05-24 15:59:42,948:INFO:Initializing Gradient Boosting Regressor
2024-05-24 15:59:42,948:INFO:Total runtime is 0.64644033908844 minutes
2024-05-24 15:59:42,954:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:42,954:INFO:Initializing create_model()
2024-05-24 15:59:42,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:42,955:INFO:Checking exceptions
2024-05-24 15:59:42,955:INFO:Importing libraries
2024-05-24 15:59:42,955:INFO:Copying training dataset
2024-05-24 15:59:42,968:INFO:Defining folds
2024-05-24 15:59:42,968:INFO:Declaring metric variables
2024-05-24 15:59:42,975:INFO:Importing untrained model
2024-05-24 15:59:42,979:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 15:59:42,987:INFO:Starting cross validation
2024-05-24 15:59:43,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:45,946:INFO:Calculating mean and std
2024-05-24 15:59:45,948:INFO:Creating metrics dataframe
2024-05-24 15:59:45,952:INFO:Uploading results into container
2024-05-24 15:59:45,953:INFO:Uploading model into container now
2024-05-24 15:59:45,954:INFO:_master_model_container: 16
2024-05-24 15:59:45,954:INFO:_display_container: 2
2024-05-24 15:59:45,955:INFO:GradientBoostingRegressor(random_state=5724)
2024-05-24 15:59:45,956:INFO:create_model() successfully completed......................................
2024-05-24 15:59:46,381:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:46,381:INFO:Creating metrics dataframe
2024-05-24 15:59:46,407:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 15:59:46,407:INFO:Total runtime is 0.7040885090827943 minutes
2024-05-24 15:59:46,416:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:46,416:INFO:Initializing create_model()
2024-05-24 15:59:46,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:46,417:INFO:Checking exceptions
2024-05-24 15:59:46,417:INFO:Importing libraries
2024-05-24 15:59:46,418:INFO:Copying training dataset
2024-05-24 15:59:46,432:INFO:Defining folds
2024-05-24 15:59:46,433:INFO:Declaring metric variables
2024-05-24 15:59:46,441:INFO:Importing untrained model
2024-05-24 15:59:46,451:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 15:59:46,466:INFO:Starting cross validation
2024-05-24 15:59:46,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:49,150:INFO:Calculating mean and std
2024-05-24 15:59:49,151:INFO:Creating metrics dataframe
2024-05-24 15:59:49,154:INFO:Uploading results into container
2024-05-24 15:59:49,155:INFO:Uploading model into container now
2024-05-24 15:59:49,156:INFO:_master_model_container: 17
2024-05-24 15:59:49,156:INFO:_display_container: 2
2024-05-24 15:59:49,156:INFO:LGBMRegressor(n_jobs=-1, random_state=5724)
2024-05-24 15:59:49,158:INFO:create_model() successfully completed......................................
2024-05-24 15:59:49,371:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:49,371:INFO:Creating metrics dataframe
2024-05-24 15:59:49,382:INFO:Initializing Dummy Regressor
2024-05-24 15:59:49,382:INFO:Total runtime is 0.7536723494529726 minutes
2024-05-24 15:59:49,388:INFO:SubProcess create_model() called ==================================
2024-05-24 15:59:49,388:INFO:Initializing create_model()
2024-05-24 15:59:49,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6B69BA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:49,388:INFO:Checking exceptions
2024-05-24 15:59:49,388:INFO:Importing libraries
2024-05-24 15:59:49,389:INFO:Copying training dataset
2024-05-24 15:59:49,396:INFO:Defining folds
2024-05-24 15:59:49,396:INFO:Declaring metric variables
2024-05-24 15:59:49,403:INFO:Importing untrained model
2024-05-24 15:59:49,409:INFO:Dummy Regressor Imported successfully
2024-05-24 15:59:49,419:INFO:Starting cross validation
2024-05-24 15:59:49,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 15:59:51,961:INFO:Calculating mean and std
2024-05-24 15:59:51,966:INFO:Creating metrics dataframe
2024-05-24 15:59:51,969:INFO:Uploading results into container
2024-05-24 15:59:51,970:INFO:Uploading model into container now
2024-05-24 15:59:51,970:INFO:_master_model_container: 18
2024-05-24 15:59:51,971:INFO:_display_container: 2
2024-05-24 15:59:51,971:INFO:DummyRegressor()
2024-05-24 15:59:51,971:INFO:create_model() successfully completed......................................
2024-05-24 15:59:52,218:INFO:SubProcess create_model() end ==================================
2024-05-24 15:59:52,218:INFO:Creating metrics dataframe
2024-05-24 15:59:52,234:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 15:59:52,246:INFO:Initializing create_model()
2024-05-24 15:59:52,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B7F580>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 15:59:52,247:INFO:Checking exceptions
2024-05-24 15:59:52,249:INFO:Importing libraries
2024-05-24 15:59:52,249:INFO:Copying training dataset
2024-05-24 15:59:52,256:INFO:Defining folds
2024-05-24 15:59:52,256:INFO:Declaring metric variables
2024-05-24 15:59:52,256:INFO:Importing untrained model
2024-05-24 15:59:52,256:INFO:Declaring custom model
2024-05-24 15:59:52,256:INFO:Huber Regressor Imported successfully
2024-05-24 15:59:52,290:INFO:Cross validation set to False
2024-05-24 15:59:52,290:INFO:Fitting Model
2024-05-24 15:59:53,574:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 15:59:53,575:INFO:HuberRegressor()
2024-05-24 15:59:53,575:INFO:create_model() successfully completed......................................
2024-05-24 15:59:53,808:INFO:_master_model_container: 18
2024-05-24 15:59:53,808:INFO:_display_container: 2
2024-05-24 15:59:53,809:INFO:HuberRegressor()
2024-05-24 15:59:53,809:INFO:compare_models() successfully completed......................................
2024-05-24 16:00:12,754:INFO:PyCaret RegressionExperiment
2024-05-24 16:00:12,754:INFO:Logging name: reg-default-name
2024-05-24 16:00:12,754:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:00:12,754:INFO:version 3.3.2
2024-05-24 16:00:12,754:INFO:Initializing setup()
2024-05-24 16:00:12,754:INFO:self.USI: b54b
2024-05-24 16:00:12,754:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 16:00:12,754:INFO:Checking environment
2024-05-24 16:00:12,754:INFO:python_version: 3.10.14
2024-05-24 16:00:12,755:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:00:12,755:INFO:machine: AMD64
2024-05-24 16:00:12,755:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:00:12,755:INFO:Memory: svmem(total=16541802496, available=2248003584, percent=86.4, used=14293798912, free=2248003584)
2024-05-24 16:00:12,755:INFO:Physical Core: 6
2024-05-24 16:00:12,755:INFO:Logical Core: 12
2024-05-24 16:00:12,755:INFO:Checking libraries
2024-05-24 16:00:12,755:INFO:System:
2024-05-24 16:00:12,755:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:00:12,755:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:00:12,755:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:00:12,755:INFO:PyCaret required dependencies:
2024-05-24 16:00:12,755:INFO:                 pip: 24.0
2024-05-24 16:00:12,755:INFO:          setuptools: 69.5.1
2024-05-24 16:00:12,755:INFO:             pycaret: 3.3.2
2024-05-24 16:00:12,756:INFO:             IPython: 8.20.0
2024-05-24 16:00:12,756:INFO:          ipywidgets: 8.1.2
2024-05-24 16:00:12,756:INFO:                tqdm: 4.66.4
2024-05-24 16:00:12,756:INFO:               numpy: 1.26.4
2024-05-24 16:00:12,756:INFO:              pandas: 2.1.4
2024-05-24 16:00:12,756:INFO:              jinja2: 3.1.3
2024-05-24 16:00:12,756:INFO:               scipy: 1.11.4
2024-05-24 16:00:12,756:INFO:              joblib: 1.3.2
2024-05-24 16:00:12,756:INFO:             sklearn: 1.4.2
2024-05-24 16:00:12,756:INFO:                pyod: 1.1.3
2024-05-24 16:00:12,756:INFO:            imblearn: 0.12.2
2024-05-24 16:00:12,756:INFO:   category_encoders: 2.6.3
2024-05-24 16:00:12,756:INFO:            lightgbm: 4.3.0
2024-05-24 16:00:12,756:INFO:               numba: 0.59.1
2024-05-24 16:00:12,756:INFO:            requests: 2.32.2
2024-05-24 16:00:12,756:INFO:          matplotlib: 3.7.5
2024-05-24 16:00:12,756:INFO:          scikitplot: 0.3.7
2024-05-24 16:00:12,756:INFO:         yellowbrick: 1.5
2024-05-24 16:00:12,757:INFO:              plotly: 5.22.0
2024-05-24 16:00:12,757:INFO:    plotly-resampler: Not installed
2024-05-24 16:00:12,757:INFO:             kaleido: 0.2.1
2024-05-24 16:00:12,757:INFO:           schemdraw: 0.15
2024-05-24 16:00:12,757:INFO:         statsmodels: 0.14.2
2024-05-24 16:00:12,757:INFO:              sktime: 0.26.0
2024-05-24 16:00:12,757:INFO:               tbats: 1.1.3
2024-05-24 16:00:12,757:INFO:            pmdarima: 2.0.4
2024-05-24 16:00:12,757:INFO:              psutil: 5.9.0
2024-05-24 16:00:12,757:INFO:          markupsafe: 2.1.3
2024-05-24 16:00:12,757:INFO:             pickle5: Not installed
2024-05-24 16:00:12,757:INFO:         cloudpickle: 3.0.0
2024-05-24 16:00:12,757:INFO:         deprecation: 2.1.0
2024-05-24 16:00:12,758:INFO:              xxhash: 3.4.1
2024-05-24 16:00:12,758:INFO:           wurlitzer: Not installed
2024-05-24 16:00:12,758:INFO:PyCaret optional dependencies:
2024-05-24 16:00:12,758:INFO:                shap: Not installed
2024-05-24 16:00:12,758:INFO:           interpret: Not installed
2024-05-24 16:00:12,758:INFO:                umap: Not installed
2024-05-24 16:00:12,758:INFO:     ydata_profiling: Not installed
2024-05-24 16:00:12,758:INFO:  explainerdashboard: Not installed
2024-05-24 16:00:12,758:INFO:             autoviz: Not installed
2024-05-24 16:00:12,758:INFO:           fairlearn: Not installed
2024-05-24 16:00:12,758:INFO:          deepchecks: Not installed
2024-05-24 16:00:12,758:INFO:             xgboost: Not installed
2024-05-24 16:00:12,758:INFO:            catboost: Not installed
2024-05-24 16:00:12,759:INFO:              kmodes: Not installed
2024-05-24 16:00:12,759:INFO:             mlxtend: Not installed
2024-05-24 16:00:12,759:INFO:       statsforecast: Not installed
2024-05-24 16:00:12,759:INFO:        tune_sklearn: Not installed
2024-05-24 16:00:12,759:INFO:                 ray: Not installed
2024-05-24 16:00:12,759:INFO:            hyperopt: Not installed
2024-05-24 16:00:12,759:INFO:              optuna: Not installed
2024-05-24 16:00:12,759:INFO:               skopt: Not installed
2024-05-24 16:00:12,759:INFO:              mlflow: Not installed
2024-05-24 16:00:12,759:INFO:              gradio: Not installed
2024-05-24 16:00:12,759:INFO:             fastapi: Not installed
2024-05-24 16:00:12,759:INFO:             uvicorn: Not installed
2024-05-24 16:00:12,759:INFO:              m2cgen: Not installed
2024-05-24 16:00:12,759:INFO:           evidently: Not installed
2024-05-24 16:00:12,759:INFO:               fugue: Not installed
2024-05-24 16:00:12,759:INFO:           streamlit: Not installed
2024-05-24 16:00:12,760:INFO:             prophet: Not installed
2024-05-24 16:00:12,760:INFO:None
2024-05-24 16:00:12,760:INFO:Set up data.
2024-05-24 16:00:12,773:INFO:Set up folding strategy.
2024-05-24 16:00:12,773:INFO:Set up train/test split.
2024-05-24 16:00:12,779:INFO:Set up index.
2024-05-24 16:00:12,780:INFO:Assigning column types.
2024-05-24 16:00:12,785:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:00:12,786:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,796:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,900:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:12,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:12,901:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,905:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:00:12,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,016:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:00:13,021:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,026:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,087:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,143:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,248:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:00:13,258:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,361:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,476:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:00:13,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,595:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,669:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,716:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,717:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:00:13,793:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:00:13,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:13,960:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:00:14,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:14,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:14,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:14,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:14,188:INFO:Preparing preprocessing pipeline...
2024-05-24 16:00:14,188:INFO:Set up simple imputation.
2024-05-24 16:00:14,193:INFO:Set up encoding of ordinal features.
2024-05-24 16:00:14,198:INFO:Set up encoding of categorical features.
2024-05-24 16:00:14,198:INFO:Set up polynomial features.
2024-05-24 16:00:14,198:INFO:Set up removing multicollinearity.
2024-05-24 16:00:14,198:INFO:Set up removing outliers.
2024-05-24 16:00:15,480:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:00:15,546:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=5034)))])
2024-05-24 16:00:15,546:INFO:Creating final display dataframe.
2024-05-24 16:00:17,685:INFO:Setup _display_container:                     Description             Value
0                    Session id              5034
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 483)
5   Transformed train set shape        (135, 483)
6    Transformed test set shape         (62, 483)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              b54b
2024-05-24 16:00:17,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:17,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:17,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:17,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:00:17,957:INFO:setup() successfully completed in 5.22s...............
2024-05-24 16:00:21,045:INFO:Initializing compare_models()
2024-05-24 16:00:21,046:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:00:21,046:INFO:Checking exceptions
2024-05-24 16:00:21,051:INFO:Preparing display monitor
2024-05-24 16:00:21,082:INFO:Initializing Linear Regression
2024-05-24 16:00:21,082:INFO:Total runtime is 0.0 minutes
2024-05-24 16:00:21,088:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:21,089:INFO:Initializing create_model()
2024-05-24 16:00:21,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lr, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:21,089:INFO:Checking exceptions
2024-05-24 16:00:21,089:INFO:Importing libraries
2024-05-24 16:00:21,089:INFO:Copying training dataset
2024-05-24 16:00:21,097:INFO:Defining folds
2024-05-24 16:00:21,097:INFO:Declaring metric variables
2024-05-24 16:00:21,102:INFO:Importing untrained model
2024-05-24 16:00:21,107:INFO:Linear Regression Imported successfully
2024-05-24 16:00:21,118:INFO:Starting cross validation
2024-05-24 16:00:21,141:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:23,465:INFO:Calculating mean and std
2024-05-24 16:00:23,467:INFO:Creating metrics dataframe
2024-05-24 16:00:23,470:INFO:Uploading results into container
2024-05-24 16:00:23,470:INFO:Uploading model into container now
2024-05-24 16:00:23,470:INFO:_master_model_container: 1
2024-05-24 16:00:23,471:INFO:_display_container: 2
2024-05-24 16:00:23,471:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:00:23,471:INFO:create_model() successfully completed......................................
2024-05-24 16:00:23,675:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:23,675:INFO:Creating metrics dataframe
2024-05-24 16:00:23,684:INFO:Initializing Lasso Regression
2024-05-24 16:00:23,685:INFO:Total runtime is 0.04338704347610474 minutes
2024-05-24 16:00:23,688:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:23,689:INFO:Initializing create_model()
2024-05-24 16:00:23,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lasso, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:23,689:INFO:Checking exceptions
2024-05-24 16:00:23,689:INFO:Importing libraries
2024-05-24 16:00:23,689:INFO:Copying training dataset
2024-05-24 16:00:23,696:INFO:Defining folds
2024-05-24 16:00:23,696:INFO:Declaring metric variables
2024-05-24 16:00:23,701:INFO:Importing untrained model
2024-05-24 16:00:23,704:INFO:Lasso Regression Imported successfully
2024-05-24 16:00:23,712:INFO:Starting cross validation
2024-05-24 16:00:23,734:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:25,515:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+07, tolerance: 7.843e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,588:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,613:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e+07, tolerance: 8.764e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,635:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 7.978e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,639:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 7.493e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,657:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+07, tolerance: 8.427e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,671:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 7.656e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,734:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+07, tolerance: 8.507e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,749:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 7.916e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,758:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:25,821:INFO:Calculating mean and std
2024-05-24 16:00:25,822:INFO:Creating metrics dataframe
2024-05-24 16:00:25,824:INFO:Uploading results into container
2024-05-24 16:00:25,825:INFO:Uploading model into container now
2024-05-24 16:00:25,825:INFO:_master_model_container: 2
2024-05-24 16:00:25,825:INFO:_display_container: 2
2024-05-24 16:00:25,825:INFO:Lasso(random_state=5034)
2024-05-24 16:00:25,826:INFO:create_model() successfully completed......................................
2024-05-24 16:00:26,011:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:26,011:INFO:Creating metrics dataframe
2024-05-24 16:00:26,019:INFO:Initializing Ridge Regression
2024-05-24 16:00:26,020:INFO:Total runtime is 0.08230401277542115 minutes
2024-05-24 16:00:26,024:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:26,024:INFO:Initializing create_model()
2024-05-24 16:00:26,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=ridge, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:26,024:INFO:Checking exceptions
2024-05-24 16:00:26,025:INFO:Importing libraries
2024-05-24 16:00:26,025:INFO:Copying training dataset
2024-05-24 16:00:26,031:INFO:Defining folds
2024-05-24 16:00:26,032:INFO:Declaring metric variables
2024-05-24 16:00:26,036:INFO:Importing untrained model
2024-05-24 16:00:26,041:INFO:Ridge Regression Imported successfully
2024-05-24 16:00:26,050:INFO:Starting cross validation
2024-05-24 16:00:26,069:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:27,822:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,838:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,858:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,904:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,905:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,940:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,950:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,990:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:27,997:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:00:28,065:INFO:Calculating mean and std
2024-05-24 16:00:28,067:INFO:Creating metrics dataframe
2024-05-24 16:00:28,069:INFO:Uploading results into container
2024-05-24 16:00:28,070:INFO:Uploading model into container now
2024-05-24 16:00:28,070:INFO:_master_model_container: 3
2024-05-24 16:00:28,071:INFO:_display_container: 2
2024-05-24 16:00:28,071:INFO:Ridge(random_state=5034)
2024-05-24 16:00:28,071:INFO:create_model() successfully completed......................................
2024-05-24 16:00:28,270:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:28,270:INFO:Creating metrics dataframe
2024-05-24 16:00:28,278:INFO:Initializing Elastic Net
2024-05-24 16:00:28,278:INFO:Total runtime is 0.11993553638458253 minutes
2024-05-24 16:00:28,282:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:28,283:INFO:Initializing create_model()
2024-05-24 16:00:28,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=en, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:28,283:INFO:Checking exceptions
2024-05-24 16:00:28,283:INFO:Importing libraries
2024-05-24 16:00:28,283:INFO:Copying training dataset
2024-05-24 16:00:28,290:INFO:Defining folds
2024-05-24 16:00:28,290:INFO:Declaring metric variables
2024-05-24 16:00:28,295:INFO:Importing untrained model
2024-05-24 16:00:28,300:INFO:Elastic Net Imported successfully
2024-05-24 16:00:28,307:INFO:Starting cross validation
2024-05-24 16:00:28,331:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:30,149:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.360e+07, tolerance: 7.843e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.898e+07, tolerance: 8.764e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,218:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.055e+07, tolerance: 7.493e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,233:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.355e+07, tolerance: 7.916e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,238:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.038e+07, tolerance: 7.978e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,288:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.671e+07, tolerance: 7.656e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,290:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.708e+07, tolerance: 8.427e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,314:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.008e+07, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.854e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,357:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.761e+07, tolerance: 8.507e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:00:30,425:INFO:Calculating mean and std
2024-05-24 16:00:30,427:INFO:Creating metrics dataframe
2024-05-24 16:00:30,429:INFO:Uploading results into container
2024-05-24 16:00:30,430:INFO:Uploading model into container now
2024-05-24 16:00:30,431:INFO:_master_model_container: 4
2024-05-24 16:00:30,431:INFO:_display_container: 2
2024-05-24 16:00:30,431:INFO:ElasticNet(random_state=5034)
2024-05-24 16:00:30,431:INFO:create_model() successfully completed......................................
2024-05-24 16:00:30,624:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:30,624:INFO:Creating metrics dataframe
2024-05-24 16:00:30,634:INFO:Initializing Least Angle Regression
2024-05-24 16:00:30,634:INFO:Total runtime is 0.1591994603474935 minutes
2024-05-24 16:00:30,639:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:30,639:INFO:Initializing create_model()
2024-05-24 16:00:30,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lar, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:30,639:INFO:Checking exceptions
2024-05-24 16:00:30,640:INFO:Importing libraries
2024-05-24 16:00:30,640:INFO:Copying training dataset
2024-05-24 16:00:30,648:INFO:Defining folds
2024-05-24 16:00:30,648:INFO:Declaring metric variables
2024-05-24 16:00:30,653:INFO:Importing untrained model
2024-05-24 16:00:30,657:INFO:Least Angle Regression Imported successfully
2024-05-24 16:00:30,667:INFO:Starting cross validation
2024-05-24 16:00:30,688:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:32,523:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 197 iterations, i.e. alpha=4.742e+04, with an active set of 109 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 16:00:32,523:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=2.670e+04, with an active set of 98 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 16:00:32,636:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=9.066e+04, with an active set of 113 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 16:00:32,767:INFO:Calculating mean and std
2024-05-24 16:00:32,767:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-24 16:00:32,768:INFO:Creating metrics dataframe
2024-05-24 16:00:32,771:INFO:Uploading results into container
2024-05-24 16:00:32,772:INFO:Uploading model into container now
2024-05-24 16:00:32,772:INFO:_master_model_container: 5
2024-05-24 16:00:32,772:INFO:_display_container: 2
2024-05-24 16:00:32,772:INFO:Lars(random_state=5034)
2024-05-24 16:00:32,772:INFO:create_model() successfully completed......................................
2024-05-24 16:00:32,967:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:32,967:INFO:Creating metrics dataframe
2024-05-24 16:00:32,977:INFO:Initializing Lasso Least Angle Regression
2024-05-24 16:00:32,977:INFO:Total runtime is 0.1982478936513265 minutes
2024-05-24 16:00:32,981:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:32,981:INFO:Initializing create_model()
2024-05-24 16:00:32,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=llar, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:32,981:INFO:Checking exceptions
2024-05-24 16:00:32,982:INFO:Importing libraries
2024-05-24 16:00:32,982:INFO:Copying training dataset
2024-05-24 16:00:32,990:INFO:Defining folds
2024-05-24 16:00:32,990:INFO:Declaring metric variables
2024-05-24 16:00:32,994:INFO:Importing untrained model
2024-05-24 16:00:32,999:INFO:Lasso Least Angle Regression Imported successfully
2024-05-24 16:00:33,007:INFO:Starting cross validation
2024-05-24 16:00:33,027:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:35,252:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=3.099e+00, with an active set of 82 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 16:00:35,266:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.597e+00, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 16:00:35,266:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 237 iterations, i.e. alpha=1.597e+00, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-24 16:00:35,345:INFO:Calculating mean and std
2024-05-24 16:00:35,346:INFO:Creating metrics dataframe
2024-05-24 16:00:35,348:INFO:Uploading results into container
2024-05-24 16:00:35,348:INFO:Uploading model into container now
2024-05-24 16:00:35,349:INFO:_master_model_container: 6
2024-05-24 16:00:35,349:INFO:_display_container: 2
2024-05-24 16:00:35,349:INFO:LassoLars(random_state=5034)
2024-05-24 16:00:35,349:INFO:create_model() successfully completed......................................
2024-05-24 16:00:35,555:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:35,555:INFO:Creating metrics dataframe
2024-05-24 16:00:35,565:INFO:Initializing Orthogonal Matching Pursuit
2024-05-24 16:00:35,565:INFO:Total runtime is 0.2413870096206665 minutes
2024-05-24 16:00:35,569:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:35,570:INFO:Initializing create_model()
2024-05-24 16:00:35,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=omp, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:35,570:INFO:Checking exceptions
2024-05-24 16:00:35,570:INFO:Importing libraries
2024-05-24 16:00:35,571:INFO:Copying training dataset
2024-05-24 16:00:35,577:INFO:Defining folds
2024-05-24 16:00:35,577:INFO:Declaring metric variables
2024-05-24 16:00:35,583:INFO:Importing untrained model
2024-05-24 16:00:35,587:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-24 16:00:35,595:INFO:Starting cross validation
2024-05-24 16:00:35,617:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:37,859:INFO:Calculating mean and std
2024-05-24 16:00:37,861:INFO:Creating metrics dataframe
2024-05-24 16:00:37,863:INFO:Uploading results into container
2024-05-24 16:00:37,864:INFO:Uploading model into container now
2024-05-24 16:00:37,864:INFO:_master_model_container: 7
2024-05-24 16:00:37,864:INFO:_display_container: 2
2024-05-24 16:00:37,865:INFO:OrthogonalMatchingPursuit()
2024-05-24 16:00:37,865:INFO:create_model() successfully completed......................................
2024-05-24 16:00:38,057:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:38,058:INFO:Creating metrics dataframe
2024-05-24 16:00:38,067:INFO:Initializing Bayesian Ridge
2024-05-24 16:00:38,067:INFO:Total runtime is 0.2830903212229411 minutes
2024-05-24 16:00:38,073:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:38,074:INFO:Initializing create_model()
2024-05-24 16:00:38,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=br, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:38,074:INFO:Checking exceptions
2024-05-24 16:00:38,074:INFO:Importing libraries
2024-05-24 16:00:38,074:INFO:Copying training dataset
2024-05-24 16:00:38,085:INFO:Defining folds
2024-05-24 16:00:38,085:INFO:Declaring metric variables
2024-05-24 16:00:38,090:INFO:Importing untrained model
2024-05-24 16:00:38,094:INFO:Bayesian Ridge Imported successfully
2024-05-24 16:00:38,103:INFO:Starting cross validation
2024-05-24 16:00:38,124:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:40,497:INFO:Calculating mean and std
2024-05-24 16:00:40,498:INFO:Creating metrics dataframe
2024-05-24 16:00:40,500:INFO:Uploading results into container
2024-05-24 16:00:40,501:INFO:Uploading model into container now
2024-05-24 16:00:40,501:INFO:_master_model_container: 8
2024-05-24 16:00:40,502:INFO:_display_container: 2
2024-05-24 16:00:40,502:INFO:BayesianRidge()
2024-05-24 16:00:40,502:INFO:create_model() successfully completed......................................
2024-05-24 16:00:40,701:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:40,702:INFO:Creating metrics dataframe
2024-05-24 16:00:40,712:INFO:Initializing Passive Aggressive Regressor
2024-05-24 16:00:40,712:INFO:Total runtime is 0.3271654764811198 minutes
2024-05-24 16:00:40,717:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:40,718:INFO:Initializing create_model()
2024-05-24 16:00:40,718:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=par, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:40,718:INFO:Checking exceptions
2024-05-24 16:00:40,718:INFO:Importing libraries
2024-05-24 16:00:40,718:INFO:Copying training dataset
2024-05-24 16:00:40,725:INFO:Defining folds
2024-05-24 16:00:40,725:INFO:Declaring metric variables
2024-05-24 16:00:40,729:INFO:Importing untrained model
2024-05-24 16:00:40,733:INFO:Passive Aggressive Regressor Imported successfully
2024-05-24 16:00:40,742:INFO:Starting cross validation
2024-05-24 16:00:40,764:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:43,004:INFO:Calculating mean and std
2024-05-24 16:00:43,005:INFO:Creating metrics dataframe
2024-05-24 16:00:43,008:INFO:Uploading results into container
2024-05-24 16:00:43,009:INFO:Uploading model into container now
2024-05-24 16:00:43,010:INFO:_master_model_container: 9
2024-05-24 16:00:43,010:INFO:_display_container: 2
2024-05-24 16:00:43,011:INFO:PassiveAggressiveRegressor(random_state=5034)
2024-05-24 16:00:43,011:INFO:create_model() successfully completed......................................
2024-05-24 16:00:43,204:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:43,205:INFO:Creating metrics dataframe
2024-05-24 16:00:43,214:INFO:Initializing Huber Regressor
2024-05-24 16:00:43,215:INFO:Total runtime is 0.3688807368278504 minutes
2024-05-24 16:00:43,218:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:43,218:INFO:Initializing create_model()
2024-05-24 16:00:43,219:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=huber, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:43,219:INFO:Checking exceptions
2024-05-24 16:00:43,219:INFO:Importing libraries
2024-05-24 16:00:43,219:INFO:Copying training dataset
2024-05-24 16:00:43,225:INFO:Defining folds
2024-05-24 16:00:43,225:INFO:Declaring metric variables
2024-05-24 16:00:43,230:INFO:Importing untrained model
2024-05-24 16:00:43,234:INFO:Huber Regressor Imported successfully
2024-05-24 16:00:43,242:INFO:Starting cross validation
2024-05-24 16:00:43,263:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:45,389:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:00:45,421:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:00:45,470:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:00:45,477:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:00:45,509:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:00:45,542:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:00:45,615:INFO:Calculating mean and std
2024-05-24 16:00:45,616:INFO:Creating metrics dataframe
2024-05-24 16:00:45,618:INFO:Uploading results into container
2024-05-24 16:00:45,619:INFO:Uploading model into container now
2024-05-24 16:00:45,620:INFO:_master_model_container: 10
2024-05-24 16:00:45,620:INFO:_display_container: 2
2024-05-24 16:00:45,621:INFO:HuberRegressor()
2024-05-24 16:00:45,621:INFO:create_model() successfully completed......................................
2024-05-24 16:00:45,824:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:45,824:INFO:Creating metrics dataframe
2024-05-24 16:00:45,835:INFO:Initializing K Neighbors Regressor
2024-05-24 16:00:45,835:INFO:Total runtime is 0.4125561356544495 minutes
2024-05-24 16:00:45,841:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:45,841:INFO:Initializing create_model()
2024-05-24 16:00:45,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=knn, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:45,841:INFO:Checking exceptions
2024-05-24 16:00:45,841:INFO:Importing libraries
2024-05-24 16:00:45,841:INFO:Copying training dataset
2024-05-24 16:00:45,849:INFO:Defining folds
2024-05-24 16:00:45,850:INFO:Declaring metric variables
2024-05-24 16:00:45,855:INFO:Importing untrained model
2024-05-24 16:00:45,860:INFO:K Neighbors Regressor Imported successfully
2024-05-24 16:00:45,870:INFO:Starting cross validation
2024-05-24 16:00:45,891:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:48,233:INFO:Calculating mean and std
2024-05-24 16:00:48,234:INFO:Creating metrics dataframe
2024-05-24 16:00:48,236:INFO:Uploading results into container
2024-05-24 16:00:48,237:INFO:Uploading model into container now
2024-05-24 16:00:48,237:INFO:_master_model_container: 11
2024-05-24 16:00:48,238:INFO:_display_container: 2
2024-05-24 16:00:48,238:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-24 16:00:48,238:INFO:create_model() successfully completed......................................
2024-05-24 16:00:48,438:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:48,438:INFO:Creating metrics dataframe
2024-05-24 16:00:48,451:INFO:Initializing Decision Tree Regressor
2024-05-24 16:00:48,451:INFO:Total runtime is 0.4561529556910197 minutes
2024-05-24 16:00:48,457:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:48,457:INFO:Initializing create_model()
2024-05-24 16:00:48,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=dt, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:48,457:INFO:Checking exceptions
2024-05-24 16:00:48,457:INFO:Importing libraries
2024-05-24 16:00:48,458:INFO:Copying training dataset
2024-05-24 16:00:48,468:INFO:Defining folds
2024-05-24 16:00:48,468:INFO:Declaring metric variables
2024-05-24 16:00:48,473:INFO:Importing untrained model
2024-05-24 16:00:48,479:INFO:Decision Tree Regressor Imported successfully
2024-05-24 16:00:48,491:INFO:Starting cross validation
2024-05-24 16:00:48,521:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:51,033:INFO:Calculating mean and std
2024-05-24 16:00:51,034:INFO:Creating metrics dataframe
2024-05-24 16:00:51,037:INFO:Uploading results into container
2024-05-24 16:00:51,038:INFO:Uploading model into container now
2024-05-24 16:00:51,038:INFO:_master_model_container: 12
2024-05-24 16:00:51,038:INFO:_display_container: 2
2024-05-24 16:00:51,039:INFO:DecisionTreeRegressor(random_state=5034)
2024-05-24 16:00:51,039:INFO:create_model() successfully completed......................................
2024-05-24 16:00:51,252:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:51,252:INFO:Creating metrics dataframe
2024-05-24 16:00:51,263:INFO:Initializing Random Forest Regressor
2024-05-24 16:00:51,263:INFO:Total runtime is 0.5030214349428813 minutes
2024-05-24 16:00:51,269:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:51,270:INFO:Initializing create_model()
2024-05-24 16:00:51,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=rf, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:51,270:INFO:Checking exceptions
2024-05-24 16:00:51,270:INFO:Importing libraries
2024-05-24 16:00:51,270:INFO:Copying training dataset
2024-05-24 16:00:51,281:INFO:Defining folds
2024-05-24 16:00:51,281:INFO:Declaring metric variables
2024-05-24 16:00:51,287:INFO:Importing untrained model
2024-05-24 16:00:51,292:INFO:Random Forest Regressor Imported successfully
2024-05-24 16:00:51,301:INFO:Starting cross validation
2024-05-24 16:00:51,340:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:54,384:INFO:Calculating mean and std
2024-05-24 16:00:54,386:INFO:Creating metrics dataframe
2024-05-24 16:00:54,388:INFO:Uploading results into container
2024-05-24 16:00:54,389:INFO:Uploading model into container now
2024-05-24 16:00:54,390:INFO:_master_model_container: 13
2024-05-24 16:00:54,390:INFO:_display_container: 2
2024-05-24 16:00:54,390:INFO:RandomForestRegressor(n_jobs=-1, random_state=5034)
2024-05-24 16:00:54,390:INFO:create_model() successfully completed......................................
2024-05-24 16:00:54,598:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:54,598:INFO:Creating metrics dataframe
2024-05-24 16:00:54,614:INFO:Initializing Extra Trees Regressor
2024-05-24 16:00:54,614:INFO:Total runtime is 0.5588596343994141 minutes
2024-05-24 16:00:54,618:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:54,619:INFO:Initializing create_model()
2024-05-24 16:00:54,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=et, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:54,619:INFO:Checking exceptions
2024-05-24 16:00:54,619:INFO:Importing libraries
2024-05-24 16:00:54,619:INFO:Copying training dataset
2024-05-24 16:00:54,629:INFO:Defining folds
2024-05-24 16:00:54,629:INFO:Declaring metric variables
2024-05-24 16:00:54,634:INFO:Importing untrained model
2024-05-24 16:00:54,639:INFO:Extra Trees Regressor Imported successfully
2024-05-24 16:00:54,647:INFO:Starting cross validation
2024-05-24 16:00:54,666:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:57,380:INFO:Calculating mean and std
2024-05-24 16:00:57,382:INFO:Creating metrics dataframe
2024-05-24 16:00:57,384:INFO:Uploading results into container
2024-05-24 16:00:57,385:INFO:Uploading model into container now
2024-05-24 16:00:57,385:INFO:_master_model_container: 14
2024-05-24 16:00:57,385:INFO:_display_container: 2
2024-05-24 16:00:57,386:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5034)
2024-05-24 16:00:57,386:INFO:create_model() successfully completed......................................
2024-05-24 16:00:57,602:INFO:SubProcess create_model() end ==================================
2024-05-24 16:00:57,603:INFO:Creating metrics dataframe
2024-05-24 16:00:57,616:INFO:Initializing AdaBoost Regressor
2024-05-24 16:00:57,616:INFO:Total runtime is 0.6089026252428691 minutes
2024-05-24 16:00:57,621:INFO:SubProcess create_model() called ==================================
2024-05-24 16:00:57,622:INFO:Initializing create_model()
2024-05-24 16:00:57,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=ada, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:00:57,622:INFO:Checking exceptions
2024-05-24 16:00:57,622:INFO:Importing libraries
2024-05-24 16:00:57,622:INFO:Copying training dataset
2024-05-24 16:00:57,631:INFO:Defining folds
2024-05-24 16:00:57,631:INFO:Declaring metric variables
2024-05-24 16:00:57,637:INFO:Importing untrained model
2024-05-24 16:00:57,642:INFO:AdaBoost Regressor Imported successfully
2024-05-24 16:00:57,652:INFO:Starting cross validation
2024-05-24 16:00:57,679:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:00:59,970:INFO:Calculating mean and std
2024-05-24 16:00:59,972:INFO:Creating metrics dataframe
2024-05-24 16:00:59,975:INFO:Uploading results into container
2024-05-24 16:00:59,976:INFO:Uploading model into container now
2024-05-24 16:00:59,976:INFO:_master_model_container: 15
2024-05-24 16:00:59,976:INFO:_display_container: 2
2024-05-24 16:00:59,977:INFO:AdaBoostRegressor(random_state=5034)
2024-05-24 16:00:59,977:INFO:create_model() successfully completed......................................
2024-05-24 16:01:00,183:INFO:SubProcess create_model() end ==================================
2024-05-24 16:01:00,183:INFO:Creating metrics dataframe
2024-05-24 16:01:00,194:INFO:Initializing Gradient Boosting Regressor
2024-05-24 16:01:00,195:INFO:Total runtime is 0.651890234152476 minutes
2024-05-24 16:01:00,201:INFO:SubProcess create_model() called ==================================
2024-05-24 16:01:00,201:INFO:Initializing create_model()
2024-05-24 16:01:00,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=gbr, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:01:00,201:INFO:Checking exceptions
2024-05-24 16:01:00,201:INFO:Importing libraries
2024-05-24 16:01:00,202:INFO:Copying training dataset
2024-05-24 16:01:00,209:INFO:Defining folds
2024-05-24 16:01:00,210:INFO:Declaring metric variables
2024-05-24 16:01:00,214:INFO:Importing untrained model
2024-05-24 16:01:00,220:INFO:Gradient Boosting Regressor Imported successfully
2024-05-24 16:01:00,228:INFO:Starting cross validation
2024-05-24 16:01:00,249:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:01:02,633:INFO:Calculating mean and std
2024-05-24 16:01:02,634:INFO:Creating metrics dataframe
2024-05-24 16:01:02,637:INFO:Uploading results into container
2024-05-24 16:01:02,638:INFO:Uploading model into container now
2024-05-24 16:01:02,638:INFO:_master_model_container: 16
2024-05-24 16:01:02,638:INFO:_display_container: 2
2024-05-24 16:01:02,639:INFO:GradientBoostingRegressor(random_state=5034)
2024-05-24 16:01:02,639:INFO:create_model() successfully completed......................................
2024-05-24 16:01:02,855:INFO:SubProcess create_model() end ==================================
2024-05-24 16:01:02,856:INFO:Creating metrics dataframe
2024-05-24 16:01:02,872:INFO:Initializing Light Gradient Boosting Machine
2024-05-24 16:01:02,872:INFO:Total runtime is 0.6964933633804322 minutes
2024-05-24 16:01:02,877:INFO:SubProcess create_model() called ==================================
2024-05-24 16:01:02,877:INFO:Initializing create_model()
2024-05-24 16:01:02,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:01:02,878:INFO:Checking exceptions
2024-05-24 16:01:02,878:INFO:Importing libraries
2024-05-24 16:01:02,878:INFO:Copying training dataset
2024-05-24 16:01:02,888:INFO:Defining folds
2024-05-24 16:01:02,888:INFO:Declaring metric variables
2024-05-24 16:01:02,893:INFO:Importing untrained model
2024-05-24 16:01:02,900:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-24 16:01:02,910:INFO:Starting cross validation
2024-05-24 16:01:02,935:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:01:05,913:INFO:Calculating mean and std
2024-05-24 16:01:05,915:INFO:Creating metrics dataframe
2024-05-24 16:01:05,919:INFO:Uploading results into container
2024-05-24 16:01:05,920:INFO:Uploading model into container now
2024-05-24 16:01:05,920:INFO:_master_model_container: 17
2024-05-24 16:01:05,921:INFO:_display_container: 2
2024-05-24 16:01:05,922:INFO:LGBMRegressor(n_jobs=-1, random_state=5034)
2024-05-24 16:01:05,922:INFO:create_model() successfully completed......................................
2024-05-24 16:01:06,172:INFO:SubProcess create_model() end ==================================
2024-05-24 16:01:06,172:INFO:Creating metrics dataframe
2024-05-24 16:01:06,185:INFO:Initializing Dummy Regressor
2024-05-24 16:01:06,185:INFO:Total runtime is 0.7517077803611756 minutes
2024-05-24 16:01:06,190:INFO:SubProcess create_model() called ==================================
2024-05-24 16:01:06,190:INFO:Initializing create_model()
2024-05-24 16:01:06,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=dummy, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6A0CB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:01:06,191:INFO:Checking exceptions
2024-05-24 16:01:06,191:INFO:Importing libraries
2024-05-24 16:01:06,191:INFO:Copying training dataset
2024-05-24 16:01:06,198:INFO:Defining folds
2024-05-24 16:01:06,199:INFO:Declaring metric variables
2024-05-24 16:01:06,204:INFO:Importing untrained model
2024-05-24 16:01:06,212:INFO:Dummy Regressor Imported successfully
2024-05-24 16:01:06,224:INFO:Starting cross validation
2024-05-24 16:01:06,250:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:01:08,585:INFO:Calculating mean and std
2024-05-24 16:01:08,586:INFO:Creating metrics dataframe
2024-05-24 16:01:08,589:INFO:Uploading results into container
2024-05-24 16:01:08,589:INFO:Uploading model into container now
2024-05-24 16:01:08,589:INFO:_master_model_container: 18
2024-05-24 16:01:08,589:INFO:_display_container: 2
2024-05-24 16:01:08,590:INFO:DummyRegressor()
2024-05-24 16:01:08,590:INFO:create_model() successfully completed......................................
2024-05-24 16:01:08,776:INFO:SubProcess create_model() end ==================================
2024-05-24 16:01:08,776:INFO:Creating metrics dataframe
2024-05-24 16:01:08,790:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:01:08,800:INFO:Initializing create_model()
2024-05-24 16:01:08,800:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:01:08,800:INFO:Checking exceptions
2024-05-24 16:01:08,802:INFO:Importing libraries
2024-05-24 16:01:08,803:INFO:Copying training dataset
2024-05-24 16:01:08,807:INFO:Defining folds
2024-05-24 16:01:08,807:INFO:Declaring metric variables
2024-05-24 16:01:08,807:INFO:Importing untrained model
2024-05-24 16:01:08,808:INFO:Declaring custom model
2024-05-24 16:01:08,808:INFO:Huber Regressor Imported successfully
2024-05-24 16:01:08,825:INFO:Cross validation set to False
2024-05-24 16:01:08,825:INFO:Fitting Model
2024-05-24 16:01:10,292:INFO:HuberRegressor()
2024-05-24 16:01:10,292:INFO:create_model() successfully completed......................................
2024-05-24 16:01:10,510:INFO:_master_model_container: 18
2024-05-24 16:01:10,510:INFO:_display_container: 2
2024-05-24 16:01:10,510:INFO:HuberRegressor()
2024-05-24 16:01:10,510:INFO:compare_models() successfully completed......................................
2024-05-24 16:06:07,754:INFO:Initializing compare_models()
2024-05-24 16:06:07,754:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, include=['lr', 'lasso'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, 'include': ['lr', 'lasso'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:06:07,754:INFO:Checking exceptions
2024-05-24 16:06:07,761:INFO:Preparing display monitor
2024-05-24 16:06:07,805:INFO:Initializing Linear Regression
2024-05-24 16:06:07,805:INFO:Total runtime is 0.0 minutes
2024-05-24 16:06:07,811:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:07,812:INFO:Initializing create_model()
2024-05-24 16:06:07,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lr, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73A63B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:07,812:INFO:Checking exceptions
2024-05-24 16:06:07,813:INFO:Importing libraries
2024-05-24 16:06:07,813:INFO:Copying training dataset
2024-05-24 16:06:07,822:INFO:Defining folds
2024-05-24 16:06:07,823:INFO:Declaring metric variables
2024-05-24 16:06:07,830:INFO:Importing untrained model
2024-05-24 16:06:07,837:INFO:Linear Regression Imported successfully
2024-05-24 16:06:07,846:INFO:Starting cross validation
2024-05-24 16:06:07,875:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:10,391:INFO:Calculating mean and std
2024-05-24 16:06:10,393:INFO:Creating metrics dataframe
2024-05-24 16:06:10,395:INFO:Uploading results into container
2024-05-24 16:06:10,395:INFO:Uploading model into container now
2024-05-24 16:06:10,396:INFO:_master_model_container: 19
2024-05-24 16:06:10,396:INFO:_display_container: 3
2024-05-24 16:06:10,397:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:06:10,397:INFO:create_model() successfully completed......................................
2024-05-24 16:06:10,611:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:10,611:INFO:Creating metrics dataframe
2024-05-24 16:06:10,619:INFO:Initializing Lasso Regression
2024-05-24 16:06:10,620:INFO:Total runtime is 0.046923200289408364 minutes
2024-05-24 16:06:10,625:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:10,626:INFO:Initializing create_model()
2024-05-24 16:06:10,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lasso, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C73A63B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:10,626:INFO:Checking exceptions
2024-05-24 16:06:10,626:INFO:Importing libraries
2024-05-24 16:06:10,627:INFO:Copying training dataset
2024-05-24 16:06:10,633:INFO:Defining folds
2024-05-24 16:06:10,633:INFO:Declaring metric variables
2024-05-24 16:06:10,638:INFO:Importing untrained model
2024-05-24 16:06:10,645:INFO:Lasso Regression Imported successfully
2024-05-24 16:06:10,653:INFO:Starting cross validation
2024-05-24 16:06:10,676:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:12,607:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+07, tolerance: 8.427e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,644:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e+07, tolerance: 8.764e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,658:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,740:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,752:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+07, tolerance: 8.507e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,765:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 7.656e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 7.978e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:12,799:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 7.916e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:14,616:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+07, tolerance: 7.843e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:14,656:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 7.493e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:14,727:INFO:Calculating mean and std
2024-05-24 16:06:14,728:INFO:Creating metrics dataframe
2024-05-24 16:06:14,730:INFO:Uploading results into container
2024-05-24 16:06:14,731:INFO:Uploading model into container now
2024-05-24 16:06:14,732:INFO:_master_model_container: 20
2024-05-24 16:06:14,732:INFO:_display_container: 3
2024-05-24 16:06:14,733:INFO:Lasso(random_state=5034)
2024-05-24 16:06:14,733:INFO:create_model() successfully completed......................................
2024-05-24 16:06:14,924:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:14,924:INFO:Creating metrics dataframe
2024-05-24 16:06:14,934:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:06:14,943:INFO:Initializing create_model()
2024-05-24 16:06:14,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=Lasso(random_state=5034), fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:14,943:INFO:Checking exceptions
2024-05-24 16:06:14,945:INFO:Importing libraries
2024-05-24 16:06:14,945:INFO:Copying training dataset
2024-05-24 16:06:14,950:INFO:Defining folds
2024-05-24 16:06:14,950:INFO:Declaring metric variables
2024-05-24 16:06:14,950:INFO:Importing untrained model
2024-05-24 16:06:14,951:INFO:Declaring custom model
2024-05-24 16:06:14,951:INFO:Lasso Regression Imported successfully
2024-05-24 16:06:14,968:INFO:Cross validation set to False
2024-05-24 16:06:14,968:INFO:Fitting Model
2024-05-24 16:06:16,250:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e+07, tolerance: 9.079e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:16,251:INFO:Lasso(random_state=5034)
2024-05-24 16:06:16,251:INFO:create_model() successfully completed......................................
2024-05-24 16:06:16,500:INFO:_master_model_container: 20
2024-05-24 16:06:16,501:INFO:_display_container: 3
2024-05-24 16:06:16,501:INFO:Lasso(random_state=5034)
2024-05-24 16:06:16,501:INFO:compare_models() successfully completed......................................
2024-05-24 16:06:25,053:INFO:Initializing compare_models()
2024-05-24 16:06:25,053:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, include=['lr', 'lasso', 'ridge'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, 'include': ['lr', 'lasso', 'ridge'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:06:25,054:INFO:Checking exceptions
2024-05-24 16:06:25,058:INFO:Preparing display monitor
2024-05-24 16:06:25,096:INFO:Initializing Linear Regression
2024-05-24 16:06:25,096:INFO:Total runtime is 0.0 minutes
2024-05-24 16:06:25,102:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:25,102:INFO:Initializing create_model()
2024-05-24 16:06:25,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lr, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6F19C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:25,103:INFO:Checking exceptions
2024-05-24 16:06:25,103:INFO:Importing libraries
2024-05-24 16:06:25,104:INFO:Copying training dataset
2024-05-24 16:06:25,116:INFO:Defining folds
2024-05-24 16:06:25,116:INFO:Declaring metric variables
2024-05-24 16:06:25,145:INFO:Importing untrained model
2024-05-24 16:06:25,169:INFO:Linear Regression Imported successfully
2024-05-24 16:06:25,189:INFO:Starting cross validation
2024-05-24 16:06:25,234:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:27,517:INFO:Calculating mean and std
2024-05-24 16:06:27,519:INFO:Creating metrics dataframe
2024-05-24 16:06:27,522:INFO:Uploading results into container
2024-05-24 16:06:27,522:INFO:Uploading model into container now
2024-05-24 16:06:27,523:INFO:_master_model_container: 21
2024-05-24 16:06:27,523:INFO:_display_container: 4
2024-05-24 16:06:27,523:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:06:27,523:INFO:create_model() successfully completed......................................
2024-05-24 16:06:27,722:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:27,722:INFO:Creating metrics dataframe
2024-05-24 16:06:27,729:INFO:Initializing Lasso Regression
2024-05-24 16:06:27,729:INFO:Total runtime is 0.04388897021611531 minutes
2024-05-24 16:06:27,733:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:27,734:INFO:Initializing create_model()
2024-05-24 16:06:27,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lasso, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6F19C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:27,734:INFO:Checking exceptions
2024-05-24 16:06:27,735:INFO:Importing libraries
2024-05-24 16:06:27,735:INFO:Copying training dataset
2024-05-24 16:06:27,742:INFO:Defining folds
2024-05-24 16:06:27,742:INFO:Declaring metric variables
2024-05-24 16:06:27,747:INFO:Importing untrained model
2024-05-24 16:06:27,753:INFO:Lasso Regression Imported successfully
2024-05-24 16:06:27,763:INFO:Starting cross validation
2024-05-24 16:06:27,790:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:29,737:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+07, tolerance: 7.843e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,758:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e+07, tolerance: 8.764e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,763:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,765:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+07, tolerance: 8.427e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,774:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 7.978e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 7.493e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,792:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 7.916e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,808:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,870:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 7.656e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,891:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+07, tolerance: 8.507e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:29,958:INFO:Calculating mean and std
2024-05-24 16:06:29,959:INFO:Creating metrics dataframe
2024-05-24 16:06:29,962:INFO:Uploading results into container
2024-05-24 16:06:29,962:INFO:Uploading model into container now
2024-05-24 16:06:29,963:INFO:_master_model_container: 22
2024-05-24 16:06:29,963:INFO:_display_container: 4
2024-05-24 16:06:29,964:INFO:Lasso(random_state=5034)
2024-05-24 16:06:29,964:INFO:create_model() successfully completed......................................
2024-05-24 16:06:30,161:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:30,161:INFO:Creating metrics dataframe
2024-05-24 16:06:30,169:INFO:Initializing Ridge Regression
2024-05-24 16:06:30,170:INFO:Total runtime is 0.08456910451253255 minutes
2024-05-24 16:06:30,176:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:30,176:INFO:Initializing create_model()
2024-05-24 16:06:30,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=ridge, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6F19C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:30,176:INFO:Checking exceptions
2024-05-24 16:06:30,176:INFO:Importing libraries
2024-05-24 16:06:30,177:INFO:Copying training dataset
2024-05-24 16:06:30,183:INFO:Defining folds
2024-05-24 16:06:30,184:INFO:Declaring metric variables
2024-05-24 16:06:30,187:INFO:Importing untrained model
2024-05-24 16:06:30,193:INFO:Ridge Regression Imported successfully
2024-05-24 16:06:30,203:INFO:Starting cross validation
2024-05-24 16:06:30,231:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:32,096:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,160:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,181:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,206:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,231:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,245:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,305:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,344:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:32,426:INFO:Calculating mean and std
2024-05-24 16:06:32,427:INFO:Creating metrics dataframe
2024-05-24 16:06:32,430:INFO:Uploading results into container
2024-05-24 16:06:32,431:INFO:Uploading model into container now
2024-05-24 16:06:32,431:INFO:_master_model_container: 23
2024-05-24 16:06:32,431:INFO:_display_container: 4
2024-05-24 16:06:32,432:INFO:Ridge(random_state=5034)
2024-05-24 16:06:32,432:INFO:create_model() successfully completed......................................
2024-05-24 16:06:32,626:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:32,626:INFO:Creating metrics dataframe
2024-05-24 16:06:32,637:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:06:32,651:INFO:Initializing create_model()
2024-05-24 16:06:32,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=Lasso(random_state=5034), fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:32,651:INFO:Checking exceptions
2024-05-24 16:06:32,653:INFO:Importing libraries
2024-05-24 16:06:32,653:INFO:Copying training dataset
2024-05-24 16:06:32,661:INFO:Defining folds
2024-05-24 16:06:32,661:INFO:Declaring metric variables
2024-05-24 16:06:32,661:INFO:Importing untrained model
2024-05-24 16:06:32,661:INFO:Declaring custom model
2024-05-24 16:06:32,663:INFO:Lasso Regression Imported successfully
2024-05-24 16:06:32,690:INFO:Cross validation set to False
2024-05-24 16:06:32,690:INFO:Fitting Model
2024-05-24 16:06:33,789:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e+07, tolerance: 9.079e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:33,790:INFO:Lasso(random_state=5034)
2024-05-24 16:06:33,790:INFO:create_model() successfully completed......................................
2024-05-24 16:06:34,027:INFO:_master_model_container: 23
2024-05-24 16:06:34,027:INFO:_display_container: 4
2024-05-24 16:06:34,027:INFO:Lasso(random_state=5034)
2024-05-24 16:06:34,028:INFO:compare_models() successfully completed......................................
2024-05-24 16:06:42,622:INFO:Initializing compare_models()
2024-05-24 16:06:42,622:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:06:42,622:INFO:Checking exceptions
2024-05-24 16:06:42,629:INFO:Preparing display monitor
2024-05-24 16:06:42,678:INFO:Initializing Linear Regression
2024-05-24 16:06:42,679:INFO:Total runtime is 1.66932741800944e-05 minutes
2024-05-24 16:06:42,688:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:42,688:INFO:Initializing create_model()
2024-05-24 16:06:42,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lr, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5A60E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:42,689:INFO:Checking exceptions
2024-05-24 16:06:42,689:INFO:Importing libraries
2024-05-24 16:06:42,690:INFO:Copying training dataset
2024-05-24 16:06:42,703:INFO:Defining folds
2024-05-24 16:06:42,703:INFO:Declaring metric variables
2024-05-24 16:06:42,710:INFO:Importing untrained model
2024-05-24 16:06:42,718:INFO:Linear Regression Imported successfully
2024-05-24 16:06:42,731:INFO:Starting cross validation
2024-05-24 16:06:42,758:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:45,062:INFO:Calculating mean and std
2024-05-24 16:06:45,063:INFO:Creating metrics dataframe
2024-05-24 16:06:45,066:INFO:Uploading results into container
2024-05-24 16:06:45,067:INFO:Uploading model into container now
2024-05-24 16:06:45,068:INFO:_master_model_container: 24
2024-05-24 16:06:45,068:INFO:_display_container: 5
2024-05-24 16:06:45,068:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:06:45,068:INFO:create_model() successfully completed......................................
2024-05-24 16:06:45,271:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:45,271:INFO:Creating metrics dataframe
2024-05-24 16:06:45,282:INFO:Initializing Lasso Regression
2024-05-24 16:06:45,282:INFO:Total runtime is 0.043413054943084714 minutes
2024-05-24 16:06:45,288:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:45,288:INFO:Initializing create_model()
2024-05-24 16:06:45,289:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=lasso, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5A60E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:45,289:INFO:Checking exceptions
2024-05-24 16:06:45,289:INFO:Importing libraries
2024-05-24 16:06:45,289:INFO:Copying training dataset
2024-05-24 16:06:45,296:INFO:Defining folds
2024-05-24 16:06:45,296:INFO:Declaring metric variables
2024-05-24 16:06:45,301:INFO:Importing untrained model
2024-05-24 16:06:45,306:INFO:Lasso Regression Imported successfully
2024-05-24 16:06:45,314:INFO:Starting cross validation
2024-05-24 16:06:45,336:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:47,205:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+07, tolerance: 7.843e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,215:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+07, tolerance: 8.466e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,228:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+07, tolerance: 8.427e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,270:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+07, tolerance: 7.978e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.829e+07, tolerance: 8.764e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,300:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 7.493e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+07, tolerance: 8.507e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,343:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+07, tolerance: 7.656e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+07, tolerance: 8.800e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,352:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+07, tolerance: 7.916e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:06:47,413:INFO:Calculating mean and std
2024-05-24 16:06:47,415:INFO:Creating metrics dataframe
2024-05-24 16:06:47,419:INFO:Uploading results into container
2024-05-24 16:06:47,420:INFO:Uploading model into container now
2024-05-24 16:06:47,420:INFO:_master_model_container: 25
2024-05-24 16:06:47,420:INFO:_display_container: 5
2024-05-24 16:06:47,421:INFO:Lasso(random_state=5034)
2024-05-24 16:06:47,421:INFO:create_model() successfully completed......................................
2024-05-24 16:06:47,614:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:47,615:INFO:Creating metrics dataframe
2024-05-24 16:06:47,623:INFO:Initializing Ridge Regression
2024-05-24 16:06:47,623:INFO:Total runtime is 0.08242783149083455 minutes
2024-05-24 16:06:47,627:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:47,627:INFO:Initializing create_model()
2024-05-24 16:06:47,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=ridge, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5A60E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:47,628:INFO:Checking exceptions
2024-05-24 16:06:47,628:INFO:Importing libraries
2024-05-24 16:06:47,628:INFO:Copying training dataset
2024-05-24 16:06:47,635:INFO:Defining folds
2024-05-24 16:06:47,635:INFO:Declaring metric variables
2024-05-24 16:06:47,638:INFO:Importing untrained model
2024-05-24 16:06:47,644:INFO:Ridge Regression Imported successfully
2024-05-24 16:06:47,652:INFO:Starting cross validation
2024-05-24 16:06:47,671:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:49,474:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,486:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,514:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,520:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,552:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,570:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,573:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,588:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,634:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:06:49,718:INFO:Calculating mean and std
2024-05-24 16:06:49,719:INFO:Creating metrics dataframe
2024-05-24 16:06:49,722:INFO:Uploading results into container
2024-05-24 16:06:49,723:INFO:Uploading model into container now
2024-05-24 16:06:49,724:INFO:_master_model_container: 26
2024-05-24 16:06:49,724:INFO:_display_container: 5
2024-05-24 16:06:49,724:INFO:Ridge(random_state=5034)
2024-05-24 16:06:49,724:INFO:create_model() successfully completed......................................
2024-05-24 16:06:49,918:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:49,918:INFO:Creating metrics dataframe
2024-05-24 16:06:49,926:INFO:Initializing Huber Regressor
2024-05-24 16:06:49,927:INFO:Total runtime is 0.12082504431406657 minutes
2024-05-24 16:06:49,930:INFO:SubProcess create_model() called ==================================
2024-05-24 16:06:49,931:INFO:Initializing create_model()
2024-05-24 16:06:49,931:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=huber, fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221BB5A60E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:49,931:INFO:Checking exceptions
2024-05-24 16:06:49,931:INFO:Importing libraries
2024-05-24 16:06:49,931:INFO:Copying training dataset
2024-05-24 16:06:49,937:INFO:Defining folds
2024-05-24 16:06:49,937:INFO:Declaring metric variables
2024-05-24 16:06:49,943:INFO:Importing untrained model
2024-05-24 16:06:49,948:INFO:Huber Regressor Imported successfully
2024-05-24 16:06:49,955:INFO:Starting cross validation
2024-05-24 16:06:49,977:INFO:Cross validating with KFold(n_splits=10, random_state=5034, shuffle=True), n_jobs=-1
2024-05-24 16:06:51,860:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:06:51,993:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:06:52,001:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:06:52,011:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:06:52,043:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:06:52,090:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:06:52,166:INFO:Calculating mean and std
2024-05-24 16:06:52,168:INFO:Creating metrics dataframe
2024-05-24 16:06:52,170:INFO:Uploading results into container
2024-05-24 16:06:52,170:INFO:Uploading model into container now
2024-05-24 16:06:52,170:INFO:_master_model_container: 27
2024-05-24 16:06:52,171:INFO:_display_container: 5
2024-05-24 16:06:52,171:INFO:HuberRegressor()
2024-05-24 16:06:52,171:INFO:create_model() successfully completed......................................
2024-05-24 16:06:52,364:INFO:SubProcess create_model() end ==================================
2024-05-24 16:06:52,364:INFO:Creating metrics dataframe
2024-05-24 16:06:52,375:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:06:52,385:INFO:Initializing create_model()
2024-05-24 16:06:52,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8664460>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=5034, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:06:52,385:INFO:Checking exceptions
2024-05-24 16:06:52,387:INFO:Importing libraries
2024-05-24 16:06:52,387:INFO:Copying training dataset
2024-05-24 16:06:52,398:INFO:Defining folds
2024-05-24 16:06:52,398:INFO:Declaring metric variables
2024-05-24 16:06:52,398:INFO:Importing untrained model
2024-05-24 16:06:52,398:INFO:Declaring custom model
2024-05-24 16:06:52,399:INFO:Huber Regressor Imported successfully
2024-05-24 16:06:52,420:INFO:Cross validation set to False
2024-05-24 16:06:52,421:INFO:Fitting Model
2024-05-24 16:06:53,518:INFO:HuberRegressor()
2024-05-24 16:06:53,518:INFO:create_model() successfully completed......................................
2024-05-24 16:06:53,733:INFO:_master_model_container: 27
2024-05-24 16:06:53,733:INFO:_display_container: 5
2024-05-24 16:06:53,734:INFO:HuberRegressor()
2024-05-24 16:06:53,734:INFO:compare_models() successfully completed......................................
2024-05-24 16:08:28,431:INFO:PyCaret RegressionExperiment
2024-05-24 16:08:28,432:INFO:Logging name: reg-default-name
2024-05-24 16:08:28,432:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:08:28,432:INFO:version 3.3.2
2024-05-24 16:08:28,432:INFO:Initializing setup()
2024-05-24 16:08:28,432:INFO:self.USI: 7f72
2024-05-24 16:08:28,432:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 16:08:28,432:INFO:Checking environment
2024-05-24 16:08:28,432:INFO:python_version: 3.10.14
2024-05-24 16:08:28,432:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:08:28,433:INFO:machine: AMD64
2024-05-24 16:08:28,433:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:08:28,433:INFO:Memory: svmem(total=16541802496, available=3059662848, percent=81.5, used=13482139648, free=3059662848)
2024-05-24 16:08:28,433:INFO:Physical Core: 6
2024-05-24 16:08:28,433:INFO:Logical Core: 12
2024-05-24 16:08:28,433:INFO:Checking libraries
2024-05-24 16:08:28,433:INFO:System:
2024-05-24 16:08:28,433:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:08:28,433:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:08:28,433:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:08:28,433:INFO:PyCaret required dependencies:
2024-05-24 16:08:28,433:INFO:                 pip: 24.0
2024-05-24 16:08:28,433:INFO:          setuptools: 69.5.1
2024-05-24 16:08:28,433:INFO:             pycaret: 3.3.2
2024-05-24 16:08:28,435:INFO:             IPython: 8.20.0
2024-05-24 16:08:28,435:INFO:          ipywidgets: 8.1.2
2024-05-24 16:08:28,435:INFO:                tqdm: 4.66.4
2024-05-24 16:08:28,435:INFO:               numpy: 1.26.4
2024-05-24 16:08:28,435:INFO:              pandas: 2.1.4
2024-05-24 16:08:28,435:INFO:              jinja2: 3.1.3
2024-05-24 16:08:28,435:INFO:               scipy: 1.11.4
2024-05-24 16:08:28,435:INFO:              joblib: 1.3.2
2024-05-24 16:08:28,435:INFO:             sklearn: 1.4.2
2024-05-24 16:08:28,435:INFO:                pyod: 1.1.3
2024-05-24 16:08:28,435:INFO:            imblearn: 0.12.2
2024-05-24 16:08:28,435:INFO:   category_encoders: 2.6.3
2024-05-24 16:08:28,435:INFO:            lightgbm: 4.3.0
2024-05-24 16:08:28,435:INFO:               numba: 0.59.1
2024-05-24 16:08:28,435:INFO:            requests: 2.32.2
2024-05-24 16:08:28,435:INFO:          matplotlib: 3.7.5
2024-05-24 16:08:28,435:INFO:          scikitplot: 0.3.7
2024-05-24 16:08:28,435:INFO:         yellowbrick: 1.5
2024-05-24 16:08:28,435:INFO:              plotly: 5.22.0
2024-05-24 16:08:28,435:INFO:    plotly-resampler: Not installed
2024-05-24 16:08:28,435:INFO:             kaleido: 0.2.1
2024-05-24 16:08:28,435:INFO:           schemdraw: 0.15
2024-05-24 16:08:28,435:INFO:         statsmodels: 0.14.2
2024-05-24 16:08:28,436:INFO:              sktime: 0.26.0
2024-05-24 16:08:28,436:INFO:               tbats: 1.1.3
2024-05-24 16:08:28,436:INFO:            pmdarima: 2.0.4
2024-05-24 16:08:28,436:INFO:              psutil: 5.9.0
2024-05-24 16:08:28,436:INFO:          markupsafe: 2.1.3
2024-05-24 16:08:28,436:INFO:             pickle5: Not installed
2024-05-24 16:08:28,436:INFO:         cloudpickle: 3.0.0
2024-05-24 16:08:28,436:INFO:         deprecation: 2.1.0
2024-05-24 16:08:28,436:INFO:              xxhash: 3.4.1
2024-05-24 16:08:28,436:INFO:           wurlitzer: Not installed
2024-05-24 16:08:28,436:INFO:PyCaret optional dependencies:
2024-05-24 16:08:28,436:INFO:                shap: Not installed
2024-05-24 16:08:28,436:INFO:           interpret: Not installed
2024-05-24 16:08:28,436:INFO:                umap: Not installed
2024-05-24 16:08:28,436:INFO:     ydata_profiling: Not installed
2024-05-24 16:08:28,436:INFO:  explainerdashboard: Not installed
2024-05-24 16:08:28,436:INFO:             autoviz: Not installed
2024-05-24 16:08:28,436:INFO:           fairlearn: Not installed
2024-05-24 16:08:28,436:INFO:          deepchecks: Not installed
2024-05-24 16:08:28,437:INFO:             xgboost: Not installed
2024-05-24 16:08:28,437:INFO:            catboost: Not installed
2024-05-24 16:08:28,437:INFO:              kmodes: Not installed
2024-05-24 16:08:28,437:INFO:             mlxtend: Not installed
2024-05-24 16:08:28,437:INFO:       statsforecast: Not installed
2024-05-24 16:08:28,437:INFO:        tune_sklearn: Not installed
2024-05-24 16:08:28,437:INFO:                 ray: Not installed
2024-05-24 16:08:28,437:INFO:            hyperopt: Not installed
2024-05-24 16:08:28,437:INFO:              optuna: Not installed
2024-05-24 16:08:28,437:INFO:               skopt: Not installed
2024-05-24 16:08:28,437:INFO:              mlflow: Not installed
2024-05-24 16:08:28,437:INFO:              gradio: Not installed
2024-05-24 16:08:28,437:INFO:             fastapi: Not installed
2024-05-24 16:08:28,437:INFO:             uvicorn: Not installed
2024-05-24 16:08:28,437:INFO:              m2cgen: Not installed
2024-05-24 16:08:28,437:INFO:           evidently: Not installed
2024-05-24 16:08:28,437:INFO:               fugue: Not installed
2024-05-24 16:08:28,437:INFO:           streamlit: Not installed
2024-05-24 16:08:28,437:INFO:             prophet: Not installed
2024-05-24 16:08:28,437:INFO:None
2024-05-24 16:08:28,437:INFO:Set up data.
2024-05-24 16:08:28,450:INFO:Set up folding strategy.
2024-05-24 16:08:28,450:INFO:Set up train/test split.
2024-05-24 16:08:28,459:INFO:Set up index.
2024-05-24 16:08:28,459:INFO:Assigning column types.
2024-05-24 16:08:28,464:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:08:28,465:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,470:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,475:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,557:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,613:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:28,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:28,615:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:28,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:28,739:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:08:28,745:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,754:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,816:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:28,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:28,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,879:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:08:28,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,013:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,015:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:08:29,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,087:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,278:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:08:29,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,517:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:08:29,589:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,635:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:08:29,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,750:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:08:29,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:29,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:30,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:30,002:INFO:Preparing preprocessing pipeline...
2024-05-24 16:08:30,002:INFO:Set up simple imputation.
2024-05-24 16:08:30,008:INFO:Set up encoding of ordinal features.
2024-05-24 16:08:30,014:INFO:Set up encoding of categorical features.
2024-05-24 16:08:30,014:INFO:Set up polynomial features.
2024-05-24 16:08:30,014:INFO:Set up removing multicollinearity.
2024-05-24 16:08:30,014:INFO:Set up removing outliers.
2024-05-24 16:08:31,242:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:08:31,310:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=7291)))])
2024-05-24 16:08:31,315:INFO:Creating final display dataframe.
2024-05-24 16:08:33,971:INFO:Setup _display_container:                     Description             Value
0                    Session id              7291
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 451)
5   Transformed train set shape        (135, 451)
6    Transformed test set shape         (62, 451)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              7f72
2024-05-24 16:08:34,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:34,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:34,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:34,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:08:34,232:INFO:setup() successfully completed in 5.82s...............
2024-05-24 16:08:34,277:INFO:Initializing compare_models()
2024-05-24 16:08:34,277:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:08:34,277:INFO:Checking exceptions
2024-05-24 16:08:34,282:INFO:Preparing display monitor
2024-05-24 16:08:34,311:INFO:Initializing Linear Regression
2024-05-24 16:08:34,312:INFO:Total runtime is 2.3376941680908202e-05 minutes
2024-05-24 16:08:34,317:INFO:SubProcess create_model() called ==================================
2024-05-24 16:08:34,317:INFO:Initializing create_model()
2024-05-24 16:08:34,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6C01360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:08:34,317:INFO:Checking exceptions
2024-05-24 16:08:34,317:INFO:Importing libraries
2024-05-24 16:08:34,318:INFO:Copying training dataset
2024-05-24 16:08:34,327:INFO:Defining folds
2024-05-24 16:08:34,327:INFO:Declaring metric variables
2024-05-24 16:08:34,337:INFO:Importing untrained model
2024-05-24 16:08:34,344:INFO:Linear Regression Imported successfully
2024-05-24 16:08:34,357:INFO:Starting cross validation
2024-05-24 16:08:34,384:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:08:36,509:INFO:Calculating mean and std
2024-05-24 16:08:36,511:INFO:Creating metrics dataframe
2024-05-24 16:08:36,514:INFO:Uploading results into container
2024-05-24 16:08:36,516:INFO:Uploading model into container now
2024-05-24 16:08:36,516:INFO:_master_model_container: 1
2024-05-24 16:08:36,517:INFO:_display_container: 2
2024-05-24 16:08:36,517:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:08:36,517:INFO:create_model() successfully completed......................................
2024-05-24 16:08:36,734:INFO:SubProcess create_model() end ==================================
2024-05-24 16:08:36,734:INFO:Creating metrics dataframe
2024-05-24 16:08:36,741:INFO:Initializing Lasso Regression
2024-05-24 16:08:36,741:INFO:Total runtime is 0.040502500534057614 minutes
2024-05-24 16:08:36,745:INFO:SubProcess create_model() called ==================================
2024-05-24 16:08:36,746:INFO:Initializing create_model()
2024-05-24 16:08:36,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6C01360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:08:36,746:INFO:Checking exceptions
2024-05-24 16:08:36,746:INFO:Importing libraries
2024-05-24 16:08:36,747:INFO:Copying training dataset
2024-05-24 16:08:36,757:INFO:Defining folds
2024-05-24 16:08:36,757:INFO:Declaring metric variables
2024-05-24 16:08:36,763:INFO:Importing untrained model
2024-05-24 16:08:36,768:INFO:Lasso Regression Imported successfully
2024-05-24 16:08:36,778:INFO:Starting cross validation
2024-05-24 16:08:36,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:08:38,640:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.568e+07, tolerance: 9.385e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,644:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+07, tolerance: 9.057e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+07, tolerance: 8.531e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,667:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.916e+07, tolerance: 8.611e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,669:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.038e+07, tolerance: 9.223e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,671:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e+07, tolerance: 8.428e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,733:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+07, tolerance: 8.686e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,748:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e+07, tolerance: 7.873e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,756:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+07, tolerance: 8.817e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,816:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.266e+07, tolerance: 8.546e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:08:38,896:INFO:Calculating mean and std
2024-05-24 16:08:38,898:INFO:Creating metrics dataframe
2024-05-24 16:08:38,900:INFO:Uploading results into container
2024-05-24 16:08:38,900:INFO:Uploading model into container now
2024-05-24 16:08:38,901:INFO:_master_model_container: 2
2024-05-24 16:08:38,901:INFO:_display_container: 2
2024-05-24 16:08:38,901:INFO:Lasso(random_state=7291)
2024-05-24 16:08:38,901:INFO:create_model() successfully completed......................................
2024-05-24 16:08:39,094:INFO:SubProcess create_model() end ==================================
2024-05-24 16:08:39,094:INFO:Creating metrics dataframe
2024-05-24 16:08:39,102:INFO:Initializing Ridge Regression
2024-05-24 16:08:39,102:INFO:Total runtime is 0.07985926071802775 minutes
2024-05-24 16:08:39,107:INFO:SubProcess create_model() called ==================================
2024-05-24 16:08:39,107:INFO:Initializing create_model()
2024-05-24 16:08:39,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6C01360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:08:39,107:INFO:Checking exceptions
2024-05-24 16:08:39,107:INFO:Importing libraries
2024-05-24 16:08:39,108:INFO:Copying training dataset
2024-05-24 16:08:39,113:INFO:Defining folds
2024-05-24 16:08:39,113:INFO:Declaring metric variables
2024-05-24 16:08:39,118:INFO:Importing untrained model
2024-05-24 16:08:39,123:INFO:Ridge Regression Imported successfully
2024-05-24 16:08:39,131:INFO:Starting cross validation
2024-05-24 16:08:39,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:08:40,805:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,877:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,904:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,907:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,935:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,943:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,947:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:40,947:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:41,023:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:41,024:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:08:41,086:INFO:Calculating mean and std
2024-05-24 16:08:41,086:INFO:Creating metrics dataframe
2024-05-24 16:08:41,089:INFO:Uploading results into container
2024-05-24 16:08:41,089:INFO:Uploading model into container now
2024-05-24 16:08:41,089:INFO:_master_model_container: 3
2024-05-24 16:08:41,090:INFO:_display_container: 2
2024-05-24 16:08:41,090:INFO:Ridge(random_state=7291)
2024-05-24 16:08:41,090:INFO:create_model() successfully completed......................................
2024-05-24 16:08:41,293:INFO:SubProcess create_model() end ==================================
2024-05-24 16:08:41,293:INFO:Creating metrics dataframe
2024-05-24 16:08:41,299:INFO:Initializing Huber Regressor
2024-05-24 16:08:41,300:INFO:Total runtime is 0.11648181676864625 minutes
2024-05-24 16:08:41,303:INFO:SubProcess create_model() called ==================================
2024-05-24 16:08:41,304:INFO:Initializing create_model()
2024-05-24 16:08:41,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6C01360>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:08:41,304:INFO:Checking exceptions
2024-05-24 16:08:41,304:INFO:Importing libraries
2024-05-24 16:08:41,304:INFO:Copying training dataset
2024-05-24 16:08:41,311:INFO:Defining folds
2024-05-24 16:08:41,312:INFO:Declaring metric variables
2024-05-24 16:08:41,315:INFO:Importing untrained model
2024-05-24 16:08:41,320:INFO:Huber Regressor Imported successfully
2024-05-24 16:08:41,328:INFO:Starting cross validation
2024-05-24 16:08:41,355:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:08:43,194:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,212:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,220:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,235:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,296:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,315:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,329:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,367:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:43,425:INFO:Calculating mean and std
2024-05-24 16:08:43,426:INFO:Creating metrics dataframe
2024-05-24 16:08:43,429:INFO:Uploading results into container
2024-05-24 16:08:43,429:INFO:Uploading model into container now
2024-05-24 16:08:43,429:INFO:_master_model_container: 4
2024-05-24 16:08:43,429:INFO:_display_container: 2
2024-05-24 16:08:43,430:INFO:HuberRegressor()
2024-05-24 16:08:43,430:INFO:create_model() successfully completed......................................
2024-05-24 16:08:43,630:INFO:SubProcess create_model() end ==================================
2024-05-24 16:08:43,630:INFO:Creating metrics dataframe
2024-05-24 16:08:43,640:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:08:43,651:INFO:Initializing create_model()
2024-05-24 16:08:43,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:08:43,651:INFO:Checking exceptions
2024-05-24 16:08:43,653:INFO:Importing libraries
2024-05-24 16:08:43,653:INFO:Copying training dataset
2024-05-24 16:08:43,659:INFO:Defining folds
2024-05-24 16:08:43,659:INFO:Declaring metric variables
2024-05-24 16:08:43,660:INFO:Importing untrained model
2024-05-24 16:08:43,660:INFO:Declaring custom model
2024-05-24 16:08:43,660:INFO:Huber Regressor Imported successfully
2024-05-24 16:08:43,692:INFO:Cross validation set to False
2024-05-24 16:08:43,692:INFO:Fitting Model
2024-05-24 16:08:44,799:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:08:44,800:INFO:HuberRegressor()
2024-05-24 16:08:44,800:INFO:create_model() successfully completed......................................
2024-05-24 16:08:45,006:INFO:_master_model_container: 4
2024-05-24 16:08:45,007:INFO:_display_container: 2
2024-05-24 16:08:45,007:INFO:HuberRegressor()
2024-05-24 16:08:45,007:INFO:compare_models() successfully completed......................................
2024-05-24 16:08:51,495:INFO:Initializing plot_model()
2024-05-24 16:08:51,496:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=1315), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C6B697B0>, system=True)
2024-05-24 16:08:51,496:INFO:Checking exceptions
2024-05-24 16:08:51,538:INFO:Preloading libraries
2024-05-24 16:08:51,547:INFO:Copying training dataset
2024-05-24 16:08:51,547:INFO:Plot type: rfe
2024-05-24 16:08:51,750:INFO:Fitting Model
2024-05-24 16:09:06,611:INFO:Initializing evaluate_model()
2024-05-24 16:09:06,611:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 16:09:06,623:INFO:Initializing plot_model()
2024-05-24 16:09:06,623:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8666A10>, system=True)
2024-05-24 16:09:06,624:INFO:Checking exceptions
2024-05-24 16:09:06,626:INFO:Preloading libraries
2024-05-24 16:09:06,627:INFO:Copying training dataset
2024-05-24 16:09:06,627:INFO:Plot type: pipeline
2024-05-24 16:09:06,831:INFO:Visual Rendered Successfully
2024-05-24 16:09:07,029:INFO:plot_model() successfully completed......................................
2024-05-24 16:09:07,825:INFO:PyCaret RegressionExperiment
2024-05-24 16:09:07,825:INFO:Logging name: reg-default-name
2024-05-24 16:09:07,825:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:09:07,825:INFO:version 3.3.2
2024-05-24 16:09:07,825:INFO:Initializing setup()
2024-05-24 16:09:07,825:INFO:self.USI: 6a52
2024-05-24 16:09:07,825:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 16:09:07,825:INFO:Checking environment
2024-05-24 16:09:07,825:INFO:python_version: 3.10.14
2024-05-24 16:09:07,825:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:09:07,826:INFO:machine: AMD64
2024-05-24 16:09:07,826:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:09:07,826:INFO:Memory: svmem(total=16541802496, available=3029975040, percent=81.7, used=13511827456, free=3029975040)
2024-05-24 16:09:07,826:INFO:Physical Core: 6
2024-05-24 16:09:07,826:INFO:Logical Core: 12
2024-05-24 16:09:07,826:INFO:Checking libraries
2024-05-24 16:09:07,826:INFO:System:
2024-05-24 16:09:07,826:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:09:07,826:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:09:07,826:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:09:07,826:INFO:PyCaret required dependencies:
2024-05-24 16:09:07,826:INFO:                 pip: 24.0
2024-05-24 16:09:07,826:INFO:          setuptools: 69.5.1
2024-05-24 16:09:07,826:INFO:             pycaret: 3.3.2
2024-05-24 16:09:07,827:INFO:             IPython: 8.20.0
2024-05-24 16:09:07,827:INFO:          ipywidgets: 8.1.2
2024-05-24 16:09:07,827:INFO:                tqdm: 4.66.4
2024-05-24 16:09:07,827:INFO:               numpy: 1.26.4
2024-05-24 16:09:07,827:INFO:              pandas: 2.1.4
2024-05-24 16:09:07,827:INFO:              jinja2: 3.1.3
2024-05-24 16:09:07,827:INFO:               scipy: 1.11.4
2024-05-24 16:09:07,827:INFO:              joblib: 1.3.2
2024-05-24 16:09:07,827:INFO:             sklearn: 1.4.2
2024-05-24 16:09:07,827:INFO:                pyod: 1.1.3
2024-05-24 16:09:07,827:INFO:            imblearn: 0.12.2
2024-05-24 16:09:07,827:INFO:   category_encoders: 2.6.3
2024-05-24 16:09:07,827:INFO:            lightgbm: 4.3.0
2024-05-24 16:09:07,827:INFO:               numba: 0.59.1
2024-05-24 16:09:07,827:INFO:            requests: 2.32.2
2024-05-24 16:09:07,827:INFO:          matplotlib: 3.7.5
2024-05-24 16:09:07,827:INFO:          scikitplot: 0.3.7
2024-05-24 16:09:07,827:INFO:         yellowbrick: 1.5
2024-05-24 16:09:07,828:INFO:              plotly: 5.22.0
2024-05-24 16:09:07,828:INFO:    plotly-resampler: Not installed
2024-05-24 16:09:07,828:INFO:             kaleido: 0.2.1
2024-05-24 16:09:07,828:INFO:           schemdraw: 0.15
2024-05-24 16:09:07,828:INFO:         statsmodels: 0.14.2
2024-05-24 16:09:07,828:INFO:              sktime: 0.26.0
2024-05-24 16:09:07,828:INFO:               tbats: 1.1.3
2024-05-24 16:09:07,828:INFO:            pmdarima: 2.0.4
2024-05-24 16:09:07,828:INFO:              psutil: 5.9.0
2024-05-24 16:09:07,828:INFO:          markupsafe: 2.1.3
2024-05-24 16:09:07,828:INFO:             pickle5: Not installed
2024-05-24 16:09:07,828:INFO:         cloudpickle: 3.0.0
2024-05-24 16:09:07,828:INFO:         deprecation: 2.1.0
2024-05-24 16:09:07,828:INFO:              xxhash: 3.4.1
2024-05-24 16:09:07,829:INFO:           wurlitzer: Not installed
2024-05-24 16:09:07,829:INFO:PyCaret optional dependencies:
2024-05-24 16:09:07,829:INFO:                shap: Not installed
2024-05-24 16:09:07,829:INFO:           interpret: Not installed
2024-05-24 16:09:07,829:INFO:                umap: Not installed
2024-05-24 16:09:07,829:INFO:     ydata_profiling: Not installed
2024-05-24 16:09:07,829:INFO:  explainerdashboard: Not installed
2024-05-24 16:09:07,829:INFO:             autoviz: Not installed
2024-05-24 16:09:07,829:INFO:           fairlearn: Not installed
2024-05-24 16:09:07,829:INFO:          deepchecks: Not installed
2024-05-24 16:09:07,829:INFO:             xgboost: Not installed
2024-05-24 16:09:07,829:INFO:            catboost: Not installed
2024-05-24 16:09:07,829:INFO:              kmodes: Not installed
2024-05-24 16:09:07,829:INFO:             mlxtend: Not installed
2024-05-24 16:09:07,829:INFO:       statsforecast: Not installed
2024-05-24 16:09:07,829:INFO:        tune_sklearn: Not installed
2024-05-24 16:09:07,829:INFO:                 ray: Not installed
2024-05-24 16:09:07,829:INFO:            hyperopt: Not installed
2024-05-24 16:09:07,830:INFO:              optuna: Not installed
2024-05-24 16:09:07,830:INFO:               skopt: Not installed
2024-05-24 16:09:07,830:INFO:              mlflow: Not installed
2024-05-24 16:09:07,830:INFO:              gradio: Not installed
2024-05-24 16:09:07,830:INFO:             fastapi: Not installed
2024-05-24 16:09:07,830:INFO:             uvicorn: Not installed
2024-05-24 16:09:07,830:INFO:              m2cgen: Not installed
2024-05-24 16:09:07,830:INFO:           evidently: Not installed
2024-05-24 16:09:07,830:INFO:               fugue: Not installed
2024-05-24 16:09:07,830:INFO:           streamlit: Not installed
2024-05-24 16:09:07,830:INFO:             prophet: Not installed
2024-05-24 16:09:07,830:INFO:None
2024-05-24 16:09:07,830:INFO:Set up data.
2024-05-24 16:09:07,844:INFO:Set up folding strategy.
2024-05-24 16:09:07,844:INFO:Set up train/test split.
2024-05-24 16:09:07,851:INFO:Set up index.
2024-05-24 16:09:07,851:INFO:Assigning column types.
2024-05-24 16:09:07,856:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:09:07,856:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,861:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,865:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,925:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:07,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:07,971:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,975:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:07,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,040:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,084:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,086:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:09:08,091:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,154:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,206:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,211:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,315:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,316:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:09:08,325:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,440:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,546:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:09:08,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,733:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,778:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,778:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:09:08,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:08,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:08,960:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:09,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:09,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:09,006:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:09:09,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:09,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:09,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:09,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:09,236:INFO:Preparing preprocessing pipeline...
2024-05-24 16:09:09,236:INFO:Set up simple imputation.
2024-05-24 16:09:09,241:INFO:Set up encoding of ordinal features.
2024-05-24 16:09:09,246:INFO:Set up encoding of categorical features.
2024-05-24 16:09:09,247:INFO:Set up polynomial features.
2024-05-24 16:09:09,247:INFO:Set up removing multicollinearity.
2024-05-24 16:09:09,247:INFO:Set up removing outliers.
2024-05-24 16:09:10,474:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:09:10,540:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=8799)))])
2024-05-24 16:09:10,540:INFO:Creating final display dataframe.
2024-05-24 16:09:12,932:INFO:Setup _display_container:                     Description             Value
0                    Session id              8799
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 446)
5   Transformed train set shape        (135, 446)
6    Transformed test set shape         (62, 446)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              6a52
2024-05-24 16:09:13,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:13,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:13,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:13,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:13,183:INFO:setup() successfully completed in 5.38s...............
2024-05-24 16:09:13,213:INFO:Initializing compare_models()
2024-05-24 16:09:13,213:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:09:13,215:INFO:Checking exceptions
2024-05-24 16:09:13,218:INFO:Preparing display monitor
2024-05-24 16:09:13,246:INFO:Initializing Linear Regression
2024-05-24 16:09:13,247:INFO:Total runtime is 2.294778823852539e-05 minutes
2024-05-24 16:09:13,250:INFO:SubProcess create_model() called ==================================
2024-05-24 16:09:13,251:INFO:Initializing create_model()
2024-05-24 16:09:13,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C8C62D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:09:13,251:INFO:Checking exceptions
2024-05-24 16:09:13,251:INFO:Importing libraries
2024-05-24 16:09:13,251:INFO:Copying training dataset
2024-05-24 16:09:13,261:INFO:Defining folds
2024-05-24 16:09:13,261:INFO:Declaring metric variables
2024-05-24 16:09:13,266:INFO:Importing untrained model
2024-05-24 16:09:13,270:INFO:Linear Regression Imported successfully
2024-05-24 16:09:13,280:INFO:Starting cross validation
2024-05-24 16:09:13,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:09:15,580:INFO:Calculating mean and std
2024-05-24 16:09:15,581:INFO:Creating metrics dataframe
2024-05-24 16:09:15,583:INFO:Uploading results into container
2024-05-24 16:09:15,584:INFO:Uploading model into container now
2024-05-24 16:09:15,585:INFO:_master_model_container: 1
2024-05-24 16:09:15,585:INFO:_display_container: 2
2024-05-24 16:09:15,585:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:09:15,585:INFO:create_model() successfully completed......................................
2024-05-24 16:09:15,813:INFO:SubProcess create_model() end ==================================
2024-05-24 16:09:15,813:INFO:Creating metrics dataframe
2024-05-24 16:09:15,822:INFO:Initializing Lasso Regression
2024-05-24 16:09:15,822:INFO:Total runtime is 0.04293461640675863 minutes
2024-05-24 16:09:15,827:INFO:SubProcess create_model() called ==================================
2024-05-24 16:09:15,828:INFO:Initializing create_model()
2024-05-24 16:09:15,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C8C62D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:09:15,828:INFO:Checking exceptions
2024-05-24 16:09:15,828:INFO:Importing libraries
2024-05-24 16:09:15,828:INFO:Copying training dataset
2024-05-24 16:09:15,837:INFO:Defining folds
2024-05-24 16:09:15,838:INFO:Declaring metric variables
2024-05-24 16:09:15,842:INFO:Importing untrained model
2024-05-24 16:09:15,847:INFO:Lasso Regression Imported successfully
2024-05-24 16:09:15,856:INFO:Starting cross validation
2024-05-24 16:09:15,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:09:17,838:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e+07, tolerance: 6.191e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,854:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e+07, tolerance: 6.935e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,858:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+07, tolerance: 4.132e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,861:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.825e+07, tolerance: 5.231e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,895:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+07, tolerance: 6.426e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,909:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.976e+07, tolerance: 6.902e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,920:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+07, tolerance: 4.971e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,928:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+07, tolerance: 6.143e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:17,962:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.985e+07, tolerance: 7.022e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:18,016:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e+07, tolerance: 7.089e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:09:18,074:INFO:Calculating mean and std
2024-05-24 16:09:18,077:INFO:Creating metrics dataframe
2024-05-24 16:09:18,078:INFO:Uploading results into container
2024-05-24 16:09:18,079:INFO:Uploading model into container now
2024-05-24 16:09:18,079:INFO:_master_model_container: 2
2024-05-24 16:09:18,079:INFO:_display_container: 2
2024-05-24 16:09:18,079:INFO:Lasso(random_state=8799)
2024-05-24 16:09:18,080:INFO:create_model() successfully completed......................................
2024-05-24 16:09:18,283:INFO:SubProcess create_model() end ==================================
2024-05-24 16:09:18,283:INFO:Creating metrics dataframe
2024-05-24 16:09:18,293:INFO:Initializing Ridge Regression
2024-05-24 16:09:18,293:INFO:Total runtime is 0.08411603768666585 minutes
2024-05-24 16:09:18,297:INFO:SubProcess create_model() called ==================================
2024-05-24 16:09:18,298:INFO:Initializing create_model()
2024-05-24 16:09:18,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C8C62D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:09:18,298:INFO:Checking exceptions
2024-05-24 16:09:18,298:INFO:Importing libraries
2024-05-24 16:09:18,298:INFO:Copying training dataset
2024-05-24 16:09:18,307:INFO:Defining folds
2024-05-24 16:09:18,307:INFO:Declaring metric variables
2024-05-24 16:09:18,311:INFO:Importing untrained model
2024-05-24 16:09:18,316:INFO:Ridge Regression Imported successfully
2024-05-24 16:09:18,325:INFO:Starting cross validation
2024-05-24 16:09:18,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:09:20,065:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,145:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,151:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,169:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=4.88736e-18): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 16:09:20,224:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,250:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,253:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,254:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:09:20,343:INFO:Calculating mean and std
2024-05-24 16:09:20,345:INFO:Creating metrics dataframe
2024-05-24 16:09:20,349:INFO:Uploading results into container
2024-05-24 16:09:20,349:INFO:Uploading model into container now
2024-05-24 16:09:20,350:INFO:_master_model_container: 3
2024-05-24 16:09:20,350:INFO:_display_container: 2
2024-05-24 16:09:20,351:INFO:Ridge(random_state=8799)
2024-05-24 16:09:20,351:INFO:create_model() successfully completed......................................
2024-05-24 16:09:20,547:INFO:SubProcess create_model() end ==================================
2024-05-24 16:09:20,548:INFO:Creating metrics dataframe
2024-05-24 16:09:20,556:INFO:Initializing Huber Regressor
2024-05-24 16:09:20,556:INFO:Total runtime is 0.12184258302052817 minutes
2024-05-24 16:09:20,561:INFO:SubProcess create_model() called ==================================
2024-05-24 16:09:20,561:INFO:Initializing create_model()
2024-05-24 16:09:20,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C8C62D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:09:20,561:INFO:Checking exceptions
2024-05-24 16:09:20,562:INFO:Importing libraries
2024-05-24 16:09:20,562:INFO:Copying training dataset
2024-05-24 16:09:20,568:INFO:Defining folds
2024-05-24 16:09:20,568:INFO:Declaring metric variables
2024-05-24 16:09:20,573:INFO:Importing untrained model
2024-05-24 16:09:20,578:INFO:Huber Regressor Imported successfully
2024-05-24 16:09:20,586:INFO:Starting cross validation
2024-05-24 16:09:20,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:09:22,467:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:22,483:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:22,543:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:22,560:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:22,591:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:22,655:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:22,715:INFO:Calculating mean and std
2024-05-24 16:09:22,718:INFO:Creating metrics dataframe
2024-05-24 16:09:22,720:INFO:Uploading results into container
2024-05-24 16:09:22,721:INFO:Uploading model into container now
2024-05-24 16:09:22,722:INFO:_master_model_container: 4
2024-05-24 16:09:22,722:INFO:_display_container: 2
2024-05-24 16:09:22,722:INFO:HuberRegressor()
2024-05-24 16:09:22,722:INFO:create_model() successfully completed......................................
2024-05-24 16:09:22,939:INFO:SubProcess create_model() end ==================================
2024-05-24 16:09:22,939:INFO:Creating metrics dataframe
2024-05-24 16:09:22,950:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:09:22,963:INFO:Initializing create_model()
2024-05-24 16:09:22,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:09:22,963:INFO:Checking exceptions
2024-05-24 16:09:22,965:INFO:Importing libraries
2024-05-24 16:09:22,965:INFO:Copying training dataset
2024-05-24 16:09:22,973:INFO:Defining folds
2024-05-24 16:09:22,973:INFO:Declaring metric variables
2024-05-24 16:09:22,973:INFO:Importing untrained model
2024-05-24 16:09:22,973:INFO:Declaring custom model
2024-05-24 16:09:22,973:INFO:Huber Regressor Imported successfully
2024-05-24 16:09:22,996:INFO:Cross validation set to False
2024-05-24 16:09:22,997:INFO:Fitting Model
2024-05-24 16:09:24,068:INFO:HuberRegressor()
2024-05-24 16:09:24,068:INFO:create_model() successfully completed......................................
2024-05-24 16:09:24,289:INFO:_master_model_container: 4
2024-05-24 16:09:24,289:INFO:_display_container: 2
2024-05-24 16:09:24,289:INFO:HuberRegressor()
2024-05-24 16:09:24,290:INFO:compare_models() successfully completed......................................
2024-05-24 16:09:24,321:INFO:Initializing evaluate_model()
2024-05-24 16:09:24,321:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 16:09:24,333:INFO:Initializing plot_model()
2024-05-24 16:09:24,333:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, system=True)
2024-05-24 16:09:24,333:INFO:Checking exceptions
2024-05-24 16:09:24,337:INFO:Preloading libraries
2024-05-24 16:09:24,338:INFO:Copying training dataset
2024-05-24 16:09:24,338:INFO:Plot type: pipeline
2024-05-24 16:09:24,544:INFO:Visual Rendered Successfully
2024-05-24 16:09:24,751:INFO:plot_model() successfully completed......................................
2024-05-24 16:09:24,790:INFO:Initializing tune_model()
2024-05-24 16:09:24,791:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>)
2024-05-24 16:09:24,791:INFO:Checking exceptions
2024-05-24 16:09:24,815:INFO:Copying training dataset
2024-05-24 16:09:24,826:INFO:Checking base model
2024-05-24 16:09:24,826:INFO:Base model : Huber Regressor
2024-05-24 16:09:24,832:INFO:Declaring metric variables
2024-05-24 16:09:24,839:INFO:Defining Hyperparameters
2024-05-24 16:09:25,091:INFO:Tuning with n_jobs=-1
2024-05-24 16:09:25,091:INFO:Initializing RandomizedSearchCV
2024-05-24 16:09:27,309:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:27,413:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:27,450:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:27,695:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:27,749:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:27,795:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:29,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:29,719:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:29,936:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:32,176:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:32,369:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:32,570:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:32,613:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:34,246:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:34,394:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:34,443:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:34,529:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:34,690:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:35,024:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:35,476:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:35,608:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:36,774:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:36,980:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:37,217:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:37,321:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:37,340:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:37,447:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:38,288:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:39,402:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:39,732:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:40,213:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:40,565:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:41,289:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:41,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:42,508:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:42,781:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:43,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:44,233:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:44,341:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:44,425:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:45,429:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:45,547:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:45,948:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:46,051:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:46,271:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:46,344:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:46,420:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 1e-06}
2024-05-24 16:09:46,421:INFO:Hyperparameter search completed
2024-05-24 16:09:46,421:INFO:SubProcess create_model() called ==================================
2024-05-24 16:09:46,422:INFO:Initializing create_model()
2024-05-24 16:09:46,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221C6CFA140>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'epsilon': 1.4, 'alpha': 1e-06})
2024-05-24 16:09:46,422:INFO:Checking exceptions
2024-05-24 16:09:46,423:INFO:Importing libraries
2024-05-24 16:09:46,423:INFO:Copying training dataset
2024-05-24 16:09:46,431:INFO:Defining folds
2024-05-24 16:09:46,431:INFO:Declaring metric variables
2024-05-24 16:09:46,436:INFO:Importing untrained model
2024-05-24 16:09:46,436:INFO:Declaring custom model
2024-05-24 16:09:46,442:INFO:Huber Regressor Imported successfully
2024-05-24 16:09:46,451:INFO:Starting cross validation
2024-05-24 16:09:46,476:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:09:48,653:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:48,773:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:48,858:INFO:Calculating mean and std
2024-05-24 16:09:48,860:INFO:Creating metrics dataframe
2024-05-24 16:09:48,866:INFO:Finalizing model
2024-05-24 16:09:50,061:INFO:Uploading results into container
2024-05-24 16:09:50,062:INFO:Uploading model into container now
2024-05-24 16:09:50,063:INFO:_master_model_container: 5
2024-05-24 16:09:50,063:INFO:_display_container: 3
2024-05-24 16:09:50,063:INFO:HuberRegressor(alpha=1e-06, epsilon=1.4, fit_intercept=False)
2024-05-24 16:09:50,064:INFO:create_model() successfully completed......................................
2024-05-24 16:09:50,297:INFO:SubProcess create_model() end ==================================
2024-05-24 16:09:50,297:INFO:choose_better activated
2024-05-24 16:09:50,302:INFO:SubProcess create_model() called ==================================
2024-05-24 16:09:50,303:INFO:Initializing create_model()
2024-05-24 16:09:50,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000221C8C610F0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:09:50,303:INFO:Checking exceptions
2024-05-24 16:09:50,305:INFO:Importing libraries
2024-05-24 16:09:50,305:INFO:Copying training dataset
2024-05-24 16:09:50,312:INFO:Defining folds
2024-05-24 16:09:50,312:INFO:Declaring metric variables
2024-05-24 16:09:50,313:INFO:Importing untrained model
2024-05-24 16:09:50,313:INFO:Declaring custom model
2024-05-24 16:09:50,313:INFO:Huber Regressor Imported successfully
2024-05-24 16:09:50,313:INFO:Starting cross validation
2024-05-24 16:09:50,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:09:52,144:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:52,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:52,177:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:52,256:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:52,378:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:52,402:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:09:52,477:INFO:Calculating mean and std
2024-05-24 16:09:52,477:INFO:Creating metrics dataframe
2024-05-24 16:09:52,480:INFO:Finalizing model
2024-05-24 16:09:53,636:INFO:Uploading results into container
2024-05-24 16:09:53,637:INFO:Uploading model into container now
2024-05-24 16:09:53,637:INFO:_master_model_container: 6
2024-05-24 16:09:53,637:INFO:_display_container: 4
2024-05-24 16:09:53,637:INFO:HuberRegressor()
2024-05-24 16:09:53,637:INFO:create_model() successfully completed......................................
2024-05-24 16:09:53,829:INFO:SubProcess create_model() end ==================================
2024-05-24 16:09:53,830:INFO:HuberRegressor() result for R2 is 0.3625
2024-05-24 16:09:53,830:INFO:HuberRegressor(alpha=1e-06, epsilon=1.4, fit_intercept=False) result for R2 is 0.3926
2024-05-24 16:09:53,830:INFO:HuberRegressor(alpha=1e-06, epsilon=1.4, fit_intercept=False) is best model
2024-05-24 16:09:53,830:INFO:choose_better completed
2024-05-24 16:09:53,843:INFO:_master_model_container: 6
2024-05-24 16:09:53,843:INFO:_display_container: 3
2024-05-24 16:09:53,843:INFO:HuberRegressor(alpha=1e-06, epsilon=1.4, fit_intercept=False)
2024-05-24 16:09:53,844:INFO:tune_model() successfully completed......................................
2024-05-24 16:09:56,568:INFO:PyCaret RegressionExperiment
2024-05-24 16:09:56,569:INFO:Logging name: reg-default-name
2024-05-24 16:09:56,569:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:09:56,569:INFO:version 3.3.2
2024-05-24 16:09:56,569:INFO:Initializing setup()
2024-05-24 16:09:56,569:INFO:self.USI: 0cae
2024-05-24 16:09:56,569:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'logging_param', 'transform_target_param', 'fold_generator', 'data', 'y', '_available_plots', 'exp_name_log', 'pipeline', 'memory', 'X_train', 'n_jobs_param', 'X_test', 'log_plots_param', 'seed', 'gpu_param', 'X', 'fold_shuffle_param', 'html_param', 'idx', 'fold_groups_param', 'y_train', '_ml_usecase', 'y_test', 'exp_id', 'USI'}
2024-05-24 16:09:56,569:INFO:Checking environment
2024-05-24 16:09:56,569:INFO:python_version: 3.10.14
2024-05-24 16:09:56,569:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:09:56,569:INFO:machine: AMD64
2024-05-24 16:09:56,569:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:09:56,570:INFO:Memory: svmem(total=16541802496, available=3037552640, percent=81.6, used=13504249856, free=3037552640)
2024-05-24 16:09:56,570:INFO:Physical Core: 6
2024-05-24 16:09:56,570:INFO:Logical Core: 12
2024-05-24 16:09:56,570:INFO:Checking libraries
2024-05-24 16:09:56,570:INFO:System:
2024-05-24 16:09:56,570:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:09:56,570:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:09:56,570:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:09:56,570:INFO:PyCaret required dependencies:
2024-05-24 16:09:56,570:INFO:                 pip: 24.0
2024-05-24 16:09:56,570:INFO:          setuptools: 69.5.1
2024-05-24 16:09:56,570:INFO:             pycaret: 3.3.2
2024-05-24 16:09:56,570:INFO:             IPython: 8.20.0
2024-05-24 16:09:56,570:INFO:          ipywidgets: 8.1.2
2024-05-24 16:09:56,570:INFO:                tqdm: 4.66.4
2024-05-24 16:09:56,570:INFO:               numpy: 1.26.4
2024-05-24 16:09:56,570:INFO:              pandas: 2.1.4
2024-05-24 16:09:56,570:INFO:              jinja2: 3.1.3
2024-05-24 16:09:56,571:INFO:               scipy: 1.11.4
2024-05-24 16:09:56,571:INFO:              joblib: 1.3.2
2024-05-24 16:09:56,571:INFO:             sklearn: 1.4.2
2024-05-24 16:09:56,571:INFO:                pyod: 1.1.3
2024-05-24 16:09:56,571:INFO:            imblearn: 0.12.2
2024-05-24 16:09:56,571:INFO:   category_encoders: 2.6.3
2024-05-24 16:09:56,571:INFO:            lightgbm: 4.3.0
2024-05-24 16:09:56,571:INFO:               numba: 0.59.1
2024-05-24 16:09:56,571:INFO:            requests: 2.32.2
2024-05-24 16:09:56,571:INFO:          matplotlib: 3.7.5
2024-05-24 16:09:56,571:INFO:          scikitplot: 0.3.7
2024-05-24 16:09:56,571:INFO:         yellowbrick: 1.5
2024-05-24 16:09:56,571:INFO:              plotly: 5.22.0
2024-05-24 16:09:56,571:INFO:    plotly-resampler: Not installed
2024-05-24 16:09:56,571:INFO:             kaleido: 0.2.1
2024-05-24 16:09:56,571:INFO:           schemdraw: 0.15
2024-05-24 16:09:56,571:INFO:         statsmodels: 0.14.2
2024-05-24 16:09:56,571:INFO:              sktime: 0.26.0
2024-05-24 16:09:56,571:INFO:               tbats: 1.1.3
2024-05-24 16:09:56,571:INFO:            pmdarima: 2.0.4
2024-05-24 16:09:56,571:INFO:              psutil: 5.9.0
2024-05-24 16:09:56,571:INFO:          markupsafe: 2.1.3
2024-05-24 16:09:56,571:INFO:             pickle5: Not installed
2024-05-24 16:09:56,571:INFO:         cloudpickle: 3.0.0
2024-05-24 16:09:56,571:INFO:         deprecation: 2.1.0
2024-05-24 16:09:56,572:INFO:              xxhash: 3.4.1
2024-05-24 16:09:56,572:INFO:           wurlitzer: Not installed
2024-05-24 16:09:56,572:INFO:PyCaret optional dependencies:
2024-05-24 16:09:56,572:INFO:                shap: Not installed
2024-05-24 16:09:56,572:INFO:           interpret: Not installed
2024-05-24 16:09:56,572:INFO:                umap: Not installed
2024-05-24 16:09:56,572:INFO:     ydata_profiling: Not installed
2024-05-24 16:09:56,572:INFO:  explainerdashboard: Not installed
2024-05-24 16:09:56,572:INFO:             autoviz: Not installed
2024-05-24 16:09:56,572:INFO:           fairlearn: Not installed
2024-05-24 16:09:56,572:INFO:          deepchecks: Not installed
2024-05-24 16:09:56,572:INFO:             xgboost: Not installed
2024-05-24 16:09:56,572:INFO:            catboost: Not installed
2024-05-24 16:09:56,572:INFO:              kmodes: Not installed
2024-05-24 16:09:56,572:INFO:             mlxtend: Not installed
2024-05-24 16:09:56,572:INFO:       statsforecast: Not installed
2024-05-24 16:09:56,572:INFO:        tune_sklearn: Not installed
2024-05-24 16:09:56,572:INFO:                 ray: Not installed
2024-05-24 16:09:56,572:INFO:            hyperopt: Not installed
2024-05-24 16:09:56,572:INFO:              optuna: Not installed
2024-05-24 16:09:56,572:INFO:               skopt: Not installed
2024-05-24 16:09:56,572:INFO:              mlflow: Not installed
2024-05-24 16:09:56,572:INFO:              gradio: Not installed
2024-05-24 16:09:56,572:INFO:             fastapi: Not installed
2024-05-24 16:09:56,573:INFO:             uvicorn: Not installed
2024-05-24 16:09:56,573:INFO:              m2cgen: Not installed
2024-05-24 16:09:56,573:INFO:           evidently: Not installed
2024-05-24 16:09:56,573:INFO:               fugue: Not installed
2024-05-24 16:09:56,573:INFO:           streamlit: Not installed
2024-05-24 16:09:56,573:INFO:             prophet: Not installed
2024-05-24 16:09:56,573:INFO:None
2024-05-24 16:09:56,573:INFO:Set up data.
2024-05-24 16:09:56,585:INFO:Set up folding strategy.
2024-05-24 16:09:56,585:INFO:Set up train/test split.
2024-05-24 16:09:56,592:INFO:Set up index.
2024-05-24 16:09:56,593:INFO:Assigning column types.
2024-05-24 16:09:56,598:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:09:56,599:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,603:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:56,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:56,719:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,724:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:56,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:56,843:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:09:56,848:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:56,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:56,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:09:56,974:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,086:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:09:57,099:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,231:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,340:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,342:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:09:57,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,460:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,581:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:09:57,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:09:57,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,841:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:09:57,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:57,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:58,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:58,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:09:58,096:INFO:Preparing preprocessing pipeline...
2024-05-24 16:09:58,096:INFO:Set up simple imputation.
2024-05-24 16:09:58,102:INFO:Set up encoding of ordinal features.
2024-05-24 16:09:58,110:INFO:Set up encoding of categorical features.
2024-05-24 16:09:58,111:INFO:Set up polynomial features.
2024-05-24 16:09:58,111:INFO:Set up removing multicollinearity.
2024-05-24 16:09:58,111:INFO:Set up removing outliers.
2024-05-24 16:11:12,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:11:12,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:11:12,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:11:12,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:11:12,536:INFO:PyCaret RegressionExperiment
2024-05-24 16:11:12,537:INFO:Logging name: reg-default-name
2024-05-24 16:11:12,537:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:11:12,537:INFO:version 3.3.2
2024-05-24 16:11:12,537:INFO:Initializing setup()
2024-05-24 16:11:12,537:INFO:self.USI: 7fa4
2024-05-24 16:11:12,537:INFO:self._variable_keys: {'X', 'y_test', 'exp_id', 'html_param', 'X_train', 'gpu_n_jobs_param', 'USI', 'n_jobs_param', 'data', 'fold_shuffle_param', 'transform_target_param', 'target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'y', 'seed', 'y_train', 'memory', 'fold_generator', '_available_plots', 'idx', '_ml_usecase', 'X_test', 'logging_param', 'pipeline', 'exp_name_log'}
2024-05-24 16:11:12,537:INFO:Checking environment
2024-05-24 16:11:12,537:INFO:python_version: 3.10.14
2024-05-24 16:11:12,537:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:11:12,537:INFO:machine: AMD64
2024-05-24 16:11:12,537:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:11:12,537:INFO:Memory: svmem(total=16541802496, available=5297475584, percent=68.0, used=11244326912, free=5297475584)
2024-05-24 16:11:12,537:INFO:Physical Core: 6
2024-05-24 16:11:12,537:INFO:Logical Core: 12
2024-05-24 16:11:12,537:INFO:Checking libraries
2024-05-24 16:11:12,537:INFO:System:
2024-05-24 16:11:12,537:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:11:12,537:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:11:12,537:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:11:12,537:INFO:PyCaret required dependencies:
2024-05-24 16:11:12,566:INFO:                 pip: 24.0
2024-05-24 16:11:12,567:INFO:          setuptools: 69.5.1
2024-05-24 16:11:12,567:INFO:             pycaret: 3.3.2
2024-05-24 16:11:12,567:INFO:             IPython: 8.20.0
2024-05-24 16:11:12,567:INFO:          ipywidgets: 8.1.2
2024-05-24 16:11:12,567:INFO:                tqdm: 4.66.4
2024-05-24 16:11:12,567:INFO:               numpy: 1.26.4
2024-05-24 16:11:12,567:INFO:              pandas: 2.1.4
2024-05-24 16:11:12,567:INFO:              jinja2: 3.1.3
2024-05-24 16:11:12,567:INFO:               scipy: 1.11.4
2024-05-24 16:11:12,567:INFO:              joblib: 1.3.2
2024-05-24 16:11:12,567:INFO:             sklearn: 1.4.2
2024-05-24 16:11:12,567:INFO:                pyod: 1.1.3
2024-05-24 16:11:12,567:INFO:            imblearn: 0.12.2
2024-05-24 16:11:12,567:INFO:   category_encoders: 2.6.3
2024-05-24 16:11:12,567:INFO:            lightgbm: 4.3.0
2024-05-24 16:11:12,567:INFO:               numba: 0.59.1
2024-05-24 16:11:12,567:INFO:            requests: 2.32.2
2024-05-24 16:11:12,567:INFO:          matplotlib: 3.7.5
2024-05-24 16:11:12,567:INFO:          scikitplot: 0.3.7
2024-05-24 16:11:12,567:INFO:         yellowbrick: 1.5
2024-05-24 16:11:12,567:INFO:              plotly: 5.22.0
2024-05-24 16:11:12,567:INFO:    plotly-resampler: Not installed
2024-05-24 16:11:12,568:INFO:             kaleido: 0.2.1
2024-05-24 16:11:12,568:INFO:           schemdraw: 0.15
2024-05-24 16:11:12,568:INFO:         statsmodels: 0.14.2
2024-05-24 16:11:12,568:INFO:              sktime: 0.26.0
2024-05-24 16:11:12,568:INFO:               tbats: 1.1.3
2024-05-24 16:11:12,568:INFO:            pmdarima: 2.0.4
2024-05-24 16:11:12,568:INFO:              psutil: 5.9.0
2024-05-24 16:11:12,568:INFO:          markupsafe: 2.1.3
2024-05-24 16:11:12,568:INFO:             pickle5: Not installed
2024-05-24 16:11:12,568:INFO:         cloudpickle: 3.0.0
2024-05-24 16:11:12,568:INFO:         deprecation: 2.1.0
2024-05-24 16:11:12,568:INFO:              xxhash: 3.4.1
2024-05-24 16:11:12,568:INFO:           wurlitzer: Not installed
2024-05-24 16:11:12,568:INFO:PyCaret optional dependencies:
2024-05-24 16:11:12,584:INFO:                shap: Not installed
2024-05-24 16:11:12,584:INFO:           interpret: Not installed
2024-05-24 16:11:12,584:INFO:                umap: Not installed
2024-05-24 16:11:12,584:INFO:     ydata_profiling: Not installed
2024-05-24 16:11:12,584:INFO:  explainerdashboard: Not installed
2024-05-24 16:11:12,584:INFO:             autoviz: Not installed
2024-05-24 16:11:12,584:INFO:           fairlearn: Not installed
2024-05-24 16:11:12,584:INFO:          deepchecks: Not installed
2024-05-24 16:11:12,584:INFO:             xgboost: Not installed
2024-05-24 16:11:12,584:INFO:            catboost: Not installed
2024-05-24 16:11:12,584:INFO:              kmodes: Not installed
2024-05-24 16:11:12,584:INFO:             mlxtend: Not installed
2024-05-24 16:11:12,584:INFO:       statsforecast: Not installed
2024-05-24 16:11:12,584:INFO:        tune_sklearn: Not installed
2024-05-24 16:11:12,584:INFO:                 ray: Not installed
2024-05-24 16:11:12,584:INFO:            hyperopt: Not installed
2024-05-24 16:11:12,585:INFO:              optuna: Not installed
2024-05-24 16:11:12,585:INFO:               skopt: Not installed
2024-05-24 16:11:12,585:INFO:              mlflow: Not installed
2024-05-24 16:11:12,585:INFO:              gradio: Not installed
2024-05-24 16:11:12,585:INFO:             fastapi: Not installed
2024-05-24 16:11:12,585:INFO:             uvicorn: Not installed
2024-05-24 16:11:12,585:INFO:              m2cgen: Not installed
2024-05-24 16:11:12,585:INFO:           evidently: Not installed
2024-05-24 16:11:12,585:INFO:               fugue: Not installed
2024-05-24 16:11:12,585:INFO:           streamlit: Not installed
2024-05-24 16:11:12,585:INFO:             prophet: Not installed
2024-05-24 16:11:12,585:INFO:None
2024-05-24 16:11:12,585:INFO:Set up data.
2024-05-24 16:11:12,595:INFO:Set up folding strategy.
2024-05-24 16:11:12,595:INFO:Set up train/test split.
2024-05-24 16:11:12,604:INFO:Set up index.
2024-05-24 16:11:12,605:INFO:Assigning column types.
2024-05-24 16:11:12,609:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:11:12,610:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,615:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,620:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,738:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:12,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:12,740:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,744:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,750:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,811:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:12,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:12,858:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:11:12,863:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,867:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,928:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:12,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:12,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,065:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,070:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,177:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:11:13,188:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,305:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,412:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,413:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:11:13,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,674:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,675:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:11:13,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:11:13,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:13,917:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:11:14,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:14,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:14,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:14,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:11:14,148:INFO:Preparing preprocessing pipeline...
2024-05-24 16:11:14,148:INFO:Set up simple imputation.
2024-05-24 16:11:14,152:INFO:Set up encoding of ordinal features.
2024-05-24 16:11:14,158:INFO:Set up encoding of categorical features.
2024-05-24 16:11:14,158:INFO:Set up polynomial features.
2024-05-24 16:11:14,158:INFO:Set up removing multicollinearity.
2024-05-24 16:11:14,158:INFO:Set up removing outliers.
2024-05-24 16:12:58,455:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py:249: UserWarning: Persisting input arguments took 6.01s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2024-05-24 16:13:03,974:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:13:04,028:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(degree=3,
                                                                   include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=3886)))])
2024-05-24 16:13:04,028:INFO:Creating final display dataframe.
2024-05-24 16:13:19,889:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py:289: UserWarning: Persisting input arguments took 5.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-05-24 16:13:40,968:INFO:PyCaret RegressionExperiment
2024-05-24 16:13:40,969:INFO:Logging name: reg-default-name
2024-05-24 16:13:40,969:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:13:40,969:INFO:version 3.3.2
2024-05-24 16:13:40,969:INFO:Initializing setup()
2024-05-24 16:13:40,969:INFO:self.USI: 9e60
2024-05-24 16:13:40,969:INFO:self._variable_keys: {'X', 'y_test', 'exp_id', 'html_param', 'X_train', 'gpu_n_jobs_param', 'USI', 'n_jobs_param', 'data', 'fold_shuffle_param', 'transform_target_param', 'target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'y', 'seed', 'y_train', 'memory', 'fold_generator', '_available_plots', 'idx', '_ml_usecase', 'X_test', 'logging_param', 'pipeline', 'exp_name_log'}
2024-05-24 16:13:40,969:INFO:Checking environment
2024-05-24 16:13:40,969:INFO:python_version: 3.10.14
2024-05-24 16:13:40,969:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:13:40,969:INFO:machine: AMD64
2024-05-24 16:13:40,969:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:13:40,970:INFO:Memory: svmem(total=16541802496, available=5286682624, percent=68.0, used=11255119872, free=5286682624)
2024-05-24 16:13:40,970:INFO:Physical Core: 6
2024-05-24 16:13:40,970:INFO:Logical Core: 12
2024-05-24 16:13:40,970:INFO:Checking libraries
2024-05-24 16:13:40,970:INFO:System:
2024-05-24 16:13:40,970:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:13:40,970:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:13:40,970:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:13:40,970:INFO:PyCaret required dependencies:
2024-05-24 16:13:40,970:INFO:                 pip: 24.0
2024-05-24 16:13:40,970:INFO:          setuptools: 69.5.1
2024-05-24 16:13:40,970:INFO:             pycaret: 3.3.2
2024-05-24 16:13:40,971:INFO:             IPython: 8.20.0
2024-05-24 16:13:40,971:INFO:          ipywidgets: 8.1.2
2024-05-24 16:13:40,971:INFO:                tqdm: 4.66.4
2024-05-24 16:13:40,971:INFO:               numpy: 1.26.4
2024-05-24 16:13:40,971:INFO:              pandas: 2.1.4
2024-05-24 16:13:40,971:INFO:              jinja2: 3.1.3
2024-05-24 16:13:40,971:INFO:               scipy: 1.11.4
2024-05-24 16:13:40,971:INFO:              joblib: 1.3.2
2024-05-24 16:13:40,971:INFO:             sklearn: 1.4.2
2024-05-24 16:13:40,971:INFO:                pyod: 1.1.3
2024-05-24 16:13:40,971:INFO:            imblearn: 0.12.2
2024-05-24 16:13:40,971:INFO:   category_encoders: 2.6.3
2024-05-24 16:13:40,971:INFO:            lightgbm: 4.3.0
2024-05-24 16:13:40,971:INFO:               numba: 0.59.1
2024-05-24 16:13:40,971:INFO:            requests: 2.32.2
2024-05-24 16:13:40,971:INFO:          matplotlib: 3.7.5
2024-05-24 16:13:40,971:INFO:          scikitplot: 0.3.7
2024-05-24 16:13:40,971:INFO:         yellowbrick: 1.5
2024-05-24 16:13:40,972:INFO:              plotly: 5.22.0
2024-05-24 16:13:40,972:INFO:    plotly-resampler: Not installed
2024-05-24 16:13:40,972:INFO:             kaleido: 0.2.1
2024-05-24 16:13:40,972:INFO:           schemdraw: 0.15
2024-05-24 16:13:40,972:INFO:         statsmodels: 0.14.2
2024-05-24 16:13:40,972:INFO:              sktime: 0.26.0
2024-05-24 16:13:40,972:INFO:               tbats: 1.1.3
2024-05-24 16:13:40,972:INFO:            pmdarima: 2.0.4
2024-05-24 16:13:40,972:INFO:              psutil: 5.9.0
2024-05-24 16:13:40,972:INFO:          markupsafe: 2.1.3
2024-05-24 16:13:40,972:INFO:             pickle5: Not installed
2024-05-24 16:13:40,972:INFO:         cloudpickle: 3.0.0
2024-05-24 16:13:40,972:INFO:         deprecation: 2.1.0
2024-05-24 16:13:40,972:INFO:              xxhash: 3.4.1
2024-05-24 16:13:40,972:INFO:           wurlitzer: Not installed
2024-05-24 16:13:40,972:INFO:PyCaret optional dependencies:
2024-05-24 16:13:40,973:INFO:                shap: Not installed
2024-05-24 16:13:40,973:INFO:           interpret: Not installed
2024-05-24 16:13:40,973:INFO:                umap: Not installed
2024-05-24 16:13:40,973:INFO:     ydata_profiling: Not installed
2024-05-24 16:13:40,973:INFO:  explainerdashboard: Not installed
2024-05-24 16:13:40,973:INFO:             autoviz: Not installed
2024-05-24 16:13:40,973:INFO:           fairlearn: Not installed
2024-05-24 16:13:40,973:INFO:          deepchecks: Not installed
2024-05-24 16:13:40,973:INFO:             xgboost: Not installed
2024-05-24 16:13:40,973:INFO:            catboost: Not installed
2024-05-24 16:13:40,973:INFO:              kmodes: Not installed
2024-05-24 16:13:40,973:INFO:             mlxtend: Not installed
2024-05-24 16:13:40,973:INFO:       statsforecast: Not installed
2024-05-24 16:13:40,973:INFO:        tune_sklearn: Not installed
2024-05-24 16:13:40,973:INFO:                 ray: Not installed
2024-05-24 16:13:40,973:INFO:            hyperopt: Not installed
2024-05-24 16:13:40,973:INFO:              optuna: Not installed
2024-05-24 16:13:40,973:INFO:               skopt: Not installed
2024-05-24 16:13:40,974:INFO:              mlflow: Not installed
2024-05-24 16:13:40,974:INFO:              gradio: Not installed
2024-05-24 16:13:40,974:INFO:             fastapi: Not installed
2024-05-24 16:13:40,974:INFO:             uvicorn: Not installed
2024-05-24 16:13:40,974:INFO:              m2cgen: Not installed
2024-05-24 16:13:40,974:INFO:           evidently: Not installed
2024-05-24 16:13:40,974:INFO:               fugue: Not installed
2024-05-24 16:13:40,974:INFO:           streamlit: Not installed
2024-05-24 16:13:40,974:INFO:             prophet: Not installed
2024-05-24 16:13:40,974:INFO:None
2024-05-24 16:13:40,974:INFO:Set up data.
2024-05-24 16:13:40,989:INFO:Set up folding strategy.
2024-05-24 16:13:40,989:INFO:Set up train/test split.
2024-05-24 16:13:40,998:INFO:Set up index.
2024-05-24 16:13:40,999:INFO:Assigning column types.
2024-05-24 16:13:41,006:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:13:41,006:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,013:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,020:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,086:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,134:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,146:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,264:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:13:41,269:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,382:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,389:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,393:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,503:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:13:41,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,633:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,744:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:13:41,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,862:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:13:41,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:41,986:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:13:42,059:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:42,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:13:42,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,226:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:13:42,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:42,465:INFO:Preparing preprocessing pipeline...
2024-05-24 16:13:42,465:INFO:Set up simple imputation.
2024-05-24 16:13:42,470:INFO:Set up encoding of ordinal features.
2024-05-24 16:13:42,477:INFO:Set up encoding of categorical features.
2024-05-24 16:13:42,477:INFO:Set up polynomial features.
2024-05-24 16:13:42,477:INFO:Set up removing multicollinearity.
2024-05-24 16:13:42,478:INFO:Set up removing outliers.
2024-05-24 16:13:43,723:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:13:43,790:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=7106)))])
2024-05-24 16:13:43,790:INFO:Creating final display dataframe.
2024-05-24 16:13:46,093:INFO:Setup _display_container:                     Description             Value
0                    Session id              7106
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 483)
5   Transformed train set shape        (135, 483)
6    Transformed test set shape         (62, 483)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              9e60
2024-05-24 16:13:46,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:46,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:46,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:46,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:13:46,343:INFO:setup() successfully completed in 5.4s...............
2024-05-24 16:13:46,372:INFO:Initializing compare_models()
2024-05-24 16:13:46,372:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:13:46,372:INFO:Checking exceptions
2024-05-24 16:13:46,375:INFO:Preparing display monitor
2024-05-24 16:13:46,403:INFO:Initializing Linear Regression
2024-05-24 16:13:46,403:INFO:Total runtime is 0.0 minutes
2024-05-24 16:13:46,407:INFO:SubProcess create_model() called ==================================
2024-05-24 16:13:46,407:INFO:Initializing create_model()
2024-05-24 16:13:46,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB92EA9B40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:13:46,408:INFO:Checking exceptions
2024-05-24 16:13:46,408:INFO:Importing libraries
2024-05-24 16:13:46,408:INFO:Copying training dataset
2024-05-24 16:13:46,416:INFO:Defining folds
2024-05-24 16:13:46,416:INFO:Declaring metric variables
2024-05-24 16:13:46,419:INFO:Importing untrained model
2024-05-24 16:13:46,429:INFO:Linear Regression Imported successfully
2024-05-24 16:13:46,438:INFO:Starting cross validation
2024-05-24 16:13:46,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:13:52,744:INFO:Calculating mean and std
2024-05-24 16:13:52,745:INFO:Creating metrics dataframe
2024-05-24 16:13:52,748:INFO:Uploading results into container
2024-05-24 16:13:52,749:INFO:Uploading model into container now
2024-05-24 16:13:52,750:INFO:_master_model_container: 1
2024-05-24 16:13:52,750:INFO:_display_container: 2
2024-05-24 16:13:52,750:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:13:52,751:INFO:create_model() successfully completed......................................
2024-05-24 16:13:52,897:INFO:SubProcess create_model() end ==================================
2024-05-24 16:13:52,897:INFO:Creating metrics dataframe
2024-05-24 16:13:52,905:INFO:Initializing Lasso Regression
2024-05-24 16:13:52,905:INFO:Total runtime is 0.10836048523585001 minutes
2024-05-24 16:13:52,911:INFO:SubProcess create_model() called ==================================
2024-05-24 16:13:52,912:INFO:Initializing create_model()
2024-05-24 16:13:52,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB92EA9B40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:13:52,912:INFO:Checking exceptions
2024-05-24 16:13:52,912:INFO:Importing libraries
2024-05-24 16:13:52,913:INFO:Copying training dataset
2024-05-24 16:13:52,919:INFO:Defining folds
2024-05-24 16:13:52,920:INFO:Declaring metric variables
2024-05-24 16:13:52,924:INFO:Importing untrained model
2024-05-24 16:13:52,930:INFO:Lasso Regression Imported successfully
2024-05-24 16:13:52,938:INFO:Starting cross validation
2024-05-24 16:13:52,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:13:55,223:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,234:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.589e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,350:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,374:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,376:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,396:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,417:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:55,460:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:57,542:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:57,552:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:13:57,619:INFO:Calculating mean and std
2024-05-24 16:13:57,621:INFO:Creating metrics dataframe
2024-05-24 16:13:57,623:INFO:Uploading results into container
2024-05-24 16:13:57,624:INFO:Uploading model into container now
2024-05-24 16:13:57,625:INFO:_master_model_container: 2
2024-05-24 16:13:57,625:INFO:_display_container: 2
2024-05-24 16:13:57,625:INFO:Lasso(random_state=7106)
2024-05-24 16:13:57,625:INFO:create_model() successfully completed......................................
2024-05-24 16:13:57,756:INFO:SubProcess create_model() end ==================================
2024-05-24 16:13:57,756:INFO:Creating metrics dataframe
2024-05-24 16:13:57,767:INFO:Initializing Ridge Regression
2024-05-24 16:13:57,767:INFO:Total runtime is 0.1893980065981547 minutes
2024-05-24 16:13:57,771:INFO:SubProcess create_model() called ==================================
2024-05-24 16:13:57,772:INFO:Initializing create_model()
2024-05-24 16:13:57,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB92EA9B40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:13:57,772:INFO:Checking exceptions
2024-05-24 16:13:57,772:INFO:Importing libraries
2024-05-24 16:13:57,772:INFO:Copying training dataset
2024-05-24 16:13:57,781:INFO:Defining folds
2024-05-24 16:13:57,781:INFO:Declaring metric variables
2024-05-24 16:13:57,785:INFO:Importing untrained model
2024-05-24 16:13:57,790:INFO:Ridge Regression Imported successfully
2024-05-24 16:13:57,802:INFO:Starting cross validation
2024-05-24 16:13:57,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:13:59,880:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,895:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,916:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,920:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,937:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,941:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,942:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,969:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:13:59,997:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:14:00,051:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:14:00,138:INFO:Calculating mean and std
2024-05-24 16:14:00,140:INFO:Creating metrics dataframe
2024-05-24 16:14:00,144:INFO:Uploading results into container
2024-05-24 16:14:00,144:INFO:Uploading model into container now
2024-05-24 16:14:00,145:INFO:_master_model_container: 3
2024-05-24 16:14:00,145:INFO:_display_container: 2
2024-05-24 16:14:00,145:INFO:Ridge(random_state=7106)
2024-05-24 16:14:00,146:INFO:create_model() successfully completed......................................
2024-05-24 16:14:00,293:INFO:SubProcess create_model() end ==================================
2024-05-24 16:14:00,293:INFO:Creating metrics dataframe
2024-05-24 16:14:00,301:INFO:Initializing Huber Regressor
2024-05-24 16:14:00,301:INFO:Total runtime is 0.23162858486175536 minutes
2024-05-24 16:14:00,305:INFO:SubProcess create_model() called ==================================
2024-05-24 16:14:00,305:INFO:Initializing create_model()
2024-05-24 16:14:00,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB92EA9B40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:14:00,306:INFO:Checking exceptions
2024-05-24 16:14:00,306:INFO:Importing libraries
2024-05-24 16:14:00,306:INFO:Copying training dataset
2024-05-24 16:14:00,313:INFO:Defining folds
2024-05-24 16:14:00,314:INFO:Declaring metric variables
2024-05-24 16:14:00,318:INFO:Importing untrained model
2024-05-24 16:14:00,322:INFO:Huber Regressor Imported successfully
2024-05-24 16:14:00,332:INFO:Starting cross validation
2024-05-24 16:14:00,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:14:02,577:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:14:02,597:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:14:02,621:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:14:02,639:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:14:02,726:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:14:02,790:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:14:02,876:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 16:14:02,877:INFO:Calculating mean and std
2024-05-24 16:14:02,878:INFO:Creating metrics dataframe
2024-05-24 16:14:02,882:INFO:Uploading results into container
2024-05-24 16:14:02,882:INFO:Uploading model into container now
2024-05-24 16:14:02,882:INFO:_master_model_container: 4
2024-05-24 16:14:02,883:INFO:_display_container: 2
2024-05-24 16:14:02,883:INFO:HuberRegressor()
2024-05-24 16:14:02,883:INFO:create_model() successfully completed......................................
2024-05-24 16:14:03,011:INFO:SubProcess create_model() end ==================================
2024-05-24 16:14:03,012:INFO:Creating metrics dataframe
2024-05-24 16:14:03,030:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:14:03,040:INFO:Initializing create_model()
2024-05-24 16:14:03,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=Lasso(random_state=7106), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:14:03,041:INFO:Checking exceptions
2024-05-24 16:14:03,043:INFO:Importing libraries
2024-05-24 16:14:03,044:INFO:Copying training dataset
2024-05-24 16:14:03,052:INFO:Defining folds
2024-05-24 16:14:03,052:INFO:Declaring metric variables
2024-05-24 16:14:03,052:INFO:Importing untrained model
2024-05-24 16:14:03,052:INFO:Declaring custom model
2024-05-24 16:14:03,053:INFO:Lasso Regression Imported successfully
2024-05-24 16:14:03,072:INFO:Cross validation set to False
2024-05-24 16:14:03,073:INFO:Fitting Model
2024-05-24 16:14:04,388:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e+07, tolerance: 9.195e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:04,389:INFO:Lasso(random_state=7106)
2024-05-24 16:14:04,389:INFO:create_model() successfully completed......................................
2024-05-24 16:14:04,581:INFO:_master_model_container: 4
2024-05-24 16:14:04,581:INFO:_display_container: 2
2024-05-24 16:14:04,581:INFO:Lasso(random_state=7106)
2024-05-24 16:14:04,582:INFO:compare_models() successfully completed......................................
2024-05-24 16:14:04,632:INFO:Initializing evaluate_model()
2024-05-24 16:14:04,632:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=Lasso(random_state=7106), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 16:14:04,647:INFO:Initializing plot_model()
2024-05-24 16:14:04,647:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Lasso(random_state=7106), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, system=True)
2024-05-24 16:14:04,647:INFO:Checking exceptions
2024-05-24 16:14:04,651:INFO:Preloading libraries
2024-05-24 16:14:04,651:INFO:Copying training dataset
2024-05-24 16:14:04,651:INFO:Plot type: pipeline
2024-05-24 16:14:04,982:INFO:Visual Rendered Successfully
2024-05-24 16:14:05,133:INFO:plot_model() successfully completed......................................
2024-05-24 16:14:05,170:INFO:Initializing tune_model()
2024-05-24 16:14:05,170:INFO:tune_model(estimator=Lasso(random_state=7106), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>)
2024-05-24 16:14:05,170:INFO:Checking exceptions
2024-05-24 16:14:05,204:INFO:Copying training dataset
2024-05-24 16:14:05,213:INFO:Checking base model
2024-05-24 16:14:05,213:INFO:Base model : Lasso Regression
2024-05-24 16:14:05,218:INFO:Declaring metric variables
2024-05-24 16:14:05,224:INFO:Defining Hyperparameters
2024-05-24 16:14:05,418:INFO:Tuning with n_jobs=-1
2024-05-24 16:14:05,418:INFO:Initializing RandomizedSearchCV
2024-05-24 16:14:07,671:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.489e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,717:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.846e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,743:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,806:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.121e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,812:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.940e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,841:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,868:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.163e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:07,884:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.537e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:08,447:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.925e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:08,506:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.182e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:08,532:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.826e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:08,557:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.550e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:09,897:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:09,954:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,084:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.472e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,100:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.661e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,102:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,111:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.980e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,131:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.209e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,300:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,677:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.998e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,712:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,777:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.102e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:10,924:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.321e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:11,975:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,056:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.426e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,302:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.751e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,386:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.970e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,389:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.646e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,391:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.214e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,470:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,520:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,856:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.644e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:12,942:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.959e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:13,018:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.846e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:13,299:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.053e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:14,238:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.292e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:14,367:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.707e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:14,492:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:14,771:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:14,797:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:14,872:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.091e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:15,003:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.124e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:15,041:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:15,147:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:15,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:15,488:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.097e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:15,615:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:16,526:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:16,570:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:16,750:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,054:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.164e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,060:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,101:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.802e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,181:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,426:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.482e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,485:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.004e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,652:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.237e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,768:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:17,805:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.134e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:20,144:INFO:Initializing create_model()
2024-05-24 16:14:20,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=Lasso(random_state=7106), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:14:20,144:INFO:Checking exceptions
2024-05-24 16:14:20,163:INFO:Importing libraries
2024-05-24 16:14:20,163:INFO:Copying training dataset
2024-05-24 16:14:20,171:INFO:Defining folds
2024-05-24 16:14:20,171:INFO:Declaring metric variables
2024-05-24 16:14:20,175:INFO:Importing untrained model
2024-05-24 16:14:20,176:INFO:Declaring custom model
2024-05-24 16:14:20,181:INFO:Lasso Regression Imported successfully
2024-05-24 16:14:20,190:INFO:Starting cross validation
2024-05-24 16:14:20,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:14:25,849:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,865:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,871:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,898:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,902:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,930:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,948:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:25,965:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.589e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:26,018:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:26,094:INFO:Calculating mean and std
2024-05-24 16:14:26,096:INFO:Creating metrics dataframe
2024-05-24 16:14:26,105:INFO:Finalizing model
2024-05-24 16:14:27,089:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e+07, tolerance: 9.195e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:27,096:INFO:Uploading results into container
2024-05-24 16:14:27,097:INFO:Uploading model into container now
2024-05-24 16:14:27,109:INFO:_master_model_container: 5
2024-05-24 16:14:27,110:INFO:_display_container: 3
2024-05-24 16:14:27,110:INFO:Lasso(random_state=7106)
2024-05-24 16:14:27,110:INFO:create_model() successfully completed......................................
2024-05-24 16:14:32,060:INFO:Initializing tune_model()
2024-05-24 16:14:32,060:INFO:tune_model(estimator=Lasso(random_state=7106), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>)
2024-05-24 16:14:32,060:INFO:Checking exceptions
2024-05-24 16:14:32,085:INFO:Copying training dataset
2024-05-24 16:14:32,093:INFO:Checking base model
2024-05-24 16:14:32,093:INFO:Base model : Lasso Regression
2024-05-24 16:14:32,109:INFO:Declaring metric variables
2024-05-24 16:14:32,117:INFO:Defining Hyperparameters
2024-05-24 16:14:32,487:INFO:Tuning with n_jobs=-1
2024-05-24 16:14:32,488:INFO:Initializing RandomizedSearchCV
2024-05-24 16:14:34,761:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:34,789:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.489e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:34,930:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.925e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:34,971:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.121e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:35,035:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.550e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:35,035:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.940e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:35,085:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.537e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:35,273:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.826e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:35,324:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.182e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:35,492:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.163e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:36,946:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,000:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.661e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,017:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.980e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,133:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,180:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.472e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,195:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.757e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,416:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,458:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.209e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,486:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:37,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.998e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,098:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.102e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.321e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,267:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.846e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,323:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.751e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,347:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,414:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.426e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,503:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.214e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,599:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.646e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,868:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:39,902:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.970e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:40,718:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,385:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.644e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,435:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.846e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,551:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.959e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,657:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.053e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,784:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,850:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.292e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:41,886:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:42,125:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:42,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.091e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:42,207:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.707e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:42,414:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:43,079:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:43,665:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.124e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:43,708:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:43,839:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.097e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,077:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,187:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,209:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,296:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,480:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.802e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,653:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.164e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,690:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:44,888:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,019:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.482e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,020:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.004e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,028:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,095:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.237e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,422:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.701e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,435:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.134e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,670:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.629e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,811:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.513e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,815:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.638e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,868:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.670e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:46,932:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.837e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:47,322:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.219e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,139:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.058e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,230:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,259:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.772e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,555:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.982e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.330e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,769:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:48,820:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:49,152:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:49,487:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:49,582:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.310e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:49,649:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.664e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:50,571:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:50,713:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.384e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:50,742:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.152e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,021:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.763e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,088:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.979e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.059e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,469:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,520:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.744e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,693:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.690e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:51,862:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.456e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:52,585:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:52,643:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.643e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:53,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.375e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:53,168:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.578e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:53,303:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.318e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:53,644:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.466e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:53,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.577e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:53,741:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:54,119:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.769e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:54,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:54,249:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:54,318:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 6.39}
2024-05-24 16:14:54,319:INFO:Hyperparameter search completed
2024-05-24 16:14:54,319:INFO:SubProcess create_model() called ==================================
2024-05-24 16:14:54,320:INFO:Initializing create_model()
2024-05-24 16:14:54,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=Lasso(random_state=7106), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB9311EB60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 6.39})
2024-05-24 16:14:54,320:INFO:Checking exceptions
2024-05-24 16:14:54,320:INFO:Importing libraries
2024-05-24 16:14:54,320:INFO:Copying training dataset
2024-05-24 16:14:54,325:INFO:Defining folds
2024-05-24 16:14:54,325:INFO:Declaring metric variables
2024-05-24 16:14:54,331:INFO:Importing untrained model
2024-05-24 16:14:54,332:INFO:Declaring custom model
2024-05-24 16:14:54,335:INFO:Lasso Regression Imported successfully
2024-05-24 16:14:54,344:INFO:Starting cross validation
2024-05-24 16:14:54,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:14:56,469:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.466e+07, tolerance: 2.982e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,476:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.578e+07, tolerance: 2.939e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,502:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+07, tolerance: 3.143e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,509:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.318e+07, tolerance: 2.781e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,528:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.813e+07, tolerance: 3.110e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,547:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.577e+07, tolerance: 2.950e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e+07, tolerance: 2.935e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,598:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+07, tolerance: 2.803e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,619:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.769e+07, tolerance: 2.928e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,674:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.375e+07, tolerance: 2.946e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:56,732:INFO:Calculating mean and std
2024-05-24 16:14:56,733:INFO:Creating metrics dataframe
2024-05-24 16:14:56,740:INFO:Finalizing model
2024-05-24 16:14:57,841:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.751e+07, tolerance: 3.231e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:14:57,848:INFO:Uploading results into container
2024-05-24 16:14:57,848:INFO:Uploading model into container now
2024-05-24 16:14:57,849:INFO:_master_model_container: 6
2024-05-24 16:14:57,849:INFO:_display_container: 4
2024-05-24 16:14:57,849:INFO:Lasso(alpha=6.39, fit_intercept=False, random_state=7106)
2024-05-24 16:14:57,849:INFO:create_model() successfully completed......................................
2024-05-24 16:14:57,996:INFO:SubProcess create_model() end ==================================
2024-05-24 16:14:57,996:INFO:choose_better activated
2024-05-24 16:14:58,001:INFO:SubProcess create_model() called ==================================
2024-05-24 16:14:58,002:INFO:Initializing create_model()
2024-05-24 16:14:58,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB92CC8D00>, estimator=Lasso(random_state=7106), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:14:58,002:INFO:Checking exceptions
2024-05-24 16:14:58,004:INFO:Importing libraries
2024-05-24 16:14:58,004:INFO:Copying training dataset
2024-05-24 16:14:58,009:INFO:Defining folds
2024-05-24 16:14:58,009:INFO:Declaring metric variables
2024-05-24 16:14:58,010:INFO:Importing untrained model
2024-05-24 16:14:58,010:INFO:Declaring custom model
2024-05-24 16:14:58,010:INFO:Lasso Regression Imported successfully
2024-05-24 16:14:58,012:INFO:Starting cross validation
2024-05-24 16:14:58,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:15:00,174:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+07, tolerance: 8.405e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,256:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+07, tolerance: 7.636e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,260:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+07, tolerance: 7.488e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,293:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e+07, tolerance: 8.852e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,316:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+07, tolerance: 8.305e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+07, tolerance: 8.328e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,363:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+07, tolerance: 8.963e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,389:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.589e+07, tolerance: 8.176e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,398:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+07, tolerance: 8.491e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,454:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.488e+07, tolerance: 9.030e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:00,518:INFO:Calculating mean and std
2024-05-24 16:15:00,518:INFO:Creating metrics dataframe
2024-05-24 16:15:00,520:INFO:Finalizing model
2024-05-24 16:15:01,772:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e+07, tolerance: 9.195e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:01,773:INFO:Uploading results into container
2024-05-24 16:15:01,773:INFO:Uploading model into container now
2024-05-24 16:15:01,773:INFO:_master_model_container: 7
2024-05-24 16:15:01,773:INFO:_display_container: 5
2024-05-24 16:15:01,774:INFO:Lasso(random_state=7106)
2024-05-24 16:15:01,774:INFO:create_model() successfully completed......................................
2024-05-24 16:15:01,933:INFO:SubProcess create_model() end ==================================
2024-05-24 16:15:01,933:INFO:Lasso(random_state=7106) result for R2 is 0.3161
2024-05-24 16:15:01,934:INFO:Lasso(alpha=6.39, fit_intercept=False, random_state=7106) result for R2 is 0.719
2024-05-24 16:15:01,934:INFO:Lasso(alpha=6.39, fit_intercept=False, random_state=7106) is best model
2024-05-24 16:15:01,934:INFO:choose_better completed
2024-05-24 16:15:01,944:INFO:_master_model_container: 7
2024-05-24 16:15:01,945:INFO:_display_container: 4
2024-05-24 16:15:01,945:INFO:Lasso(alpha=6.39, fit_intercept=False, random_state=7106)
2024-05-24 16:15:01,946:INFO:tune_model() successfully completed......................................
2024-05-24 16:15:17,397:INFO:PyCaret RegressionExperiment
2024-05-24 16:15:17,397:INFO:Logging name: reg-default-name
2024-05-24 16:15:17,397:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:15:17,397:INFO:version 3.3.2
2024-05-24 16:15:17,397:INFO:Initializing setup()
2024-05-24 16:15:17,397:INFO:self.USI: 152d
2024-05-24 16:15:17,397:INFO:self._variable_keys: {'X', 'y_test', 'exp_id', 'html_param', 'X_train', 'gpu_n_jobs_param', 'USI', 'n_jobs_param', 'data', 'fold_shuffle_param', 'transform_target_param', 'target_param', 'log_plots_param', 'fold_groups_param', 'gpu_param', 'y', 'seed', 'y_train', 'memory', 'fold_generator', '_available_plots', 'idx', '_ml_usecase', 'X_test', 'logging_param', 'pipeline', 'exp_name_log'}
2024-05-24 16:15:17,397:INFO:Checking environment
2024-05-24 16:15:17,397:INFO:python_version: 3.10.14
2024-05-24 16:15:17,397:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:15:17,397:INFO:machine: AMD64
2024-05-24 16:15:17,397:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:15:17,398:INFO:Memory: svmem(total=16541802496, available=3545374720, percent=78.6, used=12996427776, free=3545374720)
2024-05-24 16:15:17,398:INFO:Physical Core: 6
2024-05-24 16:15:17,398:INFO:Logical Core: 12
2024-05-24 16:15:17,398:INFO:Checking libraries
2024-05-24 16:15:17,398:INFO:System:
2024-05-24 16:15:17,398:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:15:17,398:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:15:17,398:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:15:17,398:INFO:PyCaret required dependencies:
2024-05-24 16:15:17,398:INFO:                 pip: 24.0
2024-05-24 16:15:17,398:INFO:          setuptools: 69.5.1
2024-05-24 16:15:17,398:INFO:             pycaret: 3.3.2
2024-05-24 16:15:17,398:INFO:             IPython: 8.20.0
2024-05-24 16:15:17,398:INFO:          ipywidgets: 8.1.2
2024-05-24 16:15:17,398:INFO:                tqdm: 4.66.4
2024-05-24 16:15:17,398:INFO:               numpy: 1.26.4
2024-05-24 16:15:17,398:INFO:              pandas: 2.1.4
2024-05-24 16:15:17,398:INFO:              jinja2: 3.1.3
2024-05-24 16:15:17,398:INFO:               scipy: 1.11.4
2024-05-24 16:15:17,399:INFO:              joblib: 1.3.2
2024-05-24 16:15:17,399:INFO:             sklearn: 1.4.2
2024-05-24 16:15:17,399:INFO:                pyod: 1.1.3
2024-05-24 16:15:17,399:INFO:            imblearn: 0.12.2
2024-05-24 16:15:17,399:INFO:   category_encoders: 2.6.3
2024-05-24 16:15:17,399:INFO:            lightgbm: 4.3.0
2024-05-24 16:15:17,399:INFO:               numba: 0.59.1
2024-05-24 16:15:17,399:INFO:            requests: 2.32.2
2024-05-24 16:15:17,399:INFO:          matplotlib: 3.7.5
2024-05-24 16:15:17,399:INFO:          scikitplot: 0.3.7
2024-05-24 16:15:17,399:INFO:         yellowbrick: 1.5
2024-05-24 16:15:17,399:INFO:              plotly: 5.22.0
2024-05-24 16:15:17,399:INFO:    plotly-resampler: Not installed
2024-05-24 16:15:17,399:INFO:             kaleido: 0.2.1
2024-05-24 16:15:17,399:INFO:           schemdraw: 0.15
2024-05-24 16:15:17,399:INFO:         statsmodels: 0.14.2
2024-05-24 16:15:17,399:INFO:              sktime: 0.26.0
2024-05-24 16:15:17,399:INFO:               tbats: 1.1.3
2024-05-24 16:15:17,399:INFO:            pmdarima: 2.0.4
2024-05-24 16:15:17,399:INFO:              psutil: 5.9.0
2024-05-24 16:15:17,399:INFO:          markupsafe: 2.1.3
2024-05-24 16:15:17,399:INFO:             pickle5: Not installed
2024-05-24 16:15:17,399:INFO:         cloudpickle: 3.0.0
2024-05-24 16:15:17,399:INFO:         deprecation: 2.1.0
2024-05-24 16:15:17,400:INFO:              xxhash: 3.4.1
2024-05-24 16:15:17,400:INFO:           wurlitzer: Not installed
2024-05-24 16:15:17,400:INFO:PyCaret optional dependencies:
2024-05-24 16:15:17,400:INFO:                shap: Not installed
2024-05-24 16:15:17,400:INFO:           interpret: Not installed
2024-05-24 16:15:17,400:INFO:                umap: Not installed
2024-05-24 16:15:17,400:INFO:     ydata_profiling: Not installed
2024-05-24 16:15:17,400:INFO:  explainerdashboard: Not installed
2024-05-24 16:15:17,400:INFO:             autoviz: Not installed
2024-05-24 16:15:17,400:INFO:           fairlearn: Not installed
2024-05-24 16:15:17,400:INFO:          deepchecks: Not installed
2024-05-24 16:15:17,400:INFO:             xgboost: Not installed
2024-05-24 16:15:17,400:INFO:            catboost: Not installed
2024-05-24 16:15:17,400:INFO:              kmodes: Not installed
2024-05-24 16:15:17,400:INFO:             mlxtend: Not installed
2024-05-24 16:15:17,400:INFO:       statsforecast: Not installed
2024-05-24 16:15:17,400:INFO:        tune_sklearn: Not installed
2024-05-24 16:15:17,400:INFO:                 ray: Not installed
2024-05-24 16:15:17,400:INFO:            hyperopt: Not installed
2024-05-24 16:15:17,400:INFO:              optuna: Not installed
2024-05-24 16:15:17,401:INFO:               skopt: Not installed
2024-05-24 16:15:17,401:INFO:              mlflow: Not installed
2024-05-24 16:15:17,401:INFO:              gradio: Not installed
2024-05-24 16:15:17,401:INFO:             fastapi: Not installed
2024-05-24 16:15:17,401:INFO:             uvicorn: Not installed
2024-05-24 16:15:17,401:INFO:              m2cgen: Not installed
2024-05-24 16:15:17,401:INFO:           evidently: Not installed
2024-05-24 16:15:17,401:INFO:               fugue: Not installed
2024-05-24 16:15:17,401:INFO:           streamlit: Not installed
2024-05-24 16:15:17,401:INFO:             prophet: Not installed
2024-05-24 16:15:17,401:INFO:None
2024-05-24 16:15:17,401:INFO:Set up data.
2024-05-24 16:15:17,412:INFO:Set up folding strategy.
2024-05-24 16:15:17,412:INFO:Set up train/test split.
2024-05-24 16:15:17,419:INFO:Set up index.
2024-05-24 16:15:17,419:INFO:Assigning column types.
2024-05-24 16:15:17,424:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:15:17,424:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,433:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,494:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,543:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,548:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,671:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:15:17,675:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,800:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,806:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:17,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:17,919:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:15:17,929:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,035:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,207:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:15:18,279:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,403:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,452:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:15:18,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:15:18,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,690:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:15:18,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:18,931:INFO:Preparing preprocessing pipeline...
2024-05-24 16:15:18,931:INFO:Set up simple imputation.
2024-05-24 16:15:18,936:INFO:Set up encoding of ordinal features.
2024-05-24 16:15:18,942:INFO:Set up encoding of categorical features.
2024-05-24 16:15:18,942:INFO:Set up polynomial features.
2024-05-24 16:15:18,942:INFO:Set up removing multicollinearity.
2024-05-24 16:15:18,942:INFO:Set up removing outliers.
2024-05-24 16:15:20,185:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:15:20,251:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=1232)))])
2024-05-24 16:15:20,251:INFO:Creating final display dataframe.
2024-05-24 16:15:22,618:INFO:Setup _display_container:                     Description             Value
0                    Session id              1232
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 444)
5   Transformed train set shape        (135, 444)
6    Transformed test set shape         (62, 444)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              152d
2024-05-24 16:15:22,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:22,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:22,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:22,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:15:22,866:INFO:setup() successfully completed in 5.49s...............
2024-05-24 16:15:22,892:INFO:Initializing compare_models()
2024-05-24 16:15:22,892:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:15:22,892:INFO:Checking exceptions
2024-05-24 16:15:22,896:INFO:Preparing display monitor
2024-05-24 16:15:22,924:INFO:Initializing Linear Regression
2024-05-24 16:15:22,924:INFO:Total runtime is 0.0 minutes
2024-05-24 16:15:22,929:INFO:SubProcess create_model() called ==================================
2024-05-24 16:15:22,929:INFO:Initializing create_model()
2024-05-24 16:15:22,930:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB9342BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:15:22,930:INFO:Checking exceptions
2024-05-24 16:15:22,930:INFO:Importing libraries
2024-05-24 16:15:22,930:INFO:Copying training dataset
2024-05-24 16:15:22,937:INFO:Defining folds
2024-05-24 16:15:22,938:INFO:Declaring metric variables
2024-05-24 16:15:22,942:INFO:Importing untrained model
2024-05-24 16:15:22,946:INFO:Linear Regression Imported successfully
2024-05-24 16:15:22,956:INFO:Starting cross validation
2024-05-24 16:15:22,986:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:15:25,055:INFO:Calculating mean and std
2024-05-24 16:15:25,057:INFO:Creating metrics dataframe
2024-05-24 16:15:25,060:INFO:Uploading results into container
2024-05-24 16:15:25,060:INFO:Uploading model into container now
2024-05-24 16:15:25,060:INFO:_master_model_container: 1
2024-05-24 16:15:25,060:INFO:_display_container: 2
2024-05-24 16:15:25,061:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:15:25,061:INFO:create_model() successfully completed......................................
2024-05-24 16:15:25,211:INFO:SubProcess create_model() end ==================================
2024-05-24 16:15:25,212:INFO:Creating metrics dataframe
2024-05-24 16:15:25,220:INFO:Initializing Lasso Regression
2024-05-24 16:15:25,220:INFO:Total runtime is 0.03825151125590007 minutes
2024-05-24 16:15:25,225:INFO:SubProcess create_model() called ==================================
2024-05-24 16:15:25,225:INFO:Initializing create_model()
2024-05-24 16:15:25,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB9342BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:15:25,225:INFO:Checking exceptions
2024-05-24 16:15:25,225:INFO:Importing libraries
2024-05-24 16:15:25,226:INFO:Copying training dataset
2024-05-24 16:15:25,236:INFO:Defining folds
2024-05-24 16:15:25,236:INFO:Declaring metric variables
2024-05-24 16:15:25,241:INFO:Importing untrained model
2024-05-24 16:15:25,245:INFO:Lasso Regression Imported successfully
2024-05-24 16:15:25,254:INFO:Starting cross validation
2024-05-24 16:15:25,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:15:27,128:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e+07, tolerance: 7.162e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,129:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e+07, tolerance: 5.604e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,130:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+07, tolerance: 5.537e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,140:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e+07, tolerance: 5.061e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+07, tolerance: 4.627e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,198:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+07, tolerance: 5.585e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,205:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e+07, tolerance: 7.080e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,208:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.926e+07, tolerance: 6.302e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,227:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+07, tolerance: 4.427e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,272:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+07, tolerance: 4.912e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 16:15:27,340:INFO:Calculating mean and std
2024-05-24 16:15:27,342:INFO:Creating metrics dataframe
2024-05-24 16:15:27,345:INFO:Uploading results into container
2024-05-24 16:15:27,345:INFO:Uploading model into container now
2024-05-24 16:15:27,346:INFO:_master_model_container: 2
2024-05-24 16:15:27,346:INFO:_display_container: 2
2024-05-24 16:15:27,346:INFO:Lasso(random_state=1232)
2024-05-24 16:15:27,347:INFO:create_model() successfully completed......................................
2024-05-24 16:15:27,496:INFO:SubProcess create_model() end ==================================
2024-05-24 16:15:27,497:INFO:Creating metrics dataframe
2024-05-24 16:15:27,506:INFO:Initializing Ridge Regression
2024-05-24 16:15:27,506:INFO:Total runtime is 0.07635821104049684 minutes
2024-05-24 16:15:27,511:INFO:SubProcess create_model() called ==================================
2024-05-24 16:15:27,511:INFO:Initializing create_model()
2024-05-24 16:15:27,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB9342BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:15:27,512:INFO:Checking exceptions
2024-05-24 16:15:27,512:INFO:Importing libraries
2024-05-24 16:15:27,512:INFO:Copying training dataset
2024-05-24 16:15:27,520:INFO:Defining folds
2024-05-24 16:15:27,520:INFO:Declaring metric variables
2024-05-24 16:15:27,525:INFO:Importing untrained model
2024-05-24 16:15:27,529:INFO:Ridge Regression Imported successfully
2024-05-24 16:15:27,538:INFO:Starting cross validation
2024-05-24 16:15:27,560:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:15:29,432:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,492:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,534:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,564:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,602:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,637:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,681:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,693:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,720:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 16:15:29,801:INFO:Calculating mean and std
2024-05-24 16:15:29,803:INFO:Creating metrics dataframe
2024-05-24 16:15:29,805:INFO:Uploading results into container
2024-05-24 16:15:29,805:INFO:Uploading model into container now
2024-05-24 16:15:29,806:INFO:_master_model_container: 3
2024-05-24 16:15:29,806:INFO:_display_container: 2
2024-05-24 16:15:29,806:INFO:Ridge(random_state=1232)
2024-05-24 16:15:29,806:INFO:create_model() successfully completed......................................
2024-05-24 16:15:29,954:INFO:SubProcess create_model() end ==================================
2024-05-24 16:15:29,954:INFO:Creating metrics dataframe
2024-05-24 16:15:29,962:INFO:Initializing Huber Regressor
2024-05-24 16:15:29,962:INFO:Total runtime is 0.11729491551717124 minutes
2024-05-24 16:15:29,967:INFO:SubProcess create_model() called ==================================
2024-05-24 16:15:29,967:INFO:Initializing create_model()
2024-05-24 16:15:29,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB9342BCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:15:29,968:INFO:Checking exceptions
2024-05-24 16:15:29,968:INFO:Importing libraries
2024-05-24 16:15:29,968:INFO:Copying training dataset
2024-05-24 16:15:29,976:INFO:Defining folds
2024-05-24 16:15:29,976:INFO:Declaring metric variables
2024-05-24 16:15:29,980:INFO:Importing untrained model
2024-05-24 16:15:29,985:INFO:Huber Regressor Imported successfully
2024-05-24 16:15:29,992:INFO:Starting cross validation
2024-05-24 16:15:30,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:15:32,064:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:32,108:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:32,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:32,214:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:32,233:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:32,297:INFO:Calculating mean and std
2024-05-24 16:15:32,299:INFO:Creating metrics dataframe
2024-05-24 16:15:32,301:INFO:Uploading results into container
2024-05-24 16:15:32,302:INFO:Uploading model into container now
2024-05-24 16:15:32,302:INFO:_master_model_container: 4
2024-05-24 16:15:32,302:INFO:_display_container: 2
2024-05-24 16:15:32,303:INFO:HuberRegressor()
2024-05-24 16:15:32,303:INFO:create_model() successfully completed......................................
2024-05-24 16:15:32,464:INFO:SubProcess create_model() end ==================================
2024-05-24 16:15:32,465:INFO:Creating metrics dataframe
2024-05-24 16:15:32,475:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:15:32,488:INFO:Initializing create_model()
2024-05-24 16:15:32,489:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:15:32,489:INFO:Checking exceptions
2024-05-24 16:15:32,492:INFO:Importing libraries
2024-05-24 16:15:32,492:INFO:Copying training dataset
2024-05-24 16:15:32,499:INFO:Defining folds
2024-05-24 16:15:32,499:INFO:Declaring metric variables
2024-05-24 16:15:32,499:INFO:Importing untrained model
2024-05-24 16:15:32,499:INFO:Declaring custom model
2024-05-24 16:15:32,500:INFO:Huber Regressor Imported successfully
2024-05-24 16:15:32,524:INFO:Cross validation set to False
2024-05-24 16:15:32,524:INFO:Fitting Model
2024-05-24 16:15:33,755:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:33,756:INFO:HuberRegressor()
2024-05-24 16:15:33,756:INFO:create_model() successfully completed......................................
2024-05-24 16:15:33,935:INFO:_master_model_container: 4
2024-05-24 16:15:33,935:INFO:_display_container: 2
2024-05-24 16:15:33,936:INFO:HuberRegressor()
2024-05-24 16:15:33,936:INFO:compare_models() successfully completed......................................
2024-05-24 16:15:41,147:INFO:Initializing create_model()
2024-05-24 16:15:41,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:15:41,148:INFO:Checking exceptions
2024-05-24 16:15:41,168:INFO:Importing libraries
2024-05-24 16:15:41,169:INFO:Copying training dataset
2024-05-24 16:15:41,180:INFO:Defining folds
2024-05-24 16:15:41,180:INFO:Declaring metric variables
2024-05-24 16:15:41,187:INFO:Importing untrained model
2024-05-24 16:15:41,187:INFO:Declaring custom model
2024-05-24 16:15:41,193:INFO:Huber Regressor Imported successfully
2024-05-24 16:15:41,204:INFO:Starting cross validation
2024-05-24 16:15:41,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:15:43,212:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:43,262:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:43,268:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:43,283:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:43,377:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:43,461:INFO:Calculating mean and std
2024-05-24 16:15:43,462:INFO:Creating metrics dataframe
2024-05-24 16:15:43,469:INFO:Finalizing model
2024-05-24 16:15:44,681:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:44,686:INFO:Uploading results into container
2024-05-24 16:15:44,687:INFO:Uploading model into container now
2024-05-24 16:15:44,699:INFO:_master_model_container: 5
2024-05-24 16:15:44,699:INFO:_display_container: 3
2024-05-24 16:15:44,700:INFO:HuberRegressor()
2024-05-24 16:15:44,700:INFO:create_model() successfully completed......................................
2024-05-24 16:15:52,061:INFO:Initializing tune_model()
2024-05-24 16:15:52,061:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>)
2024-05-24 16:15:52,061:INFO:Checking exceptions
2024-05-24 16:15:52,086:INFO:Copying training dataset
2024-05-24 16:15:52,092:INFO:Checking base model
2024-05-24 16:15:52,092:INFO:Base model : Huber Regressor
2024-05-24 16:15:52,099:INFO:Declaring metric variables
2024-05-24 16:15:52,105:INFO:Defining Hyperparameters
2024-05-24 16:15:52,523:INFO:Tuning with n_jobs=-1
2024-05-24 16:15:52,523:INFO:Initializing RandomizedSearchCV
2024-05-24 16:15:54,764:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:54,799:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:54,829:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:54,867:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:55,224:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:56,831:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:56,913:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:56,933:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:57,041:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:57,076:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:57,102:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:57,723:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:57,723:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:58,993:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:59,020:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:59,081:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:59,184:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:59,862:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:15:59,990:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:00,164:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:00,988:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:01,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:01,525:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:01,609:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:02,025:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:02,070:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:02,460:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:03,345:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:03,448:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:03,633:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:03,860:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:04,124:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:05,106:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:05,261:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:05,529:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:05,775:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:05,942:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:06,024:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:06,209:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:06,365:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:06,535:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:07,095:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:07,450:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:07,934:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:08,304:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:08,342:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:08,406:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:08,444:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:08,823:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:09,306:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:10,276:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:10,286:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:10,611:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:10,895:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:11,038:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:11,143:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:11,344:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:12,241:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:12,663:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:12,815:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:12,841:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:12,983:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:12,998:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:13,054:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:13,128:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:13,220:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.5, 'actual_estimator__alpha': 0.01}
2024-05-24 16:16:13,222:INFO:Hyperparameter search completed
2024-05-24 16:16:13,222:INFO:SubProcess create_model() called ==================================
2024-05-24 16:16:13,222:INFO:Initializing create_model()
2024-05-24 16:16:13,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB8E838E20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1.5, 'alpha': 0.01})
2024-05-24 16:16:13,222:INFO:Checking exceptions
2024-05-24 16:16:13,223:INFO:Importing libraries
2024-05-24 16:16:13,223:INFO:Copying training dataset
2024-05-24 16:16:13,230:INFO:Defining folds
2024-05-24 16:16:13,230:INFO:Declaring metric variables
2024-05-24 16:16:13,234:INFO:Importing untrained model
2024-05-24 16:16:13,234:INFO:Declaring custom model
2024-05-24 16:16:13,241:INFO:Huber Regressor Imported successfully
2024-05-24 16:16:13,251:INFO:Starting cross validation
2024-05-24 16:16:13,275:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:16:15,316:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:15,352:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:15,363:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:15,363:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:15,371:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:15,478:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:15,564:INFO:Calculating mean and std
2024-05-24 16:16:15,566:INFO:Creating metrics dataframe
2024-05-24 16:16:15,575:INFO:Finalizing model
2024-05-24 16:16:16,945:INFO:Uploading results into container
2024-05-24 16:16:16,946:INFO:Uploading model into container now
2024-05-24 16:16:16,947:INFO:_master_model_container: 6
2024-05-24 16:16:16,947:INFO:_display_container: 4
2024-05-24 16:16:16,947:INFO:HuberRegressor(alpha=0.01, epsilon=1.5)
2024-05-24 16:16:16,947:INFO:create_model() successfully completed......................................
2024-05-24 16:16:17,140:INFO:SubProcess create_model() end ==================================
2024-05-24 16:16:17,140:INFO:choose_better activated
2024-05-24 16:16:17,144:INFO:SubProcess create_model() called ==================================
2024-05-24 16:16:17,145:INFO:Initializing create_model()
2024-05-24 16:16:17,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:16:17,145:INFO:Checking exceptions
2024-05-24 16:16:17,147:INFO:Importing libraries
2024-05-24 16:16:17,147:INFO:Copying training dataset
2024-05-24 16:16:17,154:INFO:Defining folds
2024-05-24 16:16:17,154:INFO:Declaring metric variables
2024-05-24 16:16:17,154:INFO:Importing untrained model
2024-05-24 16:16:17,154:INFO:Declaring custom model
2024-05-24 16:16:17,155:INFO:Huber Regressor Imported successfully
2024-05-24 16:16:17,155:INFO:Starting cross validation
2024-05-24 16:16:17,177:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:16:19,141:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:19,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:19,259:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:19,274:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:19,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:19,408:INFO:Calculating mean and std
2024-05-24 16:16:19,409:INFO:Creating metrics dataframe
2024-05-24 16:16:19,411:INFO:Finalizing model
2024-05-24 16:16:20,641:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:20,642:INFO:Uploading results into container
2024-05-24 16:16:20,642:INFO:Uploading model into container now
2024-05-24 16:16:20,643:INFO:_master_model_container: 7
2024-05-24 16:16:20,643:INFO:_display_container: 5
2024-05-24 16:16:20,643:INFO:HuberRegressor()
2024-05-24 16:16:20,643:INFO:create_model() successfully completed......................................
2024-05-24 16:16:20,830:INFO:SubProcess create_model() end ==================================
2024-05-24 16:16:20,831:INFO:HuberRegressor() result for R2 is 0.4357
2024-05-24 16:16:20,831:INFO:HuberRegressor(alpha=0.01, epsilon=1.5) result for R2 is 0.4676
2024-05-24 16:16:20,831:INFO:HuberRegressor(alpha=0.01, epsilon=1.5) is best model
2024-05-24 16:16:20,832:INFO:choose_better completed
2024-05-24 16:16:20,844:INFO:_master_model_container: 7
2024-05-24 16:16:20,844:INFO:_display_container: 4
2024-05-24 16:16:20,844:INFO:HuberRegressor(alpha=0.01, epsilon=1.5)
2024-05-24 16:16:20,844:INFO:tune_model() successfully completed......................................
2024-05-24 16:16:35,162:INFO:Initializing create_model()
2024-05-24 16:16:35,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=4, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:16:35,163:INFO:Checking exceptions
2024-05-24 16:16:35,183:INFO:Importing libraries
2024-05-24 16:16:35,183:INFO:Copying training dataset
2024-05-24 16:16:35,194:INFO:Defining folds
2024-05-24 16:16:35,194:INFO:Declaring metric variables
2024-05-24 16:16:35,199:INFO:Importing untrained model
2024-05-24 16:16:35,199:INFO:Declaring custom model
2024-05-24 16:16:35,205:INFO:Huber Regressor Imported successfully
2024-05-24 16:16:35,217:INFO:Starting cross validation
2024-05-24 16:16:35,256:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:16:36,586:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:36,653:INFO:Calculating mean and std
2024-05-24 16:16:36,655:INFO:Creating metrics dataframe
2024-05-24 16:16:36,663:INFO:Finalizing model
2024-05-24 16:16:37,932:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:37,938:INFO:Uploading results into container
2024-05-24 16:16:37,939:INFO:Uploading model into container now
2024-05-24 16:16:37,950:INFO:_master_model_container: 8
2024-05-24 16:16:37,950:INFO:_display_container: 5
2024-05-24 16:16:37,950:INFO:HuberRegressor()
2024-05-24 16:16:37,951:INFO:create_model() successfully completed......................................
2024-05-24 16:16:53,964:INFO:Initializing create_model()
2024-05-24 16:16:53,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=7, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:16:53,964:INFO:Checking exceptions
2024-05-24 16:16:53,984:INFO:Importing libraries
2024-05-24 16:16:53,985:INFO:Copying training dataset
2024-05-24 16:16:53,994:INFO:Defining folds
2024-05-24 16:16:53,995:INFO:Declaring metric variables
2024-05-24 16:16:53,999:INFO:Importing untrained model
2024-05-24 16:16:54,000:INFO:Declaring custom model
2024-05-24 16:16:54,005:INFO:Huber Regressor Imported successfully
2024-05-24 16:16:54,019:INFO:Starting cross validation
2024-05-24 16:16:54,047:INFO:Cross validating with KFold(n_splits=7, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:16:55,674:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:55,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:55,819:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:55,897:INFO:Calculating mean and std
2024-05-24 16:16:55,899:INFO:Creating metrics dataframe
2024-05-24 16:16:55,907:INFO:Finalizing model
2024-05-24 16:16:57,158:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:16:57,164:INFO:Uploading results into container
2024-05-24 16:16:57,164:INFO:Uploading model into container now
2024-05-24 16:16:57,177:INFO:_master_model_container: 9
2024-05-24 16:16:57,177:INFO:_display_container: 6
2024-05-24 16:16:57,177:INFO:HuberRegressor()
2024-05-24 16:16:57,177:INFO:create_model() successfully completed......................................
2024-05-24 16:17:19,793:INFO:Initializing tune_model()
2024-05-24 16:17:19,793:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>)
2024-05-24 16:17:19,794:INFO:Checking exceptions
2024-05-24 16:17:19,822:INFO:Copying training dataset
2024-05-24 16:17:19,830:INFO:Checking base model
2024-05-24 16:17:19,830:INFO:Base model : Huber Regressor
2024-05-24 16:17:19,836:INFO:Declaring metric variables
2024-05-24 16:17:19,842:INFO:Defining Hyperparameters
2024-05-24 16:17:20,160:INFO:Tuning with n_jobs=-1
2024-05-24 16:17:20,161:INFO:Initializing RandomizedSearchCV
2024-05-24 16:17:22,450:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:22,545:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:22,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:22,596:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:23,664:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:24,600:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:24,733:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:24,787:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:24,838:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:25,424:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:25,601:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:25,624:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:26,669:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:27,047:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:27,078:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:27,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:27,453:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:27,998:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:28,108:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:29,249:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:29,275:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:29,888:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:30,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:30,250:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:30,497:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:31,155:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:31,404:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:31,941:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:31,982:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:32,266:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:32,550:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:32,583:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:33,548:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:33,550:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:33,958:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:34,029:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:34,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:34,585:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:34,843:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:34,988:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:35,183:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:35,203:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:35,902:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:36,341:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:36,565:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:36,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:37,010:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:37,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:37,248:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:37,738:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:37,856:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:38,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:38,545:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:38,588:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:39,165:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:39,473:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:39,498:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:39,978:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,039:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,205:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,397:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,435:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,475:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,528:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,588:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:40,652:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.5, 'actual_estimator__alpha': 0.01}
2024-05-24 16:17:40,658:INFO:Hyperparameter search completed
2024-05-24 16:17:40,659:INFO:SubProcess create_model() called ==================================
2024-05-24 16:17:40,659:INFO:Initializing create_model()
2024-05-24 16:17:40,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EB930A81C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1.5, 'alpha': 0.01})
2024-05-24 16:17:40,660:INFO:Checking exceptions
2024-05-24 16:17:40,660:INFO:Importing libraries
2024-05-24 16:17:40,660:INFO:Copying training dataset
2024-05-24 16:17:40,667:INFO:Defining folds
2024-05-24 16:17:40,667:INFO:Declaring metric variables
2024-05-24 16:17:40,670:INFO:Importing untrained model
2024-05-24 16:17:40,671:INFO:Declaring custom model
2024-05-24 16:17:40,675:INFO:Huber Regressor Imported successfully
2024-05-24 16:17:40,682:INFO:Starting cross validation
2024-05-24 16:17:40,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:17:42,564:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:42,672:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:42,692:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:42,692:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:42,694:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:42,751:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:42,816:INFO:Calculating mean and std
2024-05-24 16:17:42,819:INFO:Creating metrics dataframe
2024-05-24 16:17:42,825:INFO:Finalizing model
2024-05-24 16:17:43,911:INFO:Uploading results into container
2024-05-24 16:17:43,913:INFO:Uploading model into container now
2024-05-24 16:17:43,914:INFO:_master_model_container: 10
2024-05-24 16:17:43,914:INFO:_display_container: 7
2024-05-24 16:17:43,914:INFO:HuberRegressor(alpha=0.01, epsilon=1.5)
2024-05-24 16:17:43,914:INFO:create_model() successfully completed......................................
2024-05-24 16:17:44,060:INFO:SubProcess create_model() end ==================================
2024-05-24 16:17:44,060:INFO:choose_better activated
2024-05-24 16:17:44,064:INFO:SubProcess create_model() called ==================================
2024-05-24 16:17:44,065:INFO:Initializing create_model()
2024-05-24 16:17:44,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001EB9355EEC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:17:44,065:INFO:Checking exceptions
2024-05-24 16:17:44,067:INFO:Importing libraries
2024-05-24 16:17:44,067:INFO:Copying training dataset
2024-05-24 16:17:44,072:INFO:Defining folds
2024-05-24 16:17:44,072:INFO:Declaring metric variables
2024-05-24 16:17:44,073:INFO:Importing untrained model
2024-05-24 16:17:44,073:INFO:Declaring custom model
2024-05-24 16:17:44,073:INFO:Huber Regressor Imported successfully
2024-05-24 16:17:44,074:INFO:Starting cross validation
2024-05-24 16:17:44,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:17:45,907:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:45,968:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:45,982:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:46,000:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:46,086:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:46,166:INFO:Calculating mean and std
2024-05-24 16:17:46,166:INFO:Creating metrics dataframe
2024-05-24 16:17:46,169:INFO:Finalizing model
2024-05-24 16:17:47,268:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:17:47,269:INFO:Uploading results into container
2024-05-24 16:17:47,270:INFO:Uploading model into container now
2024-05-24 16:17:47,270:INFO:_master_model_container: 11
2024-05-24 16:17:47,270:INFO:_display_container: 8
2024-05-24 16:17:47,270:INFO:HuberRegressor()
2024-05-24 16:17:47,271:INFO:create_model() successfully completed......................................
2024-05-24 16:17:47,413:INFO:SubProcess create_model() end ==================================
2024-05-24 16:17:47,413:INFO:HuberRegressor() result for R2 is 0.4357
2024-05-24 16:17:47,413:INFO:HuberRegressor(alpha=0.01, epsilon=1.5) result for R2 is 0.4676
2024-05-24 16:17:47,414:INFO:HuberRegressor(alpha=0.01, epsilon=1.5) is best model
2024-05-24 16:17:47,414:INFO:choose_better completed
2024-05-24 16:17:47,423:INFO:_master_model_container: 11
2024-05-24 16:17:47,423:INFO:_display_container: 7
2024-05-24 16:17:47,424:INFO:HuberRegressor(alpha=0.01, epsilon=1.5)
2024-05-24 16:17:47,424:INFO:tune_model() successfully completed......................................
2024-05-24 16:18:48,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:18:48,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:18:48,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:18:48,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 16:18:48,721:INFO:PyCaret RegressionExperiment
2024-05-24 16:18:48,721:INFO:Logging name: reg-default-name
2024-05-24 16:18:48,721:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 16:18:48,721:INFO:version 3.3.2
2024-05-24 16:18:48,721:INFO:Initializing setup()
2024-05-24 16:18:48,721:INFO:self.USI: d3d9
2024-05-24 16:18:48,721:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 16:18:48,721:INFO:Checking environment
2024-05-24 16:18:48,721:INFO:python_version: 3.10.14
2024-05-24 16:18:48,721:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 16:18:48,722:INFO:machine: AMD64
2024-05-24 16:18:48,722:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 16:18:48,722:INFO:Memory: svmem(total=16541802496, available=5544411136, percent=66.5, used=10997391360, free=5544411136)
2024-05-24 16:18:48,722:INFO:Physical Core: 6
2024-05-24 16:18:48,722:INFO:Logical Core: 12
2024-05-24 16:18:48,722:INFO:Checking libraries
2024-05-24 16:18:48,722:INFO:System:
2024-05-24 16:18:48,722:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 16:18:48,722:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 16:18:48,722:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 16:18:48,722:INFO:PyCaret required dependencies:
2024-05-24 16:18:48,744:INFO:                 pip: 24.0
2024-05-24 16:18:48,744:INFO:          setuptools: 69.5.1
2024-05-24 16:18:48,744:INFO:             pycaret: 3.3.2
2024-05-24 16:18:48,744:INFO:             IPython: 8.20.0
2024-05-24 16:18:48,744:INFO:          ipywidgets: 8.1.2
2024-05-24 16:18:48,744:INFO:                tqdm: 4.66.4
2024-05-24 16:18:48,744:INFO:               numpy: 1.26.4
2024-05-24 16:18:48,744:INFO:              pandas: 2.1.4
2024-05-24 16:18:48,744:INFO:              jinja2: 3.1.3
2024-05-24 16:18:48,744:INFO:               scipy: 1.11.4
2024-05-24 16:18:48,744:INFO:              joblib: 1.3.2
2024-05-24 16:18:48,744:INFO:             sklearn: 1.4.2
2024-05-24 16:18:48,744:INFO:                pyod: 1.1.3
2024-05-24 16:18:48,744:INFO:            imblearn: 0.12.2
2024-05-24 16:18:48,744:INFO:   category_encoders: 2.6.3
2024-05-24 16:18:48,744:INFO:            lightgbm: 4.3.0
2024-05-24 16:18:48,744:INFO:               numba: 0.59.1
2024-05-24 16:18:48,744:INFO:            requests: 2.32.2
2024-05-24 16:18:48,744:INFO:          matplotlib: 3.7.5
2024-05-24 16:18:48,744:INFO:          scikitplot: 0.3.7
2024-05-24 16:18:48,744:INFO:         yellowbrick: 1.5
2024-05-24 16:18:48,744:INFO:              plotly: 5.22.0
2024-05-24 16:18:48,745:INFO:    plotly-resampler: Not installed
2024-05-24 16:18:48,745:INFO:             kaleido: 0.2.1
2024-05-24 16:18:48,745:INFO:           schemdraw: 0.15
2024-05-24 16:18:48,745:INFO:         statsmodels: 0.14.2
2024-05-24 16:18:48,745:INFO:              sktime: 0.26.0
2024-05-24 16:18:48,745:INFO:               tbats: 1.1.3
2024-05-24 16:18:48,745:INFO:            pmdarima: 2.0.4
2024-05-24 16:18:48,745:INFO:              psutil: 5.9.0
2024-05-24 16:18:48,745:INFO:          markupsafe: 2.1.3
2024-05-24 16:18:48,745:INFO:             pickle5: Not installed
2024-05-24 16:18:48,745:INFO:         cloudpickle: 3.0.0
2024-05-24 16:18:48,745:INFO:         deprecation: 2.1.0
2024-05-24 16:18:48,745:INFO:              xxhash: 3.4.1
2024-05-24 16:18:48,745:INFO:           wurlitzer: Not installed
2024-05-24 16:18:48,745:INFO:PyCaret optional dependencies:
2024-05-24 16:18:48,760:INFO:                shap: Not installed
2024-05-24 16:18:48,760:INFO:           interpret: Not installed
2024-05-24 16:18:48,760:INFO:                umap: Not installed
2024-05-24 16:18:48,760:INFO:     ydata_profiling: Not installed
2024-05-24 16:18:48,760:INFO:  explainerdashboard: Not installed
2024-05-24 16:18:48,760:INFO:             autoviz: Not installed
2024-05-24 16:18:48,760:INFO:           fairlearn: Not installed
2024-05-24 16:18:48,760:INFO:          deepchecks: Not installed
2024-05-24 16:18:48,760:INFO:             xgboost: Not installed
2024-05-24 16:18:48,760:INFO:            catboost: Not installed
2024-05-24 16:18:48,760:INFO:              kmodes: Not installed
2024-05-24 16:18:48,760:INFO:             mlxtend: Not installed
2024-05-24 16:18:48,760:INFO:       statsforecast: Not installed
2024-05-24 16:18:48,760:INFO:        tune_sklearn: Not installed
2024-05-24 16:18:48,760:INFO:                 ray: Not installed
2024-05-24 16:18:48,761:INFO:            hyperopt: Not installed
2024-05-24 16:18:48,761:INFO:              optuna: Not installed
2024-05-24 16:18:48,761:INFO:               skopt: Not installed
2024-05-24 16:18:48,761:INFO:              mlflow: Not installed
2024-05-24 16:18:48,761:INFO:              gradio: Not installed
2024-05-24 16:18:48,761:INFO:             fastapi: Not installed
2024-05-24 16:18:48,761:INFO:             uvicorn: Not installed
2024-05-24 16:18:48,761:INFO:              m2cgen: Not installed
2024-05-24 16:18:48,761:INFO:           evidently: Not installed
2024-05-24 16:18:48,761:INFO:               fugue: Not installed
2024-05-24 16:18:48,761:INFO:           streamlit: Not installed
2024-05-24 16:18:48,761:INFO:             prophet: Not installed
2024-05-24 16:18:48,761:INFO:None
2024-05-24 16:18:48,761:INFO:Set up data.
2024-05-24 16:18:48,771:INFO:Set up folding strategy.
2024-05-24 16:18:48,771:INFO:Set up train/test split.
2024-05-24 16:18:48,780:INFO:Set up index.
2024-05-24 16:18:48,780:INFO:Assigning column types.
2024-05-24 16:18:48,785:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 16:18:48,785:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,795:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,856:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:48,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:48,903:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,907:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,912:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:18:48,972:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,019:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 16:18:49,024:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,028:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,088:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,145:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,252:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 16:18:49,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,321:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,378:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,439:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,486:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 16:18:49,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,601:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,718:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 16:18:49,788:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 16:18:49,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:49,950:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 16:18:50,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:50,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:50,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:50,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:50,184:INFO:Preparing preprocessing pipeline...
2024-05-24 16:18:50,184:INFO:Set up simple imputation.
2024-05-24 16:18:50,193:INFO:Set up encoding of ordinal features.
2024-05-24 16:18:50,199:INFO:Set up encoding of categorical features.
2024-05-24 16:18:50,199:INFO:Set up polynomial features.
2024-05-24 16:18:50,199:INFO:Set up removing multicollinearity.
2024-05-24 16:18:50,199:INFO:Set up removing outliers.
2024-05-24 16:18:50,199:INFO:Set up PCA.
2024-05-24 16:18:51,725:INFO:Finished creating preprocessing pipeline.
2024-05-24 16:18:51,791:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=2058))),
                ('pca',
                 TransformerWrapper(exclude=[],
                                    transformer=PCA(n_components=10)))])
2024-05-24 16:18:51,791:INFO:Creating final display dataframe.
2024-05-24 16:18:53,674:INFO:Setup _display_container:                     Description             Value
0                    Session id              2058
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape         (197, 11)
5   Transformed train set shape         (135, 11)
6    Transformed test set shape          (62, 11)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21                          PCA              True
22                   PCA method            linear
23               PCA components                10
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              d3d9
2024-05-24 16:18:53,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:53,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:53,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:53,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 16:18:53,932:INFO:setup() successfully completed in 5.24s...............
2024-05-24 16:18:53,960:INFO:Initializing compare_models()
2024-05-24 16:18:53,960:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 16:18:53,960:INFO:Checking exceptions
2024-05-24 16:18:53,964:INFO:Preparing display monitor
2024-05-24 16:18:53,996:INFO:Initializing Linear Regression
2024-05-24 16:18:53,996:INFO:Total runtime is 0.0 minutes
2024-05-24 16:18:54,001:INFO:SubProcess create_model() called ==================================
2024-05-24 16:18:54,001:INFO:Initializing create_model()
2024-05-24 16:18:54,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201533FAD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:18:54,001:INFO:Checking exceptions
2024-05-24 16:18:54,001:INFO:Importing libraries
2024-05-24 16:18:54,001:INFO:Copying training dataset
2024-05-24 16:18:54,007:INFO:Defining folds
2024-05-24 16:18:54,009:INFO:Declaring metric variables
2024-05-24 16:18:54,013:INFO:Importing untrained model
2024-05-24 16:18:54,018:INFO:Linear Regression Imported successfully
2024-05-24 16:18:54,026:INFO:Starting cross validation
2024-05-24 16:18:54,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:18:59,735:INFO:Calculating mean and std
2024-05-24 16:18:59,737:INFO:Creating metrics dataframe
2024-05-24 16:18:59,739:INFO:Uploading results into container
2024-05-24 16:18:59,740:INFO:Uploading model into container now
2024-05-24 16:18:59,740:INFO:_master_model_container: 1
2024-05-24 16:18:59,741:INFO:_display_container: 2
2024-05-24 16:18:59,741:INFO:LinearRegression(n_jobs=-1)
2024-05-24 16:18:59,741:INFO:create_model() successfully completed......................................
2024-05-24 16:18:59,861:INFO:SubProcess create_model() end ==================================
2024-05-24 16:18:59,861:INFO:Creating metrics dataframe
2024-05-24 16:18:59,869:INFO:Initializing Lasso Regression
2024-05-24 16:18:59,869:INFO:Total runtime is 0.09788365761439005 minutes
2024-05-24 16:18:59,873:INFO:SubProcess create_model() called ==================================
2024-05-24 16:18:59,873:INFO:Initializing create_model()
2024-05-24 16:18:59,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201533FAD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:18:59,873:INFO:Checking exceptions
2024-05-24 16:18:59,873:INFO:Importing libraries
2024-05-24 16:18:59,873:INFO:Copying training dataset
2024-05-24 16:18:59,879:INFO:Defining folds
2024-05-24 16:18:59,879:INFO:Declaring metric variables
2024-05-24 16:18:59,884:INFO:Importing untrained model
2024-05-24 16:18:59,888:INFO:Lasso Regression Imported successfully
2024-05-24 16:18:59,896:INFO:Starting cross validation
2024-05-24 16:18:59,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:19:03,555:INFO:Calculating mean and std
2024-05-24 16:19:03,557:INFO:Creating metrics dataframe
2024-05-24 16:19:03,559:INFO:Uploading results into container
2024-05-24 16:19:03,559:INFO:Uploading model into container now
2024-05-24 16:19:03,559:INFO:_master_model_container: 2
2024-05-24 16:19:03,559:INFO:_display_container: 2
2024-05-24 16:19:03,560:INFO:Lasso(random_state=2058)
2024-05-24 16:19:03,560:INFO:create_model() successfully completed......................................
2024-05-24 16:19:03,671:INFO:SubProcess create_model() end ==================================
2024-05-24 16:19:03,671:INFO:Creating metrics dataframe
2024-05-24 16:19:03,678:INFO:Initializing Ridge Regression
2024-05-24 16:19:03,678:INFO:Total runtime is 0.16136761903762817 minutes
2024-05-24 16:19:03,682:INFO:SubProcess create_model() called ==================================
2024-05-24 16:19:03,682:INFO:Initializing create_model()
2024-05-24 16:19:03,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201533FAD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:19:03,682:INFO:Checking exceptions
2024-05-24 16:19:03,684:INFO:Importing libraries
2024-05-24 16:19:03,684:INFO:Copying training dataset
2024-05-24 16:19:03,689:INFO:Defining folds
2024-05-24 16:19:03,689:INFO:Declaring metric variables
2024-05-24 16:19:03,693:INFO:Importing untrained model
2024-05-24 16:19:03,697:INFO:Ridge Regression Imported successfully
2024-05-24 16:19:03,707:INFO:Starting cross validation
2024-05-24 16:19:03,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:19:05,766:INFO:Calculating mean and std
2024-05-24 16:19:05,768:INFO:Creating metrics dataframe
2024-05-24 16:19:05,770:INFO:Uploading results into container
2024-05-24 16:19:05,770:INFO:Uploading model into container now
2024-05-24 16:19:05,771:INFO:_master_model_container: 3
2024-05-24 16:19:05,772:INFO:_display_container: 2
2024-05-24 16:19:05,772:INFO:Ridge(random_state=2058)
2024-05-24 16:19:05,772:INFO:create_model() successfully completed......................................
2024-05-24 16:19:05,892:INFO:SubProcess create_model() end ==================================
2024-05-24 16:19:05,893:INFO:Creating metrics dataframe
2024-05-24 16:19:05,901:INFO:Initializing Huber Regressor
2024-05-24 16:19:05,901:INFO:Total runtime is 0.19840928713480632 minutes
2024-05-24 16:19:05,905:INFO:SubProcess create_model() called ==================================
2024-05-24 16:19:05,905:INFO:Initializing create_model()
2024-05-24 16:19:05,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201533FAD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:19:05,906:INFO:Checking exceptions
2024-05-24 16:19:05,906:INFO:Importing libraries
2024-05-24 16:19:05,906:INFO:Copying training dataset
2024-05-24 16:19:05,912:INFO:Defining folds
2024-05-24 16:19:05,912:INFO:Declaring metric variables
2024-05-24 16:19:05,915:INFO:Importing untrained model
2024-05-24 16:19:05,920:INFO:Huber Regressor Imported successfully
2024-05-24 16:19:05,927:INFO:Starting cross validation
2024-05-24 16:19:05,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:19:07,796:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:07,825:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:07,827:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:07,836:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:07,868:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:07,897:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:07,984:INFO:Calculating mean and std
2024-05-24 16:19:07,986:INFO:Creating metrics dataframe
2024-05-24 16:19:07,988:INFO:Uploading results into container
2024-05-24 16:19:07,989:INFO:Uploading model into container now
2024-05-24 16:19:07,989:INFO:_master_model_container: 4
2024-05-24 16:19:07,989:INFO:_display_container: 2
2024-05-24 16:19:07,990:INFO:HuberRegressor()
2024-05-24 16:19:07,990:INFO:create_model() successfully completed......................................
2024-05-24 16:19:08,104:INFO:SubProcess create_model() end ==================================
2024-05-24 16:19:08,105:INFO:Creating metrics dataframe
2024-05-24 16:19:08,114:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 16:19:08,124:INFO:Initializing create_model()
2024-05-24 16:19:08,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:19:08,124:INFO:Checking exceptions
2024-05-24 16:19:08,126:INFO:Importing libraries
2024-05-24 16:19:08,126:INFO:Copying training dataset
2024-05-24 16:19:08,131:INFO:Defining folds
2024-05-24 16:19:08,131:INFO:Declaring metric variables
2024-05-24 16:19:08,132:INFO:Importing untrained model
2024-05-24 16:19:08,132:INFO:Declaring custom model
2024-05-24 16:19:08,132:INFO:Huber Regressor Imported successfully
2024-05-24 16:19:08,149:INFO:Cross validation set to False
2024-05-24 16:19:08,149:INFO:Fitting Model
2024-05-24 16:19:09,148:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:09,149:INFO:HuberRegressor()
2024-05-24 16:19:09,149:INFO:create_model() successfully completed......................................
2024-05-24 16:19:09,310:INFO:_master_model_container: 4
2024-05-24 16:19:09,310:INFO:_display_container: 2
2024-05-24 16:19:09,311:INFO:HuberRegressor()
2024-05-24 16:19:09,311:INFO:compare_models() successfully completed......................................
2024-05-24 16:19:09,327:INFO:Initializing evaluate_model()
2024-05-24 16:19:09,327:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 16:19:09,341:INFO:Initializing plot_model()
2024-05-24 16:19:09,341:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 16:19:09,341:INFO:Checking exceptions
2024-05-24 16:19:09,346:INFO:Preloading libraries
2024-05-24 16:19:09,346:INFO:Copying training dataset
2024-05-24 16:19:09,346:INFO:Plot type: pipeline
2024-05-24 16:19:09,593:INFO:Visual Rendered Successfully
2024-05-24 16:19:09,713:INFO:plot_model() successfully completed......................................
2024-05-24 16:19:09,735:INFO:Initializing create_model()
2024-05-24 16:19:09,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:19:09,736:INFO:Checking exceptions
2024-05-24 16:19:09,752:INFO:Importing libraries
2024-05-24 16:19:09,753:INFO:Copying training dataset
2024-05-24 16:19:09,760:INFO:Defining folds
2024-05-24 16:19:09,760:INFO:Declaring metric variables
2024-05-24 16:19:09,764:INFO:Importing untrained model
2024-05-24 16:19:09,764:INFO:Declaring custom model
2024-05-24 16:19:09,768:INFO:Huber Regressor Imported successfully
2024-05-24 16:19:09,777:INFO:Starting cross validation
2024-05-24 16:19:09,805:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:19:11,763:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:11,777:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:11,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:11,804:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:11,865:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:11,905:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:11,968:INFO:Calculating mean and std
2024-05-24 16:19:11,969:INFO:Creating metrics dataframe
2024-05-24 16:19:11,975:INFO:Finalizing model
2024-05-24 16:19:13,028:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:13,034:INFO:Uploading results into container
2024-05-24 16:19:13,035:INFO:Uploading model into container now
2024-05-24 16:19:13,046:INFO:_master_model_container: 5
2024-05-24 16:19:13,046:INFO:_display_container: 3
2024-05-24 16:19:13,047:INFO:HuberRegressor()
2024-05-24 16:19:13,047:INFO:create_model() successfully completed......................................
2024-05-24 16:19:13,194:INFO:Initializing tune_model()
2024-05-24 16:19:13,194:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>)
2024-05-24 16:19:13,194:INFO:Checking exceptions
2024-05-24 16:19:13,216:INFO:Copying training dataset
2024-05-24 16:19:13,220:INFO:Checking base model
2024-05-24 16:19:13,220:INFO:Base model : Huber Regressor
2024-05-24 16:19:13,224:INFO:Declaring metric variables
2024-05-24 16:19:13,228:INFO:Defining Hyperparameters
2024-05-24 16:19:13,370:INFO:Tuning with n_jobs=-1
2024-05-24 16:19:13,370:INFO:Initializing RandomizedSearchCV
2024-05-24 16:19:15,446:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,500:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,516:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,583:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,586:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,604:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,679:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,695:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,832:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,852:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:15,897:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:17,595:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:17,713:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:17,806:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:17,811:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:17,939:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:17,945:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:18,060:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:18,079:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:18,195:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:18,276:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:18,297:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:19,967:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:20,128:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:20,251:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:20,472:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:20,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:20,961:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,204:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,242:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,352:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,410:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,710:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,891:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:22,943:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:23,345:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:23,410:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:24,475:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:24,629:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:24,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:24,731:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:24,901:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:24,968:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:25,196:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:25,912:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:26,655:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:26,789:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:26,938:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:27,011:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:27,119:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:27,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:27,317:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:27,380:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:28,069:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:28,325:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:28,429:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:29,097:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:29,222:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:29,372:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:30,978:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:31,042:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:31,092:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:31,123:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:31,286:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:31,294:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:31,606:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:32,334:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:32,808:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:33,078:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:33,080:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:33,097:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:33,113:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:33,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:33,281:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1, 'actual_estimator__alpha': 0.4}
2024-05-24 16:19:33,282:INFO:Hyperparameter search completed
2024-05-24 16:19:33,282:INFO:SubProcess create_model() called ==================================
2024-05-24 16:19:33,282:INFO:Initializing create_model()
2024-05-24 16:19:33,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020152576470>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1, 'alpha': 0.4})
2024-05-24 16:19:33,282:INFO:Checking exceptions
2024-05-24 16:19:33,282:INFO:Importing libraries
2024-05-24 16:19:33,283:INFO:Copying training dataset
2024-05-24 16:19:33,291:INFO:Defining folds
2024-05-24 16:19:33,292:INFO:Declaring metric variables
2024-05-24 16:19:33,297:INFO:Importing untrained model
2024-05-24 16:19:33,297:INFO:Declaring custom model
2024-05-24 16:19:33,301:INFO:Huber Regressor Imported successfully
2024-05-24 16:19:33,310:INFO:Starting cross validation
2024-05-24 16:19:33,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:19:35,241:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,351:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,353:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,370:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,449:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,450:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,462:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,477:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,533:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:35,614:INFO:Calculating mean and std
2024-05-24 16:19:35,615:INFO:Creating metrics dataframe
2024-05-24 16:19:35,623:INFO:Finalizing model
2024-05-24 16:19:36,746:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:36,751:INFO:Uploading results into container
2024-05-24 16:19:36,752:INFO:Uploading model into container now
2024-05-24 16:19:36,753:INFO:_master_model_container: 6
2024-05-24 16:19:36,753:INFO:_display_container: 4
2024-05-24 16:19:36,753:INFO:HuberRegressor(alpha=0.4, epsilon=1)
2024-05-24 16:19:36,753:INFO:create_model() successfully completed......................................
2024-05-24 16:19:36,871:INFO:SubProcess create_model() end ==================================
2024-05-24 16:19:36,871:INFO:choose_better activated
2024-05-24 16:19:36,876:INFO:SubProcess create_model() called ==================================
2024-05-24 16:19:36,877:INFO:Initializing create_model()
2024-05-24 16:19:36,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 16:19:36,877:INFO:Checking exceptions
2024-05-24 16:19:36,878:INFO:Importing libraries
2024-05-24 16:19:36,878:INFO:Copying training dataset
2024-05-24 16:19:36,885:INFO:Defining folds
2024-05-24 16:19:36,885:INFO:Declaring metric variables
2024-05-24 16:19:36,885:INFO:Importing untrained model
2024-05-24 16:19:36,885:INFO:Declaring custom model
2024-05-24 16:19:36,886:INFO:Huber Regressor Imported successfully
2024-05-24 16:19:36,886:INFO:Starting cross validation
2024-05-24 16:19:36,908:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 16:19:38,866:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:38,882:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:38,902:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:38,905:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:38,915:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:38,965:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:39,037:INFO:Calculating mean and std
2024-05-24 16:19:39,038:INFO:Creating metrics dataframe
2024-05-24 16:19:39,039:INFO:Finalizing model
2024-05-24 16:19:40,085:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 16:19:40,086:INFO:Uploading results into container
2024-05-24 16:19:40,086:INFO:Uploading model into container now
2024-05-24 16:19:40,087:INFO:_master_model_container: 7
2024-05-24 16:19:40,087:INFO:_display_container: 5
2024-05-24 16:19:40,087:INFO:HuberRegressor()
2024-05-24 16:19:40,087:INFO:create_model() successfully completed......................................
2024-05-24 16:19:40,204:INFO:SubProcess create_model() end ==================================
2024-05-24 16:19:40,204:INFO:HuberRegressor() result for R2 is 0.2938
2024-05-24 16:19:40,204:INFO:HuberRegressor(alpha=0.4, epsilon=1) result for R2 is 0.3776
2024-05-24 16:19:40,205:INFO:HuberRegressor(alpha=0.4, epsilon=1) is best model
2024-05-24 16:19:40,205:INFO:choose_better completed
2024-05-24 16:19:40,216:INFO:_master_model_container: 7
2024-05-24 16:19:40,216:INFO:_display_container: 4
2024-05-24 16:19:40,217:INFO:HuberRegressor(alpha=0.4, epsilon=1)
2024-05-24 16:19:40,217:INFO:tune_model() successfully completed......................................
2024-05-24 19:02:32,535:INFO:PyCaret RegressionExperiment
2024-05-24 19:02:32,535:INFO:Logging name: reg-default-name
2024-05-24 19:02:32,535:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 19:02:32,535:INFO:version 3.3.2
2024-05-24 19:02:32,535:INFO:Initializing setup()
2024-05-24 19:02:32,536:INFO:self.USI: 08a5
2024-05-24 19:02:32,536:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 19:02:32,536:INFO:Checking environment
2024-05-24 19:02:32,536:INFO:python_version: 3.10.14
2024-05-24 19:02:32,536:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 19:02:32,536:INFO:machine: AMD64
2024-05-24 19:02:32,536:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 19:02:32,536:INFO:Memory: svmem(total=16541802496, available=3561979904, percent=78.5, used=12979822592, free=3561979904)
2024-05-24 19:02:32,536:INFO:Physical Core: 6
2024-05-24 19:02:32,536:INFO:Logical Core: 12
2024-05-24 19:02:32,536:INFO:Checking libraries
2024-05-24 19:02:32,536:INFO:System:
2024-05-24 19:02:32,536:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 19:02:32,536:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 19:02:32,536:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 19:02:32,536:INFO:PyCaret required dependencies:
2024-05-24 19:02:32,537:INFO:                 pip: 24.0
2024-05-24 19:02:32,537:INFO:          setuptools: 69.5.1
2024-05-24 19:02:32,537:INFO:             pycaret: 3.3.2
2024-05-24 19:02:32,537:INFO:             IPython: 8.20.0
2024-05-24 19:02:32,537:INFO:          ipywidgets: 8.1.2
2024-05-24 19:02:32,537:INFO:                tqdm: 4.66.4
2024-05-24 19:02:32,537:INFO:               numpy: 1.26.4
2024-05-24 19:02:32,537:INFO:              pandas: 2.1.4
2024-05-24 19:02:32,537:INFO:              jinja2: 3.1.3
2024-05-24 19:02:32,537:INFO:               scipy: 1.11.4
2024-05-24 19:02:32,537:INFO:              joblib: 1.3.2
2024-05-24 19:02:32,537:INFO:             sklearn: 1.4.2
2024-05-24 19:02:32,538:INFO:                pyod: 1.1.3
2024-05-24 19:02:32,538:INFO:            imblearn: 0.12.2
2024-05-24 19:02:32,538:INFO:   category_encoders: 2.6.3
2024-05-24 19:02:32,538:INFO:            lightgbm: 4.3.0
2024-05-24 19:02:32,538:INFO:               numba: 0.59.1
2024-05-24 19:02:32,538:INFO:            requests: 2.32.2
2024-05-24 19:02:32,538:INFO:          matplotlib: 3.7.5
2024-05-24 19:02:32,538:INFO:          scikitplot: 0.3.7
2024-05-24 19:02:32,538:INFO:         yellowbrick: 1.5
2024-05-24 19:02:32,538:INFO:              plotly: 5.22.0
2024-05-24 19:02:32,538:INFO:    plotly-resampler: Not installed
2024-05-24 19:02:32,538:INFO:             kaleido: 0.2.1
2024-05-24 19:02:32,538:INFO:           schemdraw: 0.15
2024-05-24 19:02:32,538:INFO:         statsmodels: 0.14.2
2024-05-24 19:02:32,538:INFO:              sktime: 0.26.0
2024-05-24 19:02:32,538:INFO:               tbats: 1.1.3
2024-05-24 19:02:32,538:INFO:            pmdarima: 2.0.4
2024-05-24 19:02:32,538:INFO:              psutil: 5.9.0
2024-05-24 19:02:32,538:INFO:          markupsafe: 2.1.3
2024-05-24 19:02:32,538:INFO:             pickle5: Not installed
2024-05-24 19:02:32,538:INFO:         cloudpickle: 3.0.0
2024-05-24 19:02:32,538:INFO:         deprecation: 2.1.0
2024-05-24 19:02:32,538:INFO:              xxhash: 3.4.1
2024-05-24 19:02:32,539:INFO:           wurlitzer: Not installed
2024-05-24 19:02:32,539:INFO:PyCaret optional dependencies:
2024-05-24 19:02:32,539:INFO:                shap: Not installed
2024-05-24 19:02:32,539:INFO:           interpret: Not installed
2024-05-24 19:02:32,539:INFO:                umap: Not installed
2024-05-24 19:02:32,539:INFO:     ydata_profiling: Not installed
2024-05-24 19:02:32,539:INFO:  explainerdashboard: Not installed
2024-05-24 19:02:32,539:INFO:             autoviz: Not installed
2024-05-24 19:02:32,539:INFO:           fairlearn: Not installed
2024-05-24 19:02:32,539:INFO:          deepchecks: Not installed
2024-05-24 19:02:32,539:INFO:             xgboost: Not installed
2024-05-24 19:02:32,539:INFO:            catboost: Not installed
2024-05-24 19:02:32,539:INFO:              kmodes: Not installed
2024-05-24 19:02:32,539:INFO:             mlxtend: Not installed
2024-05-24 19:02:32,539:INFO:       statsforecast: Not installed
2024-05-24 19:02:32,539:INFO:        tune_sklearn: Not installed
2024-05-24 19:02:32,539:INFO:                 ray: Not installed
2024-05-24 19:02:32,539:INFO:            hyperopt: Not installed
2024-05-24 19:02:32,539:INFO:              optuna: Not installed
2024-05-24 19:02:32,539:INFO:               skopt: Not installed
2024-05-24 19:02:32,539:INFO:              mlflow: Not installed
2024-05-24 19:02:32,539:INFO:              gradio: Not installed
2024-05-24 19:02:32,539:INFO:             fastapi: Not installed
2024-05-24 19:02:32,539:INFO:             uvicorn: Not installed
2024-05-24 19:02:32,540:INFO:              m2cgen: Not installed
2024-05-24 19:02:32,540:INFO:           evidently: Not installed
2024-05-24 19:02:32,540:INFO:               fugue: Not installed
2024-05-24 19:02:32,540:INFO:           streamlit: Not installed
2024-05-24 19:02:32,540:INFO:             prophet: Not installed
2024-05-24 19:02:32,540:INFO:None
2024-05-24 19:02:32,540:INFO:Set up data.
2024-05-24 19:02:32,550:INFO:Set up folding strategy.
2024-05-24 19:02:32,550:INFO:Set up train/test split.
2024-05-24 19:02:32,556:INFO:Set up index.
2024-05-24 19:02:32,556:INFO:Assigning column types.
2024-05-24 19:02:32,560:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 19:02:32,561:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,566:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,570:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,631:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,679:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:32,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:32,681:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,690:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:32,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:32,801:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 19:02:32,806:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,810:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,873:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:32,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:32,926:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:02:32,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,042:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 19:02:33,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,170:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,231:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,279:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 19:02:33,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,518:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 19:02:33,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:02:33,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,756:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 19:02:33,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:33,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:34,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:34,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:34,002:INFO:Preparing preprocessing pipeline...
2024-05-24 19:02:34,002:INFO:Set up simple imputation.
2024-05-24 19:02:34,007:INFO:Set up encoding of ordinal features.
2024-05-24 19:02:34,013:INFO:Set up encoding of categorical features.
2024-05-24 19:02:34,013:INFO:Set up polynomial features.
2024-05-24 19:02:34,013:INFO:Set up removing multicollinearity.
2024-05-24 19:02:34,013:INFO:Set up removing outliers.
2024-05-24 19:02:34,013:INFO:Set up PCA.
2024-05-24 19:02:35,625:INFO:Finished creating preprocessing pipeline.
2024-05-24 19:02:35,693:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=3902))),
                ('pca',
                 TransformerWrapper(exclude=[],
                                    transformer=PCA(n_components=10)))])
2024-05-24 19:02:35,693:INFO:Creating final display dataframe.
2024-05-24 19:02:37,543:INFO:Setup _display_container:                     Description             Value
0                    Session id              3902
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape         (197, 11)
5   Transformed train set shape         (135, 11)
6    Transformed test set shape          (62, 11)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21                          PCA              True
22                   PCA method            linear
23               PCA components                10
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              08a5
2024-05-24 19:02:37,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:37,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:37,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:37,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:02:37,793:INFO:setup() successfully completed in 5.29s...............
2024-05-24 19:04:17,418:INFO:Initializing plot_model()
2024-05-24 19:04:17,418:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:04:17,418:INFO:Checking exceptions
2024-05-24 19:04:17,423:INFO:Preloading libraries
2024-05-24 19:04:17,424:INFO:Copying training dataset
2024-05-24 19:04:17,424:INFO:Plot type: parameter
2024-05-24 19:04:17,428:INFO:Visual Rendered Successfully
2024-05-24 19:04:17,699:INFO:plot_model() successfully completed......................................
2024-05-24 19:04:20,412:INFO:Initializing plot_model()
2024-05-24 19:04:20,413:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:04:20,413:INFO:Checking exceptions
2024-05-24 19:04:20,417:INFO:Preloading libraries
2024-05-24 19:04:20,418:INFO:Copying training dataset
2024-05-24 19:04:20,418:INFO:Plot type: residuals
2024-05-24 19:04:21,149:INFO:Fitting Model
2024-05-24 19:04:21,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2024-05-24 19:04:21,187:INFO:Scoring test/hold-out set
2024-05-24 19:04:21,681:INFO:Visual Rendered Successfully
2024-05-24 19:04:21,888:INFO:plot_model() successfully completed......................................
2024-05-24 19:04:49,939:INFO:Initializing plot_model()
2024-05-24 19:04:49,939:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:04:49,939:INFO:Checking exceptions
2024-05-24 19:04:49,943:INFO:Preloading libraries
2024-05-24 19:04:49,944:INFO:Copying training dataset
2024-05-24 19:04:49,944:INFO:Plot type: error
2024-05-24 19:04:50,592:INFO:Fitting Model
2024-05-24 19:04:50,592:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2024-05-24 19:04:50,593:INFO:Scoring test/hold-out set
2024-05-24 19:04:50,846:INFO:Visual Rendered Successfully
2024-05-24 19:04:51,152:INFO:plot_model() successfully completed......................................
2024-05-24 19:04:51,322:INFO:Initializing plot_model()
2024-05-24 19:04:51,322:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:04:51,322:INFO:Checking exceptions
2024-05-24 19:04:51,326:INFO:Preloading libraries
2024-05-24 19:04:51,326:INFO:Copying training dataset
2024-05-24 19:04:51,327:INFO:Plot type: cooks
2024-05-24 19:04:51,996:INFO:Fitting Model
2024-05-24 19:04:52,215:INFO:Visual Rendered Successfully
2024-05-24 19:04:52,339:INFO:plot_model() successfully completed......................................
2024-05-24 19:04:53,352:INFO:Initializing plot_model()
2024-05-24 19:04:53,352:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:04:53,352:INFO:Checking exceptions
2024-05-24 19:04:53,357:INFO:Preloading libraries
2024-05-24 19:04:53,357:INFO:Copying training dataset
2024-05-24 19:04:53,358:INFO:Plot type: error
2024-05-24 19:04:54,005:INFO:Fitting Model
2024-05-24 19:04:54,006:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but HuberRegressor was fitted with feature names
  warnings.warn(

2024-05-24 19:04:54,006:INFO:Scoring test/hold-out set
2024-05-24 19:04:54,244:INFO:Visual Rendered Successfully
2024-05-24 19:04:54,468:INFO:plot_model() successfully completed......................................
2024-05-24 19:04:57,980:INFO:Initializing plot_model()
2024-05-24 19:04:57,980:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:04:57,981:INFO:Checking exceptions
2024-05-24 19:04:57,986:INFO:Preloading libraries
2024-05-24 19:04:57,986:INFO:Copying training dataset
2024-05-24 19:04:57,986:INFO:Plot type: rfe
2024-05-24 19:04:58,780:INFO:Fitting Model
2024-05-24 19:04:59,825:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:04:59,859:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:04:59,904:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,393:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,431:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,459:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,485:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,514:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,739:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:00,921:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 19:05:01,929:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:01,960:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,006:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,504:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,558:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,610:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,641:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:02,835:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:03,031:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 19:05:03,898:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:03,928:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:03,978:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,399:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,441:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,468:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,495:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,525:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,686:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:04,841:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 338, in _fit
    self.estimator_.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 19:05:05,642:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:05,674:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:05,724:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,143:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,204:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,231:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,259:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,287:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,436:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:06,610:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 338, in _fit
    self.estimator_.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 19:05:07,193:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,216:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,256:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,536:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,571:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,593:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,620:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,650:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:07,786:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:08,550:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:08,581:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:08,631:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:08,904:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:08,951:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:08,984:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:09,017:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:09,143:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:09,824:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:09,849:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,052:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,101:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,262:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,712:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,869:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:10,901:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:11,045:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:11,391:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:11,708:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:11,727:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:05:11,913:INFO:Visual Rendered Successfully
2024-05-24 19:05:12,035:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:12,108:INFO:Initializing plot_model()
2024-05-24 19:05:12,108:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:12,108:INFO:Checking exceptions
2024-05-24 19:05:12,112:INFO:Preloading libraries
2024-05-24 19:05:12,112:INFO:Copying training dataset
2024-05-24 19:05:12,112:INFO:Plot type: feature_all
2024-05-24 19:05:12,793:INFO:Visual Rendered Successfully
2024-05-24 19:05:12,907:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:19,739:INFO:Initializing plot_model()
2024-05-24 19:05:19,740:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:19,740:INFO:Checking exceptions
2024-05-24 19:05:21,188:INFO:Initializing plot_model()
2024-05-24 19:05:21,189:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:21,189:INFO:Checking exceptions
2024-05-24 19:05:21,196:INFO:Preloading libraries
2024-05-24 19:05:21,196:INFO:Copying training dataset
2024-05-24 19:05:21,196:INFO:Plot type: residuals_interactive
2024-05-24 19:05:21,873:INFO:Calculated model residuals
2024-05-24 19:05:25,280:INFO:Calculated Tunkey-Anscombe Plot
2024-05-24 19:05:25,504:INFO:Calculated Normal QQ Plot
2024-05-24 19:05:25,601:INFO:Calculated Scale-Location Plot
2024-05-24 19:05:25,733:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2024-05-24 19:05:25,848:INFO:Visual Rendered Successfully
2024-05-24 19:05:26,005:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:26,047:INFO:Initializing plot_model()
2024-05-24 19:05:26,047:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:26,047:INFO:Checking exceptions
2024-05-24 19:05:32,998:INFO:Initializing plot_model()
2024-05-24 19:05:32,998:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:32,998:INFO:Checking exceptions
2024-05-24 19:05:33,003:INFO:Preloading libraries
2024-05-24 19:05:33,003:INFO:Copying training dataset
2024-05-24 19:05:33,003:INFO:Plot type: residuals_interactive
2024-05-24 19:05:33,662:INFO:Calculated model residuals
2024-05-24 19:05:33,789:INFO:Calculated Tunkey-Anscombe Plot
2024-05-24 19:05:33,845:INFO:Calculated Normal QQ Plot
2024-05-24 19:05:33,973:INFO:Calculated Scale-Location Plot
2024-05-24 19:05:34,088:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2024-05-24 19:05:34,208:INFO:Visual Rendered Successfully
2024-05-24 19:05:34,556:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:34,644:INFO:Initializing plot_model()
2024-05-24 19:05:34,644:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:34,645:INFO:Checking exceptions
2024-05-24 19:05:42,871:INFO:Initializing plot_model()
2024-05-24 19:05:42,872:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:42,872:INFO:Checking exceptions
2024-05-24 19:05:42,877:INFO:Preloading libraries
2024-05-24 19:05:42,878:INFO:Copying training dataset
2024-05-24 19:05:42,878:INFO:Plot type: pipeline
2024-05-24 19:05:43,103:INFO:Visual Rendered Successfully
2024-05-24 19:05:43,375:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:44,784:INFO:Initializing plot_model()
2024-05-24 19:05:44,785:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:44,785:INFO:Checking exceptions
2024-05-24 19:05:44,788:INFO:Preloading libraries
2024-05-24 19:05:44,789:INFO:Copying training dataset
2024-05-24 19:05:44,789:INFO:Plot type: parameter
2024-05-24 19:05:44,792:INFO:Visual Rendered Successfully
2024-05-24 19:05:45,114:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:47,945:INFO:Initializing plot_model()
2024-05-24 19:05:47,946:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:47,946:INFO:Checking exceptions
2024-05-24 19:05:47,951:INFO:Preloading libraries
2024-05-24 19:05:47,951:INFO:Copying training dataset
2024-05-24 19:05:47,951:INFO:Plot type: residuals
2024-05-24 19:05:48,627:INFO:Fitting Model
2024-05-24 19:05:48,627:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:05:48,666:INFO:Scoring test/hold-out set
2024-05-24 19:05:49,092:INFO:Visual Rendered Successfully
2024-05-24 19:05:49,405:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:57,823:INFO:Initializing plot_model()
2024-05-24 19:05:57,824:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:57,824:INFO:Checking exceptions
2024-05-24 19:05:57,828:INFO:Preloading libraries
2024-05-24 19:05:57,829:INFO:Copying training dataset
2024-05-24 19:05:57,829:INFO:Plot type: error
2024-05-24 19:05:58,499:INFO:Fitting Model
2024-05-24 19:05:58,500:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:05:58,500:INFO:Scoring test/hold-out set
2024-05-24 19:05:58,736:INFO:Visual Rendered Successfully
2024-05-24 19:05:59,044:INFO:plot_model() successfully completed......................................
2024-05-24 19:05:59,549:INFO:Initializing plot_model()
2024-05-24 19:05:59,549:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:05:59,549:INFO:Checking exceptions
2024-05-24 19:05:59,553:INFO:Preloading libraries
2024-05-24 19:05:59,553:INFO:Copying training dataset
2024-05-24 19:05:59,553:INFO:Plot type: cooks
2024-05-24 19:06:00,210:INFO:Fitting Model
2024-05-24 19:06:00,417:INFO:Visual Rendered Successfully
2024-05-24 19:06:00,570:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:02,249:INFO:Initializing plot_model()
2024-05-24 19:06:02,250:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:02,250:INFO:Checking exceptions
2024-05-24 19:06:02,254:INFO:Preloading libraries
2024-05-24 19:06:02,255:INFO:Copying training dataset
2024-05-24 19:06:02,255:INFO:Plot type: rfe
2024-05-24 19:06:02,911:INFO:Fitting Model
2024-05-24 19:06:03,871:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:03,900:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:03,947:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,406:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,446:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,473:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,500:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,527:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,709:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:04,884:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:05,847:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:05,876:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:05,923:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,359:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,398:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,425:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,451:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,478:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,653:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:06,822:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:07,716:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:07,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:07,802:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,217:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,256:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,282:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,310:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,493:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:08,670:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 338, in _fit
    self.estimator_.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:09,476:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:09,504:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:09,551:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:09,937:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:09,978:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:10,006:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:10,034:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:10,065:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:10,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:10,393:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 338, in _fit
    self.estimator_.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:11,007:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,032:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,071:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,362:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,398:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,422:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,445:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,468:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:11,584:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,166:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,192:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,246:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,534:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,567:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,611:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:12,725:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:13,266:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:13,292:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:13,492:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:13,527:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:13,549:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:13,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:14,095:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:14,246:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:14,280:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:14,410:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:14,857:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:15,210:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:15,227:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:15,413:INFO:Visual Rendered Successfully
2024-05-24 19:06:15,569:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:15,652:INFO:Initializing plot_model()
2024-05-24 19:06:15,653:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:15,653:INFO:Checking exceptions
2024-05-24 19:06:17,131:INFO:Initializing plot_model()
2024-05-24 19:06:17,131:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:17,131:INFO:Checking exceptions
2024-05-24 19:06:17,135:INFO:Preloading libraries
2024-05-24 19:06:17,136:INFO:Copying training dataset
2024-05-24 19:06:17,136:INFO:Plot type: residuals_interactive
2024-05-24 19:06:17,734:INFO:Calculated model residuals
2024-05-24 19:06:17,886:INFO:Calculated Tunkey-Anscombe Plot
2024-05-24 19:06:17,945:INFO:Calculated Normal QQ Plot
2024-05-24 19:06:18,050:INFO:Calculated Scale-Location Plot
2024-05-24 19:06:18,162:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2024-05-24 19:06:18,264:INFO:Visual Rendered Successfully
2024-05-24 19:06:18,406:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:19,677:INFO:Initializing plot_model()
2024-05-24 19:06:19,677:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:19,677:INFO:Checking exceptions
2024-05-24 19:06:19,682:INFO:Preloading libraries
2024-05-24 19:06:19,682:INFO:Copying training dataset
2024-05-24 19:06:19,683:INFO:Plot type: error
2024-05-24 19:06:20,331:INFO:Fitting Model
2024-05-24 19:06:20,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:06:20,331:INFO:Scoring test/hold-out set
2024-05-24 19:06:20,547:INFO:Visual Rendered Successfully
2024-05-24 19:06:20,704:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:36,236:INFO:Initializing plot_model()
2024-05-24 19:06:36,237:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:36,237:INFO:Checking exceptions
2024-05-24 19:06:36,242:INFO:Preloading libraries
2024-05-24 19:06:36,244:INFO:Copying training dataset
2024-05-24 19:06:36,244:INFO:Plot type: parameter
2024-05-24 19:06:36,249:INFO:Visual Rendered Successfully
2024-05-24 19:06:36,514:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:37,562:INFO:Initializing plot_model()
2024-05-24 19:06:37,562:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:37,563:INFO:Checking exceptions
2024-05-24 19:06:37,567:INFO:Preloading libraries
2024-05-24 19:06:37,568:INFO:Copying training dataset
2024-05-24 19:06:37,568:INFO:Plot type: residuals
2024-05-24 19:06:38,238:INFO:Fitting Model
2024-05-24 19:06:38,238:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:06:38,275:INFO:Scoring test/hold-out set
2024-05-24 19:06:38,655:INFO:Visual Rendered Successfully
2024-05-24 19:06:38,946:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:41,182:INFO:Initializing plot_model()
2024-05-24 19:06:41,182:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:41,183:INFO:Checking exceptions
2024-05-24 19:06:41,187:INFO:Preloading libraries
2024-05-24 19:06:41,187:INFO:Copying training dataset
2024-05-24 19:06:41,187:INFO:Plot type: parameter
2024-05-24 19:06:41,191:INFO:Visual Rendered Successfully
2024-05-24 19:06:41,519:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:42,933:INFO:Initializing plot_model()
2024-05-24 19:06:42,933:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:42,934:INFO:Checking exceptions
2024-05-24 19:06:42,937:INFO:Preloading libraries
2024-05-24 19:06:42,937:INFO:Copying training dataset
2024-05-24 19:06:42,938:INFO:Plot type: error
2024-05-24 19:06:43,598:INFO:Fitting Model
2024-05-24 19:06:43,598:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:06:43,599:INFO:Scoring test/hold-out set
2024-05-24 19:06:43,844:INFO:Visual Rendered Successfully
2024-05-24 19:06:44,154:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:46,400:INFO:Initializing plot_model()
2024-05-24 19:06:46,400:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:46,400:INFO:Checking exceptions
2024-05-24 19:06:46,404:INFO:Preloading libraries
2024-05-24 19:06:46,404:INFO:Copying training dataset
2024-05-24 19:06:46,405:INFO:Plot type: cooks
2024-05-24 19:06:47,047:INFO:Fitting Model
2024-05-24 19:06:47,256:INFO:Visual Rendered Successfully
2024-05-24 19:06:47,632:INFO:plot_model() successfully completed......................................
2024-05-24 19:06:48,738:INFO:Initializing plot_model()
2024-05-24 19:06:48,739:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:06:48,739:INFO:Checking exceptions
2024-05-24 19:06:48,742:INFO:Preloading libraries
2024-05-24 19:06:48,742:INFO:Copying training dataset
2024-05-24 19:06:48,744:INFO:Plot type: rfe
2024-05-24 19:06:49,419:INFO:Fitting Model
2024-05-24 19:06:50,423:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:50,453:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:50,501:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:50,925:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:50,964:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:50,990:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:51,019:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:51,047:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:51,213:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:51,379:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:52,300:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,329:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,376:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,794:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,833:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,861:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,890:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:52,916:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:53,077:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:53,239:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:54,095:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,124:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,173:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,563:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,602:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,629:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,655:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,681:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,835:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:54,988:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 338, in _fit
    self.estimator_.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 311, in _fit
    estimator.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:55,692:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:55,718:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:55,759:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,063:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,095:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,117:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,138:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,159:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,279:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,391:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning:


1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 264, in fit
    return self._fit(X, y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\feature_selection\_rfe.py", line 338, in _fit
    self.estimator_.fit(X[:, features], y, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH



2024-05-24 19:06:56,968:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:56,992:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,030:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,329:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,365:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,391:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,415:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,438:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:57,556:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,149:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,174:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,218:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,441:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,475:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,496:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,517:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:58,627:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,112:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,135:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,322:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,353:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,376:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,489:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:06:59,911:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:00,058:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:00,091:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:00,211:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:00,589:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:00,906:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:00,923:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html


2024-05-24 19:07:01,110:INFO:Visual Rendered Successfully
2024-05-24 19:07:01,248:INFO:plot_model() successfully completed......................................
2024-05-24 19:07:01,306:INFO:Initializing plot_model()
2024-05-24 19:07:01,306:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:01,307:INFO:Checking exceptions
2024-05-24 19:07:01,310:INFO:Preloading libraries
2024-05-24 19:07:01,310:INFO:Copying training dataset
2024-05-24 19:07:01,310:INFO:Plot type: feature
2024-05-24 19:07:01,774:INFO:Visual Rendered Successfully
2024-05-24 19:07:01,923:INFO:plot_model() successfully completed......................................
2024-05-24 19:07:01,962:INFO:Initializing plot_model()
2024-05-24 19:07:01,963:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:01,963:INFO:Checking exceptions
2024-05-24 19:07:01,966:INFO:Preloading libraries
2024-05-24 19:07:01,967:INFO:Copying training dataset
2024-05-24 19:07:01,967:INFO:Plot type: feature_all
2024-05-24 19:07:02,635:INFO:Visual Rendered Successfully
2024-05-24 19:07:02,789:INFO:plot_model() successfully completed......................................
2024-05-24 19:07:03,484:INFO:Initializing plot_model()
2024-05-24 19:07:03,486:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:03,486:INFO:Checking exceptions
2024-05-24 19:07:06,867:INFO:Initializing plot_model()
2024-05-24 19:07:06,868:INFO:plot_model(plot=residuals_interactive, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:06,868:INFO:Checking exceptions
2024-05-24 19:07:06,872:INFO:Preloading libraries
2024-05-24 19:07:06,872:INFO:Copying training dataset
2024-05-24 19:07:06,872:INFO:Plot type: residuals_interactive
2024-05-24 19:07:07,533:INFO:Calculated model residuals
2024-05-24 19:07:07,651:INFO:Calculated Tunkey-Anscombe Plot
2024-05-24 19:07:07,701:INFO:Calculated Normal QQ Plot
2024-05-24 19:07:07,813:INFO:Calculated Scale-Location Plot
2024-05-24 19:07:07,931:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2024-05-24 19:07:08,040:INFO:Visual Rendered Successfully
2024-05-24 19:07:08,355:INFO:plot_model() successfully completed......................................
2024-05-24 19:07:09,621:INFO:Initializing plot_model()
2024-05-24 19:07:09,621:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:09,622:INFO:Checking exceptions
2024-05-24 19:07:09,625:INFO:Preloading libraries
2024-05-24 19:07:09,627:INFO:Copying training dataset
2024-05-24 19:07:09,627:INFO:Plot type: residuals
2024-05-24 19:07:10,400:INFO:Fitting Model
2024-05-24 19:07:10,401:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:07:10,439:INFO:Scoring test/hold-out set
2024-05-24 19:07:10,873:INFO:Visual Rendered Successfully
2024-05-24 19:07:11,121:INFO:plot_model() successfully completed......................................
2024-05-24 19:07:15,602:INFO:Initializing plot_model()
2024-05-24 19:07:15,602:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:15,603:INFO:Checking exceptions
2024-05-24 19:07:15,606:INFO:Preloading libraries
2024-05-24 19:07:15,607:INFO:Copying training dataset
2024-05-24 19:07:15,607:INFO:Plot type: parameter
2024-05-24 19:07:15,610:INFO:Visual Rendered Successfully
2024-05-24 19:07:15,915:INFO:plot_model() successfully completed......................................
2024-05-24 19:07:18,569:INFO:Initializing plot_model()
2024-05-24 19:07:18,570:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000020152D1F2B0>, system=True)
2024-05-24 19:07:18,570:INFO:Checking exceptions
2024-05-24 19:07:18,574:INFO:Preloading libraries
2024-05-24 19:07:18,575:INFO:Copying training dataset
2024-05-24 19:07:18,575:INFO:Plot type: error
2024-05-24 19:07:19,284:INFO:Fitting Model
2024-05-24 19:07:19,284:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but HuberRegressor was fitted with feature names


2024-05-24 19:07:19,284:INFO:Scoring test/hold-out set
2024-05-24 19:07:19,526:INFO:Visual Rendered Successfully
2024-05-24 19:07:19,697:INFO:plot_model() successfully completed......................................
2024-05-24 19:08:23,243:INFO:PyCaret RegressionExperiment
2024-05-24 19:08:23,244:INFO:Logging name: reg-default-name
2024-05-24 19:08:23,244:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 19:08:23,244:INFO:version 3.3.2
2024-05-24 19:08:23,244:INFO:Initializing setup()
2024-05-24 19:08:23,244:INFO:self.USI: afc2
2024-05-24 19:08:23,244:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 19:08:23,244:INFO:Checking environment
2024-05-24 19:08:23,244:INFO:python_version: 3.10.14
2024-05-24 19:08:23,244:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 19:08:23,244:INFO:machine: AMD64
2024-05-24 19:08:23,244:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 19:08:23,244:INFO:Memory: svmem(total=16541802496, available=5167521792, percent=68.8, used=11374280704, free=5167521792)
2024-05-24 19:08:23,244:INFO:Physical Core: 6
2024-05-24 19:08:23,244:INFO:Logical Core: 12
2024-05-24 19:08:23,244:INFO:Checking libraries
2024-05-24 19:08:23,244:INFO:System:
2024-05-24 19:08:23,245:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 19:08:23,245:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 19:08:23,245:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 19:08:23,245:INFO:PyCaret required dependencies:
2024-05-24 19:08:23,245:INFO:                 pip: 24.0
2024-05-24 19:08:23,245:INFO:          setuptools: 69.5.1
2024-05-24 19:08:23,245:INFO:             pycaret: 3.3.2
2024-05-24 19:08:23,245:INFO:             IPython: 8.20.0
2024-05-24 19:08:23,245:INFO:          ipywidgets: 8.1.2
2024-05-24 19:08:23,245:INFO:                tqdm: 4.66.4
2024-05-24 19:08:23,245:INFO:               numpy: 1.26.4
2024-05-24 19:08:23,245:INFO:              pandas: 2.1.4
2024-05-24 19:08:23,246:INFO:              jinja2: 3.1.3
2024-05-24 19:08:23,246:INFO:               scipy: 1.11.4
2024-05-24 19:08:23,246:INFO:              joblib: 1.3.2
2024-05-24 19:08:23,246:INFO:             sklearn: 1.4.2
2024-05-24 19:08:23,246:INFO:                pyod: 1.1.3
2024-05-24 19:08:23,246:INFO:            imblearn: 0.12.2
2024-05-24 19:08:23,246:INFO:   category_encoders: 2.6.3
2024-05-24 19:08:23,246:INFO:            lightgbm: 4.3.0
2024-05-24 19:08:23,246:INFO:               numba: 0.59.1
2024-05-24 19:08:23,246:INFO:            requests: 2.32.2
2024-05-24 19:08:23,246:INFO:          matplotlib: 3.7.5
2024-05-24 19:08:23,246:INFO:          scikitplot: 0.3.7
2024-05-24 19:08:23,246:INFO:         yellowbrick: 1.5
2024-05-24 19:08:23,246:INFO:              plotly: 5.22.0
2024-05-24 19:08:23,247:INFO:    plotly-resampler: Not installed
2024-05-24 19:08:23,247:INFO:             kaleido: 0.2.1
2024-05-24 19:08:23,247:INFO:           schemdraw: 0.15
2024-05-24 19:08:23,247:INFO:         statsmodels: 0.14.2
2024-05-24 19:08:23,247:INFO:              sktime: 0.26.0
2024-05-24 19:08:23,247:INFO:               tbats: 1.1.3
2024-05-24 19:08:23,247:INFO:            pmdarima: 2.0.4
2024-05-24 19:08:23,247:INFO:              psutil: 5.9.0
2024-05-24 19:08:23,247:INFO:          markupsafe: 2.1.3
2024-05-24 19:08:23,247:INFO:             pickle5: Not installed
2024-05-24 19:08:23,247:INFO:         cloudpickle: 3.0.0
2024-05-24 19:08:23,247:INFO:         deprecation: 2.1.0
2024-05-24 19:08:23,247:INFO:              xxhash: 3.4.1
2024-05-24 19:08:23,247:INFO:           wurlitzer: Not installed
2024-05-24 19:08:23,248:INFO:PyCaret optional dependencies:
2024-05-24 19:08:23,248:INFO:                shap: Not installed
2024-05-24 19:08:23,248:INFO:           interpret: Not installed
2024-05-24 19:08:23,248:INFO:                umap: Not installed
2024-05-24 19:08:23,248:INFO:     ydata_profiling: Not installed
2024-05-24 19:08:23,248:INFO:  explainerdashboard: Not installed
2024-05-24 19:08:23,249:INFO:             autoviz: Not installed
2024-05-24 19:08:23,249:INFO:           fairlearn: Not installed
2024-05-24 19:08:23,249:INFO:          deepchecks: Not installed
2024-05-24 19:08:23,249:INFO:             xgboost: Not installed
2024-05-24 19:08:23,249:INFO:            catboost: Not installed
2024-05-24 19:08:23,249:INFO:              kmodes: Not installed
2024-05-24 19:08:23,249:INFO:             mlxtend: Not installed
2024-05-24 19:08:23,249:INFO:       statsforecast: Not installed
2024-05-24 19:08:23,249:INFO:        tune_sklearn: Not installed
2024-05-24 19:08:23,249:INFO:                 ray: Not installed
2024-05-24 19:08:23,249:INFO:            hyperopt: Not installed
2024-05-24 19:08:23,249:INFO:              optuna: Not installed
2024-05-24 19:08:23,249:INFO:               skopt: Not installed
2024-05-24 19:08:23,249:INFO:              mlflow: Not installed
2024-05-24 19:08:23,250:INFO:              gradio: Not installed
2024-05-24 19:08:23,250:INFO:             fastapi: Not installed
2024-05-24 19:08:23,250:INFO:             uvicorn: Not installed
2024-05-24 19:08:23,250:INFO:              m2cgen: Not installed
2024-05-24 19:08:23,250:INFO:           evidently: Not installed
2024-05-24 19:08:23,250:INFO:               fugue: Not installed
2024-05-24 19:08:23,250:INFO:           streamlit: Not installed
2024-05-24 19:08:23,250:INFO:             prophet: Not installed
2024-05-24 19:08:23,250:INFO:None
2024-05-24 19:08:23,250:INFO:Set up data.
2024-05-24 19:08:23,263:INFO:Set up folding strategy.
2024-05-24 19:08:23,263:INFO:Set up train/test split.
2024-05-24 19:08:23,270:INFO:Set up index.
2024-05-24 19:08:23,270:INFO:Assigning column types.
2024-05-24 19:08:23,275:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 19:08:23,276:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,281:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,286:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,349:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,397:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,402:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,407:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,521:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 19:08:23,526:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,646:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,651:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,766:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 19:08:23,775:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:23,896:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:23,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,034:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 19:08:24,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,286:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 19:08:24,359:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,483:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:24,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,532:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 19:08:24,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:24,802:INFO:Preparing preprocessing pipeline...
2024-05-24 19:08:24,802:INFO:Set up simple imputation.
2024-05-24 19:08:24,810:INFO:Set up encoding of ordinal features.
2024-05-24 19:08:24,817:INFO:Set up encoding of categorical features.
2024-05-24 19:08:24,817:INFO:Set up polynomial features.
2024-05-24 19:08:24,817:INFO:Set up removing multicollinearity.
2024-05-24 19:08:24,817:INFO:Set up removing outliers.
2024-05-24 19:08:24,817:INFO:Set up PCA.
2024-05-24 19:08:26,564:INFO:Finished creating preprocessing pipeline.
2024-05-24 19:08:26,660:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=8323))),
                ('pca',
                 TransformerWrapper(exclude=[],
                                    transformer=PCA(n_components=10)))])
2024-05-24 19:08:26,660:INFO:Creating final display dataframe.
2024-05-24 19:08:28,705:INFO:Setup _display_container:                     Description             Value
0                    Session id              8323
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape         (197, 11)
5   Transformed train set shape         (135, 11)
6    Transformed test set shape          (62, 11)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21                          PCA              True
22                   PCA method            linear
23               PCA components                10
24               Fold Generator             KFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  reg-default-name
30                          USI              afc2
2024-05-24 19:08:28,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:28,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:28,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:28,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:28,952:INFO:setup() successfully completed in 5.75s...............
2024-05-24 19:08:42,975:INFO:PyCaret RegressionExperiment
2024-05-24 19:08:42,975:INFO:Logging name: reg-default-name
2024-05-24 19:08:42,975:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 19:08:42,975:INFO:version 3.3.2
2024-05-24 19:08:42,975:INFO:Initializing setup()
2024-05-24 19:08:42,975:INFO:self.USI: 425d
2024-05-24 19:08:42,975:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 19:08:42,975:INFO:Checking environment
2024-05-24 19:08:42,975:INFO:python_version: 3.10.14
2024-05-24 19:08:42,975:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 19:08:42,975:INFO:machine: AMD64
2024-05-24 19:08:42,975:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 19:08:42,975:INFO:Memory: svmem(total=16541802496, available=5101649920, percent=69.2, used=11440152576, free=5101649920)
2024-05-24 19:08:42,975:INFO:Physical Core: 6
2024-05-24 19:08:42,975:INFO:Logical Core: 12
2024-05-24 19:08:42,975:INFO:Checking libraries
2024-05-24 19:08:42,975:INFO:System:
2024-05-24 19:08:42,976:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 19:08:42,976:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 19:08:42,976:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 19:08:42,976:INFO:PyCaret required dependencies:
2024-05-24 19:08:42,976:INFO:                 pip: 24.0
2024-05-24 19:08:42,976:INFO:          setuptools: 69.5.1
2024-05-24 19:08:42,976:INFO:             pycaret: 3.3.2
2024-05-24 19:08:42,976:INFO:             IPython: 8.20.0
2024-05-24 19:08:42,976:INFO:          ipywidgets: 8.1.2
2024-05-24 19:08:42,976:INFO:                tqdm: 4.66.4
2024-05-24 19:08:42,976:INFO:               numpy: 1.26.4
2024-05-24 19:08:42,976:INFO:              pandas: 2.1.4
2024-05-24 19:08:42,976:INFO:              jinja2: 3.1.3
2024-05-24 19:08:42,976:INFO:               scipy: 1.11.4
2024-05-24 19:08:42,976:INFO:              joblib: 1.3.2
2024-05-24 19:08:42,976:INFO:             sklearn: 1.4.2
2024-05-24 19:08:42,976:INFO:                pyod: 1.1.3
2024-05-24 19:08:42,976:INFO:            imblearn: 0.12.2
2024-05-24 19:08:42,976:INFO:   category_encoders: 2.6.3
2024-05-24 19:08:42,976:INFO:            lightgbm: 4.3.0
2024-05-24 19:08:42,977:INFO:               numba: 0.59.1
2024-05-24 19:08:42,977:INFO:            requests: 2.32.2
2024-05-24 19:08:42,977:INFO:          matplotlib: 3.7.5
2024-05-24 19:08:42,977:INFO:          scikitplot: 0.3.7
2024-05-24 19:08:42,977:INFO:         yellowbrick: 1.5
2024-05-24 19:08:42,977:INFO:              plotly: 5.22.0
2024-05-24 19:08:42,977:INFO:    plotly-resampler: Not installed
2024-05-24 19:08:42,977:INFO:             kaleido: 0.2.1
2024-05-24 19:08:42,977:INFO:           schemdraw: 0.15
2024-05-24 19:08:42,977:INFO:         statsmodels: 0.14.2
2024-05-24 19:08:42,977:INFO:              sktime: 0.26.0
2024-05-24 19:08:42,977:INFO:               tbats: 1.1.3
2024-05-24 19:08:42,977:INFO:            pmdarima: 2.0.4
2024-05-24 19:08:42,977:INFO:              psutil: 5.9.0
2024-05-24 19:08:42,977:INFO:          markupsafe: 2.1.3
2024-05-24 19:08:42,977:INFO:             pickle5: Not installed
2024-05-24 19:08:42,977:INFO:         cloudpickle: 3.0.0
2024-05-24 19:08:42,977:INFO:         deprecation: 2.1.0
2024-05-24 19:08:42,977:INFO:              xxhash: 3.4.1
2024-05-24 19:08:42,977:INFO:           wurlitzer: Not installed
2024-05-24 19:08:42,977:INFO:PyCaret optional dependencies:
2024-05-24 19:08:42,977:INFO:                shap: Not installed
2024-05-24 19:08:42,977:INFO:           interpret: Not installed
2024-05-24 19:08:42,977:INFO:                umap: Not installed
2024-05-24 19:08:42,978:INFO:     ydata_profiling: Not installed
2024-05-24 19:08:42,978:INFO:  explainerdashboard: Not installed
2024-05-24 19:08:42,978:INFO:             autoviz: Not installed
2024-05-24 19:08:42,978:INFO:           fairlearn: Not installed
2024-05-24 19:08:42,978:INFO:          deepchecks: Not installed
2024-05-24 19:08:42,978:INFO:             xgboost: Not installed
2024-05-24 19:08:42,978:INFO:            catboost: Not installed
2024-05-24 19:08:42,978:INFO:              kmodes: Not installed
2024-05-24 19:08:42,978:INFO:             mlxtend: Not installed
2024-05-24 19:08:42,978:INFO:       statsforecast: Not installed
2024-05-24 19:08:42,978:INFO:        tune_sklearn: Not installed
2024-05-24 19:08:42,978:INFO:                 ray: Not installed
2024-05-24 19:08:42,978:INFO:            hyperopt: Not installed
2024-05-24 19:08:42,978:INFO:              optuna: Not installed
2024-05-24 19:08:42,978:INFO:               skopt: Not installed
2024-05-24 19:08:42,978:INFO:              mlflow: Not installed
2024-05-24 19:08:42,978:INFO:              gradio: Not installed
2024-05-24 19:08:42,978:INFO:             fastapi: Not installed
2024-05-24 19:08:42,978:INFO:             uvicorn: Not installed
2024-05-24 19:08:42,978:INFO:              m2cgen: Not installed
2024-05-24 19:08:42,978:INFO:           evidently: Not installed
2024-05-24 19:08:42,978:INFO:               fugue: Not installed
2024-05-24 19:08:42,978:INFO:           streamlit: Not installed
2024-05-24 19:08:42,978:INFO:             prophet: Not installed
2024-05-24 19:08:42,978:INFO:None
2024-05-24 19:08:42,979:INFO:Set up data.
2024-05-24 19:08:42,989:INFO:Set up folding strategy.
2024-05-24 19:08:42,989:INFO:Set up train/test split.
2024-05-24 19:08:42,997:INFO:Set up index.
2024-05-24 19:08:42,997:INFO:Assigning column types.
2024-05-24 19:08:43,004:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 19:08:43,004:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,010:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,015:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,132:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,137:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,247:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,248:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 19:08:43,253:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,258:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,362:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,367:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,477:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,478:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 19:08:43,488:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,548:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,712:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,714:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 19:08:43,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,955:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:08:43,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:43,956:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 19:08:44,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:44,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,152:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:08:44,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,199:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 19:08:44,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:44,451:INFO:Preparing preprocessing pipeline...
2024-05-24 19:08:44,451:INFO:Set up simple imputation.
2024-05-24 19:08:44,457:INFO:Set up encoding of ordinal features.
2024-05-24 19:08:44,463:INFO:Set up encoding of categorical features.
2024-05-24 19:08:44,464:INFO:Set up polynomial features.
2024-05-24 19:08:44,464:INFO:Set up removing multicollinearity.
2024-05-24 19:08:44,464:INFO:Set up removing outliers.
2024-05-24 19:08:45,799:INFO:Finished creating preprocessing pipeline.
2024-05-24 19:08:45,868:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=7611)))])
2024-05-24 19:08:45,869:INFO:Creating final display dataframe.
2024-05-24 19:08:48,211:INFO:Setup _display_container:                     Description             Value
0                    Session id              7611
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 460)
5   Transformed train set shape        (135, 460)
6    Transformed test set shape         (62, 460)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              425d
2024-05-24 19:08:48,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:48,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:48,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:48,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:08:48,447:INFO:setup() successfully completed in 5.5s...............
2024-05-24 19:08:56,436:INFO:Initializing compare_models()
2024-05-24 19:08:56,437:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 19:08:56,437:INFO:Checking exceptions
2024-05-24 19:08:56,441:INFO:Preparing display monitor
2024-05-24 19:08:56,484:INFO:Initializing Linear Regression
2024-05-24 19:08:56,485:INFO:Total runtime is 8.928775787353516e-06 minutes
2024-05-24 19:08:56,494:INFO:SubProcess create_model() called ==================================
2024-05-24 19:08:56,495:INFO:Initializing create_model()
2024-05-24 19:08:56,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020153064190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:08:56,495:INFO:Checking exceptions
2024-05-24 19:08:56,495:INFO:Importing libraries
2024-05-24 19:08:56,496:INFO:Copying training dataset
2024-05-24 19:08:56,505:INFO:Defining folds
2024-05-24 19:08:56,505:INFO:Declaring metric variables
2024-05-24 19:08:56,511:INFO:Importing untrained model
2024-05-24 19:08:56,519:INFO:Linear Regression Imported successfully
2024-05-24 19:08:56,532:INFO:Starting cross validation
2024-05-24 19:08:56,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:09:02,772:INFO:Calculating mean and std
2024-05-24 19:09:02,773:INFO:Creating metrics dataframe
2024-05-24 19:09:02,777:INFO:Uploading results into container
2024-05-24 19:09:02,777:INFO:Uploading model into container now
2024-05-24 19:09:02,778:INFO:_master_model_container: 1
2024-05-24 19:09:02,778:INFO:_display_container: 2
2024-05-24 19:09:02,778:INFO:LinearRegression(n_jobs=-1)
2024-05-24 19:09:02,779:INFO:create_model() successfully completed......................................
2024-05-24 19:09:02,946:INFO:SubProcess create_model() end ==================================
2024-05-24 19:09:02,947:INFO:Creating metrics dataframe
2024-05-24 19:09:02,954:INFO:Initializing Lasso Regression
2024-05-24 19:09:02,954:INFO:Total runtime is 0.10783453385035197 minutes
2024-05-24 19:09:02,958:INFO:SubProcess create_model() called ==================================
2024-05-24 19:09:02,959:INFO:Initializing create_model()
2024-05-24 19:09:02,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020153064190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:09:02,959:INFO:Checking exceptions
2024-05-24 19:09:02,959:INFO:Importing libraries
2024-05-24 19:09:02,959:INFO:Copying training dataset
2024-05-24 19:09:02,967:INFO:Defining folds
2024-05-24 19:09:02,967:INFO:Declaring metric variables
2024-05-24 19:09:02,971:INFO:Importing untrained model
2024-05-24 19:09:02,976:INFO:Lasso Regression Imported successfully
2024-05-24 19:09:02,984:INFO:Starting cross validation
2024-05-24 19:09:03,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:09:04,954:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e+07, tolerance: 7.959e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:04,982:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+07, tolerance: 7.701e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:04,985:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+07, tolerance: 6.998e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:05,028:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.122e+07, tolerance: 7.358e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:05,031:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.916e+07, tolerance: 7.513e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:05,062:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.067e+07, tolerance: 7.624e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:05,064:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+07, tolerance: 6.518e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:05,065:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.316e+07, tolerance: 7.884e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:06,747:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e+07, tolerance: 7.331e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:06,809:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e+07, tolerance: 6.192e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:09:06,880:INFO:Calculating mean and std
2024-05-24 19:09:06,882:INFO:Creating metrics dataframe
2024-05-24 19:09:06,885:INFO:Uploading results into container
2024-05-24 19:09:06,886:INFO:Uploading model into container now
2024-05-24 19:09:06,886:INFO:_master_model_container: 2
2024-05-24 19:09:06,886:INFO:_display_container: 2
2024-05-24 19:09:06,887:INFO:Lasso(random_state=7611)
2024-05-24 19:09:06,887:INFO:create_model() successfully completed......................................
2024-05-24 19:09:07,074:INFO:SubProcess create_model() end ==================================
2024-05-24 19:09:07,074:INFO:Creating metrics dataframe
2024-05-24 19:09:07,083:INFO:Initializing Ridge Regression
2024-05-24 19:09:07,083:INFO:Total runtime is 0.1766510208447774 minutes
2024-05-24 19:09:07,088:INFO:SubProcess create_model() called ==================================
2024-05-24 19:09:07,088:INFO:Initializing create_model()
2024-05-24 19:09:07,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020153064190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:09:07,088:INFO:Checking exceptions
2024-05-24 19:09:07,089:INFO:Importing libraries
2024-05-24 19:09:07,089:INFO:Copying training dataset
2024-05-24 19:09:07,097:INFO:Defining folds
2024-05-24 19:09:07,097:INFO:Declaring metric variables
2024-05-24 19:09:07,101:INFO:Importing untrained model
2024-05-24 19:09:07,106:INFO:Ridge Regression Imported successfully
2024-05-24 19:09:07,116:INFO:Starting cross validation
2024-05-24 19:09:07,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:09:09,016:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,076:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,083:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,119:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,123:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,125:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:241: LinAlgWarning: Ill-conditioned matrix (rcond=6.91728e-19): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2024-05-24 19:09:09,169:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,170:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,174:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:09:09,267:INFO:Calculating mean and std
2024-05-24 19:09:09,269:INFO:Creating metrics dataframe
2024-05-24 19:09:09,272:INFO:Uploading results into container
2024-05-24 19:09:09,272:INFO:Uploading model into container now
2024-05-24 19:09:09,273:INFO:_master_model_container: 3
2024-05-24 19:09:09,273:INFO:_display_container: 2
2024-05-24 19:09:09,273:INFO:Ridge(random_state=7611)
2024-05-24 19:09:09,274:INFO:create_model() successfully completed......................................
2024-05-24 19:09:09,436:INFO:SubProcess create_model() end ==================================
2024-05-24 19:09:09,436:INFO:Creating metrics dataframe
2024-05-24 19:09:09,443:INFO:Initializing Huber Regressor
2024-05-24 19:09:09,444:INFO:Total runtime is 0.21599600712458292 minutes
2024-05-24 19:09:09,447:INFO:SubProcess create_model() called ==================================
2024-05-24 19:09:09,447:INFO:Initializing create_model()
2024-05-24 19:09:09,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020153064190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:09:09,448:INFO:Checking exceptions
2024-05-24 19:09:09,448:INFO:Importing libraries
2024-05-24 19:09:09,448:INFO:Copying training dataset
2024-05-24 19:09:09,454:INFO:Defining folds
2024-05-24 19:09:09,454:INFO:Declaring metric variables
2024-05-24 19:09:09,458:INFO:Importing untrained model
2024-05-24 19:09:09,463:INFO:Huber Regressor Imported successfully
2024-05-24 19:09:09,471:INFO:Starting cross validation
2024-05-24 19:09:09,496:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:09:11,405:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,423:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,455:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,488:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,509:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,514:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,604:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:09:11,670:INFO:Calculating mean and std
2024-05-24 19:09:11,671:INFO:Creating metrics dataframe
2024-05-24 19:09:11,674:INFO:Uploading results into container
2024-05-24 19:09:11,675:INFO:Uploading model into container now
2024-05-24 19:09:11,675:INFO:_master_model_container: 4
2024-05-24 19:09:11,675:INFO:_display_container: 2
2024-05-24 19:09:11,676:INFO:HuberRegressor()
2024-05-24 19:09:11,676:INFO:create_model() successfully completed......................................
2024-05-24 19:09:11,840:INFO:SubProcess create_model() end ==================================
2024-05-24 19:09:11,840:INFO:Creating metrics dataframe
2024-05-24 19:09:11,849:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 19:09:11,858:INFO:Initializing create_model()
2024-05-24 19:09:11,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, estimator=Lasso(random_state=7611), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:09:11,859:INFO:Checking exceptions
2024-05-24 19:09:11,861:INFO:Importing libraries
2024-05-24 19:09:11,861:INFO:Copying training dataset
2024-05-24 19:09:11,866:INFO:Defining folds
2024-05-24 19:09:11,866:INFO:Declaring metric variables
2024-05-24 19:09:11,866:INFO:Importing untrained model
2024-05-24 19:09:11,866:INFO:Declaring custom model
2024-05-24 19:09:11,867:INFO:Lasso Regression Imported successfully
2024-05-24 19:09:11,885:INFO:Cross validation set to False
2024-05-24 19:09:11,885:INFO:Fitting Model
2024-05-24 19:09:12,849:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.755e+07, tolerance: 7.904e+05


2024-05-24 19:09:12,850:INFO:Lasso(random_state=7611)
2024-05-24 19:09:12,850:INFO:create_model() successfully completed......................................
2024-05-24 19:09:13,027:INFO:_master_model_container: 4
2024-05-24 19:09:13,027:INFO:_display_container: 2
2024-05-24 19:09:13,028:INFO:Lasso(random_state=7611)
2024-05-24 19:09:13,028:INFO:compare_models() successfully completed......................................
2024-05-24 19:09:18,838:INFO:Initializing evaluate_model()
2024-05-24 19:09:18,839:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, estimator=Lasso(random_state=7611), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 19:09:18,851:INFO:Initializing plot_model()
2024-05-24 19:09:18,852:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Lasso(random_state=7611), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, system=True)
2024-05-24 19:09:18,852:INFO:Checking exceptions
2024-05-24 19:09:18,857:INFO:Preloading libraries
2024-05-24 19:09:18,857:INFO:Copying training dataset
2024-05-24 19:09:18,858:INFO:Plot type: pipeline
2024-05-24 19:09:19,100:INFO:Visual Rendered Successfully
2024-05-24 19:09:19,425:INFO:plot_model() successfully completed......................................
2024-05-24 19:09:24,997:INFO:Initializing plot_model()
2024-05-24 19:09:24,997:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Lasso(random_state=7611), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, system=True)
2024-05-24 19:09:24,997:INFO:Checking exceptions
2024-05-24 19:09:25,001:INFO:Preloading libraries
2024-05-24 19:09:25,002:INFO:Copying training dataset
2024-05-24 19:09:25,003:INFO:Plot type: error
2024-05-24 19:09:25,678:INFO:Fitting Model
2024-05-24 19:09:25,679:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but Lasso was fitted with feature names


2024-05-24 19:09:25,679:INFO:Scoring test/hold-out set
2024-05-24 19:09:25,992:INFO:Visual Rendered Successfully
2024-05-24 19:09:26,182:INFO:plot_model() successfully completed......................................
2024-05-24 19:11:10,670:INFO:Initializing plot_model()
2024-05-24 19:11:10,670:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Lasso(random_state=7611), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, system=True)
2024-05-24 19:11:10,670:INFO:Checking exceptions
2024-05-24 19:11:10,673:INFO:Preloading libraries
2024-05-24 19:11:10,674:INFO:Copying training dataset
2024-05-24 19:11:10,674:INFO:Plot type: cooks
2024-05-24 19:11:11,298:INFO:Fitting Model
2024-05-24 19:11:11,428:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pandas\core\arraylike.py:396: RuntimeWarning:

invalid value encountered in sqrt


2024-05-24 19:11:11,631:INFO:Visual Rendered Successfully
2024-05-24 19:11:11,801:INFO:plot_model() successfully completed......................................
2024-05-24 19:12:15,277:INFO:Initializing plot_model()
2024-05-24 19:12:15,278:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Lasso(random_state=7611), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015308E500>, system=True)
2024-05-24 19:12:15,278:INFO:Checking exceptions
2024-05-24 19:12:15,281:INFO:Preloading libraries
2024-05-24 19:12:15,282:INFO:Copying training dataset
2024-05-24 19:12:15,282:INFO:Plot type: pipeline
2024-05-24 19:12:15,485:INFO:Visual Rendered Successfully
2024-05-24 19:12:15,828:INFO:plot_model() successfully completed......................................
2024-05-24 19:57:51,860:INFO:PyCaret RegressionExperiment
2024-05-24 19:57:51,862:INFO:Logging name: reg-default-name
2024-05-24 19:57:51,862:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 19:57:51,862:INFO:version 3.3.2
2024-05-24 19:57:51,862:INFO:Initializing setup()
2024-05-24 19:57:51,863:INFO:self.USI: d557
2024-05-24 19:57:51,863:INFO:self._variable_keys: {'gpu_param', 'y', 'pipeline', 'seed', '_ml_usecase', 'logging_param', 'data', 'exp_name_log', 'n_jobs_param', 'X_train', 'y_test', 'fold_shuffle_param', 'X_test', 'target_param', 'fold_generator', 'gpu_n_jobs_param', 'memory', 'html_param', 'fold_groups_param', 'X', 'transform_target_param', '_available_plots', 'log_plots_param', 'USI', 'exp_id', 'idx', 'y_train'}
2024-05-24 19:57:51,863:INFO:Checking environment
2024-05-24 19:57:51,863:INFO:python_version: 3.10.14
2024-05-24 19:57:51,863:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 19:57:51,863:INFO:machine: AMD64
2024-05-24 19:57:51,864:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 19:57:51,865:INFO:Memory: svmem(total=16541802496, available=4917506048, percent=70.3, used=11624296448, free=4917506048)
2024-05-24 19:57:51,865:INFO:Physical Core: 6
2024-05-24 19:57:51,865:INFO:Logical Core: 12
2024-05-24 19:57:51,866:INFO:Checking libraries
2024-05-24 19:57:51,866:INFO:System:
2024-05-24 19:57:51,866:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 19:57:51,866:INFO:executable: C:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 19:57:51,866:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 19:57:51,866:INFO:PyCaret required dependencies:
2024-05-24 19:57:51,870:INFO:                 pip: 24.0
2024-05-24 19:57:51,871:INFO:          setuptools: 69.5.1
2024-05-24 19:57:51,871:INFO:             pycaret: 3.3.2
2024-05-24 19:57:51,871:INFO:             IPython: 8.20.0
2024-05-24 19:57:51,871:INFO:          ipywidgets: 8.1.2
2024-05-24 19:57:51,871:INFO:                tqdm: 4.66.4
2024-05-24 19:57:51,871:INFO:               numpy: 1.26.4
2024-05-24 19:57:51,871:INFO:              pandas: 2.1.4
2024-05-24 19:57:51,871:INFO:              jinja2: 3.1.3
2024-05-24 19:57:51,871:INFO:               scipy: 1.11.4
2024-05-24 19:57:51,871:INFO:              joblib: 1.3.2
2024-05-24 19:57:51,871:INFO:             sklearn: 1.4.2
2024-05-24 19:57:51,871:INFO:                pyod: 1.1.3
2024-05-24 19:57:51,871:INFO:            imblearn: 0.12.2
2024-05-24 19:57:51,872:INFO:   category_encoders: 2.6.3
2024-05-24 19:57:51,872:INFO:            lightgbm: 4.3.0
2024-05-24 19:57:51,872:INFO:               numba: 0.59.1
2024-05-24 19:57:51,872:INFO:            requests: 2.32.2
2024-05-24 19:57:51,872:INFO:          matplotlib: 3.7.5
2024-05-24 19:57:51,872:INFO:          scikitplot: 0.3.7
2024-05-24 19:57:51,872:INFO:         yellowbrick: 1.5
2024-05-24 19:57:51,872:INFO:              plotly: 5.22.0
2024-05-24 19:57:51,872:INFO:    plotly-resampler: Not installed
2024-05-24 19:57:51,872:INFO:             kaleido: 0.2.1
2024-05-24 19:57:51,872:INFO:           schemdraw: 0.15
2024-05-24 19:57:51,872:INFO:         statsmodels: 0.14.2
2024-05-24 19:57:51,872:INFO:              sktime: 0.26.0
2024-05-24 19:57:51,872:INFO:               tbats: 1.1.3
2024-05-24 19:57:51,872:INFO:            pmdarima: 2.0.4
2024-05-24 19:57:51,873:INFO:              psutil: 5.9.0
2024-05-24 19:57:51,873:INFO:          markupsafe: 2.1.3
2024-05-24 19:57:51,873:INFO:             pickle5: Not installed
2024-05-24 19:57:51,873:INFO:         cloudpickle: 3.0.0
2024-05-24 19:57:51,873:INFO:         deprecation: 2.1.0
2024-05-24 19:57:51,873:INFO:              xxhash: 3.4.1
2024-05-24 19:57:51,873:INFO:           wurlitzer: Not installed
2024-05-24 19:57:51,873:INFO:PyCaret optional dependencies:
2024-05-24 19:57:51,873:INFO:                shap: Not installed
2024-05-24 19:57:51,873:INFO:           interpret: Not installed
2024-05-24 19:57:51,873:INFO:                umap: Not installed
2024-05-24 19:57:51,873:INFO:     ydata_profiling: Not installed
2024-05-24 19:57:51,873:INFO:  explainerdashboard: Not installed
2024-05-24 19:57:51,873:INFO:             autoviz: Not installed
2024-05-24 19:57:51,873:INFO:           fairlearn: Not installed
2024-05-24 19:57:51,874:INFO:          deepchecks: Not installed
2024-05-24 19:57:51,874:INFO:             xgboost: Not installed
2024-05-24 19:57:51,874:INFO:            catboost: Not installed
2024-05-24 19:57:51,874:INFO:              kmodes: Not installed
2024-05-24 19:57:51,874:INFO:             mlxtend: Not installed
2024-05-24 19:57:51,874:INFO:       statsforecast: Not installed
2024-05-24 19:57:51,874:INFO:        tune_sklearn: Not installed
2024-05-24 19:57:51,874:INFO:                 ray: Not installed
2024-05-24 19:57:51,874:INFO:            hyperopt: Not installed
2024-05-24 19:57:51,874:INFO:              optuna: Not installed
2024-05-24 19:57:51,874:INFO:               skopt: Not installed
2024-05-24 19:57:51,874:INFO:              mlflow: Not installed
2024-05-24 19:57:51,874:INFO:              gradio: Not installed
2024-05-24 19:57:51,874:INFO:             fastapi: Not installed
2024-05-24 19:57:51,874:INFO:             uvicorn: Not installed
2024-05-24 19:57:51,875:INFO:              m2cgen: Not installed
2024-05-24 19:57:51,875:INFO:           evidently: Not installed
2024-05-24 19:57:51,875:INFO:               fugue: Not installed
2024-05-24 19:57:51,875:INFO:           streamlit: Not installed
2024-05-24 19:57:51,875:INFO:             prophet: Not installed
2024-05-24 19:57:51,875:INFO:None
2024-05-24 19:57:51,875:INFO:Set up data.
2024-05-24 19:57:51,896:INFO:Set up folding strategy.
2024-05-24 19:57:51,901:INFO:Set up train/test split.
2024-05-24 19:57:51,930:INFO:Set up index.
2024-05-24 19:57:51,930:INFO:Assigning column types.
2024-05-24 19:57:51,939:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 19:57:51,941:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:57:51,948:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:57:51,958:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,144:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,152:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,160:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,321:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,323:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 19:57:52,329:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,498:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,506:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,694:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 19:57:52,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:52,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:52,903:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,064:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,065:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 19:57:53,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,231:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,358:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 19:57:53,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,671:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 19:57:53,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,754:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 19:57:53,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:57:53,995:INFO:Preparing preprocessing pipeline...
2024-05-24 19:57:53,995:INFO:Set up simple imputation.
2024-05-24 19:57:54,003:INFO:Set up encoding of ordinal features.
2024-05-24 19:57:54,013:INFO:Set up encoding of categorical features.
2024-05-24 19:57:54,013:INFO:Set up polynomial features.
2024-05-24 19:57:54,014:INFO:Set up removing multicollinearity.
2024-05-24 19:57:54,014:INFO:Set up removing outliers.
2024-05-24 19:57:55,590:INFO:Finished creating preprocessing pipeline.
2024-05-24 19:57:55,703:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=7429)))])
2024-05-24 19:57:55,703:INFO:Creating final display dataframe.
2024-05-24 19:57:58,734:INFO:Setup _display_container:                     Description             Value
0                    Session id              7429
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 482)
5   Transformed train set shape        (135, 482)
6    Transformed test set shape         (62, 482)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              d557
2024-05-24 19:58:00,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:58:00,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:58:00,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:58:00,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 19:58:00,626:INFO:setup() successfully completed in 8.84s...............
2024-05-24 19:58:00,688:INFO:Initializing compare_models()
2024-05-24 19:58:00,688:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 19:58:00,688:INFO:Checking exceptions
2024-05-24 19:58:00,693:INFO:Preparing display monitor
2024-05-24 19:58:00,724:INFO:Initializing Linear Regression
2024-05-24 19:58:00,724:INFO:Total runtime is 0.0 minutes
2024-05-24 19:58:00,731:INFO:SubProcess create_model() called ==================================
2024-05-24 19:58:00,733:INFO:Initializing create_model()
2024-05-24 19:58:00,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E99B6EFEE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:00,734:INFO:Checking exceptions
2024-05-24 19:58:00,734:INFO:Importing libraries
2024-05-24 19:58:00,734:INFO:Copying training dataset
2024-05-24 19:58:00,745:INFO:Defining folds
2024-05-24 19:58:00,745:INFO:Declaring metric variables
2024-05-24 19:58:00,749:INFO:Importing untrained model
2024-05-24 19:58:00,754:INFO:Linear Regression Imported successfully
2024-05-24 19:58:00,767:INFO:Starting cross validation
2024-05-24 19:58:00,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:06,913:INFO:Calculating mean and std
2024-05-24 19:58:06,916:INFO:Creating metrics dataframe
2024-05-24 19:58:06,919:INFO:Uploading results into container
2024-05-24 19:58:06,919:INFO:Uploading model into container now
2024-05-24 19:58:06,920:INFO:_master_model_container: 1
2024-05-24 19:58:06,920:INFO:_display_container: 2
2024-05-24 19:58:06,921:INFO:LinearRegression(n_jobs=-1)
2024-05-24 19:58:06,921:INFO:create_model() successfully completed......................................
2024-05-24 19:58:07,431:INFO:SubProcess create_model() end ==================================
2024-05-24 19:58:07,431:INFO:Creating metrics dataframe
2024-05-24 19:58:07,440:INFO:Initializing Lasso Regression
2024-05-24 19:58:07,441:INFO:Total runtime is 0.11193888584772746 minutes
2024-05-24 19:58:07,444:INFO:SubProcess create_model() called ==================================
2024-05-24 19:58:07,445:INFO:Initializing create_model()
2024-05-24 19:58:07,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E99B6EFEE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:07,445:INFO:Checking exceptions
2024-05-24 19:58:07,445:INFO:Importing libraries
2024-05-24 19:58:07,445:INFO:Copying training dataset
2024-05-24 19:58:07,451:INFO:Defining folds
2024-05-24 19:58:07,451:INFO:Declaring metric variables
2024-05-24 19:58:07,456:INFO:Importing untrained model
2024-05-24 19:58:07,462:INFO:Lasso Regression Imported successfully
2024-05-24 19:58:07,472:INFO:Starting cross validation
2024-05-24 19:58:07,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:09,421:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+07, tolerance: 7.007e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,424:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+07, tolerance: 6.359e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,447:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+07, tolerance: 5.762e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,467:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+07, tolerance: 6.323e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,473:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+07, tolerance: 7.898e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,521:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+07, tolerance: 8.567e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,537:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e+07, tolerance: 7.149e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:09,555:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+07, tolerance: 5.777e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:11,247:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+07, tolerance: 7.359e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:11,253:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.541e+07, tolerance: 8.304e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 19:58:11,303:INFO:Calculating mean and std
2024-05-24 19:58:11,304:INFO:Creating metrics dataframe
2024-05-24 19:58:11,307:INFO:Uploading results into container
2024-05-24 19:58:11,307:INFO:Uploading model into container now
2024-05-24 19:58:11,308:INFO:_master_model_container: 2
2024-05-24 19:58:11,308:INFO:_display_container: 2
2024-05-24 19:58:11,308:INFO:Lasso(random_state=7429)
2024-05-24 19:58:11,309:INFO:create_model() successfully completed......................................
2024-05-24 19:58:11,429:INFO:SubProcess create_model() end ==================================
2024-05-24 19:58:11,429:INFO:Creating metrics dataframe
2024-05-24 19:58:11,435:INFO:Initializing Ridge Regression
2024-05-24 19:58:11,435:INFO:Total runtime is 0.17852003971735636 minutes
2024-05-24 19:58:11,438:INFO:SubProcess create_model() called ==================================
2024-05-24 19:58:11,438:INFO:Initializing create_model()
2024-05-24 19:58:11,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E99B6EFEE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:11,439:INFO:Checking exceptions
2024-05-24 19:58:11,439:INFO:Importing libraries
2024-05-24 19:58:11,439:INFO:Copying training dataset
2024-05-24 19:58:11,444:INFO:Defining folds
2024-05-24 19:58:11,445:INFO:Declaring metric variables
2024-05-24 19:58:11,449:INFO:Importing untrained model
2024-05-24 19:58:11,453:INFO:Ridge Regression Imported successfully
2024-05-24 19:58:11,463:INFO:Starting cross validation
2024-05-24 19:58:11,489:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:13,353:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,424:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,437:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,462:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,469:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,476:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,486:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,494:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,537:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,595:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 19:58:13,700:INFO:Calculating mean and std
2024-05-24 19:58:13,703:INFO:Creating metrics dataframe
2024-05-24 19:58:13,706:INFO:Uploading results into container
2024-05-24 19:58:13,707:INFO:Uploading model into container now
2024-05-24 19:58:13,708:INFO:_master_model_container: 3
2024-05-24 19:58:13,708:INFO:_display_container: 2
2024-05-24 19:58:13,708:INFO:Ridge(random_state=7429)
2024-05-24 19:58:13,709:INFO:create_model() successfully completed......................................
2024-05-24 19:58:13,844:INFO:SubProcess create_model() end ==================================
2024-05-24 19:58:13,844:INFO:Creating metrics dataframe
2024-05-24 19:58:13,853:INFO:Initializing Huber Regressor
2024-05-24 19:58:13,853:INFO:Total runtime is 0.2188176194826762 minutes
2024-05-24 19:58:13,857:INFO:SubProcess create_model() called ==================================
2024-05-24 19:58:13,858:INFO:Initializing create_model()
2024-05-24 19:58:13,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E99B6EFEE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:13,858:INFO:Checking exceptions
2024-05-24 19:58:13,858:INFO:Importing libraries
2024-05-24 19:58:13,859:INFO:Copying training dataset
2024-05-24 19:58:13,867:INFO:Defining folds
2024-05-24 19:58:13,868:INFO:Declaring metric variables
2024-05-24 19:58:13,872:INFO:Importing untrained model
2024-05-24 19:58:13,875:INFO:Huber Regressor Imported successfully
2024-05-24 19:58:13,884:INFO:Starting cross validation
2024-05-24 19:58:13,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:15,937:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,026:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,072:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,153:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,160:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,201:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,231:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,239:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,341:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:16,482:INFO:Calculating mean and std
2024-05-24 19:58:16,484:INFO:Creating metrics dataframe
2024-05-24 19:58:16,488:INFO:Uploading results into container
2024-05-24 19:58:16,489:INFO:Uploading model into container now
2024-05-24 19:58:16,489:INFO:_master_model_container: 4
2024-05-24 19:58:16,489:INFO:_display_container: 2
2024-05-24 19:58:16,489:INFO:HuberRegressor()
2024-05-24 19:58:16,490:INFO:create_model() successfully completed......................................
2024-05-24 19:58:16,628:INFO:SubProcess create_model() end ==================================
2024-05-24 19:58:16,628:INFO:Creating metrics dataframe
2024-05-24 19:58:16,636:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 19:58:16,648:INFO:Initializing create_model()
2024-05-24 19:58:16,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:16,649:INFO:Checking exceptions
2024-05-24 19:58:16,650:INFO:Importing libraries
2024-05-24 19:58:16,652:INFO:Copying training dataset
2024-05-24 19:58:16,658:INFO:Defining folds
2024-05-24 19:58:16,659:INFO:Declaring metric variables
2024-05-24 19:58:16,659:INFO:Importing untrained model
2024-05-24 19:58:16,659:INFO:Declaring custom model
2024-05-24 19:58:16,659:INFO:Huber Regressor Imported successfully
2024-05-24 19:58:16,687:INFO:Cross validation set to False
2024-05-24 19:58:16,687:INFO:Fitting Model
2024-05-24 19:58:17,842:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:17,843:INFO:HuberRegressor()
2024-05-24 19:58:17,843:INFO:create_model() successfully completed......................................
2024-05-24 19:58:17,972:INFO:_master_model_container: 4
2024-05-24 19:58:17,972:INFO:_display_container: 2
2024-05-24 19:58:17,972:INFO:HuberRegressor()
2024-05-24 19:58:17,973:INFO:compare_models() successfully completed......................................
2024-05-24 19:58:17,986:INFO:Initializing evaluate_model()
2024-05-24 19:58:17,986:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 19:58:18,003:INFO:Initializing plot_model()
2024-05-24 19:58:18,003:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, system=True)
2024-05-24 19:58:18,004:INFO:Checking exceptions
2024-05-24 19:58:18,008:INFO:Preloading libraries
2024-05-24 19:58:18,009:INFO:Copying training dataset
2024-05-24 19:58:18,009:INFO:Plot type: pipeline
2024-05-24 19:58:18,247:INFO:Visual Rendered Successfully
2024-05-24 19:58:18,359:INFO:plot_model() successfully completed......................................
2024-05-24 19:58:18,372:INFO:Initializing create_model()
2024-05-24 19:58:18,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:18,372:INFO:Checking exceptions
2024-05-24 19:58:18,392:INFO:Importing libraries
2024-05-24 19:58:18,393:INFO:Copying training dataset
2024-05-24 19:58:18,401:INFO:Defining folds
2024-05-24 19:58:18,401:INFO:Declaring metric variables
2024-05-24 19:58:18,407:INFO:Importing untrained model
2024-05-24 19:58:18,407:INFO:Declaring custom model
2024-05-24 19:58:18,412:INFO:Huber Regressor Imported successfully
2024-05-24 19:58:18,423:INFO:Starting cross validation
2024-05-24 19:58:18,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:20,284:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,297:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,385:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,396:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,440:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,473:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,485:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,488:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,522:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:20,594:INFO:Calculating mean and std
2024-05-24 19:58:20,596:INFO:Creating metrics dataframe
2024-05-24 19:58:20,603:INFO:Finalizing model
2024-05-24 19:58:21,829:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:21,833:INFO:Uploading results into container
2024-05-24 19:58:21,835:INFO:Uploading model into container now
2024-05-24 19:58:21,845:INFO:_master_model_container: 5
2024-05-24 19:58:21,845:INFO:_display_container: 3
2024-05-24 19:58:21,845:INFO:HuberRegressor()
2024-05-24 19:58:21,845:INFO:create_model() successfully completed......................................
2024-05-24 19:58:21,969:INFO:Initializing tune_model()
2024-05-24 19:58:21,969:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>)
2024-05-24 19:58:21,970:INFO:Checking exceptions
2024-05-24 19:58:21,990:INFO:Copying training dataset
2024-05-24 19:58:21,994:INFO:Checking base model
2024-05-24 19:58:21,995:INFO:Base model : Huber Regressor
2024-05-24 19:58:22,001:INFO:Declaring metric variables
2024-05-24 19:58:22,007:INFO:Defining Hyperparameters
2024-05-24 19:58:22,149:INFO:Tuning with n_jobs=-1
2024-05-24 19:58:22,149:INFO:Initializing RandomizedSearchCV
2024-05-24 19:58:24,232:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,295:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,387:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,438:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,463:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,467:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,548:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,576:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,586:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:24,889:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,487:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,577:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,624:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,695:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,845:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,870:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,925:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:26,961:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:27,222:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:27,252:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:28,571:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:28,592:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:28,799:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:28,875:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:28,941:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:29,040:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:29,103:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:29,200:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:29,415:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:29,490:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:29,561:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:30,960:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:31,109:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:31,216:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:31,381:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:31,472:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:31,546:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:31,711:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,002:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,235:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,240:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,247:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,278:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,343:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,456:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,463:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:33,968:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:34,090:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:34,386:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:35,135:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:35,384:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:35,457:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:35,685:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:36,284:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:36,392:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:36,566:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:37,228:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:37,358:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:37,561:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:37,570:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:37,908:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:37,951:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:38,162:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:38,605:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:39,041:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:39,259:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:39,334:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:39,547:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:39,830:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:40,106:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:40,783:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:41,022:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:41,270:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.2, 'actual_estimator__alpha': 1e-06}
2024-05-24 19:58:41,271:INFO:Hyperparameter search completed
2024-05-24 19:58:41,271:INFO:SubProcess create_model() called ==================================
2024-05-24 19:58:41,272:INFO:Initializing create_model()
2024-05-24 19:58:41,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E9D18F1ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1.2, 'alpha': 1e-06})
2024-05-24 19:58:41,272:INFO:Checking exceptions
2024-05-24 19:58:41,272:INFO:Importing libraries
2024-05-24 19:58:41,272:INFO:Copying training dataset
2024-05-24 19:58:41,280:INFO:Defining folds
2024-05-24 19:58:41,280:INFO:Declaring metric variables
2024-05-24 19:58:41,284:INFO:Importing untrained model
2024-05-24 19:58:41,284:INFO:Declaring custom model
2024-05-24 19:58:41,288:INFO:Huber Regressor Imported successfully
2024-05-24 19:58:41,296:INFO:Starting cross validation
2024-05-24 19:58:41,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:43,067:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:43,140:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:43,240:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:43,310:INFO:Calculating mean and std
2024-05-24 19:58:43,311:INFO:Creating metrics dataframe
2024-05-24 19:58:43,319:INFO:Finalizing model
2024-05-24 19:58:44,360:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:44,367:INFO:Uploading results into container
2024-05-24 19:58:44,368:INFO:Uploading model into container now
2024-05-24 19:58:44,368:INFO:_master_model_container: 6
2024-05-24 19:58:44,368:INFO:_display_container: 4
2024-05-24 19:58:44,368:INFO:HuberRegressor(alpha=1e-06, epsilon=1.2)
2024-05-24 19:58:44,368:INFO:create_model() successfully completed......................................
2024-05-24 19:58:44,482:INFO:SubProcess create_model() end ==================================
2024-05-24 19:58:44,482:INFO:choose_better activated
2024-05-24 19:58:44,485:INFO:SubProcess create_model() called ==================================
2024-05-24 19:58:44,486:INFO:Initializing create_model()
2024-05-24 19:58:44,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E9D177B670>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 19:58:44,486:INFO:Checking exceptions
2024-05-24 19:58:44,489:INFO:Importing libraries
2024-05-24 19:58:44,489:INFO:Copying training dataset
2024-05-24 19:58:44,494:INFO:Defining folds
2024-05-24 19:58:44,494:INFO:Declaring metric variables
2024-05-24 19:58:44,494:INFO:Importing untrained model
2024-05-24 19:58:44,494:INFO:Declaring custom model
2024-05-24 19:58:44,494:INFO:Huber Regressor Imported successfully
2024-05-24 19:58:44,494:INFO:Starting cross validation
2024-05-24 19:58:44,511:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 19:58:46,288:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,310:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,335:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,342:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,415:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,416:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,455:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,473:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,491:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:46,554:INFO:Calculating mean and std
2024-05-24 19:58:46,555:INFO:Creating metrics dataframe
2024-05-24 19:58:46,557:INFO:Finalizing model
2024-05-24 19:58:47,614:WARNING:C:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 19:58:47,614:INFO:Uploading results into container
2024-05-24 19:58:47,615:INFO:Uploading model into container now
2024-05-24 19:58:47,615:INFO:_master_model_container: 7
2024-05-24 19:58:47,615:INFO:_display_container: 5
2024-05-24 19:58:47,616:INFO:HuberRegressor()
2024-05-24 19:58:47,616:INFO:create_model() successfully completed......................................
2024-05-24 19:58:47,721:INFO:SubProcess create_model() end ==================================
2024-05-24 19:58:47,721:INFO:HuberRegressor() result for R2 is 0.4527
2024-05-24 19:58:47,721:INFO:HuberRegressor(alpha=1e-06, epsilon=1.2) result for R2 is 0.4795
2024-05-24 19:58:47,721:INFO:HuberRegressor(alpha=1e-06, epsilon=1.2) is best model
2024-05-24 19:58:47,721:INFO:choose_better completed
2024-05-24 19:58:47,731:INFO:_master_model_container: 7
2024-05-24 19:58:47,731:INFO:_display_container: 4
2024-05-24 19:58:47,732:INFO:HuberRegressor(alpha=1e-06, epsilon=1.2)
2024-05-24 19:58:47,732:INFO:tune_model() successfully completed......................................
2024-05-24 20:01:39,344:INFO:PyCaret RegressionExperiment
2024-05-24 20:01:39,344:INFO:Logging name: reg-default-name
2024-05-24 20:01:39,344:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 20:01:39,344:INFO:version 3.3.2
2024-05-24 20:01:39,344:INFO:Initializing setup()
2024-05-24 20:01:39,345:INFO:self.USI: b81e
2024-05-24 20:01:39,345:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 20:01:39,345:INFO:Checking environment
2024-05-24 20:01:39,345:INFO:python_version: 3.10.14
2024-05-24 20:01:39,345:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 20:01:39,345:INFO:machine: AMD64
2024-05-24 20:01:39,345:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 20:01:39,345:INFO:Memory: svmem(total=16541802496, available=2376179712, percent=85.6, used=14165622784, free=2376179712)
2024-05-24 20:01:39,345:INFO:Physical Core: 6
2024-05-24 20:01:39,345:INFO:Logical Core: 12
2024-05-24 20:01:39,345:INFO:Checking libraries
2024-05-24 20:01:39,346:INFO:System:
2024-05-24 20:01:39,346:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 20:01:39,346:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 20:01:39,346:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 20:01:39,346:INFO:PyCaret required dependencies:
2024-05-24 20:01:39,346:INFO:                 pip: 24.0
2024-05-24 20:01:39,346:INFO:          setuptools: 69.5.1
2024-05-24 20:01:39,346:INFO:             pycaret: 3.3.2
2024-05-24 20:01:39,346:INFO:             IPython: 8.20.0
2024-05-24 20:01:39,346:INFO:          ipywidgets: 8.1.2
2024-05-24 20:01:39,346:INFO:                tqdm: 4.66.4
2024-05-24 20:01:39,346:INFO:               numpy: 1.26.4
2024-05-24 20:01:39,346:INFO:              pandas: 2.1.4
2024-05-24 20:01:39,346:INFO:              jinja2: 3.1.3
2024-05-24 20:01:39,346:INFO:               scipy: 1.11.4
2024-05-24 20:01:39,346:INFO:              joblib: 1.3.2
2024-05-24 20:01:39,347:INFO:             sklearn: 1.4.2
2024-05-24 20:01:39,347:INFO:                pyod: 1.1.3
2024-05-24 20:01:39,347:INFO:            imblearn: 0.12.2
2024-05-24 20:01:39,347:INFO:   category_encoders: 2.6.3
2024-05-24 20:01:39,347:INFO:            lightgbm: 4.3.0
2024-05-24 20:01:39,347:INFO:               numba: 0.59.1
2024-05-24 20:01:39,347:INFO:            requests: 2.32.2
2024-05-24 20:01:39,347:INFO:          matplotlib: 3.7.5
2024-05-24 20:01:39,347:INFO:          scikitplot: 0.3.7
2024-05-24 20:01:39,347:INFO:         yellowbrick: 1.5
2024-05-24 20:01:39,347:INFO:              plotly: 5.22.0
2024-05-24 20:01:39,347:INFO:    plotly-resampler: Not installed
2024-05-24 20:01:39,347:INFO:             kaleido: 0.2.1
2024-05-24 20:01:39,347:INFO:           schemdraw: 0.15
2024-05-24 20:01:39,347:INFO:         statsmodels: 0.14.2
2024-05-24 20:01:39,347:INFO:              sktime: 0.26.0
2024-05-24 20:01:39,348:INFO:               tbats: 1.1.3
2024-05-24 20:01:39,348:INFO:            pmdarima: 2.0.4
2024-05-24 20:01:39,348:INFO:              psutil: 5.9.0
2024-05-24 20:01:39,348:INFO:          markupsafe: 2.1.3
2024-05-24 20:01:39,348:INFO:             pickle5: Not installed
2024-05-24 20:01:39,348:INFO:         cloudpickle: 3.0.0
2024-05-24 20:01:39,348:INFO:         deprecation: 2.1.0
2024-05-24 20:01:39,348:INFO:              xxhash: 3.4.1
2024-05-24 20:01:39,348:INFO:           wurlitzer: Not installed
2024-05-24 20:01:39,349:INFO:PyCaret optional dependencies:
2024-05-24 20:01:39,349:INFO:                shap: Not installed
2024-05-24 20:01:39,349:INFO:           interpret: Not installed
2024-05-24 20:01:39,349:INFO:                umap: Not installed
2024-05-24 20:01:39,349:INFO:     ydata_profiling: Not installed
2024-05-24 20:01:39,349:INFO:  explainerdashboard: Not installed
2024-05-24 20:01:39,349:INFO:             autoviz: Not installed
2024-05-24 20:01:39,349:INFO:           fairlearn: Not installed
2024-05-24 20:01:39,349:INFO:          deepchecks: Not installed
2024-05-24 20:01:39,349:INFO:             xgboost: Not installed
2024-05-24 20:01:39,349:INFO:            catboost: Not installed
2024-05-24 20:01:39,349:INFO:              kmodes: Not installed
2024-05-24 20:01:39,349:INFO:             mlxtend: Not installed
2024-05-24 20:01:39,349:INFO:       statsforecast: Not installed
2024-05-24 20:01:39,349:INFO:        tune_sklearn: Not installed
2024-05-24 20:01:39,350:INFO:                 ray: Not installed
2024-05-24 20:01:39,350:INFO:            hyperopt: Not installed
2024-05-24 20:01:39,350:INFO:              optuna: Not installed
2024-05-24 20:01:39,350:INFO:               skopt: Not installed
2024-05-24 20:01:39,350:INFO:              mlflow: Not installed
2024-05-24 20:01:39,350:INFO:              gradio: Not installed
2024-05-24 20:01:39,350:INFO:             fastapi: Not installed
2024-05-24 20:01:39,350:INFO:             uvicorn: Not installed
2024-05-24 20:01:39,350:INFO:              m2cgen: Not installed
2024-05-24 20:01:39,350:INFO:           evidently: Not installed
2024-05-24 20:01:39,350:INFO:               fugue: Not installed
2024-05-24 20:01:39,350:INFO:           streamlit: Not installed
2024-05-24 20:01:39,350:INFO:             prophet: Not installed
2024-05-24 20:01:39,350:INFO:None
2024-05-24 20:01:39,350:INFO:Set up data.
2024-05-24 20:01:39,356:INFO:Set up folding strategy.
2024-05-24 20:01:39,357:INFO:Set up train/test split.
2024-05-24 20:01:39,360:INFO:Set up index.
2024-05-24 20:01:39,361:INFO:Assigning column types.
2024-05-24 20:01:39,364:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 20:01:39,364:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,369:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,374:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,483:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,485:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,490:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,602:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 20:01:39,607:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,611:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,723:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,727:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,838:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 20:01:39,847:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,954:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:39,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:39,964:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,082:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 20:01:40,150:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,196:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,311:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 20:01:40,378:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,491:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 20:01:40,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,570:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 20:01:40,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:40,803:INFO:Preparing preprocessing pipeline...
2024-05-24 20:01:40,804:INFO:Set up simple imputation.
2024-05-24 20:01:40,804:INFO:Set up polynomial features.
2024-05-24 20:01:40,804:INFO:Set up removing multicollinearity.
2024-05-24 20:01:40,804:INFO:Set up removing outliers.
2024-05-24 20:01:40,853:INFO:Finished creating preprocessing pipeline.
2024-05-24 20:01:40,861:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['curbweight', 'cylindernumber',
                                             'carvolume', 'enginepower',
                                             'averagempg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=8518)))])
2024-05-24 20:01:40,862:INFO:Creating final display dataframe.
2024-05-24 20:01:41,791:INFO:Setup _display_container:                     Description             Value
0                    Session id              8518
1                        Target             price
2                   Target type        Regression
3           Original data shape          (183, 6)
4        Transformed data shape          (176, 8)
5   Transformed train set shape          (121, 8)
6    Transformed test set shape           (55, 8)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              b81e
2024-05-24 20:01:41,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:41,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:42,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:42,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 20:01:42,032:INFO:setup() successfully completed in 2.75s...............
2024-05-24 20:01:53,734:INFO:Initializing compare_models()
2024-05-24 20:01:53,734:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 20:01:53,734:INFO:Checking exceptions
2024-05-24 20:01:53,738:INFO:Preparing display monitor
2024-05-24 20:01:53,780:INFO:Initializing Linear Regression
2024-05-24 20:01:53,780:INFO:Total runtime is 0.0 minutes
2024-05-24 20:01:53,788:INFO:SubProcess create_model() called ==================================
2024-05-24 20:01:53,788:INFO:Initializing create_model()
2024-05-24 20:01:53,789:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015BED2050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 20:01:53,789:INFO:Checking exceptions
2024-05-24 20:01:53,789:INFO:Importing libraries
2024-05-24 20:01:53,789:INFO:Copying training dataset
2024-05-24 20:01:53,796:INFO:Defining folds
2024-05-24 20:01:53,796:INFO:Declaring metric variables
2024-05-24 20:01:53,802:INFO:Importing untrained model
2024-05-24 20:01:53,811:INFO:Linear Regression Imported successfully
2024-05-24 20:01:53,826:INFO:Starting cross validation
2024-05-24 20:01:53,843:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 20:01:58,688:INFO:Calculating mean and std
2024-05-24 20:01:58,689:INFO:Creating metrics dataframe
2024-05-24 20:01:58,693:INFO:Uploading results into container
2024-05-24 20:01:58,693:INFO:Uploading model into container now
2024-05-24 20:01:58,694:INFO:_master_model_container: 1
2024-05-24 20:01:58,694:INFO:_display_container: 2
2024-05-24 20:01:58,694:INFO:LinearRegression(n_jobs=-1)
2024-05-24 20:01:58,694:INFO:create_model() successfully completed......................................
2024-05-24 20:01:58,906:INFO:SubProcess create_model() end ==================================
2024-05-24 20:01:58,907:INFO:Creating metrics dataframe
2024-05-24 20:01:58,916:INFO:Initializing Lasso Regression
2024-05-24 20:01:58,916:INFO:Total runtime is 0.08559902509053548 minutes
2024-05-24 20:01:58,922:INFO:SubProcess create_model() called ==================================
2024-05-24 20:01:58,922:INFO:Initializing create_model()
2024-05-24 20:01:58,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015BED2050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 20:01:58,922:INFO:Checking exceptions
2024-05-24 20:01:58,922:INFO:Importing libraries
2024-05-24 20:01:58,922:INFO:Copying training dataset
2024-05-24 20:01:58,926:INFO:Defining folds
2024-05-24 20:01:58,926:INFO:Declaring metric variables
2024-05-24 20:01:58,932:INFO:Importing untrained model
2024-05-24 20:01:58,937:INFO:Lasso Regression Imported successfully
2024-05-24 20:01:58,946:INFO:Starting cross validation
2024-05-24 20:01:58,963:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 20:01:59,291:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+08, tolerance: 2.482e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:01:59,293:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+08, tolerance: 2.459e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:01:59,312:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e+08, tolerance: 2.415e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:01:59,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+08, tolerance: 2.564e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:01:59,344:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+08, tolerance: 2.330e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:01:59,363:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+08, tolerance: 2.070e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:01:59,372:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+08, tolerance: 2.417e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:02:01,297:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+08, tolerance: 2.401e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:02:01,322:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+08, tolerance: 2.390e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 20:02:01,350:INFO:Calculating mean and std
2024-05-24 20:02:01,351:INFO:Creating metrics dataframe
2024-05-24 20:02:01,353:INFO:Uploading results into container
2024-05-24 20:02:01,354:INFO:Uploading model into container now
2024-05-24 20:02:01,354:INFO:_master_model_container: 2
2024-05-24 20:02:01,354:INFO:_display_container: 2
2024-05-24 20:02:01,354:INFO:Lasso(random_state=8518)
2024-05-24 20:02:01,354:INFO:create_model() successfully completed......................................
2024-05-24 20:02:01,537:INFO:SubProcess create_model() end ==================================
2024-05-24 20:02:01,537:INFO:Creating metrics dataframe
2024-05-24 20:02:01,546:INFO:Initializing Ridge Regression
2024-05-24 20:02:01,546:INFO:Total runtime is 0.12943434317906696 minutes
2024-05-24 20:02:01,550:INFO:SubProcess create_model() called ==================================
2024-05-24 20:02:01,550:INFO:Initializing create_model()
2024-05-24 20:02:01,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015BED2050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 20:02:01,550:INFO:Checking exceptions
2024-05-24 20:02:01,550:INFO:Importing libraries
2024-05-24 20:02:01,551:INFO:Copying training dataset
2024-05-24 20:02:01,554:INFO:Defining folds
2024-05-24 20:02:01,554:INFO:Declaring metric variables
2024-05-24 20:02:01,558:INFO:Importing untrained model
2024-05-24 20:02:01,561:INFO:Ridge Regression Imported successfully
2024-05-24 20:02:01,569:INFO:Starting cross validation
2024-05-24 20:02:01,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 20:02:01,925:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.14553e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-24 20:02:01,939:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.61334e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-24 20:02:01,940:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=9.06949e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-24 20:02:01,947:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=8.23113e-21): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-24 20:02:02,000:INFO:Calculating mean and std
2024-05-24 20:02:02,001:INFO:Creating metrics dataframe
2024-05-24 20:02:02,005:INFO:Uploading results into container
2024-05-24 20:02:02,005:INFO:Uploading model into container now
2024-05-24 20:02:02,006:INFO:_master_model_container: 3
2024-05-24 20:02:02,006:INFO:_display_container: 2
2024-05-24 20:02:02,006:INFO:Ridge(random_state=8518)
2024-05-24 20:02:02,006:INFO:create_model() successfully completed......................................
2024-05-24 20:02:02,179:INFO:SubProcess create_model() end ==================================
2024-05-24 20:02:02,179:INFO:Creating metrics dataframe
2024-05-24 20:02:02,187:INFO:Initializing Huber Regressor
2024-05-24 20:02:02,187:INFO:Total runtime is 0.14011569023132323 minutes
2024-05-24 20:02:02,191:INFO:SubProcess create_model() called ==================================
2024-05-24 20:02:02,191:INFO:Initializing create_model()
2024-05-24 20:02:02,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015BED2050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 20:02:02,192:INFO:Checking exceptions
2024-05-24 20:02:02,192:INFO:Importing libraries
2024-05-24 20:02:02,192:INFO:Copying training dataset
2024-05-24 20:02:02,196:INFO:Defining folds
2024-05-24 20:02:02,196:INFO:Declaring metric variables
2024-05-24 20:02:02,201:INFO:Importing untrained model
2024-05-24 20:02:02,206:INFO:Huber Regressor Imported successfully
2024-05-24 20:02:02,215:INFO:Starting cross validation
2024-05-24 20:02:02,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 20:02:02,573:INFO:Calculating mean and std
2024-05-24 20:02:02,574:INFO:Creating metrics dataframe
2024-05-24 20:02:02,576:INFO:Uploading results into container
2024-05-24 20:02:02,576:INFO:Uploading model into container now
2024-05-24 20:02:02,577:INFO:_master_model_container: 4
2024-05-24 20:02:02,577:INFO:_display_container: 2
2024-05-24 20:02:02,577:INFO:HuberRegressor()
2024-05-24 20:02:02,577:INFO:create_model() successfully completed......................................
2024-05-24 20:02:02,754:INFO:SubProcess create_model() end ==================================
2024-05-24 20:02:02,754:INFO:Creating metrics dataframe
2024-05-24 20:02:02,763:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 20:02:02,775:INFO:Initializing create_model()
2024-05-24 20:02:02,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 20:02:02,775:INFO:Checking exceptions
2024-05-24 20:02:02,777:INFO:Importing libraries
2024-05-24 20:02:02,777:INFO:Copying training dataset
2024-05-24 20:02:02,781:INFO:Defining folds
2024-05-24 20:02:02,782:INFO:Declaring metric variables
2024-05-24 20:02:02,782:INFO:Importing untrained model
2024-05-24 20:02:02,782:INFO:Declaring custom model
2024-05-24 20:02:02,783:INFO:Linear Regression Imported successfully
2024-05-24 20:02:02,792:INFO:Cross validation set to False
2024-05-24 20:02:02,792:INFO:Fitting Model
2024-05-24 20:02:03,144:INFO:LinearRegression(n_jobs=-1)
2024-05-24 20:02:03,145:INFO:create_model() successfully completed......................................
2024-05-24 20:02:03,567:INFO:_master_model_container: 4
2024-05-24 20:02:03,567:INFO:_display_container: 2
2024-05-24 20:02:03,567:INFO:LinearRegression(n_jobs=-1)
2024-05-24 20:02:03,567:INFO:compare_models() successfully completed......................................
2024-05-24 20:02:13,282:INFO:Initializing evaluate_model()
2024-05-24 20:02:13,282:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 20:02:13,293:INFO:Initializing plot_model()
2024-05-24 20:02:13,293:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:02:13,293:INFO:Checking exceptions
2024-05-24 20:02:13,295:INFO:Preloading libraries
2024-05-24 20:02:13,296:INFO:Copying training dataset
2024-05-24 20:02:13,296:INFO:Plot type: pipeline
2024-05-24 20:02:13,453:INFO:Visual Rendered Successfully
2024-05-24 20:02:13,776:INFO:plot_model() successfully completed......................................
2024-05-24 20:02:17,046:INFO:Initializing plot_model()
2024-05-24 20:02:17,046:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:02:17,046:INFO:Checking exceptions
2024-05-24 20:02:17,048:INFO:Preloading libraries
2024-05-24 20:02:17,049:INFO:Copying training dataset
2024-05-24 20:02:17,049:INFO:Plot type: error
2024-05-24 20:02:17,357:INFO:Fitting Model
2024-05-24 20:02:17,358:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2024-05-24 20:02:17,358:INFO:Scoring test/hold-out set
2024-05-24 20:02:17,582:INFO:Visual Rendered Successfully
2024-05-24 20:02:17,898:INFO:plot_model() successfully completed......................................
2024-05-24 20:02:28,112:INFO:Initializing plot_model()
2024-05-24 20:02:28,112:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:02:28,113:INFO:Checking exceptions
2024-05-24 20:02:28,115:INFO:Preloading libraries
2024-05-24 20:02:28,116:INFO:Copying training dataset
2024-05-24 20:02:28,116:INFO:Plot type: feature
2024-05-24 20:02:28,385:INFO:Visual Rendered Successfully
2024-05-24 20:02:28,748:INFO:plot_model() successfully completed......................................
2024-05-24 20:03:06,198:INFO:Initializing plot_model()
2024-05-24 20:03:06,199:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:06,199:INFO:Checking exceptions
2024-05-24 20:03:06,201:INFO:Preloading libraries
2024-05-24 20:03:06,202:INFO:Copying training dataset
2024-05-24 20:03:06,202:INFO:Plot type: feature_all
2024-05-24 20:03:06,480:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning:

divide by zero encountered in scalar divide


2024-05-24 20:03:06,480:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning:

divide by zero encountered in scalar divide


2024-05-24 20:03:06,480:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\matplotlib\patches.py:739: RuntimeWarning:

invalid value encountered in scalar add


2024-05-24 20:03:06,481:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning:

invalid value encountered in scalar add


2024-05-24 20:03:06,515:INFO:Visual Rendered Successfully
2024-05-24 20:03:06,687:INFO:plot_model() successfully completed......................................
2024-05-24 20:03:09,480:INFO:Initializing plot_model()
2024-05-24 20:03:09,480:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:09,481:INFO:Checking exceptions
2024-05-24 20:03:12,866:INFO:Initializing plot_model()
2024-05-24 20:03:12,866:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:12,867:INFO:Checking exceptions
2024-05-24 20:03:12,869:INFO:Preloading libraries
2024-05-24 20:03:12,869:INFO:Copying training dataset
2024-05-24 20:03:12,869:INFO:Plot type: learning
2024-05-24 20:03:13,153:INFO:Fitting Model
2024-05-24 20:03:13,515:INFO:Visual Rendered Successfully
2024-05-24 20:03:13,825:INFO:plot_model() successfully completed......................................
2024-05-24 20:03:30,339:INFO:Initializing plot_model()
2024-05-24 20:03:30,339:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:30,339:INFO:Checking exceptions
2024-05-24 20:03:30,343:INFO:Preloading libraries
2024-05-24 20:03:30,343:INFO:Copying training dataset
2024-05-24 20:03:30,343:INFO:Plot type: manifold
2024-05-24 20:03:30,687:INFO:Fitting & Transforming Model
2024-05-24 20:03:31,386:INFO:Visual Rendered Successfully
2024-05-24 20:03:31,729:INFO:plot_model() successfully completed......................................
2024-05-24 20:03:38,938:INFO:Initializing plot_model()
2024-05-24 20:03:38,938:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:38,938:INFO:Checking exceptions
2024-05-24 20:03:38,943:INFO:Preloading libraries
2024-05-24 20:03:38,943:INFO:Copying training dataset
2024-05-24 20:03:38,943:INFO:Plot type: vc
2024-05-24 20:03:38,943:INFO:Determining param_name
2024-05-24 20:03:41,245:INFO:Initializing plot_model()
2024-05-24 20:03:41,245:INFO:plot_model(plot=learning, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:41,245:INFO:Checking exceptions
2024-05-24 20:03:41,247:INFO:Preloading libraries
2024-05-24 20:03:41,248:INFO:Copying training dataset
2024-05-24 20:03:41,248:INFO:Plot type: learning
2024-05-24 20:03:41,538:INFO:Fitting Model
2024-05-24 20:03:41,954:INFO:Visual Rendered Successfully
2024-05-24 20:03:42,314:INFO:plot_model() successfully completed......................................
2024-05-24 20:03:44,194:INFO:Initializing plot_model()
2024-05-24 20:03:44,194:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:44,194:INFO:Checking exceptions
2024-05-24 20:03:44,197:INFO:Preloading libraries
2024-05-24 20:03:44,197:INFO:Copying training dataset
2024-05-24 20:03:44,197:INFO:Plot type: rfe
2024-05-24 20:03:44,549:INFO:Fitting Model
2024-05-24 20:03:45,122:INFO:Visual Rendered Successfully
2024-05-24 20:03:45,297:INFO:plot_model() successfully completed......................................
2024-05-24 20:03:57,587:INFO:Initializing plot_model()
2024-05-24 20:03:57,587:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:03:57,588:INFO:Checking exceptions
2024-05-24 20:03:57,591:INFO:Preloading libraries
2024-05-24 20:03:57,592:INFO:Copying training dataset
2024-05-24 20:03:57,592:INFO:Plot type: error
2024-05-24 20:03:57,877:INFO:Fitting Model
2024-05-24 20:03:57,877:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py:493: UserWarning:

X does not have valid feature names, but LinearRegression was fitted with feature names


2024-05-24 20:03:57,878:INFO:Scoring test/hold-out set
2024-05-24 20:03:58,090:INFO:Visual Rendered Successfully
2024-05-24 20:03:58,375:INFO:plot_model() successfully completed......................................
2024-05-24 20:04:03,403:INFO:Initializing plot_model()
2024-05-24 20:04:03,403:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, system=True)
2024-05-24 20:04:03,403:INFO:Checking exceptions
2024-05-24 20:04:03,406:INFO:Preloading libraries
2024-05-24 20:04:03,406:INFO:Copying training dataset
2024-05-24 20:04:03,406:INFO:Plot type: feature
2024-05-24 20:04:03,694:INFO:Visual Rendered Successfully
2024-05-24 20:04:04,027:INFO:plot_model() successfully completed......................................
2024-05-24 20:05:05,800:INFO:Initializing tune_model()
2024-05-24 20:05:05,800:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>)
2024-05-24 20:05:05,801:INFO:Checking exceptions
2024-05-24 20:05:05,830:INFO:Copying training dataset
2024-05-24 20:05:05,834:INFO:Checking base model
2024-05-24 20:05:05,834:INFO:Base model : Linear Regression
2024-05-24 20:05:05,841:INFO:Declaring metric variables
2024-05-24 20:05:05,848:INFO:Defining Hyperparameters
2024-05-24 20:05:05,849:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2024-05-24 20:05:06,331:INFO:Tuning with n_jobs=-1
2024-05-24 20:05:06,331:INFO:Initializing GridSearchCV
2024-05-24 20:05:06,983:INFO:best_params: {'actual_estimator__fit_intercept': False}
2024-05-24 20:05:06,983:INFO:Hyperparameter search completed
2024-05-24 20:05:06,984:INFO:SubProcess create_model() called ==================================
2024-05-24 20:05:06,984:INFO:Initializing create_model()
2024-05-24 20:05:06,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201530E4EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False})
2024-05-24 20:05:06,985:INFO:Checking exceptions
2024-05-24 20:05:06,985:INFO:Importing libraries
2024-05-24 20:05:06,985:INFO:Copying training dataset
2024-05-24 20:05:06,989:INFO:Defining folds
2024-05-24 20:05:06,990:INFO:Declaring metric variables
2024-05-24 20:05:06,994:INFO:Importing untrained model
2024-05-24 20:05:06,994:INFO:Declaring custom model
2024-05-24 20:05:06,999:INFO:Linear Regression Imported successfully
2024-05-24 20:05:07,008:INFO:Starting cross validation
2024-05-24 20:05:07,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 20:05:07,359:INFO:Calculating mean and std
2024-05-24 20:05:07,360:INFO:Creating metrics dataframe
2024-05-24 20:05:07,366:INFO:Finalizing model
2024-05-24 20:05:07,531:INFO:Uploading results into container
2024-05-24 20:05:07,532:INFO:Uploading model into container now
2024-05-24 20:05:07,534:INFO:_master_model_container: 5
2024-05-24 20:05:07,534:INFO:_display_container: 3
2024-05-24 20:05:07,534:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2024-05-24 20:05:07,534:INFO:create_model() successfully completed......................................
2024-05-24 20:05:07,743:INFO:SubProcess create_model() end ==================================
2024-05-24 20:05:07,743:INFO:choose_better activated
2024-05-24 20:05:07,747:INFO:SubProcess create_model() called ==================================
2024-05-24 20:05:07,748:INFO:Initializing create_model()
2024-05-24 20:05:07,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015BD95AB0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 20:05:07,748:INFO:Checking exceptions
2024-05-24 20:05:07,750:INFO:Importing libraries
2024-05-24 20:05:07,750:INFO:Copying training dataset
2024-05-24 20:05:07,755:INFO:Defining folds
2024-05-24 20:05:07,755:INFO:Declaring metric variables
2024-05-24 20:05:07,755:INFO:Importing untrained model
2024-05-24 20:05:07,755:INFO:Declaring custom model
2024-05-24 20:05:07,756:INFO:Linear Regression Imported successfully
2024-05-24 20:05:07,756:INFO:Starting cross validation
2024-05-24 20:05:07,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 20:05:08,093:INFO:Calculating mean and std
2024-05-24 20:05:08,094:INFO:Creating metrics dataframe
2024-05-24 20:05:08,096:INFO:Finalizing model
2024-05-24 20:05:08,240:INFO:Uploading results into container
2024-05-24 20:05:08,241:INFO:Uploading model into container now
2024-05-24 20:05:08,241:INFO:_master_model_container: 6
2024-05-24 20:05:08,241:INFO:_display_container: 4
2024-05-24 20:05:08,241:INFO:LinearRegression(n_jobs=-1)
2024-05-24 20:05:08,241:INFO:create_model() successfully completed......................................
2024-05-24 20:05:08,426:INFO:SubProcess create_model() end ==================================
2024-05-24 20:05:08,426:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.847
2024-05-24 20:05:08,427:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) result for R2 is 0.8501
2024-05-24 20:05:08,427:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) is best model
2024-05-24 20:05:08,427:INFO:choose_better completed
2024-05-24 20:05:08,441:INFO:_master_model_container: 6
2024-05-24 20:05:08,442:INFO:_display_container: 3
2024-05-24 20:05:08,442:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2024-05-24 20:05:08,442:INFO:tune_model() successfully completed......................................
2024-05-24 20:09:13,146:ERROR:
'explainerdashboard' is a soft dependency and not included in the pycaret installation. Please run: `pip install explainerdashboard` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-05-24 22:47:28,158:INFO:PyCaret RegressionExperiment
2024-05-24 22:47:28,159:INFO:Logging name: reg-default-name
2024-05-24 22:47:28,159:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 22:47:28,161:INFO:version 3.3.2
2024-05-24 22:47:28,161:INFO:Initializing setup()
2024-05-24 22:47:28,161:INFO:self.USI: 4a19
2024-05-24 22:47:28,161:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 22:47:28,161:INFO:Checking environment
2024-05-24 22:47:28,162:INFO:python_version: 3.10.14
2024-05-24 22:47:28,162:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 22:47:28,162:INFO:machine: AMD64
2024-05-24 22:47:28,162:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 22:47:28,163:INFO:Memory: svmem(total=16541802496, available=2278092800, percent=86.2, used=14263709696, free=2278092800)
2024-05-24 22:47:28,163:INFO:Physical Core: 6
2024-05-24 22:47:28,164:INFO:Logical Core: 12
2024-05-24 22:47:28,164:INFO:Checking libraries
2024-05-24 22:47:28,164:INFO:System:
2024-05-24 22:47:28,164:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 22:47:28,164:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 22:47:28,164:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 22:47:28,164:INFO:PyCaret required dependencies:
2024-05-24 22:47:28,167:INFO:                 pip: 24.0
2024-05-24 22:47:28,167:INFO:          setuptools: 69.5.1
2024-05-24 22:47:28,167:INFO:             pycaret: 3.3.2
2024-05-24 22:47:28,167:INFO:             IPython: 8.20.0
2024-05-24 22:47:28,167:INFO:          ipywidgets: 8.1.2
2024-05-24 22:47:28,167:INFO:                tqdm: 4.66.4
2024-05-24 22:47:28,167:INFO:               numpy: 1.26.4
2024-05-24 22:47:28,167:INFO:              pandas: 2.1.4
2024-05-24 22:47:28,167:INFO:              jinja2: 3.1.3
2024-05-24 22:47:28,167:INFO:               scipy: 1.11.4
2024-05-24 22:47:28,167:INFO:              joblib: 1.3.2
2024-05-24 22:47:28,167:INFO:             sklearn: 1.4.2
2024-05-24 22:47:28,167:INFO:                pyod: 1.1.3
2024-05-24 22:47:28,167:INFO:            imblearn: 0.12.2
2024-05-24 22:47:28,167:INFO:   category_encoders: 2.6.3
2024-05-24 22:47:28,167:INFO:            lightgbm: 4.3.0
2024-05-24 22:47:28,167:INFO:               numba: 0.59.1
2024-05-24 22:47:28,167:INFO:            requests: 2.32.2
2024-05-24 22:47:28,167:INFO:          matplotlib: 3.7.5
2024-05-24 22:47:28,167:INFO:          scikitplot: 0.3.7
2024-05-24 22:47:28,167:INFO:         yellowbrick: 1.5
2024-05-24 22:47:28,168:INFO:              plotly: 5.22.0
2024-05-24 22:47:28,168:INFO:    plotly-resampler: Not installed
2024-05-24 22:47:28,168:INFO:             kaleido: 0.2.1
2024-05-24 22:47:28,168:INFO:           schemdraw: 0.15
2024-05-24 22:47:28,168:INFO:         statsmodels: 0.14.2
2024-05-24 22:47:28,168:INFO:              sktime: 0.26.0
2024-05-24 22:47:28,168:INFO:               tbats: 1.1.3
2024-05-24 22:47:28,168:INFO:            pmdarima: 2.0.4
2024-05-24 22:47:28,168:INFO:              psutil: 5.9.0
2024-05-24 22:47:28,168:INFO:          markupsafe: 2.1.3
2024-05-24 22:47:28,168:INFO:             pickle5: Not installed
2024-05-24 22:47:28,168:INFO:         cloudpickle: 3.0.0
2024-05-24 22:47:28,168:INFO:         deprecation: 2.1.0
2024-05-24 22:47:28,168:INFO:              xxhash: 3.4.1
2024-05-24 22:47:28,168:INFO:           wurlitzer: Not installed
2024-05-24 22:47:28,168:INFO:PyCaret optional dependencies:
2024-05-24 22:47:28,168:INFO:                shap: Not installed
2024-05-24 22:47:28,168:INFO:           interpret: Not installed
2024-05-24 22:47:28,168:INFO:                umap: Not installed
2024-05-24 22:47:28,168:INFO:     ydata_profiling: Not installed
2024-05-24 22:47:28,168:INFO:  explainerdashboard: Not installed
2024-05-24 22:47:28,168:INFO:             autoviz: Not installed
2024-05-24 22:47:28,168:INFO:           fairlearn: Not installed
2024-05-24 22:47:28,169:INFO:          deepchecks: Not installed
2024-05-24 22:47:28,169:INFO:             xgboost: Not installed
2024-05-24 22:47:28,169:INFO:            catboost: Not installed
2024-05-24 22:47:28,169:INFO:              kmodes: Not installed
2024-05-24 22:47:28,169:INFO:             mlxtend: Not installed
2024-05-24 22:47:28,169:INFO:       statsforecast: Not installed
2024-05-24 22:47:28,169:INFO:        tune_sklearn: Not installed
2024-05-24 22:47:28,169:INFO:                 ray: Not installed
2024-05-24 22:47:28,169:INFO:            hyperopt: Not installed
2024-05-24 22:47:28,169:INFO:              optuna: Not installed
2024-05-24 22:47:28,169:INFO:               skopt: Not installed
2024-05-24 22:47:28,169:INFO:              mlflow: Not installed
2024-05-24 22:47:28,169:INFO:              gradio: Not installed
2024-05-24 22:47:28,169:INFO:             fastapi: Not installed
2024-05-24 22:47:28,169:INFO:             uvicorn: Not installed
2024-05-24 22:47:28,169:INFO:              m2cgen: Not installed
2024-05-24 22:47:28,169:INFO:           evidently: Not installed
2024-05-24 22:47:28,169:INFO:               fugue: Not installed
2024-05-24 22:47:28,169:INFO:           streamlit: Not installed
2024-05-24 22:47:28,169:INFO:             prophet: Not installed
2024-05-24 22:47:28,169:INFO:None
2024-05-24 22:47:28,170:INFO:Set up data.
2024-05-24 22:47:28,212:INFO:Set up folding strategy.
2024-05-24 22:47:28,216:INFO:Set up train/test split.
2024-05-24 22:47:28,244:INFO:Set up index.
2024-05-24 22:47:28,245:INFO:Assigning column types.
2024-05-24 22:47:28,253:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 22:47:28,257:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,266:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,272:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,332:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,381:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,385:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,390:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,496:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 22:47:28,500:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,504:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,557:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,603:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,608:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,612:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,751:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 22:47:28,768:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:28,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:28,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,078:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 22:47:29,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,428:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 22:47:29,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:47:29,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,640:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 22:47:29,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:29,854:INFO:Preparing preprocessing pipeline...
2024-05-24 22:47:29,856:INFO:Set up simple imputation.
2024-05-24 22:47:29,862:INFO:Set up encoding of ordinal features.
2024-05-24 22:47:29,871:INFO:Set up encoding of categorical features.
2024-05-24 22:47:29,872:INFO:Set up polynomial features.
2024-05-24 22:47:29,872:INFO:Set up removing multicollinearity.
2024-05-24 22:47:29,872:INFO:Set up removing outliers.
2024-05-24 22:47:31,143:INFO:Finished creating preprocessing pipeline.
2024-05-24 22:47:31,203:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4194)))])
2024-05-24 22:47:31,203:INFO:Creating final display dataframe.
2024-05-24 22:47:33,544:INFO:Setup _display_container:                     Description             Value
0                    Session id              4194
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 472)
5   Transformed train set shape        (135, 472)
6    Transformed test set shape         (62, 472)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              4a19
2024-05-24 22:47:33,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:33,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:33,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:33,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:47:33,777:INFO:setup() successfully completed in 5.77s...............
2024-05-24 22:47:33,922:INFO:Initializing compare_models()
2024-05-24 22:47:33,923:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 22:47:33,923:INFO:Checking exceptions
2024-05-24 22:47:33,927:INFO:Preparing display monitor
2024-05-24 22:47:33,959:INFO:Initializing Linear Regression
2024-05-24 22:47:33,959:INFO:Total runtime is 0.0 minutes
2024-05-24 22:47:33,963:INFO:SubProcess create_model() called ==================================
2024-05-24 22:47:33,964:INFO:Initializing create_model()
2024-05-24 22:47:33,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015C33A620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:47:33,964:INFO:Checking exceptions
2024-05-24 22:47:33,964:INFO:Importing libraries
2024-05-24 22:47:33,964:INFO:Copying training dataset
2024-05-24 22:47:33,970:INFO:Defining folds
2024-05-24 22:47:33,970:INFO:Declaring metric variables
2024-05-24 22:47:33,974:INFO:Importing untrained model
2024-05-24 22:47:33,979:INFO:Linear Regression Imported successfully
2024-05-24 22:47:33,988:INFO:Starting cross validation
2024-05-24 22:47:34,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:47:52,582:INFO:Calculating mean and std
2024-05-24 22:47:52,584:INFO:Creating metrics dataframe
2024-05-24 22:47:52,589:INFO:Uploading results into container
2024-05-24 22:47:52,589:INFO:Uploading model into container now
2024-05-24 22:47:52,590:INFO:_master_model_container: 1
2024-05-24 22:47:52,590:INFO:_display_container: 2
2024-05-24 22:47:52,590:INFO:LinearRegression(n_jobs=-1)
2024-05-24 22:47:52,591:INFO:create_model() successfully completed......................................
2024-05-24 22:47:54,514:INFO:SubProcess create_model() end ==================================
2024-05-24 22:47:54,514:INFO:Creating metrics dataframe
2024-05-24 22:47:54,541:INFO:Initializing Lasso Regression
2024-05-24 22:47:54,541:INFO:Total runtime is 0.3430438677469889 minutes
2024-05-24 22:47:54,548:INFO:SubProcess create_model() called ==================================
2024-05-24 22:47:54,549:INFO:Initializing create_model()
2024-05-24 22:47:54,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015C33A620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:47:54,549:INFO:Checking exceptions
2024-05-24 22:47:54,550:INFO:Importing libraries
2024-05-24 22:47:54,550:INFO:Copying training dataset
2024-05-24 22:47:54,561:INFO:Defining folds
2024-05-24 22:47:54,561:INFO:Declaring metric variables
2024-05-24 22:47:54,569:INFO:Importing untrained model
2024-05-24 22:47:54,576:INFO:Lasso Regression Imported successfully
2024-05-24 22:47:54,590:INFO:Starting cross validation
2024-05-24 22:47:54,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:47:57,338:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+07, tolerance: 5.517e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,350:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+07, tolerance: 6.230e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,388:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+07, tolerance: 5.340e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,452:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+07, tolerance: 6.093e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,462:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+07, tolerance: 6.069e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,544:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+07, tolerance: 4.674e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,644:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+07, tolerance: 6.217e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:47:57,792:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e+07, tolerance: 6.000e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:02,298:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+07, tolerance: 6.159e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:02,471:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e+07, tolerance: 6.192e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:02,535:INFO:Calculating mean and std
2024-05-24 22:48:02,536:INFO:Creating metrics dataframe
2024-05-24 22:48:02,539:INFO:Uploading results into container
2024-05-24 22:48:02,539:INFO:Uploading model into container now
2024-05-24 22:48:02,540:INFO:_master_model_container: 2
2024-05-24 22:48:02,540:INFO:_display_container: 2
2024-05-24 22:48:02,540:INFO:Lasso(random_state=4194)
2024-05-24 22:48:02,540:INFO:create_model() successfully completed......................................
2024-05-24 22:48:02,832:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:02,832:INFO:Creating metrics dataframe
2024-05-24 22:48:02,841:INFO:Initializing Ridge Regression
2024-05-24 22:48:02,841:INFO:Total runtime is 0.48137493928273517 minutes
2024-05-24 22:48:02,845:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:02,845:INFO:Initializing create_model()
2024-05-24 22:48:02,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015C33A620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:02,845:INFO:Checking exceptions
2024-05-24 22:48:02,845:INFO:Importing libraries
2024-05-24 22:48:02,845:INFO:Copying training dataset
2024-05-24 22:48:02,851:INFO:Defining folds
2024-05-24 22:48:02,851:INFO:Declaring metric variables
2024-05-24 22:48:02,855:INFO:Importing untrained model
2024-05-24 22:48:02,858:INFO:Ridge Regression Imported successfully
2024-05-24 22:48:02,867:INFO:Starting cross validation
2024-05-24 22:48:02,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:04,782:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:04,952:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:04,972:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,023:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,035:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,051:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,064:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,106:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,108:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,109:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 22:48:05,240:INFO:Calculating mean and std
2024-05-24 22:48:05,242:INFO:Creating metrics dataframe
2024-05-24 22:48:05,246:INFO:Uploading results into container
2024-05-24 22:48:05,247:INFO:Uploading model into container now
2024-05-24 22:48:05,248:INFO:_master_model_container: 3
2024-05-24 22:48:05,248:INFO:_display_container: 2
2024-05-24 22:48:05,249:INFO:Ridge(random_state=4194)
2024-05-24 22:48:05,249:INFO:create_model() successfully completed......................................
2024-05-24 22:48:05,601:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:05,601:INFO:Creating metrics dataframe
2024-05-24 22:48:05,613:INFO:Initializing Huber Regressor
2024-05-24 22:48:05,613:INFO:Total runtime is 0.5275719245274861 minutes
2024-05-24 22:48:05,619:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:05,619:INFO:Initializing create_model()
2024-05-24 22:48:05,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015C33A620>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:05,619:INFO:Checking exceptions
2024-05-24 22:48:05,619:INFO:Importing libraries
2024-05-24 22:48:05,619:INFO:Copying training dataset
2024-05-24 22:48:05,629:INFO:Defining folds
2024-05-24 22:48:05,629:INFO:Declaring metric variables
2024-05-24 22:48:05,635:INFO:Importing untrained model
2024-05-24 22:48:05,638:INFO:Huber Regressor Imported successfully
2024-05-24 22:48:05,645:INFO:Starting cross validation
2024-05-24 22:48:05,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:07,957:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 22:48:07,958:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 22:48:07,971:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 22:48:08,063:INFO:Calculating mean and std
2024-05-24 22:48:08,064:INFO:Creating metrics dataframe
2024-05-24 22:48:08,067:INFO:Uploading results into container
2024-05-24 22:48:08,068:INFO:Uploading model into container now
2024-05-24 22:48:08,068:INFO:_master_model_container: 4
2024-05-24 22:48:08,068:INFO:_display_container: 2
2024-05-24 22:48:08,068:INFO:HuberRegressor()
2024-05-24 22:48:08,068:INFO:create_model() successfully completed......................................
2024-05-24 22:48:08,361:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:08,361:INFO:Creating metrics dataframe
2024-05-24 22:48:08,373:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 22:48:08,383:INFO:Initializing create_model()
2024-05-24 22:48:08,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=Lasso(random_state=4194), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:08,383:INFO:Checking exceptions
2024-05-24 22:48:08,384:INFO:Importing libraries
2024-05-24 22:48:08,385:INFO:Copying training dataset
2024-05-24 22:48:08,389:INFO:Defining folds
2024-05-24 22:48:08,389:INFO:Declaring metric variables
2024-05-24 22:48:08,389:INFO:Importing untrained model
2024-05-24 22:48:08,389:INFO:Declaring custom model
2024-05-24 22:48:08,390:INFO:Lasso Regression Imported successfully
2024-05-24 22:48:08,409:INFO:Cross validation set to False
2024-05-24 22:48:08,409:INFO:Fitting Model
2024-05-24 22:48:09,629:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+07, tolerance: 6.394e+05


2024-05-24 22:48:09,630:INFO:Lasso(random_state=4194)
2024-05-24 22:48:09,630:INFO:create_model() successfully completed......................................
2024-05-24 22:48:09,927:INFO:_master_model_container: 4
2024-05-24 22:48:09,927:INFO:_display_container: 2
2024-05-24 22:48:09,927:INFO:Lasso(random_state=4194)
2024-05-24 22:48:09,928:INFO:compare_models() successfully completed......................................
2024-05-24 22:48:09,999:INFO:Initializing evaluate_model()
2024-05-24 22:48:09,999:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=Lasso(random_state=4194), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 22:48:10,015:INFO:Initializing plot_model()
2024-05-24 22:48:10,015:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Lasso(random_state=4194), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, system=True)
2024-05-24 22:48:10,016:INFO:Checking exceptions
2024-05-24 22:48:10,020:INFO:Preloading libraries
2024-05-24 22:48:10,021:INFO:Copying training dataset
2024-05-24 22:48:10,021:INFO:Plot type: pipeline
2024-05-24 22:48:10,312:INFO:Visual Rendered Successfully
2024-05-24 22:48:10,690:INFO:plot_model() successfully completed......................................
2024-05-24 22:48:10,745:INFO:Initializing create_model()
2024-05-24 22:48:10,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=Lasso(random_state=4194), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:10,747:INFO:Checking exceptions
2024-05-24 22:48:10,765:INFO:Importing libraries
2024-05-24 22:48:10,765:INFO:Copying training dataset
2024-05-24 22:48:10,771:INFO:Defining folds
2024-05-24 22:48:10,771:INFO:Declaring metric variables
2024-05-24 22:48:10,775:INFO:Importing untrained model
2024-05-24 22:48:10,775:INFO:Declaring custom model
2024-05-24 22:48:10,780:INFO:Lasso Regression Imported successfully
2024-05-24 22:48:10,787:INFO:Starting cross validation
2024-05-24 22:48:10,817:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:12,591:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+07, tolerance: 6.159e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:12,825:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e+07, tolerance: 6.192e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:12,830:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+07, tolerance: 6.069e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:12,888:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+07, tolerance: 6.093e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:12,973:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e+07, tolerance: 6.000e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:12,991:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+07, tolerance: 6.217e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:13,018:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+07, tolerance: 5.340e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:13,085:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+07, tolerance: 4.674e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:13,160:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+07, tolerance: 6.230e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:13,242:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+07, tolerance: 5.517e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:13,307:INFO:Calculating mean and std
2024-05-24 22:48:13,308:INFO:Creating metrics dataframe
2024-05-24 22:48:13,314:INFO:Finalizing model
2024-05-24 22:48:14,493:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+07, tolerance: 6.394e+05


2024-05-24 22:48:14,499:INFO:Uploading results into container
2024-05-24 22:48:14,499:INFO:Uploading model into container now
2024-05-24 22:48:14,507:INFO:_master_model_container: 5
2024-05-24 22:48:14,509:INFO:_display_container: 3
2024-05-24 22:48:14,509:INFO:Lasso(random_state=4194)
2024-05-24 22:48:14,509:INFO:create_model() successfully completed......................................
2024-05-24 22:48:14,827:INFO:Initializing tune_model()
2024-05-24 22:48:14,827:INFO:tune_model(estimator=Lasso(random_state=4194), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>)
2024-05-24 22:48:14,828:INFO:Checking exceptions
2024-05-24 22:48:14,846:INFO:Copying training dataset
2024-05-24 22:48:14,852:INFO:Checking base model
2024-05-24 22:48:14,852:INFO:Base model : Lasso Regression
2024-05-24 22:48:14,856:INFO:Declaring metric variables
2024-05-24 22:48:14,860:INFO:Defining Hyperparameters
2024-05-24 22:48:15,222:INFO:Tuning with n_jobs=-1
2024-05-24 22:48:15,222:INFO:Initializing RandomizedSearchCV
2024-05-24 22:48:17,317:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.503e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,333:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.909e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,403:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.061e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,487:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.099e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,524:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.761e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,526:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.647e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,592:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:17,620:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.320e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:18,402:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:18,592:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.643e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:18,862:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,361:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.592e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,493:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.609e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,580:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.073e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,595:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.644e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,689:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.758e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,727:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.504e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,748:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.711e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:19,752:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.441e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:20,161:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+07, tolerance: 6.159e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:21,008:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.010e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:21,556:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+07, tolerance: 6.217e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:21,820:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.962e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:21,884:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+07, tolerance: 4.674e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:21,931:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.190e+07, tolerance: 6.093e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:22,007:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.360e+07, tolerance: 5.517e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:22,025:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+07, tolerance: 6.000e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:22,188:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+07, tolerance: 5.340e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:22,244:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.619e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:22,306:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+07, tolerance: 6.192e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:22,572:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e+07, tolerance: 6.069e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:23,010:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+07, tolerance: 6.230e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:23,623:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.982e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,049:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,079:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.507e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,107:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.163e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,199:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.329e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,214:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.628e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,423:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.095e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:24,694:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.582e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:25,374:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.597e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:25,493:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.569e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:25,806:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.528e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,137:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.806e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,185:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.351e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,220:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.472e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,234:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.123e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,255:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.592e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,642:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.783e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:26,880:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.050e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:27,010:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.961e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:27,398:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.292e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:27,503:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.965e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:27,736:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.863e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:28,289:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.073e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:28,382:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:28,470:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.791e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:28,474:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.027e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:29,026:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.433e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:29,078:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.746e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:29,415:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.193e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:29,613:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:29,914:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.856e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,012:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.597e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,116:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,206:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.743e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,765:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.035e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,780:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.426e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,793:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.688e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:30,930:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.150e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:31,078:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.590e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:31,540:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.254e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:31,723:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.726e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:32,023:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.200e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:32,319:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.976e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:32,974:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e+07, tolerance: 6.159e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:33,051:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.198e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:33,178:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.693e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:33,326:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.257e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:33,557:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e+07, tolerance: 6.230e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:33,661:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e+07, tolerance: 6.217e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:33,723:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+07, tolerance: 6.069e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:34,136:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+07, tolerance: 6.000e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:34,160:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.786e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:34,456:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+07, tolerance: 4.674e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:34,510:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.245e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:35,229:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.701e+07, tolerance: 6.192e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:35,541:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+07, tolerance: 5.340e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:35,577:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.585e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:35,646:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.379e+07, tolerance: 5.517e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:35,814:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.075e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:35,870:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.248e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:36,043:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.920e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:36,156:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.344e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:36,502:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.781e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:36,722:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+07, tolerance: 6.093e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:37,119:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.118e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:37,342:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.945e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:37,569:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.371e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:37,592:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.599e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:37,679:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 8.87}
2024-05-24 22:48:37,680:INFO:Hyperparameter search completed
2024-05-24 22:48:37,680:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:37,681:INFO:Initializing create_model()
2024-05-24 22:48:37,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=Lasso(random_state=4194), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015BF873A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 8.87})
2024-05-24 22:48:37,681:INFO:Checking exceptions
2024-05-24 22:48:37,681:INFO:Importing libraries
2024-05-24 22:48:37,681:INFO:Copying training dataset
2024-05-24 22:48:37,688:INFO:Defining folds
2024-05-24 22:48:37,688:INFO:Declaring metric variables
2024-05-24 22:48:37,691:INFO:Importing untrained model
2024-05-24 22:48:37,691:INFO:Declaring custom model
2024-05-24 22:48:37,697:INFO:Lasso Regression Imported successfully
2024-05-24 22:48:37,705:INFO:Starting cross validation
2024-05-24 22:48:37,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:39,890:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.582e+07, tolerance: 2.428e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:39,942:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.962e+07, tolerance: 2.567e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,064:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.329e+07, tolerance: 2.454e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,066:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.507e+07, tolerance: 2.625e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,080:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.597e+07, tolerance: 2.536e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,092:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e+07, tolerance: 2.277e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,139:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.095e+07, tolerance: 2.593e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,150:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.628e+07, tolerance: 2.592e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,214:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.982e+07, tolerance: 2.627e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,539:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.619e+07, tolerance: 2.622e+06
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:40,607:INFO:Calculating mean and std
2024-05-24 22:48:40,609:INFO:Creating metrics dataframe
2024-05-24 22:48:40,614:INFO:Finalizing model
2024-05-24 22:48:41,958:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+08, tolerance: 2.787e+06


2024-05-24 22:48:41,963:INFO:Uploading results into container
2024-05-24 22:48:41,964:INFO:Uploading model into container now
2024-05-24 22:48:41,964:INFO:_master_model_container: 6
2024-05-24 22:48:41,964:INFO:_display_container: 4
2024-05-24 22:48:41,965:INFO:Lasso(alpha=8.87, fit_intercept=False, random_state=4194)
2024-05-24 22:48:41,965:INFO:create_model() successfully completed......................................
2024-05-24 22:48:42,285:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:42,285:INFO:choose_better activated
2024-05-24 22:48:42,289:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:42,290:INFO:Initializing create_model()
2024-05-24 22:48:42,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CDBA290>, estimator=Lasso(random_state=4194), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:42,290:INFO:Checking exceptions
2024-05-24 22:48:42,291:INFO:Importing libraries
2024-05-24 22:48:42,291:INFO:Copying training dataset
2024-05-24 22:48:42,296:INFO:Defining folds
2024-05-24 22:48:42,296:INFO:Declaring metric variables
2024-05-24 22:48:42,297:INFO:Importing untrained model
2024-05-24 22:48:42,297:INFO:Declaring custom model
2024-05-24 22:48:42,297:INFO:Lasso Regression Imported successfully
2024-05-24 22:48:42,297:INFO:Starting cross validation
2024-05-24 22:48:42,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:44,578:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+07, tolerance: 6.159e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:44,656:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+07, tolerance: 6.230e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:44,689:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+07, tolerance: 6.069e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:44,745:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e+07, tolerance: 6.192e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:44,754:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+07, tolerance: 6.217e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:44,854:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+07, tolerance: 4.674e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:44,960:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+07, tolerance: 5.517e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:45,053:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e+07, tolerance: 6.000e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:45,118:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+07, tolerance: 5.340e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:45,122:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+07, tolerance: 6.093e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 22:48:45,235:INFO:Calculating mean and std
2024-05-24 22:48:45,236:INFO:Creating metrics dataframe
2024-05-24 22:48:45,239:INFO:Finalizing model
2024-05-24 22:48:47,058:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+07, tolerance: 6.394e+05


2024-05-24 22:48:47,059:INFO:Uploading results into container
2024-05-24 22:48:47,060:INFO:Uploading model into container now
2024-05-24 22:48:47,061:INFO:_master_model_container: 7
2024-05-24 22:48:47,061:INFO:_display_container: 5
2024-05-24 22:48:47,061:INFO:Lasso(random_state=4194)
2024-05-24 22:48:47,062:INFO:create_model() successfully completed......................................
2024-05-24 22:48:47,476:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:47,476:INFO:Lasso(random_state=4194) result for R2 is 0.365
2024-05-24 22:48:47,477:INFO:Lasso(alpha=8.87, fit_intercept=False, random_state=4194) result for R2 is 0.7364
2024-05-24 22:48:47,477:INFO:Lasso(alpha=8.87, fit_intercept=False, random_state=4194) is best model
2024-05-24 22:48:47,477:INFO:choose_better completed
2024-05-24 22:48:47,494:INFO:_master_model_container: 7
2024-05-24 22:48:47,494:INFO:_display_container: 4
2024-05-24 22:48:47,495:INFO:Lasso(alpha=8.87, fit_intercept=False, random_state=4194)
2024-05-24 22:48:47,495:INFO:tune_model() successfully completed......................................
2024-05-24 22:48:48,027:INFO:PyCaret RegressionExperiment
2024-05-24 22:48:48,027:INFO:Logging name: reg-default-name
2024-05-24 22:48:48,027:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 22:48:48,027:INFO:version 3.3.2
2024-05-24 22:48:48,027:INFO:Initializing setup()
2024-05-24 22:48:48,027:INFO:self.USI: 2dbc
2024-05-24 22:48:48,028:INFO:self._variable_keys: {'_available_plots', 'transform_target_param', 'pipeline', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y', 'logging_param', 'seed', 'log_plots_param', 'memory', 'exp_name_log', 'USI', 'y_test', 'html_param', 'exp_id', 'y_train', 'X_train', 'idx', 'target_param', 'fold_generator', 'fold_groups_param', 'X', '_ml_usecase', 'X_test', 'data', 'gpu_param', 'n_jobs_param'}
2024-05-24 22:48:48,028:INFO:Checking environment
2024-05-24 22:48:48,028:INFO:python_version: 3.10.14
2024-05-24 22:48:48,028:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 22:48:48,028:INFO:machine: AMD64
2024-05-24 22:48:48,028:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 22:48:48,028:INFO:Memory: svmem(total=16541802496, available=668037120, percent=96.0, used=15873765376, free=668037120)
2024-05-24 22:48:48,028:INFO:Physical Core: 6
2024-05-24 22:48:48,028:INFO:Logical Core: 12
2024-05-24 22:48:48,028:INFO:Checking libraries
2024-05-24 22:48:48,028:INFO:System:
2024-05-24 22:48:48,029:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 22:48:48,029:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 22:48:48,029:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 22:48:48,029:INFO:PyCaret required dependencies:
2024-05-24 22:48:48,029:INFO:                 pip: 24.0
2024-05-24 22:48:48,029:INFO:          setuptools: 69.5.1
2024-05-24 22:48:48,029:INFO:             pycaret: 3.3.2
2024-05-24 22:48:48,029:INFO:             IPython: 8.20.0
2024-05-24 22:48:48,029:INFO:          ipywidgets: 8.1.2
2024-05-24 22:48:48,029:INFO:                tqdm: 4.66.4
2024-05-24 22:48:48,029:INFO:               numpy: 1.26.4
2024-05-24 22:48:48,030:INFO:              pandas: 2.1.4
2024-05-24 22:48:48,030:INFO:              jinja2: 3.1.3
2024-05-24 22:48:48,030:INFO:               scipy: 1.11.4
2024-05-24 22:48:48,030:INFO:              joblib: 1.3.2
2024-05-24 22:48:48,030:INFO:             sklearn: 1.4.2
2024-05-24 22:48:48,030:INFO:                pyod: 1.1.3
2024-05-24 22:48:48,030:INFO:            imblearn: 0.12.2
2024-05-24 22:48:48,030:INFO:   category_encoders: 2.6.3
2024-05-24 22:48:48,030:INFO:            lightgbm: 4.3.0
2024-05-24 22:48:48,030:INFO:               numba: 0.59.1
2024-05-24 22:48:48,030:INFO:            requests: 2.32.2
2024-05-24 22:48:48,030:INFO:          matplotlib: 3.7.5
2024-05-24 22:48:48,030:INFO:          scikitplot: 0.3.7
2024-05-24 22:48:48,031:INFO:         yellowbrick: 1.5
2024-05-24 22:48:48,031:INFO:              plotly: 5.22.0
2024-05-24 22:48:48,031:INFO:    plotly-resampler: Not installed
2024-05-24 22:48:48,031:INFO:             kaleido: 0.2.1
2024-05-24 22:48:48,031:INFO:           schemdraw: 0.15
2024-05-24 22:48:48,031:INFO:         statsmodels: 0.14.2
2024-05-24 22:48:48,031:INFO:              sktime: 0.26.0
2024-05-24 22:48:48,031:INFO:               tbats: 1.1.3
2024-05-24 22:48:48,031:INFO:            pmdarima: 2.0.4
2024-05-24 22:48:48,031:INFO:              psutil: 5.9.0
2024-05-24 22:48:48,031:INFO:          markupsafe: 2.1.3
2024-05-24 22:48:48,031:INFO:             pickle5: Not installed
2024-05-24 22:48:48,031:INFO:         cloudpickle: 3.0.0
2024-05-24 22:48:48,031:INFO:         deprecation: 2.1.0
2024-05-24 22:48:48,031:INFO:              xxhash: 3.4.1
2024-05-24 22:48:48,032:INFO:           wurlitzer: Not installed
2024-05-24 22:48:48,032:INFO:PyCaret optional dependencies:
2024-05-24 22:48:48,032:INFO:                shap: Not installed
2024-05-24 22:48:48,032:INFO:           interpret: Not installed
2024-05-24 22:48:48,032:INFO:                umap: Not installed
2024-05-24 22:48:48,032:INFO:     ydata_profiling: Not installed
2024-05-24 22:48:48,032:INFO:  explainerdashboard: Not installed
2024-05-24 22:48:48,032:INFO:             autoviz: Not installed
2024-05-24 22:48:48,032:INFO:           fairlearn: Not installed
2024-05-24 22:48:48,032:INFO:          deepchecks: Not installed
2024-05-24 22:48:48,032:INFO:             xgboost: Not installed
2024-05-24 22:48:48,032:INFO:            catboost: Not installed
2024-05-24 22:48:48,032:INFO:              kmodes: Not installed
2024-05-24 22:48:48,032:INFO:             mlxtend: Not installed
2024-05-24 22:48:48,032:INFO:       statsforecast: Not installed
2024-05-24 22:48:48,032:INFO:        tune_sklearn: Not installed
2024-05-24 22:48:48,032:INFO:                 ray: Not installed
2024-05-24 22:48:48,032:INFO:            hyperopt: Not installed
2024-05-24 22:48:48,032:INFO:              optuna: Not installed
2024-05-24 22:48:48,032:INFO:               skopt: Not installed
2024-05-24 22:48:48,033:INFO:              mlflow: Not installed
2024-05-24 22:48:48,033:INFO:              gradio: Not installed
2024-05-24 22:48:48,033:INFO:             fastapi: Not installed
2024-05-24 22:48:48,033:INFO:             uvicorn: Not installed
2024-05-24 22:48:48,033:INFO:              m2cgen: Not installed
2024-05-24 22:48:48,033:INFO:           evidently: Not installed
2024-05-24 22:48:48,033:INFO:               fugue: Not installed
2024-05-24 22:48:48,033:INFO:           streamlit: Not installed
2024-05-24 22:48:48,033:INFO:             prophet: Not installed
2024-05-24 22:48:48,033:INFO:None
2024-05-24 22:48:48,033:INFO:Set up data.
2024-05-24 22:48:48,040:INFO:Set up folding strategy.
2024-05-24 22:48:48,040:INFO:Set up train/test split.
2024-05-24 22:48:48,045:INFO:Set up index.
2024-05-24 22:48:48,045:INFO:Assigning column types.
2024-05-24 22:48:48,050:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 22:48:48,050:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,268:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,279:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,418:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,420:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 22:48:48,430:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,436:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,629:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,638:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,729:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,804:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 22:48:48,821:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:48,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:48,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,131:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 22:48:49,222:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,299:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,411:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,470:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 22:48:49,561:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,708:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 22:48:49,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,771:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 22:48:49,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:49,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:50,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:50,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:50,114:INFO:Preparing preprocessing pipeline...
2024-05-24 22:48:50,114:INFO:Set up simple imputation.
2024-05-24 22:48:50,114:INFO:Set up polynomial features.
2024-05-24 22:48:50,114:INFO:Set up removing multicollinearity.
2024-05-24 22:48:50,114:INFO:Set up removing outliers.
2024-05-24 22:48:50,164:INFO:Finished creating preprocessing pipeline.
2024-05-24 22:48:50,172:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['curbweight', 'cylindernumber',
                                             'carvolume', 'enginepower',
                                             'averagempg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4460)))])
2024-05-24 22:48:50,172:INFO:Creating final display dataframe.
2024-05-24 22:48:51,243:INFO:Setup _display_container:                     Description             Value
0                    Session id              4460
1                        Target             price
2                   Target type        Regression
3           Original data shape          (183, 6)
4        Transformed data shape          (176, 7)
5   Transformed train set shape          (121, 7)
6    Transformed test set shape           (55, 7)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              2dbc
2024-05-24 22:48:51,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:51,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:51,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:51,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-24 22:48:51,591:INFO:setup() successfully completed in 3.62s...............
2024-05-24 22:48:51,613:INFO:Initializing compare_models()
2024-05-24 22:48:51,613:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 22:48:51,613:INFO:Checking exceptions
2024-05-24 22:48:51,615:INFO:Preparing display monitor
2024-05-24 22:48:51,641:INFO:Initializing Linear Regression
2024-05-24 22:48:51,641:INFO:Total runtime is 0.0 minutes
2024-05-24 22:48:51,646:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:51,646:INFO:Initializing create_model()
2024-05-24 22:48:51,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201632004F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:51,647:INFO:Checking exceptions
2024-05-24 22:48:51,647:INFO:Importing libraries
2024-05-24 22:48:51,647:INFO:Copying training dataset
2024-05-24 22:48:51,651:INFO:Defining folds
2024-05-24 22:48:51,652:INFO:Declaring metric variables
2024-05-24 22:48:51,656:INFO:Importing untrained model
2024-05-24 22:48:51,660:INFO:Linear Regression Imported successfully
2024-05-24 22:48:51,668:INFO:Starting cross validation
2024-05-24 22:48:51,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:52,194:INFO:Calculating mean and std
2024-05-24 22:48:52,195:INFO:Creating metrics dataframe
2024-05-24 22:48:52,199:INFO:Uploading results into container
2024-05-24 22:48:52,200:INFO:Uploading model into container now
2024-05-24 22:48:52,205:INFO:_master_model_container: 1
2024-05-24 22:48:52,205:INFO:_display_container: 2
2024-05-24 22:48:52,206:INFO:LinearRegression(n_jobs=-1)
2024-05-24 22:48:52,207:INFO:create_model() successfully completed......................................
2024-05-24 22:48:52,802:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:52,803:INFO:Creating metrics dataframe
2024-05-24 22:48:52,816:INFO:Initializing Lasso Regression
2024-05-24 22:48:52,816:INFO:Total runtime is 0.01957845687866211 minutes
2024-05-24 22:48:52,824:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:52,825:INFO:Initializing create_model()
2024-05-24 22:48:52,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201632004F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:52,826:INFO:Checking exceptions
2024-05-24 22:48:52,826:INFO:Importing libraries
2024-05-24 22:48:52,826:INFO:Copying training dataset
2024-05-24 22:48:52,834:INFO:Defining folds
2024-05-24 22:48:52,836:INFO:Declaring metric variables
2024-05-24 22:48:52,843:INFO:Importing untrained model
2024-05-24 22:48:52,856:INFO:Lasso Regression Imported successfully
2024-05-24 22:48:52,871:INFO:Starting cross validation
2024-05-24 22:48:52,888:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:53,557:INFO:Calculating mean and std
2024-05-24 22:48:53,559:INFO:Creating metrics dataframe
2024-05-24 22:48:53,563:INFO:Uploading results into container
2024-05-24 22:48:53,564:INFO:Uploading model into container now
2024-05-24 22:48:53,565:INFO:_master_model_container: 2
2024-05-24 22:48:53,565:INFO:_display_container: 2
2024-05-24 22:48:53,566:INFO:Lasso(random_state=4460)
2024-05-24 22:48:53,567:INFO:create_model() successfully completed......................................
2024-05-24 22:48:54,198:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:54,198:INFO:Creating metrics dataframe
2024-05-24 22:48:54,212:INFO:Initializing Ridge Regression
2024-05-24 22:48:54,212:INFO:Total runtime is 0.04283694426218669 minutes
2024-05-24 22:48:54,221:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:54,221:INFO:Initializing create_model()
2024-05-24 22:48:54,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201632004F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:54,222:INFO:Checking exceptions
2024-05-24 22:48:54,222:INFO:Importing libraries
2024-05-24 22:48:54,223:INFO:Copying training dataset
2024-05-24 22:48:54,229:INFO:Defining folds
2024-05-24 22:48:54,230:INFO:Declaring metric variables
2024-05-24 22:48:54,239:INFO:Importing untrained model
2024-05-24 22:48:54,248:INFO:Ridge Regression Imported successfully
2024-05-24 22:48:54,292:INFO:Starting cross validation
2024-05-24 22:48:54,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:54,882:INFO:Calculating mean and std
2024-05-24 22:48:54,885:INFO:Creating metrics dataframe
2024-05-24 22:48:54,890:INFO:Uploading results into container
2024-05-24 22:48:54,891:INFO:Uploading model into container now
2024-05-24 22:48:54,892:INFO:_master_model_container: 3
2024-05-24 22:48:54,892:INFO:_display_container: 2
2024-05-24 22:48:54,892:INFO:Ridge(random_state=4460)
2024-05-24 22:48:54,892:INFO:create_model() successfully completed......................................
2024-05-24 22:48:55,431:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:55,431:INFO:Creating metrics dataframe
2024-05-24 22:48:55,445:INFO:Initializing Huber Regressor
2024-05-24 22:48:55,445:INFO:Total runtime is 0.06338611841201783 minutes
2024-05-24 22:48:55,452:INFO:SubProcess create_model() called ==================================
2024-05-24 22:48:55,452:INFO:Initializing create_model()
2024-05-24 22:48:55,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000201632004F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:55,453:INFO:Checking exceptions
2024-05-24 22:48:55,453:INFO:Importing libraries
2024-05-24 22:48:55,454:INFO:Copying training dataset
2024-05-24 22:48:55,460:INFO:Defining folds
2024-05-24 22:48:55,460:INFO:Declaring metric variables
2024-05-24 22:48:55,482:INFO:Importing untrained model
2024-05-24 22:48:55,489:INFO:Huber Regressor Imported successfully
2024-05-24 22:48:55,503:INFO:Starting cross validation
2024-05-24 22:48:55,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:48:55,915:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 22:48:56,143:INFO:Calculating mean and std
2024-05-24 22:48:56,145:INFO:Creating metrics dataframe
2024-05-24 22:48:56,148:INFO:Uploading results into container
2024-05-24 22:48:56,150:INFO:Uploading model into container now
2024-05-24 22:48:56,150:INFO:_master_model_container: 4
2024-05-24 22:48:56,151:INFO:_display_container: 2
2024-05-24 22:48:56,151:INFO:HuberRegressor()
2024-05-24 22:48:56,151:INFO:create_model() successfully completed......................................
2024-05-24 22:48:56,686:INFO:SubProcess create_model() end ==================================
2024-05-24 22:48:56,686:INFO:Creating metrics dataframe
2024-05-24 22:48:56,727:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 22:48:56,757:INFO:Initializing create_model()
2024-05-24 22:48:56,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:48:56,758:INFO:Checking exceptions
2024-05-24 22:48:56,761:INFO:Importing libraries
2024-05-24 22:48:56,761:INFO:Copying training dataset
2024-05-24 22:48:56,778:INFO:Defining folds
2024-05-24 22:48:56,778:INFO:Declaring metric variables
2024-05-24 22:48:56,778:INFO:Importing untrained model
2024-05-24 22:48:56,779:INFO:Declaring custom model
2024-05-24 22:48:56,779:INFO:Linear Regression Imported successfully
2024-05-24 22:48:56,802:INFO:Cross validation set to False
2024-05-24 22:48:56,803:INFO:Fitting Model
2024-05-24 22:48:57,124:INFO:LinearRegression(n_jobs=-1)
2024-05-24 22:48:57,125:INFO:create_model() successfully completed......................................
2024-05-24 22:48:57,861:INFO:_master_model_container: 4
2024-05-24 22:48:57,861:INFO:_display_container: 2
2024-05-24 22:48:57,862:INFO:LinearRegression(n_jobs=-1)
2024-05-24 22:48:57,862:INFO:compare_models() successfully completed......................................
2024-05-24 22:48:58,032:INFO:Initializing evaluate_model()
2024-05-24 22:48:58,032:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 22:48:58,046:INFO:Initializing plot_model()
2024-05-24 22:48:58,046:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, system=True)
2024-05-24 22:48:58,046:INFO:Checking exceptions
2024-05-24 22:48:58,049:INFO:Preloading libraries
2024-05-24 22:48:58,049:INFO:Copying training dataset
2024-05-24 22:48:58,049:INFO:Plot type: pipeline
2024-05-24 22:48:58,324:INFO:Visual Rendered Successfully
2024-05-24 22:48:58,924:INFO:plot_model() successfully completed......................................
2024-05-24 22:48:58,994:INFO:Initializing tune_model()
2024-05-24 22:48:58,994:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>)
2024-05-24 22:48:58,994:INFO:Checking exceptions
2024-05-24 22:48:59,026:INFO:Copying training dataset
2024-05-24 22:48:59,031:INFO:Checking base model
2024-05-24 22:48:59,031:INFO:Base model : Linear Regression
2024-05-24 22:48:59,040:INFO:Declaring metric variables
2024-05-24 22:48:59,047:INFO:Defining Hyperparameters
2024-05-24 22:48:59,048:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2024-05-24 22:48:59,623:INFO:Tuning with n_jobs=-1
2024-05-24 22:48:59,623:INFO:Initializing GridSearchCV
2024-05-24 22:49:00,641:INFO:best_params: {'actual_estimator__fit_intercept': False}
2024-05-24 22:49:00,642:INFO:Hyperparameter search completed
2024-05-24 22:49:00,643:INFO:SubProcess create_model() called ==================================
2024-05-24 22:49:00,643:INFO:Initializing create_model()
2024-05-24 22:49:00,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002015B7A2470>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False})
2024-05-24 22:49:00,644:INFO:Checking exceptions
2024-05-24 22:49:00,644:INFO:Importing libraries
2024-05-24 22:49:00,644:INFO:Copying training dataset
2024-05-24 22:49:00,650:INFO:Defining folds
2024-05-24 22:49:00,650:INFO:Declaring metric variables
2024-05-24 22:49:00,657:INFO:Importing untrained model
2024-05-24 22:49:00,657:INFO:Declaring custom model
2024-05-24 22:49:00,663:INFO:Linear Regression Imported successfully
2024-05-24 22:49:00,677:INFO:Starting cross validation
2024-05-24 22:49:00,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:49:01,441:INFO:Calculating mean and std
2024-05-24 22:49:01,443:INFO:Creating metrics dataframe
2024-05-24 22:49:01,453:INFO:Finalizing model
2024-05-24 22:49:01,767:INFO:Uploading results into container
2024-05-24 22:49:01,768:INFO:Uploading model into container now
2024-05-24 22:49:01,769:INFO:_master_model_container: 5
2024-05-24 22:49:01,770:INFO:_display_container: 3
2024-05-24 22:49:01,771:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2024-05-24 22:49:01,771:INFO:create_model() successfully completed......................................
2024-05-24 22:49:02,315:INFO:SubProcess create_model() end ==================================
2024-05-24 22:49:02,315:INFO:choose_better activated
2024-05-24 22:49:02,326:INFO:SubProcess create_model() called ==================================
2024-05-24 22:49:02,327:INFO:Initializing create_model()
2024-05-24 22:49:02,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002015CFD2530>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 22:49:02,327:INFO:Checking exceptions
2024-05-24 22:49:02,330:INFO:Importing libraries
2024-05-24 22:49:02,330:INFO:Copying training dataset
2024-05-24 22:49:02,337:INFO:Defining folds
2024-05-24 22:49:02,339:INFO:Declaring metric variables
2024-05-24 22:49:02,343:INFO:Importing untrained model
2024-05-24 22:49:02,343:INFO:Declaring custom model
2024-05-24 22:49:02,344:INFO:Linear Regression Imported successfully
2024-05-24 22:49:02,345:INFO:Starting cross validation
2024-05-24 22:49:02,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 22:49:02,985:INFO:Calculating mean and std
2024-05-24 22:49:02,986:INFO:Creating metrics dataframe
2024-05-24 22:49:02,990:INFO:Finalizing model
2024-05-24 22:49:03,293:INFO:Uploading results into container
2024-05-24 22:49:03,294:INFO:Uploading model into container now
2024-05-24 22:49:03,295:INFO:_master_model_container: 6
2024-05-24 22:49:03,295:INFO:_display_container: 4
2024-05-24 22:49:03,295:INFO:LinearRegression(n_jobs=-1)
2024-05-24 22:49:03,295:INFO:create_model() successfully completed......................................
2024-05-24 22:49:03,751:INFO:SubProcess create_model() end ==================================
2024-05-24 22:49:03,751:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.7909
2024-05-24 22:49:03,752:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) result for R2 is 0.7923
2024-05-24 22:49:03,752:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) is best model
2024-05-24 22:49:03,752:INFO:choose_better completed
2024-05-24 22:49:03,772:INFO:_master_model_container: 6
2024-05-24 22:49:03,773:INFO:_display_container: 3
2024-05-24 22:49:03,773:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2024-05-24 22:49:03,774:INFO:tune_model() successfully completed......................................
2024-05-24 22:49:04,346:ERROR:
'explainerdashboard' is a soft dependency and not included in the pycaret installation. Please run: `pip install explainerdashboard` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-05-24 23:19:13,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 23:19:13,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 23:19:13,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 23:19:13,373:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-24 23:19:13,701:INFO:PyCaret RegressionExperiment
2024-05-24 23:19:13,701:INFO:Logging name: reg-default-name
2024-05-24 23:19:13,701:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 23:19:13,701:INFO:version 3.3.2
2024-05-24 23:19:13,701:INFO:Initializing setup()
2024-05-24 23:19:13,701:INFO:self.USI: 883e
2024-05-24 23:19:13,702:INFO:self._variable_keys: {'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'pipeline', 'USI', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'target_param', 'X_train', 'fold_generator', 'y_test', 'log_plots_param', 'data', 'exp_name_log', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'memory', 'seed', 'y', 'X_test', 'X', '_available_plots', 'transform_target_param'}
2024-05-24 23:19:13,702:INFO:Checking environment
2024-05-24 23:19:13,702:INFO:python_version: 3.10.14
2024-05-24 23:19:13,702:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 23:19:13,702:INFO:machine: AMD64
2024-05-24 23:19:13,702:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 23:19:13,702:INFO:Memory: svmem(total=16541802496, available=5603684352, percent=66.1, used=10938118144, free=5603684352)
2024-05-24 23:19:13,702:INFO:Physical Core: 6
2024-05-24 23:19:13,702:INFO:Logical Core: 12
2024-05-24 23:19:13,702:INFO:Checking libraries
2024-05-24 23:19:13,702:INFO:System:
2024-05-24 23:19:13,702:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 23:19:13,702:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 23:19:13,702:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 23:19:13,702:INFO:PyCaret required dependencies:
2024-05-24 23:19:15,227:INFO:                 pip: 24.0
2024-05-24 23:19:15,227:INFO:          setuptools: 69.5.1
2024-05-24 23:19:15,227:INFO:             pycaret: 3.3.2
2024-05-24 23:19:15,227:INFO:             IPython: 8.20.0
2024-05-24 23:19:15,227:INFO:          ipywidgets: 8.1.2
2024-05-24 23:19:15,227:INFO:                tqdm: 4.66.4
2024-05-24 23:19:15,227:INFO:               numpy: 1.26.4
2024-05-24 23:19:15,227:INFO:              pandas: 2.1.4
2024-05-24 23:19:15,227:INFO:              jinja2: 3.1.3
2024-05-24 23:19:15,227:INFO:               scipy: 1.11.4
2024-05-24 23:19:15,227:INFO:              joblib: 1.3.2
2024-05-24 23:19:15,227:INFO:             sklearn: 1.4.2
2024-05-24 23:19:15,227:INFO:                pyod: 1.1.3
2024-05-24 23:19:15,228:INFO:            imblearn: 0.12.2
2024-05-24 23:19:15,228:INFO:   category_encoders: 2.6.3
2024-05-24 23:19:15,228:INFO:            lightgbm: 4.3.0
2024-05-24 23:19:15,228:INFO:               numba: 0.59.1
2024-05-24 23:19:15,228:INFO:            requests: 2.32.2
2024-05-24 23:19:15,228:INFO:          matplotlib: 3.7.5
2024-05-24 23:19:15,228:INFO:          scikitplot: 0.3.7
2024-05-24 23:19:15,228:INFO:         yellowbrick: 1.5
2024-05-24 23:19:15,228:INFO:              plotly: 5.22.0
2024-05-24 23:19:15,228:INFO:    plotly-resampler: Not installed
2024-05-24 23:19:15,228:INFO:             kaleido: 0.2.1
2024-05-24 23:19:15,228:INFO:           schemdraw: 0.15
2024-05-24 23:19:15,228:INFO:         statsmodels: 0.14.2
2024-05-24 23:19:15,228:INFO:              sktime: 0.26.0
2024-05-24 23:19:15,228:INFO:               tbats: 1.1.3
2024-05-24 23:19:15,228:INFO:            pmdarima: 2.0.4
2024-05-24 23:19:15,228:INFO:              psutil: 5.9.0
2024-05-24 23:19:15,228:INFO:          markupsafe: 2.1.3
2024-05-24 23:19:15,228:INFO:             pickle5: Not installed
2024-05-24 23:19:15,228:INFO:         cloudpickle: 3.0.0
2024-05-24 23:19:15,228:INFO:         deprecation: 2.1.0
2024-05-24 23:19:15,228:INFO:              xxhash: 3.4.1
2024-05-24 23:19:15,228:INFO:           wurlitzer: Not installed
2024-05-24 23:19:15,228:INFO:PyCaret optional dependencies:
2024-05-24 23:19:22,229:INFO:                shap: 0.44.1
2024-05-24 23:19:22,229:INFO:           interpret: 0.6.1
2024-05-24 23:19:22,229:INFO:                umap: 0.5.6
2024-05-24 23:19:22,229:INFO:     ydata_profiling: 4.8.3
2024-05-24 23:19:22,229:INFO:  explainerdashboard: 0.4.7
2024-05-24 23:19:22,229:INFO:             autoviz: Not installed
2024-05-24 23:19:22,229:INFO:           fairlearn: 0.7.0
2024-05-24 23:19:22,229:INFO:          deepchecks: Not installed
2024-05-24 23:19:22,229:INFO:             xgboost: 2.0.3
2024-05-24 23:19:22,229:INFO:            catboost: 1.2.5
2024-05-24 23:19:22,230:INFO:              kmodes: 0.12.2
2024-05-24 23:19:22,230:INFO:             mlxtend: 0.23.1
2024-05-24 23:19:22,230:INFO:       statsforecast: 1.5.0
2024-05-24 23:19:22,230:INFO:        tune_sklearn: Not installed
2024-05-24 23:19:22,230:INFO:                 ray: Not installed
2024-05-24 23:19:22,230:INFO:            hyperopt: 0.2.7
2024-05-24 23:19:22,230:INFO:              optuna: 3.6.1
2024-05-24 23:19:22,230:INFO:               skopt: 0.10.1
2024-05-24 23:19:22,230:INFO:              mlflow: 2.13.0
2024-05-24 23:19:22,230:INFO:              gradio: 4.31.5
2024-05-24 23:19:22,230:INFO:             fastapi: 0.111.0
2024-05-24 23:19:22,230:INFO:             uvicorn: 0.29.0
2024-05-24 23:19:22,230:INFO:              m2cgen: 0.10.0
2024-05-24 23:19:22,230:INFO:           evidently: 0.4.25
2024-05-24 23:19:22,230:INFO:               fugue: 0.8.7
2024-05-24 23:19:22,230:INFO:           streamlit: Not installed
2024-05-24 23:19:22,230:INFO:             prophet: Not installed
2024-05-24 23:19:22,230:INFO:None
2024-05-24 23:19:22,230:INFO:Set up data.
2024-05-24 23:19:22,244:INFO:Set up folding strategy.
2024-05-24 23:19:22,244:INFO:Set up train/test split.
2024-05-24 23:19:22,251:INFO:Set up index.
2024-05-24 23:19:22,252:INFO:Assigning column types.
2024-05-24 23:19:22,258:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 23:19:22,258:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:19:22,262:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:19:22,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:19:22,320:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:22,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:22,361:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:22,363:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,130:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,134:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,138:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,189:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,227:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,230:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,230:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 23:19:28,234:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,238:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,331:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,332:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,334:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,340:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,348:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,403:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,458:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,461:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,461:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 23:19:28,470:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,572:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,575:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,695:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,698:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,698:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 23:19:28,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,818:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,819:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,821:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,891:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:19:28,934:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:28,937:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:28,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 23:19:29,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:29,041:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:29,044:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:29,110:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:19:29,154:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:29,157:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:29,158:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 23:19:29,270:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:29,273:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:29,399:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:29,402:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:29,405:INFO:Preparing preprocessing pipeline...
2024-05-24 23:19:29,405:INFO:Set up simple imputation.
2024-05-24 23:19:29,413:INFO:Set up encoding of ordinal features.
2024-05-24 23:19:29,420:INFO:Set up encoding of categorical features.
2024-05-24 23:19:29,420:INFO:Set up polynomial features.
2024-05-24 23:19:29,420:INFO:Set up removing multicollinearity.
2024-05-24 23:19:29,420:INFO:Set up removing outliers.
2024-05-24 23:19:30,758:INFO:Finished creating preprocessing pipeline.
2024-05-24 23:19:30,823:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'wheelbase',
                                             'carlength', 'carwidth',
                                             'carheight', 'curbweight',
                                             'enginesize', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'horsepower', 'peakrpm', 'citympg',
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_...
                                    transformer=TargetEncoder(cols=['CarName'],
                                                              handle_missing='return_nan'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=7135)))])
2024-05-24 23:19:30,823:INFO:Creating final display dataframe.
2024-05-24 23:19:32,957:INFO:Setup _display_container:                     Description             Value
0                    Session id              7135
1                        Target             price
2                   Target type        Regression
3           Original data shape         (205, 25)
4        Transformed data shape        (197, 476)
5   Transformed train set shape        (135, 476)
6    Transformed test set shape         (62, 476)
7              Numeric features                14
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.9
19              Remove outliers              True
20           Outliers threshold              0.05
21               Fold Generator             KFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  reg-default-name
27                          USI              883e
2024-05-24 23:19:33,099:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:33,104:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:33,255:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:19:33,258:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:19:33,260:INFO:setup() successfully completed in 19.67s...............
2024-05-24 23:19:33,272:INFO:Initializing compare_models()
2024-05-24 23:19:33,272:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 23:19:33,273:INFO:Checking exceptions
2024-05-24 23:19:33,276:INFO:Preparing display monitor
2024-05-24 23:19:33,302:INFO:Initializing Linear Regression
2024-05-24 23:19:33,302:INFO:Total runtime is 0.0 minutes
2024-05-24 23:19:33,308:INFO:SubProcess create_model() called ==================================
2024-05-24 23:19:33,308:INFO:Initializing create_model()
2024-05-24 23:19:33,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB072CA8C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:19:33,308:INFO:Checking exceptions
2024-05-24 23:19:33,308:INFO:Importing libraries
2024-05-24 23:19:33,308:INFO:Copying training dataset
2024-05-24 23:19:33,313:INFO:Defining folds
2024-05-24 23:19:33,313:INFO:Declaring metric variables
2024-05-24 23:19:33,317:INFO:Importing untrained model
2024-05-24 23:19:33,321:INFO:Linear Regression Imported successfully
2024-05-24 23:19:33,330:INFO:Starting cross validation
2024-05-24 23:19:33,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:19:42,029:INFO:Calculating mean and std
2024-05-24 23:19:42,031:INFO:Creating metrics dataframe
2024-05-24 23:19:42,034:INFO:Uploading results into container
2024-05-24 23:19:42,034:INFO:Uploading model into container now
2024-05-24 23:19:42,036:INFO:_master_model_container: 1
2024-05-24 23:19:42,036:INFO:_display_container: 2
2024-05-24 23:19:42,037:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:19:42,037:INFO:create_model() successfully completed......................................
2024-05-24 23:19:42,200:INFO:SubProcess create_model() end ==================================
2024-05-24 23:19:42,200:INFO:Creating metrics dataframe
2024-05-24 23:19:42,209:INFO:Initializing Lasso Regression
2024-05-24 23:19:42,209:INFO:Total runtime is 0.1484437902768453 minutes
2024-05-24 23:19:42,213:INFO:SubProcess create_model() called ==================================
2024-05-24 23:19:42,213:INFO:Initializing create_model()
2024-05-24 23:19:42,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB072CA8C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:19:42,213:INFO:Checking exceptions
2024-05-24 23:19:42,214:INFO:Importing libraries
2024-05-24 23:19:42,214:INFO:Copying training dataset
2024-05-24 23:19:42,221:INFO:Defining folds
2024-05-24 23:19:42,222:INFO:Declaring metric variables
2024-05-24 23:19:42,227:INFO:Importing untrained model
2024-05-24 23:19:42,232:INFO:Lasso Regression Imported successfully
2024-05-24 23:19:42,241:INFO:Starting cross validation
2024-05-24 23:19:42,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:19:44,173:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+07, tolerance: 8.715e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,316:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e+07, tolerance: 8.836e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+07, tolerance: 7.372e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,335:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+07, tolerance: 6.426e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,355:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e+07, tolerance: 7.153e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,364:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.721e+07, tolerance: 7.104e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,380:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+07, tolerance: 8.364e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:44,437:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+07, tolerance: 7.778e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:47,321:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+07, tolerance: 9.021e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:47,332:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+07, tolerance: 8.111e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:19:47,395:INFO:Calculating mean and std
2024-05-24 23:19:47,397:INFO:Creating metrics dataframe
2024-05-24 23:19:47,399:INFO:Uploading results into container
2024-05-24 23:19:47,399:INFO:Uploading model into container now
2024-05-24 23:19:47,400:INFO:_master_model_container: 2
2024-05-24 23:19:47,400:INFO:_display_container: 2
2024-05-24 23:19:47,400:INFO:Lasso(random_state=7135)
2024-05-24 23:19:47,400:INFO:create_model() successfully completed......................................
2024-05-24 23:19:47,544:INFO:SubProcess create_model() end ==================================
2024-05-24 23:19:47,545:INFO:Creating metrics dataframe
2024-05-24 23:19:47,553:INFO:Initializing Ridge Regression
2024-05-24 23:19:47,553:INFO:Total runtime is 0.23751343886057535 minutes
2024-05-24 23:19:47,556:INFO:SubProcess create_model() called ==================================
2024-05-24 23:19:47,558:INFO:Initializing create_model()
2024-05-24 23:19:47,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB072CA8C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:19:47,558:INFO:Checking exceptions
2024-05-24 23:19:47,559:INFO:Importing libraries
2024-05-24 23:19:47,559:INFO:Copying training dataset
2024-05-24 23:19:47,565:INFO:Defining folds
2024-05-24 23:19:47,565:INFO:Declaring metric variables
2024-05-24 23:19:47,569:INFO:Importing untrained model
2024-05-24 23:19:47,576:INFO:Ridge Regression Imported successfully
2024-05-24 23:19:47,585:INFO:Starting cross validation
2024-05-24 23:19:47,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:19:49,498:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,554:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,564:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,628:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,629:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,631:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,651:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,654:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,688:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.
  warnings.warn(

2024-05-24 23:19:49,760:INFO:Calculating mean and std
2024-05-24 23:19:49,761:INFO:Creating metrics dataframe
2024-05-24 23:19:49,763:INFO:Uploading results into container
2024-05-24 23:19:49,764:INFO:Uploading model into container now
2024-05-24 23:19:49,765:INFO:_master_model_container: 3
2024-05-24 23:19:49,765:INFO:_display_container: 2
2024-05-24 23:19:49,765:INFO:Ridge(random_state=7135)
2024-05-24 23:19:49,765:INFO:create_model() successfully completed......................................
2024-05-24 23:19:49,915:INFO:SubProcess create_model() end ==================================
2024-05-24 23:19:49,915:INFO:Creating metrics dataframe
2024-05-24 23:19:49,927:INFO:Initializing Huber Regressor
2024-05-24 23:19:49,927:INFO:Total runtime is 0.27708276112874347 minutes
2024-05-24 23:19:49,932:INFO:SubProcess create_model() called ==================================
2024-05-24 23:19:49,932:INFO:Initializing create_model()
2024-05-24 23:19:49,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB072CA8C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:19:49,933:INFO:Checking exceptions
2024-05-24 23:19:49,933:INFO:Importing libraries
2024-05-24 23:19:49,933:INFO:Copying training dataset
2024-05-24 23:19:49,941:INFO:Defining folds
2024-05-24 23:19:49,941:INFO:Declaring metric variables
2024-05-24 23:19:49,946:INFO:Importing untrained model
2024-05-24 23:19:49,952:INFO:Huber Regressor Imported successfully
2024-05-24 23:19:49,960:INFO:Starting cross validation
2024-05-24 23:19:49,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:19:52,108:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:52,121:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:52,121:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:52,175:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:52,176:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:52,262:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 23:19:52,263:INFO:Calculating mean and std
2024-05-24 23:19:52,264:INFO:Creating metrics dataframe
2024-05-24 23:19:52,266:INFO:Uploading results into container
2024-05-24 23:19:52,267:INFO:Uploading model into container now
2024-05-24 23:19:52,267:INFO:_master_model_container: 4
2024-05-24 23:19:52,267:INFO:_display_container: 2
2024-05-24 23:19:52,268:INFO:HuberRegressor()
2024-05-24 23:19:52,268:INFO:create_model() successfully completed......................................
2024-05-24 23:19:52,406:INFO:SubProcess create_model() end ==================================
2024-05-24 23:19:52,406:INFO:Creating metrics dataframe
2024-05-24 23:19:52,415:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 23:19:52,427:INFO:Initializing create_model()
2024-05-24 23:19:52,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:19:52,427:INFO:Checking exceptions
2024-05-24 23:19:52,429:INFO:Importing libraries
2024-05-24 23:19:52,430:INFO:Copying training dataset
2024-05-24 23:19:52,437:INFO:Defining folds
2024-05-24 23:19:52,437:INFO:Declaring metric variables
2024-05-24 23:19:52,437:INFO:Importing untrained model
2024-05-24 23:19:52,437:INFO:Declaring custom model
2024-05-24 23:19:52,437:INFO:Huber Regressor Imported successfully
2024-05-24 23:19:52,468:INFO:Cross validation set to False
2024-05-24 23:19:52,468:INFO:Fitting Model
2024-05-24 23:19:53,615:INFO:HuberRegressor()
2024-05-24 23:19:53,615:INFO:create_model() successfully completed......................................
2024-05-24 23:19:53,783:INFO:_master_model_container: 4
2024-05-24 23:19:53,783:INFO:_display_container: 2
2024-05-24 23:19:53,783:INFO:HuberRegressor()
2024-05-24 23:19:53,783:INFO:compare_models() successfully completed......................................
2024-05-24 23:19:53,838:INFO:Initializing evaluate_model()
2024-05-24 23:19:53,839:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=HuberRegressor(), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 23:19:53,854:INFO:Initializing plot_model()
2024-05-24 23:19:53,854:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, system=True)
2024-05-24 23:19:53,854:INFO:Checking exceptions
2024-05-24 23:19:53,858:INFO:Preloading libraries
2024-05-24 23:19:53,860:INFO:Copying training dataset
2024-05-24 23:19:53,860:INFO:Plot type: pipeline
2024-05-24 23:19:54,142:INFO:Visual Rendered Successfully
2024-05-24 23:19:54,291:INFO:plot_model() successfully completed......................................
2024-05-24 23:19:54,347:INFO:Initializing create_model()
2024-05-24 23:19:54,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:19:54,348:INFO:Checking exceptions
2024-05-24 23:19:54,369:INFO:Importing libraries
2024-05-24 23:19:54,369:INFO:Copying training dataset
2024-05-24 23:19:54,377:INFO:Defining folds
2024-05-24 23:19:54,377:INFO:Declaring metric variables
2024-05-24 23:19:54,384:INFO:Importing untrained model
2024-05-24 23:19:54,384:INFO:Declaring custom model
2024-05-24 23:19:54,389:INFO:Huber Regressor Imported successfully
2024-05-24 23:19:54,399:INFO:Starting cross validation
2024-05-24 23:19:54,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:19:56,647:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:56,662:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:56,679:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:56,702:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:56,744:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:19:56,816:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 23:19:56,816:INFO:Calculating mean and std
2024-05-24 23:19:56,817:INFO:Creating metrics dataframe
2024-05-24 23:19:56,823:INFO:Finalizing model
2024-05-24 23:19:58,030:INFO:Uploading results into container
2024-05-24 23:19:58,031:INFO:Uploading model into container now
2024-05-24 23:19:58,044:INFO:_master_model_container: 5
2024-05-24 23:19:58,044:INFO:_display_container: 3
2024-05-24 23:19:58,045:INFO:HuberRegressor()
2024-05-24 23:19:58,045:INFO:create_model() successfully completed......................................
2024-05-24 23:19:58,250:INFO:Initializing tune_model()
2024-05-24 23:19:58,250:INFO:tune_model(estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>)
2024-05-24 23:19:58,250:INFO:Checking exceptions
2024-05-24 23:19:58,274:INFO:Copying training dataset
2024-05-24 23:19:58,280:INFO:Checking base model
2024-05-24 23:19:58,281:INFO:Base model : Huber Regressor
2024-05-24 23:19:58,286:INFO:Declaring metric variables
2024-05-24 23:19:58,289:INFO:Defining Hyperparameters
2024-05-24 23:19:58,473:INFO:Tuning with n_jobs=-1
2024-05-24 23:19:58,474:INFO:Initializing RandomizedSearchCV
2024-05-24 23:20:00,752:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:00,762:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:00,876:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:00,920:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:00,926:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:00,951:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:01,054:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:01,685:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:03,171:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:03,337:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:03,590:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:03,597:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:03,668:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:04,065:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:04,567:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:04,884:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:05,381:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:05,496:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:07,442:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:07,571:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:07,726:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:08,038:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:09,457:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:10,063:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:10,616:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:12,331:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:12,704:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:12,731:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:12,826:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:13,088:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:13,098:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:14,802:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:15,159:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:15,273:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:15,427:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:15,561:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:16,048:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:16,633:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:16,924:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:16,926:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:17,487:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:17,621:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:17,757:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:19,380:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:19,787:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:19,864:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.9, 'actual_estimator__alpha': 1e-07}
2024-05-24 23:20:19,864:INFO:Hyperparameter search completed
2024-05-24 23:20:19,864:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:19,865:INFO:Initializing create_model()
2024-05-24 23:20:19,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB29B77640>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1.9, 'alpha': 1e-07})
2024-05-24 23:20:19,865:INFO:Checking exceptions
2024-05-24 23:20:19,865:INFO:Importing libraries
2024-05-24 23:20:19,865:INFO:Copying training dataset
2024-05-24 23:20:19,872:INFO:Defining folds
2024-05-24 23:20:19,873:INFO:Declaring metric variables
2024-05-24 23:20:19,878:INFO:Importing untrained model
2024-05-24 23:20:19,878:INFO:Declaring custom model
2024-05-24 23:20:19,882:INFO:Huber Regressor Imported successfully
2024-05-24 23:20:19,890:INFO:Starting cross validation
2024-05-24 23:20:19,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:20:21,858:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:22,055:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:22,179:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:22,197:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:22,207:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:22,388:INFO:Calculating mean and std
2024-05-24 23:20:22,389:INFO:Creating metrics dataframe
2024-05-24 23:20:22,397:INFO:Finalizing model
2024-05-24 23:20:23,745:INFO:Uploading results into container
2024-05-24 23:20:23,746:INFO:Uploading model into container now
2024-05-24 23:20:23,747:INFO:_master_model_container: 6
2024-05-24 23:20:23,747:INFO:_display_container: 4
2024-05-24 23:20:23,748:INFO:HuberRegressor(alpha=1e-07, epsilon=1.9)
2024-05-24 23:20:23,748:INFO:create_model() successfully completed......................................
2024-05-24 23:20:23,901:INFO:SubProcess create_model() end ==================================
2024-05-24 23:20:23,901:INFO:choose_better activated
2024-05-24 23:20:23,905:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:23,905:INFO:Initializing create_model()
2024-05-24 23:20:23,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:23,906:INFO:Checking exceptions
2024-05-24 23:20:23,909:INFO:Importing libraries
2024-05-24 23:20:23,909:INFO:Copying training dataset
2024-05-24 23:20:23,915:INFO:Defining folds
2024-05-24 23:20:23,916:INFO:Declaring metric variables
2024-05-24 23:20:23,916:INFO:Importing untrained model
2024-05-24 23:20:23,916:INFO:Declaring custom model
2024-05-24 23:20:23,916:INFO:Huber Regressor Imported successfully
2024-05-24 23:20:23,916:INFO:Starting cross validation
2024-05-24 23:20:23,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:20:26,104:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:26,312:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:26,312:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:26,429:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:26,430:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:20:26,516:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
1 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py", line 338, in fit
    raise ValueError(
ValueError: HuberRegressor convergence failed: l-BFGS-b solver terminated with ABNORMAL_TERMINATION_IN_LNSRCH

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-05-24 23:20:26,517:INFO:Calculating mean and std
2024-05-24 23:20:26,517:INFO:Creating metrics dataframe
2024-05-24 23:20:26,519:INFO:Finalizing model
2024-05-24 23:20:27,692:INFO:Uploading results into container
2024-05-24 23:20:27,693:INFO:Uploading model into container now
2024-05-24 23:20:27,694:INFO:_master_model_container: 7
2024-05-24 23:20:27,694:INFO:_display_container: 5
2024-05-24 23:20:27,694:INFO:HuberRegressor()
2024-05-24 23:20:27,694:INFO:create_model() successfully completed......................................
2024-05-24 23:20:27,848:INFO:SubProcess create_model() end ==================================
2024-05-24 23:20:27,848:INFO:HuberRegressor() result for R2 is 0.2727
2024-05-24 23:20:27,849:INFO:HuberRegressor(alpha=1e-07, epsilon=1.9) result for R2 is 0.3936
2024-05-24 23:20:27,849:INFO:HuberRegressor(alpha=1e-07, epsilon=1.9) is best model
2024-05-24 23:20:27,849:INFO:choose_better completed
2024-05-24 23:20:27,866:INFO:_master_model_container: 7
2024-05-24 23:20:27,866:INFO:_display_container: 4
2024-05-24 23:20:27,867:INFO:HuberRegressor(alpha=1e-07, epsilon=1.9)
2024-05-24 23:20:27,867:INFO:tune_model() successfully completed......................................
2024-05-24 23:20:28,189:INFO:Initializing plot_model()
2024-05-24 23:20:28,190:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=HuberRegressor(), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB072CABC0>, system=True)
2024-05-24 23:20:28,190:INFO:Checking exceptions
2024-05-24 23:20:28,196:INFO:Preloading libraries
2024-05-24 23:20:28,197:INFO:Copying training dataset
2024-05-24 23:20:28,197:INFO:Plot type: feature
2024-05-24 23:20:29,009:INFO:Visual Rendered Successfully
2024-05-24 23:20:29,178:INFO:plot_model() successfully completed......................................
2024-05-24 23:20:36,032:INFO:PyCaret RegressionExperiment
2024-05-24 23:20:36,032:INFO:Logging name: reg-default-name
2024-05-24 23:20:36,032:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 23:20:36,032:INFO:version 3.3.2
2024-05-24 23:20:36,032:INFO:Initializing setup()
2024-05-24 23:20:36,032:INFO:self.USI: 8f7a
2024-05-24 23:20:36,034:INFO:self._variable_keys: {'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'pipeline', 'USI', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'target_param', 'X_train', 'fold_generator', 'y_test', 'log_plots_param', 'data', 'exp_name_log', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'memory', 'seed', 'y', 'X_test', 'X', '_available_plots', 'transform_target_param'}
2024-05-24 23:20:36,034:INFO:Checking environment
2024-05-24 23:20:36,034:INFO:python_version: 3.10.14
2024-05-24 23:20:36,034:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 23:20:36,034:INFO:machine: AMD64
2024-05-24 23:20:36,034:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 23:20:36,034:INFO:Memory: svmem(total=16541802496, available=3462492160, percent=79.1, used=13079310336, free=3462492160)
2024-05-24 23:20:36,034:INFO:Physical Core: 6
2024-05-24 23:20:36,034:INFO:Logical Core: 12
2024-05-24 23:20:36,034:INFO:Checking libraries
2024-05-24 23:20:36,034:INFO:System:
2024-05-24 23:20:36,034:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 23:20:36,034:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 23:20:36,034:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 23:20:36,034:INFO:PyCaret required dependencies:
2024-05-24 23:20:36,035:INFO:                 pip: 24.0
2024-05-24 23:20:36,035:INFO:          setuptools: 69.5.1
2024-05-24 23:20:36,035:INFO:             pycaret: 3.3.2
2024-05-24 23:20:36,035:INFO:             IPython: 8.20.0
2024-05-24 23:20:36,035:INFO:          ipywidgets: 8.1.2
2024-05-24 23:20:36,035:INFO:                tqdm: 4.66.4
2024-05-24 23:20:36,035:INFO:               numpy: 1.26.4
2024-05-24 23:20:36,035:INFO:              pandas: 2.1.4
2024-05-24 23:20:36,035:INFO:              jinja2: 3.1.3
2024-05-24 23:20:36,035:INFO:               scipy: 1.11.4
2024-05-24 23:20:36,035:INFO:              joblib: 1.3.2
2024-05-24 23:20:36,035:INFO:             sklearn: 1.4.2
2024-05-24 23:20:36,035:INFO:                pyod: 1.1.3
2024-05-24 23:20:36,035:INFO:            imblearn: 0.12.2
2024-05-24 23:20:36,035:INFO:   category_encoders: 2.6.3
2024-05-24 23:20:36,035:INFO:            lightgbm: 4.3.0
2024-05-24 23:20:36,035:INFO:               numba: 0.59.1
2024-05-24 23:20:36,035:INFO:            requests: 2.32.2
2024-05-24 23:20:36,035:INFO:          matplotlib: 3.7.5
2024-05-24 23:20:36,035:INFO:          scikitplot: 0.3.7
2024-05-24 23:20:36,035:INFO:         yellowbrick: 1.5
2024-05-24 23:20:36,035:INFO:              plotly: 5.22.0
2024-05-24 23:20:36,035:INFO:    plotly-resampler: Not installed
2024-05-24 23:20:36,035:INFO:             kaleido: 0.2.1
2024-05-24 23:20:36,035:INFO:           schemdraw: 0.15
2024-05-24 23:20:36,035:INFO:         statsmodels: 0.14.2
2024-05-24 23:20:36,035:INFO:              sktime: 0.26.0
2024-05-24 23:20:36,035:INFO:               tbats: 1.1.3
2024-05-24 23:20:36,035:INFO:            pmdarima: 2.0.4
2024-05-24 23:20:36,035:INFO:              psutil: 5.9.0
2024-05-24 23:20:36,035:INFO:          markupsafe: 2.1.3
2024-05-24 23:20:36,035:INFO:             pickle5: Not installed
2024-05-24 23:20:36,035:INFO:         cloudpickle: 3.0.0
2024-05-24 23:20:36,036:INFO:         deprecation: 2.1.0
2024-05-24 23:20:36,036:INFO:              xxhash: 3.4.1
2024-05-24 23:20:36,036:INFO:           wurlitzer: Not installed
2024-05-24 23:20:36,036:INFO:PyCaret optional dependencies:
2024-05-24 23:20:36,036:INFO:                shap: 0.44.1
2024-05-24 23:20:36,036:INFO:           interpret: 0.6.1
2024-05-24 23:20:36,036:INFO:                umap: 0.5.6
2024-05-24 23:20:36,036:INFO:     ydata_profiling: 4.8.3
2024-05-24 23:20:36,036:INFO:  explainerdashboard: 0.4.7
2024-05-24 23:20:36,036:INFO:             autoviz: Not installed
2024-05-24 23:20:36,036:INFO:           fairlearn: 0.7.0
2024-05-24 23:20:36,036:INFO:          deepchecks: Not installed
2024-05-24 23:20:36,036:INFO:             xgboost: 2.0.3
2024-05-24 23:20:36,036:INFO:            catboost: 1.2.5
2024-05-24 23:20:36,036:INFO:              kmodes: 0.12.2
2024-05-24 23:20:36,036:INFO:             mlxtend: 0.23.1
2024-05-24 23:20:36,036:INFO:       statsforecast: 1.5.0
2024-05-24 23:20:36,036:INFO:        tune_sklearn: Not installed
2024-05-24 23:20:36,036:INFO:                 ray: Not installed
2024-05-24 23:20:36,036:INFO:            hyperopt: 0.2.7
2024-05-24 23:20:36,036:INFO:              optuna: 3.6.1
2024-05-24 23:20:36,036:INFO:               skopt: 0.10.1
2024-05-24 23:20:36,036:INFO:              mlflow: 2.13.0
2024-05-24 23:20:36,036:INFO:              gradio: 4.31.5
2024-05-24 23:20:36,036:INFO:             fastapi: 0.111.0
2024-05-24 23:20:36,037:INFO:             uvicorn: 0.29.0
2024-05-24 23:20:36,037:INFO:              m2cgen: 0.10.0
2024-05-24 23:20:36,037:INFO:           evidently: 0.4.25
2024-05-24 23:20:36,037:INFO:               fugue: 0.8.7
2024-05-24 23:20:36,037:INFO:           streamlit: Not installed
2024-05-24 23:20:36,037:INFO:             prophet: Not installed
2024-05-24 23:20:36,037:INFO:None
2024-05-24 23:20:36,037:INFO:Set up data.
2024-05-24 23:20:36,042:INFO:Set up folding strategy.
2024-05-24 23:20:36,042:INFO:Set up train/test split.
2024-05-24 23:20:36,045:INFO:Set up index.
2024-05-24 23:20:36,045:INFO:Assigning column types.
2024-05-24 23:20:36,048:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 23:20:36,048:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,053:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,058:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,162:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,164:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,165:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,170:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,174:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,278:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,280:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,281:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 23:20:36,286:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,290:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,348:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,393:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,397:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,401:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,406:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,464:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,510:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,512:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,513:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 23:20:36,523:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,583:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,627:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,630:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,641:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,750:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,750:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,753:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,754:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 23:20:36,823:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,868:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,871:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:36,983:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:36,987:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:36,987:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 23:20:37,059:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:37,104:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:37,106:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:37,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:37,223:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:37,225:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:37,226:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 23:20:37,338:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:37,340:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:37,458:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:37,460:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:37,464:INFO:Finished creating preprocessing pipeline.
2024-05-24 23:20:37,464:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)])
2024-05-24 23:20:37,464:INFO:Creating final display dataframe.
2024-05-24 23:20:37,494:INFO:Setup _display_container:                    Description       Value
0                   Session id        7219
1                       Target       price
2                  Target type  Regression
3          Original data shape    (183, 6)
4       Transformed data shape    (183, 6)
5  Transformed train set shape    (128, 6)
6   Transformed test set shape     (55, 6)
7             Numeric features           5
2024-05-24 23:20:37,621:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:37,623:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:37,741:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:37,744:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:37,745:INFO:setup() successfully completed in 1.77s...............
2024-05-24 23:20:37,769:INFO:Initializing compare_models()
2024-05-24 23:20:37,769:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 23:20:37,769:INFO:Checking exceptions
2024-05-24 23:20:37,771:INFO:Preparing display monitor
2024-05-24 23:20:37,801:INFO:Initializing Linear Regression
2024-05-24 23:20:37,801:INFO:Total runtime is 0.0 minutes
2024-05-24 23:20:37,805:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:37,806:INFO:Initializing create_model()
2024-05-24 23:20:37,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB289060E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:37,806:INFO:Checking exceptions
2024-05-24 23:20:37,806:INFO:Importing libraries
2024-05-24 23:20:37,806:INFO:Copying training dataset
2024-05-24 23:20:37,810:INFO:Defining folds
2024-05-24 23:20:37,810:INFO:Declaring metric variables
2024-05-24 23:20:37,815:INFO:Importing untrained model
2024-05-24 23:20:37,820:INFO:Linear Regression Imported successfully
2024-05-24 23:20:37,831:INFO:Starting cross validation
2024-05-24 23:20:37,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:20:37,953:INFO:Calculating mean and std
2024-05-24 23:20:37,953:INFO:Creating metrics dataframe
2024-05-24 23:20:37,955:INFO:Uploading results into container
2024-05-24 23:20:37,955:INFO:Uploading model into container now
2024-05-24 23:20:37,956:INFO:_master_model_container: 1
2024-05-24 23:20:37,956:INFO:_display_container: 2
2024-05-24 23:20:37,956:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:20:37,956:INFO:create_model() successfully completed......................................
2024-05-24 23:20:38,123:INFO:SubProcess create_model() end ==================================
2024-05-24 23:20:38,123:INFO:Creating metrics dataframe
2024-05-24 23:20:38,131:INFO:Initializing Lasso Regression
2024-05-24 23:20:38,131:INFO:Total runtime is 0.00550374984741211 minutes
2024-05-24 23:20:38,134:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:38,135:INFO:Initializing create_model()
2024-05-24 23:20:38,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB289060E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:38,135:INFO:Checking exceptions
2024-05-24 23:20:38,135:INFO:Importing libraries
2024-05-24 23:20:38,135:INFO:Copying training dataset
2024-05-24 23:20:38,139:INFO:Defining folds
2024-05-24 23:20:38,139:INFO:Declaring metric variables
2024-05-24 23:20:38,143:INFO:Importing untrained model
2024-05-24 23:20:38,147:INFO:Lasso Regression Imported successfully
2024-05-24 23:20:38,155:INFO:Starting cross validation
2024-05-24 23:20:38,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:20:38,234:INFO:Calculating mean and std
2024-05-24 23:20:38,236:INFO:Creating metrics dataframe
2024-05-24 23:20:38,238:INFO:Uploading results into container
2024-05-24 23:20:38,238:INFO:Uploading model into container now
2024-05-24 23:20:38,239:INFO:_master_model_container: 2
2024-05-24 23:20:38,239:INFO:_display_container: 2
2024-05-24 23:20:38,239:INFO:Lasso(random_state=7219)
2024-05-24 23:20:38,239:INFO:create_model() successfully completed......................................
2024-05-24 23:20:38,394:INFO:SubProcess create_model() end ==================================
2024-05-24 23:20:38,394:INFO:Creating metrics dataframe
2024-05-24 23:20:38,402:INFO:Initializing Ridge Regression
2024-05-24 23:20:38,402:INFO:Total runtime is 0.010023832321166992 minutes
2024-05-24 23:20:38,406:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:38,408:INFO:Initializing create_model()
2024-05-24 23:20:38,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB289060E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:38,408:INFO:Checking exceptions
2024-05-24 23:20:38,408:INFO:Importing libraries
2024-05-24 23:20:38,408:INFO:Copying training dataset
2024-05-24 23:20:38,414:INFO:Defining folds
2024-05-24 23:20:38,414:INFO:Declaring metric variables
2024-05-24 23:20:38,419:INFO:Importing untrained model
2024-05-24 23:20:38,423:INFO:Ridge Regression Imported successfully
2024-05-24 23:20:38,430:INFO:Starting cross validation
2024-05-24 23:20:38,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:20:38,515:INFO:Calculating mean and std
2024-05-24 23:20:38,516:INFO:Creating metrics dataframe
2024-05-24 23:20:38,517:INFO:Uploading results into container
2024-05-24 23:20:38,519:INFO:Uploading model into container now
2024-05-24 23:20:38,519:INFO:_master_model_container: 3
2024-05-24 23:20:38,519:INFO:_display_container: 2
2024-05-24 23:20:38,519:INFO:Ridge(random_state=7219)
2024-05-24 23:20:38,519:INFO:create_model() successfully completed......................................
2024-05-24 23:20:38,678:INFO:SubProcess create_model() end ==================================
2024-05-24 23:20:38,678:INFO:Creating metrics dataframe
2024-05-24 23:20:38,688:INFO:Initializing Huber Regressor
2024-05-24 23:20:38,688:INFO:Total runtime is 0.014780886967976888 minutes
2024-05-24 23:20:38,692:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:38,693:INFO:Initializing create_model()
2024-05-24 23:20:38,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB289060E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:38,693:INFO:Checking exceptions
2024-05-24 23:20:38,693:INFO:Importing libraries
2024-05-24 23:20:38,693:INFO:Copying training dataset
2024-05-24 23:20:38,697:INFO:Defining folds
2024-05-24 23:20:38,697:INFO:Declaring metric variables
2024-05-24 23:20:38,701:INFO:Importing untrained model
2024-05-24 23:20:38,706:INFO:Huber Regressor Imported successfully
2024-05-24 23:20:38,715:INFO:Starting cross validation
2024-05-24 23:20:38,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:20:38,813:INFO:Calculating mean and std
2024-05-24 23:20:38,815:INFO:Creating metrics dataframe
2024-05-24 23:20:38,817:INFO:Uploading results into container
2024-05-24 23:20:38,818:INFO:Uploading model into container now
2024-05-24 23:20:38,818:INFO:_master_model_container: 4
2024-05-24 23:20:38,818:INFO:_display_container: 2
2024-05-24 23:20:38,819:INFO:HuberRegressor()
2024-05-24 23:20:38,819:INFO:create_model() successfully completed......................................
2024-05-24 23:20:38,975:INFO:SubProcess create_model() end ==================================
2024-05-24 23:20:38,975:INFO:Creating metrics dataframe
2024-05-24 23:20:38,986:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 23:20:38,996:INFO:Initializing create_model()
2024-05-24 23:20:38,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB28938C70>, estimator=Ridge(random_state=7219), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:38,996:INFO:Checking exceptions
2024-05-24 23:20:38,998:INFO:Importing libraries
2024-05-24 23:20:38,998:INFO:Copying training dataset
2024-05-24 23:20:39,003:INFO:Defining folds
2024-05-24 23:20:39,003:INFO:Declaring metric variables
2024-05-24 23:20:39,004:INFO:Importing untrained model
2024-05-24 23:20:39,004:INFO:Declaring custom model
2024-05-24 23:20:39,004:INFO:Ridge Regression Imported successfully
2024-05-24 23:20:39,005:INFO:Cross validation set to False
2024-05-24 23:20:39,005:INFO:Fitting Model
2024-05-24 23:20:39,007:INFO:Ridge(random_state=7219)
2024-05-24 23:20:39,007:INFO:create_model() successfully completed......................................
2024-05-24 23:20:39,219:INFO:_master_model_container: 4
2024-05-24 23:20:39,219:INFO:_display_container: 2
2024-05-24 23:20:39,220:INFO:Ridge(random_state=7219)
2024-05-24 23:20:39,220:INFO:compare_models() successfully completed......................................
2024-05-24 23:20:57,105:INFO:PyCaret RegressionExperiment
2024-05-24 23:20:57,106:INFO:Logging name: reg-default-name
2024-05-24 23:20:57,106:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 23:20:57,106:INFO:version 3.3.2
2024-05-24 23:20:57,106:INFO:Initializing setup()
2024-05-24 23:20:57,106:INFO:self.USI: 847b
2024-05-24 23:20:57,106:INFO:self._variable_keys: {'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'pipeline', 'USI', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'target_param', 'X_train', 'fold_generator', 'y_test', 'log_plots_param', 'data', 'exp_name_log', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'memory', 'seed', 'y', 'X_test', 'X', '_available_plots', 'transform_target_param'}
2024-05-24 23:20:57,106:INFO:Checking environment
2024-05-24 23:20:57,106:INFO:python_version: 3.10.14
2024-05-24 23:20:57,106:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 23:20:57,106:INFO:machine: AMD64
2024-05-24 23:20:57,106:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 23:20:57,106:INFO:Memory: svmem(total=16541802496, available=3308068864, percent=80.0, used=13233733632, free=3308068864)
2024-05-24 23:20:57,106:INFO:Physical Core: 6
2024-05-24 23:20:57,106:INFO:Logical Core: 12
2024-05-24 23:20:57,106:INFO:Checking libraries
2024-05-24 23:20:57,106:INFO:System:
2024-05-24 23:20:57,106:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 23:20:57,107:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 23:20:57,107:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 23:20:57,107:INFO:PyCaret required dependencies:
2024-05-24 23:20:57,107:INFO:                 pip: 24.0
2024-05-24 23:20:57,107:INFO:          setuptools: 69.5.1
2024-05-24 23:20:57,107:INFO:             pycaret: 3.3.2
2024-05-24 23:20:57,107:INFO:             IPython: 8.20.0
2024-05-24 23:20:57,107:INFO:          ipywidgets: 8.1.2
2024-05-24 23:20:57,107:INFO:                tqdm: 4.66.4
2024-05-24 23:20:57,107:INFO:               numpy: 1.26.4
2024-05-24 23:20:57,107:INFO:              pandas: 2.1.4
2024-05-24 23:20:57,107:INFO:              jinja2: 3.1.3
2024-05-24 23:20:57,107:INFO:               scipy: 1.11.4
2024-05-24 23:20:57,107:INFO:              joblib: 1.3.2
2024-05-24 23:20:57,107:INFO:             sklearn: 1.4.2
2024-05-24 23:20:57,107:INFO:                pyod: 1.1.3
2024-05-24 23:20:57,107:INFO:            imblearn: 0.12.2
2024-05-24 23:20:57,107:INFO:   category_encoders: 2.6.3
2024-05-24 23:20:57,107:INFO:            lightgbm: 4.3.0
2024-05-24 23:20:57,107:INFO:               numba: 0.59.1
2024-05-24 23:20:57,108:INFO:            requests: 2.32.2
2024-05-24 23:20:57,108:INFO:          matplotlib: 3.7.5
2024-05-24 23:20:57,108:INFO:          scikitplot: 0.3.7
2024-05-24 23:20:57,108:INFO:         yellowbrick: 1.5
2024-05-24 23:20:57,108:INFO:              plotly: 5.22.0
2024-05-24 23:20:57,108:INFO:    plotly-resampler: Not installed
2024-05-24 23:20:57,108:INFO:             kaleido: 0.2.1
2024-05-24 23:20:57,108:INFO:           schemdraw: 0.15
2024-05-24 23:20:57,108:INFO:         statsmodels: 0.14.2
2024-05-24 23:20:57,108:INFO:              sktime: 0.26.0
2024-05-24 23:20:57,108:INFO:               tbats: 1.1.3
2024-05-24 23:20:57,108:INFO:            pmdarima: 2.0.4
2024-05-24 23:20:57,108:INFO:              psutil: 5.9.0
2024-05-24 23:20:57,108:INFO:          markupsafe: 2.1.3
2024-05-24 23:20:57,108:INFO:             pickle5: Not installed
2024-05-24 23:20:57,108:INFO:         cloudpickle: 3.0.0
2024-05-24 23:20:57,109:INFO:         deprecation: 2.1.0
2024-05-24 23:20:57,109:INFO:              xxhash: 3.4.1
2024-05-24 23:20:57,109:INFO:           wurlitzer: Not installed
2024-05-24 23:20:57,109:INFO:PyCaret optional dependencies:
2024-05-24 23:20:57,109:INFO:                shap: 0.44.1
2024-05-24 23:20:57,109:INFO:           interpret: 0.6.1
2024-05-24 23:20:57,109:INFO:                umap: 0.5.6
2024-05-24 23:20:57,109:INFO:     ydata_profiling: 4.8.3
2024-05-24 23:20:57,109:INFO:  explainerdashboard: 0.4.7
2024-05-24 23:20:57,109:INFO:             autoviz: Not installed
2024-05-24 23:20:57,109:INFO:           fairlearn: 0.7.0
2024-05-24 23:20:57,109:INFO:          deepchecks: Not installed
2024-05-24 23:20:57,109:INFO:             xgboost: 2.0.3
2024-05-24 23:20:57,109:INFO:            catboost: 1.2.5
2024-05-24 23:20:57,109:INFO:              kmodes: 0.12.2
2024-05-24 23:20:57,109:INFO:             mlxtend: 0.23.1
2024-05-24 23:20:57,111:INFO:       statsforecast: 1.5.0
2024-05-24 23:20:57,111:INFO:        tune_sklearn: Not installed
2024-05-24 23:20:57,111:INFO:                 ray: Not installed
2024-05-24 23:20:57,111:INFO:            hyperopt: 0.2.7
2024-05-24 23:20:57,111:INFO:              optuna: 3.6.1
2024-05-24 23:20:57,111:INFO:               skopt: 0.10.1
2024-05-24 23:20:57,111:INFO:              mlflow: 2.13.0
2024-05-24 23:20:57,111:INFO:              gradio: 4.31.5
2024-05-24 23:20:57,111:INFO:             fastapi: 0.111.0
2024-05-24 23:20:57,111:INFO:             uvicorn: 0.29.0
2024-05-24 23:20:57,111:INFO:              m2cgen: 0.10.0
2024-05-24 23:20:57,111:INFO:           evidently: 0.4.25
2024-05-24 23:20:57,111:INFO:               fugue: 0.8.7
2024-05-24 23:20:57,111:INFO:           streamlit: Not installed
2024-05-24 23:20:57,111:INFO:             prophet: Not installed
2024-05-24 23:20:57,112:INFO:None
2024-05-24 23:20:57,112:INFO:Set up data.
2024-05-24 23:20:57,116:INFO:Set up folding strategy.
2024-05-24 23:20:57,116:INFO:Set up train/test split.
2024-05-24 23:20:57,119:INFO:Set up index.
2024-05-24 23:20:57,119:INFO:Assigning column types.
2024-05-24 23:20:57,123:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 23:20:57,123:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,128:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,134:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,242:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,247:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:57,247:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,252:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,257:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,364:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,367:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:57,367:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 23:20:57,372:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,377:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,484:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,485:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,488:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:57,493:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,497:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,603:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,603:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,606:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:57,607:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 23:20:57,616:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,727:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,730:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:57,739:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,798:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,853:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,853:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,855:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:57,856:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 23:20:57,931:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:57,979:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:57,981:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:58,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:58,095:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:20:58,095:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:58,098:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:58,099:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 23:20:58,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:58,212:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:58,216:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:58,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:20:58,327:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:58,330:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:58,331:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 23:20:58,441:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:58,445:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:58,556:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:58,559:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:58,560:INFO:Preparing preprocessing pipeline...
2024-05-24 23:20:58,560:INFO:Set up simple imputation.
2024-05-24 23:20:58,561:INFO:Set up polynomial features.
2024-05-24 23:20:58,561:INFO:Set up removing multicollinearity.
2024-05-24 23:20:58,561:INFO:Set up removing outliers.
2024-05-24 23:20:58,615:INFO:Finished creating preprocessing pipeline.
2024-05-24 23:20:58,623:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['curbweight', 'cylindernumber',
                                             'carvolume', 'enginepower',
                                             'averagempg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=8007)))])
2024-05-24 23:20:58,623:INFO:Creating final display dataframe.
2024-05-24 23:20:59,532:INFO:Setup _display_container:                     Description             Value
0                    Session id              8007
1                        Target             price
2                   Target type        Regression
3           Original data shape          (183, 6)
4        Transformed data shape          (176, 7)
5   Transformed train set shape          (121, 7)
6    Transformed test set shape           (55, 7)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14     Remove multicollinearity              True
15  Multicollinearity threshold               0.9
16              Remove outliers              True
17           Outliers threshold              0.05
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              847b
2024-05-24 23:20:59,653:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:59,656:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:59,777:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:20:59,779:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:20:59,781:INFO:setup() successfully completed in 2.73s...............
2024-05-24 23:20:59,846:INFO:Initializing compare_models()
2024-05-24 23:20:59,846:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 23:20:59,847:INFO:Checking exceptions
2024-05-24 23:20:59,849:INFO:Preparing display monitor
2024-05-24 23:20:59,883:INFO:Initializing Linear Regression
2024-05-24 23:20:59,883:INFO:Total runtime is 0.0 minutes
2024-05-24 23:20:59,891:INFO:SubProcess create_model() called ==================================
2024-05-24 23:20:59,892:INFO:Initializing create_model()
2024-05-24 23:20:59,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB27F68370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:20:59,892:INFO:Checking exceptions
2024-05-24 23:20:59,894:INFO:Importing libraries
2024-05-24 23:20:59,894:INFO:Copying training dataset
2024-05-24 23:20:59,899:INFO:Defining folds
2024-05-24 23:20:59,899:INFO:Declaring metric variables
2024-05-24 23:20:59,910:INFO:Importing untrained model
2024-05-24 23:20:59,918:INFO:Linear Regression Imported successfully
2024-05-24 23:20:59,930:INFO:Starting cross validation
2024-05-24 23:20:59,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:21:00,470:INFO:Calculating mean and std
2024-05-24 23:21:00,471:INFO:Creating metrics dataframe
2024-05-24 23:21:00,473:INFO:Uploading results into container
2024-05-24 23:21:00,473:INFO:Uploading model into container now
2024-05-24 23:21:00,474:INFO:_master_model_container: 1
2024-05-24 23:21:00,474:INFO:_display_container: 2
2024-05-24 23:21:00,474:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:21:00,474:INFO:create_model() successfully completed......................................
2024-05-24 23:21:00,651:INFO:SubProcess create_model() end ==================================
2024-05-24 23:21:00,652:INFO:Creating metrics dataframe
2024-05-24 23:21:00,657:INFO:Initializing Lasso Regression
2024-05-24 23:21:00,658:INFO:Total runtime is 0.012920610109965007 minutes
2024-05-24 23:21:00,662:INFO:SubProcess create_model() called ==================================
2024-05-24 23:21:00,662:INFO:Initializing create_model()
2024-05-24 23:21:00,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB27F68370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:21:00,663:INFO:Checking exceptions
2024-05-24 23:21:00,663:INFO:Importing libraries
2024-05-24 23:21:00,663:INFO:Copying training dataset
2024-05-24 23:21:00,667:INFO:Defining folds
2024-05-24 23:21:00,667:INFO:Declaring metric variables
2024-05-24 23:21:00,670:INFO:Importing untrained model
2024-05-24 23:21:00,675:INFO:Lasso Regression Imported successfully
2024-05-24 23:21:00,686:INFO:Starting cross validation
2024-05-24 23:21:00,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:21:01,031:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+08, tolerance: 2.507e+05
  model = cd_fast.enet_coordinate_descent(

2024-05-24 23:21:01,076:INFO:Calculating mean and std
2024-05-24 23:21:01,078:INFO:Creating metrics dataframe
2024-05-24 23:21:01,081:INFO:Uploading results into container
2024-05-24 23:21:01,082:INFO:Uploading model into container now
2024-05-24 23:21:01,082:INFO:_master_model_container: 2
2024-05-24 23:21:01,082:INFO:_display_container: 2
2024-05-24 23:21:01,083:INFO:Lasso(random_state=8007)
2024-05-24 23:21:01,083:INFO:create_model() successfully completed......................................
2024-05-24 23:21:01,242:INFO:SubProcess create_model() end ==================================
2024-05-24 23:21:01,243:INFO:Creating metrics dataframe
2024-05-24 23:21:01,257:INFO:Initializing Ridge Regression
2024-05-24 23:21:01,258:INFO:Total runtime is 0.022919011116027833 minutes
2024-05-24 23:21:01,265:INFO:SubProcess create_model() called ==================================
2024-05-24 23:21:01,266:INFO:Initializing create_model()
2024-05-24 23:21:01,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB27F68370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:21:01,267:INFO:Checking exceptions
2024-05-24 23:21:01,267:INFO:Importing libraries
2024-05-24 23:21:01,267:INFO:Copying training dataset
2024-05-24 23:21:01,273:INFO:Defining folds
2024-05-24 23:21:01,273:INFO:Declaring metric variables
2024-05-24 23:21:01,282:INFO:Importing untrained model
2024-05-24 23:21:01,287:INFO:Ridge Regression Imported successfully
2024-05-24 23:21:01,299:INFO:Starting cross validation
2024-05-24 23:21:01,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:21:01,689:INFO:Calculating mean and std
2024-05-24 23:21:01,690:INFO:Creating metrics dataframe
2024-05-24 23:21:01,693:INFO:Uploading results into container
2024-05-24 23:21:01,694:INFO:Uploading model into container now
2024-05-24 23:21:01,695:INFO:_master_model_container: 3
2024-05-24 23:21:01,695:INFO:_display_container: 2
2024-05-24 23:21:01,695:INFO:Ridge(random_state=8007)
2024-05-24 23:21:01,696:INFO:create_model() successfully completed......................................
2024-05-24 23:21:01,860:INFO:SubProcess create_model() end ==================================
2024-05-24 23:21:01,861:INFO:Creating metrics dataframe
2024-05-24 23:21:01,870:INFO:Initializing Huber Regressor
2024-05-24 23:21:01,870:INFO:Total runtime is 0.03312741120656332 minutes
2024-05-24 23:21:01,875:INFO:SubProcess create_model() called ==================================
2024-05-24 23:21:01,875:INFO:Initializing create_model()
2024-05-24 23:21:01,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB27F68370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:21:01,875:INFO:Checking exceptions
2024-05-24 23:21:01,876:INFO:Importing libraries
2024-05-24 23:21:01,876:INFO:Copying training dataset
2024-05-24 23:21:01,882:INFO:Defining folds
2024-05-24 23:21:01,882:INFO:Declaring metric variables
2024-05-24 23:21:01,887:INFO:Importing untrained model
2024-05-24 23:21:01,891:INFO:Huber Regressor Imported successfully
2024-05-24 23:21:01,902:INFO:Starting cross validation
2024-05-24 23:21:01,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:21:02,349:INFO:Calculating mean and std
2024-05-24 23:21:02,350:INFO:Creating metrics dataframe
2024-05-24 23:21:02,352:INFO:Uploading results into container
2024-05-24 23:21:02,353:INFO:Uploading model into container now
2024-05-24 23:21:02,353:INFO:_master_model_container: 4
2024-05-24 23:21:02,353:INFO:_display_container: 2
2024-05-24 23:21:02,353:INFO:HuberRegressor()
2024-05-24 23:21:02,353:INFO:create_model() successfully completed......................................
2024-05-24 23:21:02,507:INFO:SubProcess create_model() end ==================================
2024-05-24 23:21:02,508:INFO:Creating metrics dataframe
2024-05-24 23:21:02,518:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-24 23:21:02,529:INFO:Initializing create_model()
2024-05-24 23:21:02,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:21:02,530:INFO:Checking exceptions
2024-05-24 23:21:02,533:INFO:Importing libraries
2024-05-24 23:21:02,533:INFO:Copying training dataset
2024-05-24 23:21:02,536:INFO:Defining folds
2024-05-24 23:21:02,536:INFO:Declaring metric variables
2024-05-24 23:21:02,536:INFO:Importing untrained model
2024-05-24 23:21:02,536:INFO:Declaring custom model
2024-05-24 23:21:02,536:INFO:Linear Regression Imported successfully
2024-05-24 23:21:02,547:INFO:Cross validation set to False
2024-05-24 23:21:02,547:INFO:Fitting Model
2024-05-24 23:21:02,718:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:21:02,718:INFO:create_model() successfully completed......................................
2024-05-24 23:21:02,904:INFO:_master_model_container: 4
2024-05-24 23:21:02,904:INFO:_display_container: 2
2024-05-24 23:21:02,904:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:21:02,904:INFO:compare_models() successfully completed......................................
2024-05-24 23:21:06,297:INFO:Initializing evaluate_model()
2024-05-24 23:21:06,298:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 23:21:06,306:INFO:Initializing plot_model()
2024-05-24 23:21:06,307:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, system=True)
2024-05-24 23:21:06,307:INFO:Checking exceptions
2024-05-24 23:21:06,308:INFO:Preloading libraries
2024-05-24 23:21:06,308:INFO:Copying training dataset
2024-05-24 23:21:06,310:INFO:Plot type: pipeline
2024-05-24 23:21:06,451:INFO:Visual Rendered Successfully
2024-05-24 23:21:06,598:INFO:plot_model() successfully completed......................................
2024-05-24 23:21:24,594:INFO:Initializing plot_model()
2024-05-24 23:21:24,594:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, system=True)
2024-05-24 23:21:24,594:INFO:Checking exceptions
2024-05-24 23:21:24,595:INFO:Preloading libraries
2024-05-24 23:21:24,597:INFO:Copying training dataset
2024-05-24 23:21:24,597:INFO:Plot type: feature
2024-05-24 23:21:24,854:INFO:Visual Rendered Successfully
2024-05-24 23:21:24,995:INFO:plot_model() successfully completed......................................
2024-05-24 23:21:29,512:INFO:Initializing tune_model()
2024-05-24 23:21:29,512:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>)
2024-05-24 23:21:29,512:INFO:Checking exceptions
2024-05-24 23:21:29,532:INFO:Copying training dataset
2024-05-24 23:21:29,535:INFO:Checking base model
2024-05-24 23:21:29,535:INFO:Base model : Linear Regression
2024-05-24 23:21:29,540:INFO:Declaring metric variables
2024-05-24 23:21:29,544:INFO:Defining Hyperparameters
2024-05-24 23:21:29,545:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2024-05-24 23:21:29,746:INFO:Tuning with n_jobs=-1
2024-05-24 23:21:29,746:INFO:Initializing GridSearchCV
2024-05-24 23:21:30,443:INFO:best_params: {'actual_estimator__fit_intercept': False}
2024-05-24 23:21:30,444:INFO:Hyperparameter search completed
2024-05-24 23:21:30,444:INFO:SubProcess create_model() called ==================================
2024-05-24 23:21:30,444:INFO:Initializing create_model()
2024-05-24 23:21:30,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB6F0F7760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False})
2024-05-24 23:21:30,444:INFO:Checking exceptions
2024-05-24 23:21:30,444:INFO:Importing libraries
2024-05-24 23:21:30,444:INFO:Copying training dataset
2024-05-24 23:21:30,447:INFO:Defining folds
2024-05-24 23:21:30,447:INFO:Declaring metric variables
2024-05-24 23:21:30,451:INFO:Importing untrained model
2024-05-24 23:21:30,451:INFO:Declaring custom model
2024-05-24 23:21:30,457:INFO:Linear Regression Imported successfully
2024-05-24 23:21:30,465:INFO:Starting cross validation
2024-05-24 23:21:30,476:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:21:30,866:INFO:Calculating mean and std
2024-05-24 23:21:30,867:INFO:Creating metrics dataframe
2024-05-24 23:21:30,873:INFO:Finalizing model
2024-05-24 23:21:31,043:INFO:Uploading results into container
2024-05-24 23:21:31,044:INFO:Uploading model into container now
2024-05-24 23:21:31,045:INFO:_master_model_container: 5
2024-05-24 23:21:31,045:INFO:_display_container: 3
2024-05-24 23:21:31,046:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2024-05-24 23:21:31,046:INFO:create_model() successfully completed......................................
2024-05-24 23:21:31,206:INFO:SubProcess create_model() end ==================================
2024-05-24 23:21:31,206:INFO:choose_better activated
2024-05-24 23:21:31,209:INFO:SubProcess create_model() called ==================================
2024-05-24 23:21:31,210:INFO:Initializing create_model()
2024-05-24 23:21:31,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB29AEA0B0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:21:31,210:INFO:Checking exceptions
2024-05-24 23:21:31,212:INFO:Importing libraries
2024-05-24 23:21:31,212:INFO:Copying training dataset
2024-05-24 23:21:31,215:INFO:Defining folds
2024-05-24 23:21:31,215:INFO:Declaring metric variables
2024-05-24 23:21:31,215:INFO:Importing untrained model
2024-05-24 23:21:31,215:INFO:Declaring custom model
2024-05-24 23:21:31,216:INFO:Linear Regression Imported successfully
2024-05-24 23:21:31,217:INFO:Starting cross validation
2024-05-24 23:21:31,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:21:31,614:INFO:Calculating mean and std
2024-05-24 23:21:31,615:INFO:Creating metrics dataframe
2024-05-24 23:21:31,617:INFO:Finalizing model
2024-05-24 23:21:31,769:INFO:Uploading results into container
2024-05-24 23:21:31,770:INFO:Uploading model into container now
2024-05-24 23:21:31,770:INFO:_master_model_container: 6
2024-05-24 23:21:31,770:INFO:_display_container: 4
2024-05-24 23:21:31,770:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:21:31,770:INFO:create_model() successfully completed......................................
2024-05-24 23:21:31,934:INFO:SubProcess create_model() end ==================================
2024-05-24 23:21:31,934:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.7938
2024-05-24 23:21:31,935:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) result for R2 is 0.7943
2024-05-24 23:21:31,935:INFO:LinearRegression(fit_intercept=False, n_jobs=-1) is best model
2024-05-24 23:21:31,935:INFO:choose_better completed
2024-05-24 23:21:31,947:INFO:_master_model_container: 6
2024-05-24 23:21:31,948:INFO:_display_container: 3
2024-05-24 23:21:31,948:INFO:LinearRegression(fit_intercept=False, n_jobs=-1)
2024-05-24 23:21:31,948:INFO:tune_model() successfully completed......................................
2024-05-24 23:21:40,109:INFO:Soft dependency imported: explainerdashboard: 0.4.7
2024-05-24 23:21:57,711:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py:548: FutureWarning:

The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.


2024-05-24 23:22:56,594:INFO:Soft dependency imported: explainerdashboard: 0.4.7
2024-05-24 23:22:56,905:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\metrics\_scorer.py:548: FutureWarning:

The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.


2024-05-24 23:29:43,827:INFO:PyCaret RegressionExperiment
2024-05-24 23:29:43,827:INFO:Logging name: reg-default-name
2024-05-24 23:29:43,827:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 23:29:43,827:INFO:version 3.3.2
2024-05-24 23:29:43,827:INFO:Initializing setup()
2024-05-24 23:29:43,827:INFO:self.USI: 67be
2024-05-24 23:29:43,827:INFO:self._variable_keys: {'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'pipeline', 'USI', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'target_param', 'X_train', 'fold_generator', 'y_test', 'log_plots_param', 'data', 'exp_name_log', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'memory', 'seed', 'y', 'X_test', 'X', '_available_plots', 'transform_target_param'}
2024-05-24 23:29:43,827:INFO:Checking environment
2024-05-24 23:29:43,827:INFO:python_version: 3.10.14
2024-05-24 23:29:43,828:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 23:29:43,828:INFO:machine: AMD64
2024-05-24 23:29:43,828:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 23:29:43,828:INFO:Memory: svmem(total=16541802496, available=5932740608, percent=64.1, used=10609061888, free=5932740608)
2024-05-24 23:29:43,828:INFO:Physical Core: 6
2024-05-24 23:29:43,828:INFO:Logical Core: 12
2024-05-24 23:29:43,828:INFO:Checking libraries
2024-05-24 23:29:43,828:INFO:System:
2024-05-24 23:29:43,828:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 23:29:43,828:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 23:29:43,828:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 23:29:43,828:INFO:PyCaret required dependencies:
2024-05-24 23:29:43,828:INFO:                 pip: 24.0
2024-05-24 23:29:43,828:INFO:          setuptools: 69.5.1
2024-05-24 23:29:43,828:INFO:             pycaret: 3.3.2
2024-05-24 23:29:43,828:INFO:             IPython: 8.20.0
2024-05-24 23:29:43,828:INFO:          ipywidgets: 8.1.2
2024-05-24 23:29:43,828:INFO:                tqdm: 4.66.4
2024-05-24 23:29:43,829:INFO:               numpy: 1.26.4
2024-05-24 23:29:43,829:INFO:              pandas: 2.1.4
2024-05-24 23:29:43,829:INFO:              jinja2: 3.1.3
2024-05-24 23:29:43,829:INFO:               scipy: 1.11.4
2024-05-24 23:29:43,829:INFO:              joblib: 1.3.2
2024-05-24 23:29:43,829:INFO:             sklearn: 1.4.2
2024-05-24 23:29:43,829:INFO:                pyod: 1.1.3
2024-05-24 23:29:43,829:INFO:            imblearn: 0.12.2
2024-05-24 23:29:43,829:INFO:   category_encoders: 2.6.3
2024-05-24 23:29:43,829:INFO:            lightgbm: 4.3.0
2024-05-24 23:29:43,829:INFO:               numba: 0.59.1
2024-05-24 23:29:43,829:INFO:            requests: 2.32.2
2024-05-24 23:29:43,829:INFO:          matplotlib: 3.7.5
2024-05-24 23:29:43,829:INFO:          scikitplot: 0.3.7
2024-05-24 23:29:43,829:INFO:         yellowbrick: 1.5
2024-05-24 23:29:43,829:INFO:              plotly: 5.22.0
2024-05-24 23:29:43,829:INFO:    plotly-resampler: Not installed
2024-05-24 23:29:43,829:INFO:             kaleido: 0.2.1
2024-05-24 23:29:43,829:INFO:           schemdraw: 0.15
2024-05-24 23:29:43,829:INFO:         statsmodels: 0.14.2
2024-05-24 23:29:43,829:INFO:              sktime: 0.26.0
2024-05-24 23:29:43,829:INFO:               tbats: 1.1.3
2024-05-24 23:29:43,829:INFO:            pmdarima: 2.0.4
2024-05-24 23:29:43,829:INFO:              psutil: 5.9.0
2024-05-24 23:29:43,829:INFO:          markupsafe: 2.1.3
2024-05-24 23:29:43,829:INFO:             pickle5: Not installed
2024-05-24 23:29:43,830:INFO:         cloudpickle: 3.0.0
2024-05-24 23:29:43,830:INFO:         deprecation: 2.1.0
2024-05-24 23:29:43,830:INFO:              xxhash: 3.4.1
2024-05-24 23:29:43,830:INFO:           wurlitzer: Not installed
2024-05-24 23:29:43,830:INFO:PyCaret optional dependencies:
2024-05-24 23:29:43,830:INFO:                shap: 0.44.1
2024-05-24 23:29:43,830:INFO:           interpret: 0.6.1
2024-05-24 23:29:43,830:INFO:                umap: 0.5.6
2024-05-24 23:29:43,830:INFO:     ydata_profiling: 4.8.3
2024-05-24 23:29:43,830:INFO:  explainerdashboard: 0.4.7
2024-05-24 23:29:43,830:INFO:             autoviz: Not installed
2024-05-24 23:29:43,830:INFO:           fairlearn: 0.7.0
2024-05-24 23:29:43,830:INFO:          deepchecks: Not installed
2024-05-24 23:29:43,830:INFO:             xgboost: 2.0.3
2024-05-24 23:29:43,830:INFO:            catboost: 1.2.5
2024-05-24 23:29:43,830:INFO:              kmodes: 0.12.2
2024-05-24 23:29:43,830:INFO:             mlxtend: 0.23.1
2024-05-24 23:29:43,830:INFO:       statsforecast: 1.5.0
2024-05-24 23:29:43,830:INFO:        tune_sklearn: Not installed
2024-05-24 23:29:43,830:INFO:                 ray: Not installed
2024-05-24 23:29:43,830:INFO:            hyperopt: 0.2.7
2024-05-24 23:29:43,830:INFO:              optuna: 3.6.1
2024-05-24 23:29:43,830:INFO:               skopt: 0.10.1
2024-05-24 23:29:43,830:INFO:              mlflow: 2.13.0
2024-05-24 23:29:43,830:INFO:              gradio: 4.31.5
2024-05-24 23:29:43,830:INFO:             fastapi: 0.111.0
2024-05-24 23:29:43,831:INFO:             uvicorn: 0.29.0
2024-05-24 23:29:43,831:INFO:              m2cgen: 0.10.0
2024-05-24 23:29:43,831:INFO:           evidently: 0.4.25
2024-05-24 23:29:43,831:INFO:               fugue: 0.8.7
2024-05-24 23:29:43,831:INFO:           streamlit: Not installed
2024-05-24 23:29:43,831:INFO:             prophet: Not installed
2024-05-24 23:29:43,831:INFO:None
2024-05-24 23:29:43,831:INFO:Set up data.
2024-05-24 23:29:43,835:INFO:Set up folding strategy.
2024-05-24 23:29:43,835:INFO:Set up train/test split.
2024-05-24 23:29:43,838:INFO:Set up index.
2024-05-24 23:29:43,838:INFO:Assigning column types.
2024-05-24 23:29:43,842:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 23:29:43,842:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,847:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,853:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,963:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:43,966:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:43,967:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,972:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:29:43,977:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,035:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,081:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,083:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,084:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 23:29:44,089:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,093:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,196:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,199:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,204:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,209:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,267:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,314:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,319:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,320:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 23:29:44,330:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,436:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,439:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,507:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,553:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,556:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,557:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 23:29:44,623:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,669:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,672:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,789:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,792:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,793:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 23:29:44,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:44,906:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:44,909:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:44,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:29:45,022:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:45,024:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:45,024:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 23:29:45,136:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:45,139:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:45,250:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:45,253:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:45,261:INFO:Preparing preprocessing pipeline...
2024-05-24 23:29:45,262:INFO:Set up simple imputation.
2024-05-24 23:29:45,262:INFO:Set up removing multicollinearity.
2024-05-24 23:29:45,262:INFO:Set up removing outliers.
2024-05-24 23:29:45,292:INFO:Finished creating preprocessing pipeline.
2024-05-24 23:29:45,299:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['curbweight', 'cylindernumber',
                                             'carvolume', 'enginepower',
                                             'averagempg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4437)))])
2024-05-24 23:29:45,299:INFO:Creating final display dataframe.
2024-05-24 23:29:46,157:INFO:Setup _display_container:                     Description             Value
0                    Session id              4437
1                        Target             price
2                   Target type        Regression
3           Original data shape          (183, 6)
4        Transformed data shape          (176, 6)
5   Transformed train set shape          (121, 6)
6    Transformed test set shape           (55, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14              Remove outliers              True
15           Outliers threshold              0.05
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              67be
2024-05-24 23:29:46,279:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:46,283:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:46,394:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:29:46,397:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:29:46,398:INFO:setup() successfully completed in 2.7s...............
2024-05-24 23:29:46,430:INFO:Initializing compare_models()
2024-05-24 23:29:46,430:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 23:29:46,431:INFO:Checking exceptions
2024-05-24 23:29:46,432:INFO:Preparing display monitor
2024-05-24 23:29:46,459:INFO:Initializing Linear Regression
2024-05-24 23:29:46,459:INFO:Total runtime is 0.0 minutes
2024-05-24 23:29:46,464:INFO:SubProcess create_model() called ==================================
2024-05-24 23:29:46,465:INFO:Initializing create_model()
2024-05-24 23:29:46,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB34EA50C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:29:46,465:INFO:Checking exceptions
2024-05-24 23:29:46,465:INFO:Importing libraries
2024-05-24 23:29:46,466:INFO:Copying training dataset
2024-05-24 23:29:46,472:INFO:Defining folds
2024-05-24 23:29:46,472:INFO:Declaring metric variables
2024-05-24 23:29:46,476:INFO:Importing untrained model
2024-05-24 23:29:46,481:INFO:Linear Regression Imported successfully
2024-05-24 23:29:46,492:INFO:Starting cross validation
2024-05-24 23:29:46,506:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:29:54,478:INFO:Calculating mean and std
2024-05-24 23:29:54,480:INFO:Creating metrics dataframe
2024-05-24 23:29:54,485:INFO:Uploading results into container
2024-05-24 23:29:54,486:INFO:Uploading model into container now
2024-05-24 23:29:54,488:INFO:_master_model_container: 1
2024-05-24 23:29:54,488:INFO:_display_container: 2
2024-05-24 23:29:54,489:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:29:54,489:INFO:create_model() successfully completed......................................
2024-05-24 23:29:54,841:INFO:SubProcess create_model() end ==================================
2024-05-24 23:29:54,841:INFO:Creating metrics dataframe
2024-05-24 23:29:54,849:INFO:Initializing Lasso Regression
2024-05-24 23:29:54,850:INFO:Total runtime is 0.13985262314478555 minutes
2024-05-24 23:29:54,856:INFO:SubProcess create_model() called ==================================
2024-05-24 23:29:54,857:INFO:Initializing create_model()
2024-05-24 23:29:54,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB34EA50C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:29:54,858:INFO:Checking exceptions
2024-05-24 23:29:54,858:INFO:Importing libraries
2024-05-24 23:29:54,858:INFO:Copying training dataset
2024-05-24 23:29:54,863:INFO:Defining folds
2024-05-24 23:29:54,863:INFO:Declaring metric variables
2024-05-24 23:29:54,868:INFO:Importing untrained model
2024-05-24 23:29:54,874:INFO:Lasso Regression Imported successfully
2024-05-24 23:29:54,882:INFO:Starting cross validation
2024-05-24 23:29:54,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:29:58,036:INFO:Calculating mean and std
2024-05-24 23:29:58,037:INFO:Creating metrics dataframe
2024-05-24 23:29:58,040:INFO:Uploading results into container
2024-05-24 23:29:58,040:INFO:Uploading model into container now
2024-05-24 23:29:58,040:INFO:_master_model_container: 2
2024-05-24 23:29:58,040:INFO:_display_container: 2
2024-05-24 23:29:58,041:INFO:Lasso(random_state=4437)
2024-05-24 23:29:58,041:INFO:create_model() successfully completed......................................
2024-05-24 23:29:58,266:INFO:SubProcess create_model() end ==================================
2024-05-24 23:29:58,266:INFO:Creating metrics dataframe
2024-05-24 23:29:58,274:INFO:Initializing Ridge Regression
2024-05-24 23:29:58,274:INFO:Total runtime is 0.19692630767822264 minutes
2024-05-24 23:29:58,278:INFO:SubProcess create_model() called ==================================
2024-05-24 23:29:58,278:INFO:Initializing create_model()
2024-05-24 23:29:58,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB34EA50C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:29:58,278:INFO:Checking exceptions
2024-05-24 23:29:58,278:INFO:Importing libraries
2024-05-24 23:29:58,278:INFO:Copying training dataset
2024-05-24 23:29:58,283:INFO:Defining folds
2024-05-24 23:29:58,283:INFO:Declaring metric variables
2024-05-24 23:29:58,287:INFO:Importing untrained model
2024-05-24 23:29:58,292:INFO:Ridge Regression Imported successfully
2024-05-24 23:29:58,303:INFO:Starting cross validation
2024-05-24 23:29:58,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:29:58,645:INFO:Calculating mean and std
2024-05-24 23:29:58,647:INFO:Creating metrics dataframe
2024-05-24 23:29:58,651:INFO:Uploading results into container
2024-05-24 23:29:58,652:INFO:Uploading model into container now
2024-05-24 23:29:58,652:INFO:_master_model_container: 3
2024-05-24 23:29:58,652:INFO:_display_container: 2
2024-05-24 23:29:58,653:INFO:Ridge(random_state=4437)
2024-05-24 23:29:58,653:INFO:create_model() successfully completed......................................
2024-05-24 23:29:58,895:INFO:SubProcess create_model() end ==================================
2024-05-24 23:29:58,895:INFO:Creating metrics dataframe
2024-05-24 23:29:58,904:INFO:Initializing Huber Regressor
2024-05-24 23:29:58,904:INFO:Total runtime is 0.20741277535756428 minutes
2024-05-24 23:29:58,909:INFO:SubProcess create_model() called ==================================
2024-05-24 23:29:58,909:INFO:Initializing create_model()
2024-05-24 23:29:58,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB34EA50C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:29:58,909:INFO:Checking exceptions
2024-05-24 23:29:58,909:INFO:Importing libraries
2024-05-24 23:29:58,910:INFO:Copying training dataset
2024-05-24 23:29:58,914:INFO:Defining folds
2024-05-24 23:29:58,915:INFO:Declaring metric variables
2024-05-24 23:29:58,919:INFO:Importing untrained model
2024-05-24 23:29:58,924:INFO:Huber Regressor Imported successfully
2024-05-24 23:29:58,933:INFO:Starting cross validation
2024-05-24 23:29:58,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:29:59,272:INFO:Calculating mean and std
2024-05-24 23:29:59,273:INFO:Creating metrics dataframe
2024-05-24 23:29:59,276:INFO:Uploading results into container
2024-05-24 23:29:59,277:INFO:Uploading model into container now
2024-05-24 23:29:59,277:INFO:_master_model_container: 4
2024-05-24 23:29:59,277:INFO:_display_container: 2
2024-05-24 23:29:59,277:INFO:HuberRegressor()
2024-05-24 23:29:59,278:INFO:create_model() successfully completed......................................
2024-05-24 23:29:59,516:INFO:SubProcess create_model() end ==================================
2024-05-24 23:29:59,517:INFO:Creating metrics dataframe
2024-05-24 23:29:59,525:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 23:29:59,538:INFO:Initializing create_model()
2024-05-24 23:29:59,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:29:59,538:INFO:Checking exceptions
2024-05-24 23:29:59,540:INFO:Importing libraries
2024-05-24 23:29:59,540:INFO:Copying training dataset
2024-05-24 23:29:59,543:INFO:Defining folds
2024-05-24 23:29:59,543:INFO:Declaring metric variables
2024-05-24 23:29:59,543:INFO:Importing untrained model
2024-05-24 23:29:59,543:INFO:Declaring custom model
2024-05-24 23:29:59,544:INFO:Linear Regression Imported successfully
2024-05-24 23:29:59,553:INFO:Cross validation set to False
2024-05-24 23:29:59,553:INFO:Fitting Model
2024-05-24 23:29:59,735:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:29:59,735:INFO:create_model() successfully completed......................................
2024-05-24 23:29:59,989:INFO:_master_model_container: 4
2024-05-24 23:29:59,989:INFO:_display_container: 2
2024-05-24 23:29:59,990:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:29:59,990:INFO:compare_models() successfully completed......................................
2024-05-24 23:30:00,005:INFO:Initializing evaluate_model()
2024-05-24 23:30:00,005:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 23:30:00,022:INFO:Initializing plot_model()
2024-05-24 23:30:00,022:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, system=True)
2024-05-24 23:30:00,022:INFO:Checking exceptions
2024-05-24 23:30:00,026:INFO:Preloading libraries
2024-05-24 23:30:00,026:INFO:Copying training dataset
2024-05-24 23:30:00,026:INFO:Plot type: pipeline
2024-05-24 23:30:00,164:INFO:Visual Rendered Successfully
2024-05-24 23:30:00,399:INFO:plot_model() successfully completed......................................
2024-05-24 23:30:00,467:INFO:Initializing tune_model()
2024-05-24 23:30:00,468:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>)
2024-05-24 23:30:00,468:INFO:Checking exceptions
2024-05-24 23:30:00,494:INFO:Copying training dataset
2024-05-24 23:30:00,498:INFO:Checking base model
2024-05-24 23:30:00,499:INFO:Base model : Linear Regression
2024-05-24 23:30:00,505:INFO:Declaring metric variables
2024-05-24 23:30:00,511:INFO:Defining Hyperparameters
2024-05-24 23:30:00,511:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2024-05-24 23:30:00,774:INFO:Tuning with n_jobs=-1
2024-05-24 23:30:00,775:INFO:Initializing GridSearchCV
2024-05-24 23:30:01,360:INFO:best_params: {'actual_estimator__fit_intercept': True}
2024-05-24 23:30:01,360:INFO:Hyperparameter search completed
2024-05-24 23:30:01,360:INFO:SubProcess create_model() called ==================================
2024-05-24 23:30:01,360:INFO:Initializing create_model()
2024-05-24 23:30:01,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB349685B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2024-05-24 23:30:01,361:INFO:Checking exceptions
2024-05-24 23:30:01,361:INFO:Importing libraries
2024-05-24 23:30:01,361:INFO:Copying training dataset
2024-05-24 23:30:01,364:INFO:Defining folds
2024-05-24 23:30:01,364:INFO:Declaring metric variables
2024-05-24 23:30:01,367:INFO:Importing untrained model
2024-05-24 23:30:01,367:INFO:Declaring custom model
2024-05-24 23:30:01,372:INFO:Linear Regression Imported successfully
2024-05-24 23:30:01,381:INFO:Starting cross validation
2024-05-24 23:30:01,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:30:01,767:INFO:Calculating mean and std
2024-05-24 23:30:01,769:INFO:Creating metrics dataframe
2024-05-24 23:30:01,774:INFO:Finalizing model
2024-05-24 23:30:01,982:INFO:Uploading results into container
2024-05-24 23:30:01,983:INFO:Uploading model into container now
2024-05-24 23:30:01,984:INFO:_master_model_container: 5
2024-05-24 23:30:01,984:INFO:_display_container: 3
2024-05-24 23:30:01,985:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:30:01,985:INFO:create_model() successfully completed......................................
2024-05-24 23:30:02,240:INFO:SubProcess create_model() end ==================================
2024-05-24 23:30:02,240:INFO:choose_better activated
2024-05-24 23:30:02,244:INFO:SubProcess create_model() called ==================================
2024-05-24 23:30:02,244:INFO:Initializing create_model()
2024-05-24 23:30:02,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:30:02,245:INFO:Checking exceptions
2024-05-24 23:30:02,247:INFO:Importing libraries
2024-05-24 23:30:02,247:INFO:Copying training dataset
2024-05-24 23:30:02,250:INFO:Defining folds
2024-05-24 23:30:02,250:INFO:Declaring metric variables
2024-05-24 23:30:02,250:INFO:Importing untrained model
2024-05-24 23:30:02,250:INFO:Declaring custom model
2024-05-24 23:30:02,250:INFO:Linear Regression Imported successfully
2024-05-24 23:30:02,251:INFO:Starting cross validation
2024-05-24 23:30:02,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:30:02,624:INFO:Calculating mean and std
2024-05-24 23:30:02,624:INFO:Creating metrics dataframe
2024-05-24 23:30:02,626:INFO:Finalizing model
2024-05-24 23:30:02,761:INFO:Uploading results into container
2024-05-24 23:30:02,762:INFO:Uploading model into container now
2024-05-24 23:30:02,762:INFO:_master_model_container: 6
2024-05-24 23:30:02,762:INFO:_display_container: 4
2024-05-24 23:30:02,762:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:30:02,762:INFO:create_model() successfully completed......................................
2024-05-24 23:30:03,010:INFO:SubProcess create_model() end ==================================
2024-05-24 23:30:03,010:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.8179
2024-05-24 23:30:03,010:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.8179
2024-05-24 23:30:03,011:INFO:LinearRegression(n_jobs=-1) is best model
2024-05-24 23:30:03,011:INFO:choose_better completed
2024-05-24 23:30:03,011:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-24 23:30:03,021:INFO:_master_model_container: 6
2024-05-24 23:30:03,021:INFO:_display_container: 3
2024-05-24 23:30:03,022:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:30:03,022:INFO:tune_model() successfully completed......................................
2024-05-24 23:30:14,420:INFO:Initializing plot_model()
2024-05-24 23:30:14,420:INFO:plot_model(plot=rfe, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, system=True)
2024-05-24 23:30:14,420:INFO:Checking exceptions
2024-05-24 23:30:14,422:INFO:Preloading libraries
2024-05-24 23:30:14,422:INFO:Copying training dataset
2024-05-24 23:30:14,422:INFO:Plot type: rfe
2024-05-24 23:30:14,713:INFO:Fitting Model
2024-05-24 23:30:15,075:INFO:Visual Rendered Successfully
2024-05-24 23:30:15,299:INFO:plot_model() successfully completed......................................
2024-05-24 23:30:18,285:INFO:Initializing plot_model()
2024-05-24 23:30:18,285:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB288F4FD0>, system=True)
2024-05-24 23:30:18,285:INFO:Checking exceptions
2024-05-24 23:30:18,287:INFO:Preloading libraries
2024-05-24 23:30:18,287:INFO:Copying training dataset
2024-05-24 23:30:18,287:INFO:Plot type: feature
2024-05-24 23:30:18,541:INFO:Visual Rendered Successfully
2024-05-24 23:30:18,753:INFO:plot_model() successfully completed......................................
2024-05-24 23:31:30,037:INFO:PyCaret RegressionExperiment
2024-05-24 23:31:30,037:INFO:Logging name: reg-default-name
2024-05-24 23:31:30,037:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 23:31:30,037:INFO:version 3.3.2
2024-05-24 23:31:30,037:INFO:Initializing setup()
2024-05-24 23:31:30,038:INFO:self.USI: 1f06
2024-05-24 23:31:30,038:INFO:self._variable_keys: {'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'pipeline', 'USI', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'target_param', 'X_train', 'fold_generator', 'y_test', 'log_plots_param', 'data', 'exp_name_log', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'memory', 'seed', 'y', 'X_test', 'X', '_available_plots', 'transform_target_param'}
2024-05-24 23:31:30,038:INFO:Checking environment
2024-05-24 23:31:30,038:INFO:python_version: 3.10.14
2024-05-24 23:31:30,038:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 23:31:30,038:INFO:machine: AMD64
2024-05-24 23:31:30,038:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 23:31:30,038:INFO:Memory: svmem(total=16541802496, available=2474885120, percent=85.0, used=14066917376, free=2474885120)
2024-05-24 23:31:30,038:INFO:Physical Core: 6
2024-05-24 23:31:30,038:INFO:Logical Core: 12
2024-05-24 23:31:30,038:INFO:Checking libraries
2024-05-24 23:31:30,038:INFO:System:
2024-05-24 23:31:30,038:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 23:31:30,038:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 23:31:30,038:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 23:31:30,038:INFO:PyCaret required dependencies:
2024-05-24 23:31:30,038:INFO:                 pip: 24.0
2024-05-24 23:31:30,038:INFO:          setuptools: 69.5.1
2024-05-24 23:31:30,038:INFO:             pycaret: 3.3.2
2024-05-24 23:31:30,038:INFO:             IPython: 8.20.0
2024-05-24 23:31:30,038:INFO:          ipywidgets: 8.1.2
2024-05-24 23:31:30,039:INFO:                tqdm: 4.66.4
2024-05-24 23:31:30,039:INFO:               numpy: 1.26.4
2024-05-24 23:31:30,039:INFO:              pandas: 2.1.4
2024-05-24 23:31:30,039:INFO:              jinja2: 3.1.3
2024-05-24 23:31:30,039:INFO:               scipy: 1.11.4
2024-05-24 23:31:30,039:INFO:              joblib: 1.3.2
2024-05-24 23:31:30,039:INFO:             sklearn: 1.4.2
2024-05-24 23:31:30,039:INFO:                pyod: 1.1.3
2024-05-24 23:31:30,039:INFO:            imblearn: 0.12.2
2024-05-24 23:31:30,039:INFO:   category_encoders: 2.6.3
2024-05-24 23:31:30,039:INFO:            lightgbm: 4.3.0
2024-05-24 23:31:30,039:INFO:               numba: 0.59.1
2024-05-24 23:31:30,039:INFO:            requests: 2.32.2
2024-05-24 23:31:30,040:INFO:          matplotlib: 3.7.5
2024-05-24 23:31:30,040:INFO:          scikitplot: 0.3.7
2024-05-24 23:31:30,040:INFO:         yellowbrick: 1.5
2024-05-24 23:31:30,040:INFO:              plotly: 5.22.0
2024-05-24 23:31:30,040:INFO:    plotly-resampler: Not installed
2024-05-24 23:31:30,040:INFO:             kaleido: 0.2.1
2024-05-24 23:31:30,040:INFO:           schemdraw: 0.15
2024-05-24 23:31:30,040:INFO:         statsmodels: 0.14.2
2024-05-24 23:31:30,040:INFO:              sktime: 0.26.0
2024-05-24 23:31:30,040:INFO:               tbats: 1.1.3
2024-05-24 23:31:30,040:INFO:            pmdarima: 2.0.4
2024-05-24 23:31:30,040:INFO:              psutil: 5.9.0
2024-05-24 23:31:30,040:INFO:          markupsafe: 2.1.3
2024-05-24 23:31:30,040:INFO:             pickle5: Not installed
2024-05-24 23:31:30,040:INFO:         cloudpickle: 3.0.0
2024-05-24 23:31:30,040:INFO:         deprecation: 2.1.0
2024-05-24 23:31:30,040:INFO:              xxhash: 3.4.1
2024-05-24 23:31:30,040:INFO:           wurlitzer: Not installed
2024-05-24 23:31:30,040:INFO:PyCaret optional dependencies:
2024-05-24 23:31:30,040:INFO:                shap: 0.44.1
2024-05-24 23:31:30,040:INFO:           interpret: 0.6.1
2024-05-24 23:31:30,040:INFO:                umap: 0.5.6
2024-05-24 23:31:30,040:INFO:     ydata_profiling: 4.8.3
2024-05-24 23:31:30,040:INFO:  explainerdashboard: 0.4.7
2024-05-24 23:31:30,040:INFO:             autoviz: Not installed
2024-05-24 23:31:30,041:INFO:           fairlearn: 0.7.0
2024-05-24 23:31:30,041:INFO:          deepchecks: Not installed
2024-05-24 23:31:30,041:INFO:             xgboost: 2.0.3
2024-05-24 23:31:30,041:INFO:            catboost: 1.2.5
2024-05-24 23:31:30,041:INFO:              kmodes: 0.12.2
2024-05-24 23:31:30,041:INFO:             mlxtend: 0.23.1
2024-05-24 23:31:30,041:INFO:       statsforecast: 1.5.0
2024-05-24 23:31:30,041:INFO:        tune_sklearn: Not installed
2024-05-24 23:31:30,041:INFO:                 ray: Not installed
2024-05-24 23:31:30,041:INFO:            hyperopt: 0.2.7
2024-05-24 23:31:30,041:INFO:              optuna: 3.6.1
2024-05-24 23:31:30,041:INFO:               skopt: 0.10.1
2024-05-24 23:31:30,041:INFO:              mlflow: 2.13.0
2024-05-24 23:31:30,041:INFO:              gradio: 4.31.5
2024-05-24 23:31:30,041:INFO:             fastapi: 0.111.0
2024-05-24 23:31:30,041:INFO:             uvicorn: 0.29.0
2024-05-24 23:31:30,041:INFO:              m2cgen: 0.10.0
2024-05-24 23:31:30,041:INFO:           evidently: 0.4.25
2024-05-24 23:31:30,041:INFO:               fugue: 0.8.7
2024-05-24 23:31:30,041:INFO:           streamlit: Not installed
2024-05-24 23:31:30,041:INFO:             prophet: Not installed
2024-05-24 23:31:30,041:INFO:None
2024-05-24 23:31:30,041:INFO:Set up data.
2024-05-24 23:31:30,047:INFO:Set up folding strategy.
2024-05-24 23:31:30,047:INFO:Set up train/test split.
2024-05-24 23:31:30,051:INFO:Set up index.
2024-05-24 23:31:30,051:INFO:Assigning column types.
2024-05-24 23:31:30,056:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 23:31:30,056:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,060:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,065:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,168:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,170:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:30,171:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,175:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,181:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,303:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,306:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:30,306:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 23:31:30,311:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,381:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,425:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,427:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:30,433:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,437:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,502:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,546:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,549:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:30,550:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 23:31:30,559:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,616:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,660:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,662:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:30,672:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,774:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,777:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:30,777:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 23:31:30,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:30,891:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:30,896:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:31,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:31,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:31:31,079:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:31,081:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:31,082:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 23:31:31,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:31,212:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:31,215:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:31,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:31:31,332:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:31,334:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:31,335:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 23:31:31,472:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:31,475:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:31,592:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:31,595:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:31,597:INFO:Preparing preprocessing pipeline...
2024-05-24 23:31:31,597:INFO:Set up simple imputation.
2024-05-24 23:31:31,598:INFO:Set up removing multicollinearity.
2024-05-24 23:31:31,598:INFO:Set up removing outliers.
2024-05-24 23:31:31,649:INFO:Finished creating preprocessing pipeline.
2024-05-24 23:31:31,657:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['symboling', 'aspiration_std',
                                             'carbody', 'drivewheel_fwd',
                                             'wheelbase', 'carlength',
                                             'carwidth', 'carheight',
                                             'curbweight', 'enginetype',
                                             'cylindernumber', 'enginesize',
                                             'fuelsystem', 'boreratio',
                                             'stroke', 'compressionratio',
                                             'hor...,
                                             'highwaympg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=1349)))])
2024-05-24 23:31:31,657:INFO:Creating final display dataframe.
2024-05-24 23:31:32,644:INFO:Setup _display_container:                     Description             Value
0                    Session id              1349
1                        Target             price
2                   Target type        Regression
3           Original data shape         (202, 21)
4        Transformed data shape         (195, 20)
5   Transformed train set shape         (134, 20)
6    Transformed test set shape          (61, 20)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14              Remove outliers              True
15           Outliers threshold              0.05
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              1f06
2024-05-24 23:31:32,810:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:32,813:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:32,929:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:31:32,934:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:31:32,936:INFO:setup() successfully completed in 2.95s...............
2024-05-24 23:31:36,425:INFO:Initializing compare_models()
2024-05-24 23:31:36,426:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 23:31:36,426:INFO:Checking exceptions
2024-05-24 23:31:36,430:INFO:Preparing display monitor
2024-05-24 23:31:36,461:INFO:Initializing Linear Regression
2024-05-24 23:31:36,461:INFO:Total runtime is 0.0 minutes
2024-05-24 23:31:36,468:INFO:SubProcess create_model() called ==================================
2024-05-24 23:31:36,468:INFO:Initializing create_model()
2024-05-24 23:31:36,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB349C3AF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:31:36,469:INFO:Checking exceptions
2024-05-24 23:31:36,469:INFO:Importing libraries
2024-05-24 23:31:36,469:INFO:Copying training dataset
2024-05-24 23:31:36,481:INFO:Defining folds
2024-05-24 23:31:36,481:INFO:Declaring metric variables
2024-05-24 23:31:36,485:INFO:Importing untrained model
2024-05-24 23:31:36,490:INFO:Linear Regression Imported successfully
2024-05-24 23:31:36,502:INFO:Starting cross validation
2024-05-24 23:31:36,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:31:36,896:INFO:Calculating mean and std
2024-05-24 23:31:36,896:INFO:Creating metrics dataframe
2024-05-24 23:31:36,898:INFO:Uploading results into container
2024-05-24 23:31:36,898:INFO:Uploading model into container now
2024-05-24 23:31:36,899:INFO:_master_model_container: 1
2024-05-24 23:31:36,899:INFO:_display_container: 2
2024-05-24 23:31:36,899:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:31:36,899:INFO:create_model() successfully completed......................................
2024-05-24 23:31:37,214:INFO:SubProcess create_model() end ==================================
2024-05-24 23:31:37,216:INFO:Creating metrics dataframe
2024-05-24 23:31:37,222:INFO:Initializing Lasso Regression
2024-05-24 23:31:37,222:INFO:Total runtime is 0.012678468227386474 minutes
2024-05-24 23:31:37,225:INFO:SubProcess create_model() called ==================================
2024-05-24 23:31:37,226:INFO:Initializing create_model()
2024-05-24 23:31:37,226:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB349C3AF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:31:37,226:INFO:Checking exceptions
2024-05-24 23:31:37,226:INFO:Importing libraries
2024-05-24 23:31:37,227:INFO:Copying training dataset
2024-05-24 23:31:37,233:INFO:Defining folds
2024-05-24 23:31:37,233:INFO:Declaring metric variables
2024-05-24 23:31:37,236:INFO:Importing untrained model
2024-05-24 23:31:37,240:INFO:Lasso Regression Imported successfully
2024-05-24 23:31:37,248:INFO:Starting cross validation
2024-05-24 23:31:37,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:31:37,614:INFO:Calculating mean and std
2024-05-24 23:31:37,615:INFO:Creating metrics dataframe
2024-05-24 23:31:37,617:INFO:Uploading results into container
2024-05-24 23:31:37,618:INFO:Uploading model into container now
2024-05-24 23:31:37,618:INFO:_master_model_container: 2
2024-05-24 23:31:37,618:INFO:_display_container: 2
2024-05-24 23:31:37,619:INFO:Lasso(random_state=1349)
2024-05-24 23:31:37,619:INFO:create_model() successfully completed......................................
2024-05-24 23:31:37,915:INFO:SubProcess create_model() end ==================================
2024-05-24 23:31:37,915:INFO:Creating metrics dataframe
2024-05-24 23:31:37,921:INFO:Initializing Ridge Regression
2024-05-24 23:31:37,921:INFO:Total runtime is 0.024340546131134032 minutes
2024-05-24 23:31:37,926:INFO:SubProcess create_model() called ==================================
2024-05-24 23:31:37,927:INFO:Initializing create_model()
2024-05-24 23:31:37,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB349C3AF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:31:37,927:INFO:Checking exceptions
2024-05-24 23:31:37,927:INFO:Importing libraries
2024-05-24 23:31:37,927:INFO:Copying training dataset
2024-05-24 23:31:37,932:INFO:Defining folds
2024-05-24 23:31:37,932:INFO:Declaring metric variables
2024-05-24 23:31:37,937:INFO:Importing untrained model
2024-05-24 23:31:37,943:INFO:Ridge Regression Imported successfully
2024-05-24 23:31:37,950:INFO:Starting cross validation
2024-05-24 23:31:37,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:31:38,305:INFO:Calculating mean and std
2024-05-24 23:31:38,306:INFO:Creating metrics dataframe
2024-05-24 23:31:38,308:INFO:Uploading results into container
2024-05-24 23:31:38,309:INFO:Uploading model into container now
2024-05-24 23:31:38,310:INFO:_master_model_container: 3
2024-05-24 23:31:38,310:INFO:_display_container: 2
2024-05-24 23:31:38,310:INFO:Ridge(random_state=1349)
2024-05-24 23:31:38,310:INFO:create_model() successfully completed......................................
2024-05-24 23:31:38,613:INFO:SubProcess create_model() end ==================================
2024-05-24 23:31:38,614:INFO:Creating metrics dataframe
2024-05-24 23:31:38,621:INFO:Initializing Huber Regressor
2024-05-24 23:31:38,621:INFO:Total runtime is 0.036000728607177734 minutes
2024-05-24 23:31:38,626:INFO:SubProcess create_model() called ==================================
2024-05-24 23:31:38,626:INFO:Initializing create_model()
2024-05-24 23:31:38,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB349C3AF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:31:38,626:INFO:Checking exceptions
2024-05-24 23:31:38,626:INFO:Importing libraries
2024-05-24 23:31:38,626:INFO:Copying training dataset
2024-05-24 23:31:38,632:INFO:Defining folds
2024-05-24 23:31:38,632:INFO:Declaring metric variables
2024-05-24 23:31:38,637:INFO:Importing untrained model
2024-05-24 23:31:38,645:INFO:Huber Regressor Imported successfully
2024-05-24 23:31:38,657:INFO:Starting cross validation
2024-05-24 23:31:38,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:31:39,016:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,017:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,028:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,030:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,037:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,039:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,053:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,056:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,071:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,072:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-24 23:31:39,088:INFO:Calculating mean and std
2024-05-24 23:31:39,091:INFO:Creating metrics dataframe
2024-05-24 23:31:39,093:INFO:Uploading results into container
2024-05-24 23:31:39,094:INFO:Uploading model into container now
2024-05-24 23:31:39,094:INFO:_master_model_container: 4
2024-05-24 23:31:39,095:INFO:_display_container: 2
2024-05-24 23:31:39,095:INFO:HuberRegressor()
2024-05-24 23:31:39,095:INFO:create_model() successfully completed......................................
2024-05-24 23:31:39,401:INFO:SubProcess create_model() end ==================================
2024-05-24 23:31:39,402:INFO:Creating metrics dataframe
2024-05-24 23:31:39,411:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 23:31:39,423:INFO:Initializing create_model()
2024-05-24 23:31:39,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=Ridge(random_state=1349), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:31:39,425:INFO:Checking exceptions
2024-05-24 23:31:39,426:INFO:Importing libraries
2024-05-24 23:31:39,426:INFO:Copying training dataset
2024-05-24 23:31:39,434:INFO:Defining folds
2024-05-24 23:31:39,434:INFO:Declaring metric variables
2024-05-24 23:31:39,434:INFO:Importing untrained model
2024-05-24 23:31:39,434:INFO:Declaring custom model
2024-05-24 23:31:39,435:INFO:Ridge Regression Imported successfully
2024-05-24 23:31:39,448:INFO:Cross validation set to False
2024-05-24 23:31:39,448:INFO:Fitting Model
2024-05-24 23:31:39,589:INFO:Ridge(random_state=1349)
2024-05-24 23:31:39,589:INFO:create_model() successfully completed......................................
2024-05-24 23:31:39,901:INFO:_master_model_container: 4
2024-05-24 23:31:39,901:INFO:_display_container: 2
2024-05-24 23:31:39,902:INFO:Ridge(random_state=1349)
2024-05-24 23:31:39,902:INFO:compare_models() successfully completed......................................
2024-05-24 23:31:43,169:INFO:Initializing evaluate_model()
2024-05-24 23:31:43,169:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=Ridge(random_state=1349), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 23:31:43,180:INFO:Initializing plot_model()
2024-05-24 23:31:43,180:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Ridge(random_state=1349), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, system=True)
2024-05-24 23:31:43,180:INFO:Checking exceptions
2024-05-24 23:31:43,183:INFO:Preloading libraries
2024-05-24 23:31:43,184:INFO:Copying training dataset
2024-05-24 23:31:43,184:INFO:Plot type: pipeline
2024-05-24 23:31:43,326:INFO:Visual Rendered Successfully
2024-05-24 23:31:43,611:INFO:plot_model() successfully completed......................................
2024-05-24 23:31:46,814:INFO:Initializing tune_model()
2024-05-24 23:31:46,814:INFO:tune_model(estimator=Ridge(random_state=1349), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>)
2024-05-24 23:31:46,814:INFO:Checking exceptions
2024-05-24 23:31:46,836:INFO:Copying training dataset
2024-05-24 23:31:46,841:INFO:Checking base model
2024-05-24 23:31:46,842:INFO:Base model : Ridge Regression
2024-05-24 23:31:46,847:INFO:Declaring metric variables
2024-05-24 23:31:46,851:INFO:Defining Hyperparameters
2024-05-24 23:31:47,201:INFO:Tuning with n_jobs=-1
2024-05-24 23:31:47,201:INFO:Initializing RandomizedSearchCV
2024-05-24 23:31:50,238:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 4.48}
2024-05-24 23:31:50,239:INFO:Hyperparameter search completed
2024-05-24 23:31:50,239:INFO:SubProcess create_model() called ==================================
2024-05-24 23:31:50,240:INFO:Initializing create_model()
2024-05-24 23:31:50,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=Ridge(random_state=1349), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB30642830>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 4.48})
2024-05-24 23:31:50,240:INFO:Checking exceptions
2024-05-24 23:31:50,240:INFO:Importing libraries
2024-05-24 23:31:50,240:INFO:Copying training dataset
2024-05-24 23:31:50,247:INFO:Defining folds
2024-05-24 23:31:50,247:INFO:Declaring metric variables
2024-05-24 23:31:50,252:INFO:Importing untrained model
2024-05-24 23:31:50,252:INFO:Declaring custom model
2024-05-24 23:31:50,258:INFO:Ridge Regression Imported successfully
2024-05-24 23:31:50,266:INFO:Starting cross validation
2024-05-24 23:31:50,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:31:50,647:INFO:Calculating mean and std
2024-05-24 23:31:50,648:INFO:Creating metrics dataframe
2024-05-24 23:31:50,654:INFO:Finalizing model
2024-05-24 23:31:50,803:INFO:Uploading results into container
2024-05-24 23:31:50,803:INFO:Uploading model into container now
2024-05-24 23:31:50,805:INFO:_master_model_container: 5
2024-05-24 23:31:50,805:INFO:_display_container: 3
2024-05-24 23:31:50,806:INFO:Ridge(alpha=4.48, random_state=1349)
2024-05-24 23:31:50,806:INFO:create_model() successfully completed......................................
2024-05-24 23:31:51,102:INFO:SubProcess create_model() end ==================================
2024-05-24 23:31:51,102:INFO:choose_better activated
2024-05-24 23:31:51,106:INFO:SubProcess create_model() called ==================================
2024-05-24 23:31:51,107:INFO:Initializing create_model()
2024-05-24 23:31:51,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB3A969510>, estimator=Ridge(random_state=1349), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:31:51,107:INFO:Checking exceptions
2024-05-24 23:31:51,108:INFO:Importing libraries
2024-05-24 23:31:51,108:INFO:Copying training dataset
2024-05-24 23:31:51,114:INFO:Defining folds
2024-05-24 23:31:51,114:INFO:Declaring metric variables
2024-05-24 23:31:51,114:INFO:Importing untrained model
2024-05-24 23:31:51,114:INFO:Declaring custom model
2024-05-24 23:31:51,115:INFO:Ridge Regression Imported successfully
2024-05-24 23:31:51,115:INFO:Starting cross validation
2024-05-24 23:31:51,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:31:51,462:INFO:Calculating mean and std
2024-05-24 23:31:51,463:INFO:Creating metrics dataframe
2024-05-24 23:31:51,465:INFO:Finalizing model
2024-05-24 23:31:51,663:INFO:Uploading results into container
2024-05-24 23:31:51,664:INFO:Uploading model into container now
2024-05-24 23:31:51,664:INFO:_master_model_container: 6
2024-05-24 23:31:51,664:INFO:_display_container: 4
2024-05-24 23:31:51,664:INFO:Ridge(random_state=1349)
2024-05-24 23:31:51,664:INFO:create_model() successfully completed......................................
2024-05-24 23:31:51,974:INFO:SubProcess create_model() end ==================================
2024-05-24 23:31:51,975:INFO:Ridge(random_state=1349) result for R2 is 0.808
2024-05-24 23:31:51,975:INFO:Ridge(alpha=4.48, random_state=1349) result for R2 is 0.8163
2024-05-24 23:31:51,976:INFO:Ridge(alpha=4.48, random_state=1349) is best model
2024-05-24 23:31:51,976:INFO:choose_better completed
2024-05-24 23:31:51,986:INFO:_master_model_container: 6
2024-05-24 23:31:51,987:INFO:_display_container: 3
2024-05-24 23:31:51,987:INFO:Ridge(alpha=4.48, random_state=1349)
2024-05-24 23:31:51,987:INFO:tune_model() successfully completed......................................
2024-05-24 23:32:19,063:INFO:PyCaret RegressionExperiment
2024-05-24 23:32:19,063:INFO:Logging name: reg-default-name
2024-05-24 23:32:19,063:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-24 23:32:19,063:INFO:version 3.3.2
2024-05-24 23:32:19,063:INFO:Initializing setup()
2024-05-24 23:32:19,063:INFO:self.USI: 37ab
2024-05-24 23:32:19,063:INFO:self._variable_keys: {'gpu_param', 'html_param', 'n_jobs_param', 'y_train', 'pipeline', 'USI', '_ml_usecase', 'exp_id', 'gpu_n_jobs_param', 'logging_param', 'target_param', 'X_train', 'fold_generator', 'y_test', 'log_plots_param', 'data', 'exp_name_log', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'memory', 'seed', 'y', 'X_test', 'X', '_available_plots', 'transform_target_param'}
2024-05-24 23:32:19,064:INFO:Checking environment
2024-05-24 23:32:19,064:INFO:python_version: 3.10.14
2024-05-24 23:32:19,064:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-05-24 23:32:19,064:INFO:machine: AMD64
2024-05-24 23:32:19,064:INFO:platform: Windows-10-10.0.22621-SP0
2024-05-24 23:32:19,064:INFO:Memory: svmem(total=16541802496, available=2466619392, percent=85.1, used=14075183104, free=2466619392)
2024-05-24 23:32:19,064:INFO:Physical Core: 6
2024-05-24 23:32:19,064:INFO:Logical Core: 12
2024-05-24 23:32:19,064:INFO:Checking libraries
2024-05-24 23:32:19,064:INFO:System:
2024-05-24 23:32:19,064:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-05-24 23:32:19,065:INFO:executable: c:\Users\chavv\anaconda\envs\automl\python.exe
2024-05-24 23:32:19,065:INFO:   machine: Windows-10-10.0.22621-SP0
2024-05-24 23:32:19,065:INFO:PyCaret required dependencies:
2024-05-24 23:32:19,065:INFO:                 pip: 24.0
2024-05-24 23:32:19,065:INFO:          setuptools: 69.5.1
2024-05-24 23:32:19,065:INFO:             pycaret: 3.3.2
2024-05-24 23:32:19,065:INFO:             IPython: 8.20.0
2024-05-24 23:32:19,065:INFO:          ipywidgets: 8.1.2
2024-05-24 23:32:19,065:INFO:                tqdm: 4.66.4
2024-05-24 23:32:19,065:INFO:               numpy: 1.26.4
2024-05-24 23:32:19,065:INFO:              pandas: 2.1.4
2024-05-24 23:32:19,065:INFO:              jinja2: 3.1.3
2024-05-24 23:32:19,065:INFO:               scipy: 1.11.4
2024-05-24 23:32:19,065:INFO:              joblib: 1.3.2
2024-05-24 23:32:19,065:INFO:             sklearn: 1.4.2
2024-05-24 23:32:19,066:INFO:                pyod: 1.1.3
2024-05-24 23:32:19,066:INFO:            imblearn: 0.12.2
2024-05-24 23:32:19,066:INFO:   category_encoders: 2.6.3
2024-05-24 23:32:19,066:INFO:            lightgbm: 4.3.0
2024-05-24 23:32:19,066:INFO:               numba: 0.59.1
2024-05-24 23:32:19,066:INFO:            requests: 2.32.2
2024-05-24 23:32:19,066:INFO:          matplotlib: 3.7.5
2024-05-24 23:32:19,066:INFO:          scikitplot: 0.3.7
2024-05-24 23:32:19,066:INFO:         yellowbrick: 1.5
2024-05-24 23:32:19,066:INFO:              plotly: 5.22.0
2024-05-24 23:32:19,066:INFO:    plotly-resampler: Not installed
2024-05-24 23:32:19,066:INFO:             kaleido: 0.2.1
2024-05-24 23:32:19,066:INFO:           schemdraw: 0.15
2024-05-24 23:32:19,066:INFO:         statsmodels: 0.14.2
2024-05-24 23:32:19,066:INFO:              sktime: 0.26.0
2024-05-24 23:32:19,066:INFO:               tbats: 1.1.3
2024-05-24 23:32:19,066:INFO:            pmdarima: 2.0.4
2024-05-24 23:32:19,066:INFO:              psutil: 5.9.0
2024-05-24 23:32:19,066:INFO:          markupsafe: 2.1.3
2024-05-24 23:32:19,066:INFO:             pickle5: Not installed
2024-05-24 23:32:19,066:INFO:         cloudpickle: 3.0.0
2024-05-24 23:32:19,066:INFO:         deprecation: 2.1.0
2024-05-24 23:32:19,066:INFO:              xxhash: 3.4.1
2024-05-24 23:32:19,066:INFO:           wurlitzer: Not installed
2024-05-24 23:32:19,066:INFO:PyCaret optional dependencies:
2024-05-24 23:32:19,067:INFO:                shap: 0.44.1
2024-05-24 23:32:19,067:INFO:           interpret: 0.6.1
2024-05-24 23:32:19,067:INFO:                umap: 0.5.6
2024-05-24 23:32:19,067:INFO:     ydata_profiling: 4.8.3
2024-05-24 23:32:19,067:INFO:  explainerdashboard: 0.4.7
2024-05-24 23:32:19,067:INFO:             autoviz: Not installed
2024-05-24 23:32:19,067:INFO:           fairlearn: 0.7.0
2024-05-24 23:32:19,067:INFO:          deepchecks: Not installed
2024-05-24 23:32:19,067:INFO:             xgboost: 2.0.3
2024-05-24 23:32:19,067:INFO:            catboost: 1.2.5
2024-05-24 23:32:19,067:INFO:              kmodes: 0.12.2
2024-05-24 23:32:19,067:INFO:             mlxtend: 0.23.1
2024-05-24 23:32:19,067:INFO:       statsforecast: 1.5.0
2024-05-24 23:32:19,067:INFO:        tune_sklearn: Not installed
2024-05-24 23:32:19,067:INFO:                 ray: Not installed
2024-05-24 23:32:19,067:INFO:            hyperopt: 0.2.7
2024-05-24 23:32:19,067:INFO:              optuna: 3.6.1
2024-05-24 23:32:19,067:INFO:               skopt: 0.10.1
2024-05-24 23:32:19,067:INFO:              mlflow: 2.13.0
2024-05-24 23:32:19,067:INFO:              gradio: 4.31.5
2024-05-24 23:32:19,067:INFO:             fastapi: 0.111.0
2024-05-24 23:32:19,067:INFO:             uvicorn: 0.29.0
2024-05-24 23:32:19,067:INFO:              m2cgen: 0.10.0
2024-05-24 23:32:19,068:INFO:           evidently: 0.4.25
2024-05-24 23:32:19,068:INFO:               fugue: 0.8.7
2024-05-24 23:32:19,068:INFO:           streamlit: Not installed
2024-05-24 23:32:19,068:INFO:             prophet: Not installed
2024-05-24 23:32:19,068:INFO:None
2024-05-24 23:32:19,068:INFO:Set up data.
2024-05-24 23:32:19,072:INFO:Set up folding strategy.
2024-05-24 23:32:19,072:INFO:Set up train/test split.
2024-05-24 23:32:19,074:INFO:Set up index.
2024-05-24 23:32:19,074:INFO:Assigning column types.
2024-05-24 23:32:19,077:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-24 23:32:19,077:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,144:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,190:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,193:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,193:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,198:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,203:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,309:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,311:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,312:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-24 23:32:19,317:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,321:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,379:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,433:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,434:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,437:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,442:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,550:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,551:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,553:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,555:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-24 23:32:19,563:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,670:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,673:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,683:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,780:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,783:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,784:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-24 23:32:19,849:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:19,906:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:19,909:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:19,974:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:20,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-24 23:32:20,017:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:20,019:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:20,020:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-24 23:32:20,089:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:20,142:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:20,144:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:20,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-24 23:32:20,257:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:20,260:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:20,261:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-24 23:32:20,370:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:20,373:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:20,493:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:20,496:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:20,497:INFO:Preparing preprocessing pipeline...
2024-05-24 23:32:20,497:INFO:Set up simple imputation.
2024-05-24 23:32:20,498:INFO:Set up removing multicollinearity.
2024-05-24 23:32:20,498:INFO:Set up removing outliers.
2024-05-24 23:32:20,529:INFO:Finished creating preprocessing pipeline.
2024-05-24 23:32:20,536:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\chavv\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['curbweight', 'cylindernumber',
                                             'carvolume', 'enginepower',
                                             'averagempg'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.9))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=7626)))])
2024-05-24 23:32:20,536:INFO:Creating final display dataframe.
2024-05-24 23:32:21,361:INFO:Setup _display_container:                     Description             Value
0                    Session id              7626
1                        Target             price
2                   Target type        Regression
3           Original data shape          (183, 6)
4        Transformed data shape          (176, 6)
5   Transformed train set shape          (121, 6)
6    Transformed test set shape           (55, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Remove multicollinearity              True
13  Multicollinearity threshold               0.9
14              Remove outliers              True
15           Outliers threshold              0.05
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              37ab
2024-05-24 23:32:21,476:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:21,479:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:21,604:INFO:Soft dependency imported: xgboost: 2.0.3
2024-05-24 23:32:21,607:INFO:Soft dependency imported: catboost: 1.2.5
2024-05-24 23:32:21,607:INFO:setup() successfully completed in 2.6s...............
2024-05-24 23:32:21,644:INFO:Initializing compare_models()
2024-05-24 23:32:21,644:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, include=['lr', 'lasso', 'ridge', 'huber'], fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, 'include': ['lr', 'lasso', 'ridge', 'huber'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-24 23:32:21,644:INFO:Checking exceptions
2024-05-24 23:32:21,647:INFO:Preparing display monitor
2024-05-24 23:32:21,676:INFO:Initializing Linear Regression
2024-05-24 23:32:21,676:INFO:Total runtime is 0.0 minutes
2024-05-24 23:32:21,680:INFO:SubProcess create_model() called ==================================
2024-05-24 23:32:21,680:INFO:Initializing create_model()
2024-05-24 23:32:21,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB2F14D600>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:32:21,680:INFO:Checking exceptions
2024-05-24 23:32:21,680:INFO:Importing libraries
2024-05-24 23:32:21,680:INFO:Copying training dataset
2024-05-24 23:32:21,685:INFO:Defining folds
2024-05-24 23:32:21,685:INFO:Declaring metric variables
2024-05-24 23:32:21,690:INFO:Importing untrained model
2024-05-24 23:32:21,701:INFO:Linear Regression Imported successfully
2024-05-24 23:32:21,714:INFO:Starting cross validation
2024-05-24 23:32:21,732:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:32:22,080:INFO:Calculating mean and std
2024-05-24 23:32:22,081:INFO:Creating metrics dataframe
2024-05-24 23:32:22,083:INFO:Uploading results into container
2024-05-24 23:32:22,084:INFO:Uploading model into container now
2024-05-24 23:32:22,084:INFO:_master_model_container: 1
2024-05-24 23:32:22,084:INFO:_display_container: 2
2024-05-24 23:32:22,084:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:32:22,084:INFO:create_model() successfully completed......................................
2024-05-24 23:32:22,396:INFO:SubProcess create_model() end ==================================
2024-05-24 23:32:22,396:INFO:Creating metrics dataframe
2024-05-24 23:32:22,404:INFO:Initializing Lasso Regression
2024-05-24 23:32:22,404:INFO:Total runtime is 0.012126727898915609 minutes
2024-05-24 23:32:22,407:INFO:SubProcess create_model() called ==================================
2024-05-24 23:32:22,408:INFO:Initializing create_model()
2024-05-24 23:32:22,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB2F14D600>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:32:22,408:INFO:Checking exceptions
2024-05-24 23:32:22,409:INFO:Importing libraries
2024-05-24 23:32:22,409:INFO:Copying training dataset
2024-05-24 23:32:22,412:INFO:Defining folds
2024-05-24 23:32:22,412:INFO:Declaring metric variables
2024-05-24 23:32:22,415:INFO:Importing untrained model
2024-05-24 23:32:22,420:INFO:Lasso Regression Imported successfully
2024-05-24 23:32:22,428:INFO:Starting cross validation
2024-05-24 23:32:22,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:32:22,769:INFO:Calculating mean and std
2024-05-24 23:32:22,770:INFO:Creating metrics dataframe
2024-05-24 23:32:22,772:INFO:Uploading results into container
2024-05-24 23:32:22,773:INFO:Uploading model into container now
2024-05-24 23:32:22,774:INFO:_master_model_container: 2
2024-05-24 23:32:22,774:INFO:_display_container: 2
2024-05-24 23:32:22,774:INFO:Lasso(random_state=7626)
2024-05-24 23:32:22,775:INFO:create_model() successfully completed......................................
2024-05-24 23:32:23,064:INFO:SubProcess create_model() end ==================================
2024-05-24 23:32:23,064:INFO:Creating metrics dataframe
2024-05-24 23:32:23,071:INFO:Initializing Ridge Regression
2024-05-24 23:32:23,072:INFO:Total runtime is 0.02327175537745158 minutes
2024-05-24 23:32:23,076:INFO:SubProcess create_model() called ==================================
2024-05-24 23:32:23,076:INFO:Initializing create_model()
2024-05-24 23:32:23,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB2F14D600>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:32:23,077:INFO:Checking exceptions
2024-05-24 23:32:23,077:INFO:Importing libraries
2024-05-24 23:32:23,077:INFO:Copying training dataset
2024-05-24 23:32:23,081:INFO:Defining folds
2024-05-24 23:32:23,081:INFO:Declaring metric variables
2024-05-24 23:32:23,085:INFO:Importing untrained model
2024-05-24 23:32:23,089:INFO:Ridge Regression Imported successfully
2024-05-24 23:32:23,097:INFO:Starting cross validation
2024-05-24 23:32:23,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:32:23,446:INFO:Calculating mean and std
2024-05-24 23:32:23,447:INFO:Creating metrics dataframe
2024-05-24 23:32:23,449:INFO:Uploading results into container
2024-05-24 23:32:23,450:INFO:Uploading model into container now
2024-05-24 23:32:23,451:INFO:_master_model_container: 3
2024-05-24 23:32:23,451:INFO:_display_container: 2
2024-05-24 23:32:23,451:INFO:Ridge(random_state=7626)
2024-05-24 23:32:23,451:INFO:create_model() successfully completed......................................
2024-05-24 23:32:23,757:INFO:SubProcess create_model() end ==================================
2024-05-24 23:32:23,757:INFO:Creating metrics dataframe
2024-05-24 23:32:23,765:INFO:Initializing Huber Regressor
2024-05-24 23:32:23,766:INFO:Total runtime is 0.03483006556828817 minutes
2024-05-24 23:32:23,771:INFO:SubProcess create_model() called ==================================
2024-05-24 23:32:23,772:INFO:Initializing create_model()
2024-05-24 23:32:23,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB2F14D600>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:32:23,772:INFO:Checking exceptions
2024-05-24 23:32:23,772:INFO:Importing libraries
2024-05-24 23:32:23,773:INFO:Copying training dataset
2024-05-24 23:32:23,776:INFO:Defining folds
2024-05-24 23:32:23,777:INFO:Declaring metric variables
2024-05-24 23:32:23,782:INFO:Importing untrained model
2024-05-24 23:32:23,787:INFO:Huber Regressor Imported successfully
2024-05-24 23:32:23,795:INFO:Starting cross validation
2024-05-24 23:32:23,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:32:24,203:INFO:Calculating mean and std
2024-05-24 23:32:24,204:INFO:Creating metrics dataframe
2024-05-24 23:32:24,206:INFO:Uploading results into container
2024-05-24 23:32:24,207:INFO:Uploading model into container now
2024-05-24 23:32:24,207:INFO:_master_model_container: 4
2024-05-24 23:32:24,207:INFO:_display_container: 2
2024-05-24 23:32:24,208:INFO:HuberRegressor()
2024-05-24 23:32:24,208:INFO:create_model() successfully completed......................................
2024-05-24 23:32:24,495:INFO:SubProcess create_model() end ==================================
2024-05-24 23:32:24,496:INFO:Creating metrics dataframe
2024-05-24 23:32:24,506:WARNING:c:\Users\chavv\anaconda\envs\automl\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-05-24 23:32:24,515:INFO:Initializing create_model()
2024-05-24 23:32:24,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:32:24,515:INFO:Checking exceptions
2024-05-24 23:32:24,517:INFO:Importing libraries
2024-05-24 23:32:24,517:INFO:Copying training dataset
2024-05-24 23:32:24,521:INFO:Defining folds
2024-05-24 23:32:24,521:INFO:Declaring metric variables
2024-05-24 23:32:24,521:INFO:Importing untrained model
2024-05-24 23:32:24,521:INFO:Declaring custom model
2024-05-24 23:32:24,522:INFO:Linear Regression Imported successfully
2024-05-24 23:32:24,529:INFO:Cross validation set to False
2024-05-24 23:32:24,529:INFO:Fitting Model
2024-05-24 23:32:24,703:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:32:24,703:INFO:create_model() successfully completed......................................
2024-05-24 23:32:25,016:INFO:_master_model_container: 4
2024-05-24 23:32:25,016:INFO:_display_container: 2
2024-05-24 23:32:25,017:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:32:25,017:INFO:compare_models() successfully completed......................................
2024-05-24 23:32:28,569:INFO:Initializing evaluate_model()
2024-05-24 23:32:28,570:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-24 23:32:28,584:INFO:Initializing plot_model()
2024-05-24 23:32:28,585:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, system=True)
2024-05-24 23:32:28,585:INFO:Checking exceptions
2024-05-24 23:32:28,586:INFO:Preloading libraries
2024-05-24 23:32:28,586:INFO:Copying training dataset
2024-05-24 23:32:28,586:INFO:Plot type: pipeline
2024-05-24 23:32:28,710:INFO:Visual Rendered Successfully
2024-05-24 23:32:29,003:INFO:plot_model() successfully completed......................................
2024-05-24 23:32:34,743:INFO:Initializing tune_model()
2024-05-24 23:32:34,743:INFO:tune_model(estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>)
2024-05-24 23:32:34,743:INFO:Checking exceptions
2024-05-24 23:32:34,766:INFO:Copying training dataset
2024-05-24 23:32:34,769:INFO:Checking base model
2024-05-24 23:32:34,769:INFO:Base model : Linear Regression
2024-05-24 23:32:34,775:INFO:Declaring metric variables
2024-05-24 23:32:34,781:INFO:Defining Hyperparameters
2024-05-24 23:32:34,781:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2024-05-24 23:32:35,131:INFO:Tuning with n_jobs=-1
2024-05-24 23:32:35,131:INFO:Initializing GridSearchCV
2024-05-24 23:32:35,831:INFO:best_params: {'actual_estimator__fit_intercept': True}
2024-05-24 23:32:35,832:INFO:Hyperparameter search completed
2024-05-24 23:32:35,832:INFO:SubProcess create_model() called ==================================
2024-05-24 23:32:35,832:INFO:Initializing create_model()
2024-05-24 23:32:35,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB33F2BEB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2024-05-24 23:32:35,833:INFO:Checking exceptions
2024-05-24 23:32:35,833:INFO:Importing libraries
2024-05-24 23:32:35,833:INFO:Copying training dataset
2024-05-24 23:32:35,837:INFO:Defining folds
2024-05-24 23:32:35,838:INFO:Declaring metric variables
2024-05-24 23:32:35,843:INFO:Importing untrained model
2024-05-24 23:32:35,843:INFO:Declaring custom model
2024-05-24 23:32:35,848:INFO:Linear Regression Imported successfully
2024-05-24 23:32:35,860:INFO:Starting cross validation
2024-05-24 23:32:35,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:32:36,301:INFO:Calculating mean and std
2024-05-24 23:32:36,303:INFO:Creating metrics dataframe
2024-05-24 23:32:36,312:INFO:Finalizing model
2024-05-24 23:32:36,499:INFO:Uploading results into container
2024-05-24 23:32:36,500:INFO:Uploading model into container now
2024-05-24 23:32:36,501:INFO:_master_model_container: 5
2024-05-24 23:32:36,501:INFO:_display_container: 3
2024-05-24 23:32:36,502:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:32:36,502:INFO:create_model() successfully completed......................................
2024-05-24 23:32:36,819:INFO:SubProcess create_model() end ==================================
2024-05-24 23:32:36,819:INFO:choose_better activated
2024-05-24 23:32:36,824:INFO:SubProcess create_model() called ==================================
2024-05-24 23:32:36,825:INFO:Initializing create_model()
2024-05-24 23:32:36,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001BB331BEF20>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-24 23:32:36,825:INFO:Checking exceptions
2024-05-24 23:32:36,827:INFO:Importing libraries
2024-05-24 23:32:36,827:INFO:Copying training dataset
2024-05-24 23:32:36,831:INFO:Defining folds
2024-05-24 23:32:36,831:INFO:Declaring metric variables
2024-05-24 23:32:36,831:INFO:Importing untrained model
2024-05-24 23:32:36,831:INFO:Declaring custom model
2024-05-24 23:32:36,833:INFO:Linear Regression Imported successfully
2024-05-24 23:32:36,833:INFO:Starting cross validation
2024-05-24 23:32:36,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-24 23:32:37,196:INFO:Calculating mean and std
2024-05-24 23:32:37,197:INFO:Creating metrics dataframe
2024-05-24 23:32:37,200:INFO:Finalizing model
2024-05-24 23:32:37,372:INFO:Uploading results into container
2024-05-24 23:32:37,373:INFO:Uploading model into container now
2024-05-24 23:32:37,373:INFO:_master_model_container: 6
2024-05-24 23:32:37,373:INFO:_display_container: 4
2024-05-24 23:32:37,373:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:32:37,373:INFO:create_model() successfully completed......................................
2024-05-24 23:32:37,664:INFO:SubProcess create_model() end ==================================
2024-05-24 23:32:37,665:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.7625
2024-05-24 23:32:37,665:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.7625
2024-05-24 23:32:37,665:INFO:LinearRegression(n_jobs=-1) is best model
2024-05-24 23:32:37,665:INFO:choose_better completed
2024-05-24 23:32:37,665:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-24 23:32:37,677:INFO:_master_model_container: 6
2024-05-24 23:32:37,678:INFO:_display_container: 3
2024-05-24 23:32:37,678:INFO:LinearRegression(n_jobs=-1)
2024-05-24 23:32:37,678:INFO:tune_model() successfully completed......................................
